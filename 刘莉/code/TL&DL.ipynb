{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习与深度学习结合-在图片识别中的应用\n",
    "## 2021-6\n",
    "学号:2201201Z5012 刘莉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤一：导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2：准备实验数据\n",
    "实验所用数据是kaggle里面的一个图片数据集，链接如下\n",
    "https://www.kaggle.com/binhminhs10/food5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理数据集\n",
    "def dframe(dtype,datapath):\n",
    "    X = []\n",
    "    y = []\n",
    "    path = datapath + dtype + '/'\n",
    "    for i in os.listdir(path):\n",
    "        # 图像\n",
    "        X.append(i)\n",
    "        # 标签\n",
    "        y.append(i.split('_')[0])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    df = pd.DataFrame()\n",
    "    df['dataname'] = X\n",
    "    df['label'] = y\n",
    "    return df\n",
    "# 设置数据路径\n",
    "datapath = './Food-5K/'\n",
    "df_train = dframe('training',datapath)\n",
    "df_val = dframe('validation',datapath)\n",
    "df_test = dframe('evaluation',datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1_995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1_996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>1_997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>1_998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1_999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataname label\n",
       "2995  1_995.jpg     1\n",
       "2996  1_996.jpg     1\n",
       "2997  1_997.jpg     1\n",
       "2998  1_998.jpg     1\n",
       "2999  1_999.jpg     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看最后5个训练数据\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入处理图片的包\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 validated image filenames belonging to 2 classes.\n",
      "Found 1000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 处理图片为合适的数据格式\n",
    "# 创建一个ImageDataGenerator对象\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "# 生成图像批次，扩充数据集，并设置图像增强的参数（利用flow_from_dataframe方法）\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    directory='Food-5K/training/',\n",
    "    x_col='dataname',\n",
    "    y_col='label',\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    ")\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    directory='Food-5K/validation/',\n",
    "    x_col='dataname',\n",
    "    y_col='label',\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3：训练模型\n",
    "通过迁移学习技术来训练模型，不需要从头开始跑 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 27s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 导入预训练模型\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "feature_extractor = ResNet50(weights='imagenet', \n",
    "                             input_shape=(224, 224, 3),\n",
    "                             include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 将ResNet50作为基础，并根据实验数据对其中最后一部分进行调整\n",
    "# Set this parameter to make sure it's not being trained\n",
    "feature_extractor.trainable = False\n",
    "\n",
    "# 设置输入层\n",
    "input_ = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "# 设置特征提取器\n",
    "x = feature_extractor(input_, training=False)\n",
    "\n",
    "# 设置池化层\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 将最后一层的激活函数设置为Sigmoid函数\n",
    "output_ = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# 创建新的model\n",
    "model = tf.keras.Model(input_, output_)\n",
    "\n",
    "# 定义损失函数及优化器\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 输出模型运行结果\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "D:\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 505s 5s/step - loss: 0.3921 - accuracy: 0.8175 - val_loss: 0.1159 - val_accuracy: 0.9630\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 498s 5s/step - loss: 0.1059 - accuracy: 0.9662 - val_loss: 0.0963 - val_accuracy: 0.9670\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 486s 5s/step - loss: 0.0716 - accuracy: 0.9769 - val_loss: 0.0988 - val_accuracy: 0.9650\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 483s 5s/step - loss: 0.0742 - accuracy: 0.9741 - val_loss: 0.0793 - val_accuracy: 0.9700\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 483s 5s/step - loss: 0.0588 - accuracy: 0.9779 - val_loss: 0.0927 - val_accuracy: 0.9700\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 482s 5s/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 0.0759 - val_accuracy: 0.9710\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 498s 5s/step - loss: 0.0550 - accuracy: 0.9795 - val_loss: 0.0696 - val_accuracy: 0.9750\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 512s 5s/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 0.0640 - val_accuracy: 0.9790\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 514s 5s/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.0634 - val_accuracy: 0.9780\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 492s 5s/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.0775 - val_accuracy: 0.9700\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 499s 5s/step - loss: 0.0534 - accuracy: 0.9814 - val_loss: 0.0649 - val_accuracy: 0.9730\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 514s 5s/step - loss: 0.0296 - accuracy: 0.9929 - val_loss: 0.0717 - val_accuracy: 0.9760\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 499s 5s/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.0574 - val_accuracy: 0.9750\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 496s 5s/step - loss: 0.0353 - accuracy: 0.9877 - val_loss: 0.0622 - val_accuracy: 0.9750\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 507s 5s/step - loss: 0.0352 - accuracy: 0.9865 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 535s 6s/step - loss: 0.0332 - accuracy: 0.9906 - val_loss: 0.0595 - val_accuracy: 0.9760\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 550s 6s/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0588 - val_accuracy: 0.9770\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 543s 6s/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.0514 - val_accuracy: 0.9790\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 522s 6s/step - loss: 0.0251 - accuracy: 0.9946 - val_loss: 0.0683 - val_accuracy: 0.9760\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 536s 6s/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 0.0553 - val_accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b057dcef08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据实验数据来拟合模型\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4：测试模型\n",
    "在测试数据集上验证模型，并结合一个pillow库来加载和调整图片大小，以及 scikit-learn 来确定模型性能。\n",
    "利用scikit-learn 库的分类报告，以生成关于模型执行的报告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in d:\\anaconda3\\lib\\site-packages (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关库（函数）\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================模型分类测试结果报告====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       500\n",
      "           1       0.98      0.97      0.98       500\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "--------------------------------------------------\n",
      "[[490  10]\n",
      " [ 13 487]]\n"
     ]
    }
   ],
   "source": [
    "# 测试数据\n",
    "# 实际标签\n",
    "y_true = []\n",
    "# 预测标签\n",
    "y_pred = []\n",
    "\n",
    "for i in os.listdir('Food-5K/evaluation'):\n",
    "    # 读取测试图片数据\n",
    "    img = Image.open('Food-5K/evaluation/' + i)\n",
    "    img = img.resize((224, 224)) #调整图片尺寸\n",
    "    img = np.array(img)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    y_true.append(int(i.split('_')[0]))\n",
    "    y_pred.append(1 if model.predict(img) > 0.5 else 0)\n",
    "    \n",
    "# 打印分类结果报告\n",
    "print('='*20+'模型分类测试结果报告'+'='*20)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('-'*50)\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存二次训练好模型的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./myTrainModel/resnet50_food_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# 设置模型保存路径\n",
    "savepath = './myTrainModel/'\n",
    "modelname = 'resnet50_food_model'\n",
    "model.save(savepath+modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载自己训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "loadpath = './myTrainModel/'\n",
    "modelname = 'resnet50_food_model'\n",
    "# 加载自己训练好的模型\n",
    "model = tf.keras.models.load_model(loadpath + modelname')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
