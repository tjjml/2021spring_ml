{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0ba6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T02:47:13.120734Z",
     "start_time": "2021-07-10T02:47:10.354338Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce76b05f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T02:47:14.045462Z",
     "start_time": "2021-07-10T02:47:13.963718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u3000\\u3000燕子去了，有再来的时候；杨柳枯了，有再青的时候；桃花谢了，有再开的时候。但是，聪明的，你告诉我，我们的日子为什么一去不复返呢？——是有人偷了他们罢：那是谁？又藏在何处呢？是他们自己逃走了罢：现在又'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('朱自清.txt',encoding='utf-8') as f:\n",
    "    corpus_chars = f.read()\n",
    "corpus_chars[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de93040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T02:47:15.173034Z",
     "start_time": "2021-07-10T02:47:15.151547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_chars = corpus_chars.replace('\\n',' ').replace('\\u3000',' ').replace('\\r',' ').replace('  ',' ').replace('  ',' ')\n",
    "corpus_chars=corpus_chars[:50000] \n",
    "len(corpus_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c074bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:04.220103Z",
     "start_time": "2021-07-09T12:46:04.213108Z"
    }
   },
   "outputs": [],
   "source": [
    "# 建立字符索引，把每个字符映射成一个从0开始的连续整数\n",
    "idx_to_char = list(set(corpus_chars)) # 所有不同的字符的列表\n",
    "char_to_idx = dict([(char,i) for i,char in enumerate(idx_to_char)]) # ｛char:idx}\n",
    "vocab_size = len(char_to_idx)\n",
    "vocab_size # 词典中不同字符的个数\n",
    "char_to_idx.get('汇')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08475166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:04.161139Z",
     "start_time": "2021-07-09T13:43:04.140135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars:   燕子 去 了 ， 有 再 来 的 时\n",
      "indices: [1312, 1312, 1296, 1192, 1312, 1083, 1312, 173, 1312, 98, 1312, 597, 1312, 453, 1312, 311, 1312, 614, 1312, 291]\n"
     ]
    }
   ],
   "source": [
    "corpus_indices = [char_to_idx[char] for char in corpus_chars] # 将每个字符转换成索引\n",
    "sample = corpus_indices[:20]\n",
    "print('chars:',''.join([idx_to_char[idx] for idx in sample]))\n",
    "print('indices:',sample) # 空格为1467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c292f9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:41.106348Z",
     "start_time": "2021-07-09T13:43:41.094008Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取特征词向量，用word2vec训练\n",
    "import gensim\n",
    "def train_word2vec_model(text,save_path):\n",
    "    model = gensim.models.Word2Vec(text,vector_size=100,min_count=1,window=5)\n",
    "    model.save(save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "808e37f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:42.674546Z",
     "start_time": "2021-07-09T13:43:42.116267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.8666472e-03, -5.8289622e-03,  6.4622974e-03,  1.1263156e-03,\n",
       "       -2.8119159e-03,  6.1453986e-03, -9.2387199e-06,  1.0511898e-03,\n",
       "        9.0559367e-03, -9.3491720e-03, -5.9714173e-03, -9.5812250e-03,\n",
       "        6.6310167e-03, -8.9056566e-03, -4.4304682e-03, -1.3209343e-03,\n",
       "        1.2212896e-03,  1.8017649e-03, -1.5733480e-04, -1.7512107e-03,\n",
       "       -2.1083809e-03,  6.9443081e-03, -1.7246294e-03,  6.5303803e-03,\n",
       "        2.9004954e-03, -4.7146892e-03, -7.1290992e-03,  3.3541871e-03,\n",
       "        4.1413306e-05, -2.6964045e-03,  8.8155838e-03, -2.3798679e-03,\n",
       "        4.9240352e-04,  5.4495572e-03,  3.4132313e-03, -9.1690710e-03,\n",
       "       -9.5094442e-03, -5.3740237e-03, -9.3492772e-03, -5.7461503e-04,\n",
       "        2.3370313e-03,  7.2864629e-03, -1.6360736e-03,  3.7358522e-03,\n",
       "        1.3703585e-04,  5.6899977e-03, -7.5556971e-03,  8.1030102e-03,\n",
       "        4.2802882e-03,  5.4254029e-03,  8.3587049e-03, -4.6507598e-04,\n",
       "        9.0548424e-03, -5.0911712e-03,  3.4983135e-03, -7.7332091e-03,\n",
       "       -5.8767246e-03, -2.6590324e-03, -2.4841595e-03, -4.8102522e-03,\n",
       "        7.5139999e-03,  7.8329798e-03,  2.4641443e-03,  6.2969443e-04,\n",
       "       -8.3056306e-03,  9.0310499e-03, -2.1281124e-03, -5.7680132e-03,\n",
       "        6.3405847e-03, -2.8672456e-04, -3.7140870e-03,  6.6825435e-03,\n",
       "        9.0157269e-03,  3.4722089e-04, -4.1505075e-03,  9.0454193e-03,\n",
       "       -4.2258739e-04, -6.2810206e-03, -1.7689348e-03,  2.1476173e-03,\n",
       "        2.8885175e-03,  9.5950700e-03, -9.4353175e-03, -7.9112463e-03,\n",
       "        3.0224442e-03,  2.0237470e-03,  2.7037025e-03, -4.9676299e-03,\n",
       "       -1.0689640e-03,  9.9732038e-03, -1.6119599e-03, -9.6031139e-03,\n",
       "        9.7753163e-03, -9.9077867e-03,  8.1359437e-03,  1.7855049e-03,\n",
       "       -6.1044265e-03, -6.9953082e-03,  1.5893006e-03, -7.7857735e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = train_word2vec_model(corpus_chars,'word2vec.model').wv\n",
    "char_to_vec= dict() # 字与向量的映射\n",
    "# char_to_idx\n",
    "for i in idx_to_char:\n",
    "    char_to_vec[i] = word2vec_model[i]\n",
    "char_to_vec['风']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a4472d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:46.162766Z",
     "start_time": "2021-07-09T13:43:46.156221Z"
    }
   },
   "outputs": [],
   "source": [
    "num_steps = 35\n",
    "batch_size = 2\n",
    "state = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14a0ae57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:46.820999Z",
     "start_time": "2021-07-09T13:43:46.812299Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对时序数据进行采样\n",
    "# 每次随机读取小批量的样本\n",
    "# 相邻采样\n",
    "# 其中batch_size指每个小批量的样本数，num_steps为每个样本所包含的时间步数\n",
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps):\n",
    "    corpus_indices = torch.tensor(corpus_indices,dtype=torch.float32)\n",
    "    data_len = len(corpus_indices)\n",
    "    batch_len = data_len//batch_size\n",
    "    indices = corpus_indices[0:batch_size*batch_len].view(batch_size,batch_len)\n",
    "    epoch_size = (batch_len-1)//num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i = i * num_steps\n",
    "        x = indices[:,i:i+num_steps]\n",
    "        y = indices[:,i+1:i+num_steps+1]\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28b89542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:47.566570Z",
     "start_time": "2021-07-09T13:43:47.554673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [15., 16., 17., 18., 19., 20.]]) \n",
      "y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [16., 17., 18., 19., 20., 21.]]) \n",
      "\n",
      "x: tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [21., 22., 23., 24., 25., 26.]]) \n",
      "y: tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [22., 23., 24., 25., 26., 27.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = list(range(30))\n",
    "for x,y in data_iter_consecutive(example,batch_size=2,num_steps=6):\n",
    "    print('x:',x,'\\ny:',y,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01bcb1e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:48.597243Z",
     "start_time": "2021-07-09T13:43:48.592233Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9af4174c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:43:49.329240Z",
     "start_time": "2021-07-09T13:43:49.315675Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义模型，一个含单隐藏层，隐藏单元个数为256的循环神经网络层\n",
    "num_hiddens = 256\n",
    "rnn_layer = nn.RNN(input_size=100,hidden_size=num_hiddens)\n",
    "# rnn输入为（时间步数，批量大小，词向量长度）\n",
    "# 在前向计算后返回输出和隐藏状态h，输出是隐藏层在各个时间步上计算并输出的隐藏状态，形状为（时间步数，批量大小，隐藏单元的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c382475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:06.647037Z",
     "start_time": "2021-07-09T13:44:06.640029Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载预训练的词向量\n",
    "def pretrained_embedding_layer(char_to_vec,char_to_idx):\n",
    "    vocab_len = vocab_size+1 # +1是因为有个0向量占一个位置\n",
    "    emb_dim = 100\n",
    "    # 初始化嵌入矩阵\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    # 用词向量填充嵌入矩阵，每行为一个词向量\n",
    "    for char,idx in char_to_idx.items():\n",
    "        emb_matrix[idx+1,:] = char_to_vec[char] # +1是因为0向量索引为0，词向量是从索引1开始\n",
    "    # 将嵌入矩阵传入embedding层，作为权重矩阵\n",
    "    weight = torch.from_numpy(emb_matrix)\n",
    "    embedding = nn.Embedding.from_pretrained(weight)\n",
    "    embedding.weight.requires_grad = True\n",
    "    \n",
    "    return embedding\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bbb4ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:15.468116Z",
     "start_time": "2021-07-09T13:44:15.453036Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 7.8924e-03, -1.3058e-02, -7.0441e-02, -9.7521e-02, -6.6472e-02,\n",
       "            1.1272e-02,  2.2787e-02,  6.7410e-02, -7.4864e-02, -1.7933e-02,\n",
       "           -5.3138e-02,  3.7329e-02,  9.5321e-02,  2.5724e-02, -3.7598e-02,\n",
       "           -3.5511e-02,  5.1815e-02, -3.0662e-02, -3.3188e-02, -1.4269e-03,\n",
       "           -9.8482e-02,  1.5738e-02, -3.1819e-02, -1.8706e-02, -1.4760e-02,\n",
       "            4.0744e-02, -7.6507e-02,  4.4752e-02, -5.4792e-02,  9.2973e-02,\n",
       "           -6.5255e-02,  5.5479e-02, -2.6164e-02,  9.5290e-03,  5.9470e-03,\n",
       "            4.4912e-02,  3.8407e-02, -6.9121e-02, -1.8717e-03,  5.4405e-03,\n",
       "            7.9869e-02,  1.8706e-02,  5.1258e-02,  1.2849e-03,  2.8547e-02,\n",
       "            8.1578e-03, -1.0277e-01, -5.1942e-02,  1.4911e-02,  2.5798e-02,\n",
       "           -6.1167e-02, -1.1691e-02, -5.5279e-02, -2.9778e-02,  9.3656e-02,\n",
       "            9.8206e-02, -9.0899e-02,  3.5481e-03,  6.6941e-02, -5.3665e-02,\n",
       "           -1.6145e-02, -5.9621e-02, -8.1803e-02, -3.7865e-02, -2.7307e-03,\n",
       "           -1.5666e-02, -2.8116e-02,  4.8921e-02, -3.0069e-02,  3.1303e-02,\n",
       "            2.4888e-02, -5.3694e-03,  3.4835e-02, -9.0283e-02, -5.7231e-02,\n",
       "            7.0443e-02, -5.8853e-02,  3.5310e-02, -2.0232e-02,  1.1763e-02,\n",
       "            5.8539e-02,  1.8210e-02,  4.8749e-02,  3.5548e-02,  1.1073e-01,\n",
       "            7.5270e-02, -1.6428e-02, -4.5882e-02, -4.5539e-02, -5.1937e-02,\n",
       "            1.7278e-02,  2.0272e-02, -4.4563e-02,  5.6149e-02,  1.1663e-02,\n",
       "            1.3277e-02,  6.0892e-02,  3.1474e-02,  3.6013e-03,  2.4774e-03,\n",
       "           -3.3154e-03,  1.4958e-02,  4.0293e-05, -9.8397e-03,  4.2319e-02,\n",
       "           -8.3301e-02,  7.5860e-02, -2.6363e-02,  2.3192e-02,  2.0559e-02,\n",
       "            6.5630e-02,  1.4292e-02,  3.1185e-03, -4.5719e-02,  3.1989e-02,\n",
       "            4.3393e-02,  3.3955e-02,  6.5635e-03,  2.6976e-02, -2.5217e-02,\n",
       "           -2.9711e-02,  3.0321e-02, -1.1546e-01, -8.0459e-02, -5.1714e-02,\n",
       "           -1.0534e-04, -3.7787e-02,  6.6001e-03, -7.7310e-02,  4.1418e-02,\n",
       "            4.4890e-02,  2.2460e-02,  3.3971e-02, -1.5422e-02, -5.8027e-02,\n",
       "            7.6572e-02,  7.1863e-02, -1.4428e-02, -3.4654e-02,  1.9463e-02,\n",
       "            4.1262e-02,  3.3376e-03, -4.1931e-02,  3.2135e-02, -2.0671e-02,\n",
       "            8.7272e-02, -2.3757e-02, -8.7127e-03,  3.5929e-02, -1.2094e-02,\n",
       "           -5.1759e-02, -3.4640e-02,  4.5631e-02,  5.9641e-02,  1.4980e-02,\n",
       "            4.5150e-02, -7.2822e-03, -1.1096e-01,  8.1557e-02, -5.7700e-02,\n",
       "           -7.9931e-02,  4.4025e-02,  2.2163e-02, -4.0877e-02, -9.7650e-02,\n",
       "           -3.2839e-02,  5.0170e-02, -3.9254e-02, -4.0260e-02, -4.1244e-02,\n",
       "            4.6728e-02, -5.3567e-02,  4.7744e-02,  3.1778e-02,  1.3953e-02,\n",
       "           -1.9384e-02,  3.3217e-02, -5.3512e-02, -2.8149e-02, -9.6355e-03,\n",
       "           -6.7332e-02,  9.6103e-02,  1.1842e-02,  8.9449e-02,  6.3440e-02,\n",
       "            7.4916e-02, -1.1427e-02,  6.7556e-02, -1.5565e-02, -2.3005e-02,\n",
       "           -9.0922e-02,  2.5804e-02, -2.9209e-02, -3.3676e-02, -1.0720e-01,\n",
       "            3.6956e-02,  2.7628e-02,  7.8418e-02,  3.3944e-02,  4.7833e-02,\n",
       "           -3.3844e-02,  4.6938e-02,  2.8452e-02,  2.8620e-02,  4.2548e-02,\n",
       "            1.0873e-02, -2.7580e-02, -3.5360e-02,  7.4458e-03, -7.9566e-02,\n",
       "            7.5090e-02,  4.2027e-02, -1.9778e-02, -5.5405e-02, -8.3890e-02,\n",
       "           -8.1115e-03, -5.4407e-02,  5.5203e-02, -8.6583e-03, -2.4522e-02,\n",
       "           -2.8113e-02,  2.4407e-02, -4.1071e-04, -6.9563e-02, -6.1577e-02,\n",
       "            9.1605e-03, -7.9941e-02, -5.3594e-02,  8.4310e-02, -2.1605e-02,\n",
       "           -1.1000e-01,  7.9183e-02,  4.4496e-02,  9.4571e-02,  1.6848e-02,\n",
       "           -2.8022e-02,  3.6122e-02,  4.2409e-03, -1.1149e-02, -2.8197e-02,\n",
       "            2.3994e-02, -5.7827e-02,  3.4352e-04,  3.5027e-02, -9.0622e-02,\n",
       "           -8.7519e-02, -3.6121e-02, -3.9539e-03,  8.8696e-02,  7.1507e-02,\n",
       "            5.6270e-02, -4.6268e-02,  7.3466e-02,  7.8303e-02,  5.6817e-02,\n",
       "           -9.6682e-04]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 7.8924e-03, -1.3058e-02, -7.0441e-02, -9.7521e-02, -6.6472e-02,\n",
       "            1.1272e-02,  2.2787e-02,  6.7410e-02, -7.4864e-02, -1.7933e-02,\n",
       "           -5.3138e-02,  3.7329e-02,  9.5321e-02,  2.5724e-02, -3.7598e-02,\n",
       "           -3.5511e-02,  5.1815e-02, -3.0662e-02, -3.3188e-02, -1.4269e-03,\n",
       "           -9.8482e-02,  1.5738e-02, -3.1819e-02, -1.8706e-02, -1.4760e-02,\n",
       "            4.0744e-02, -7.6507e-02,  4.4752e-02, -5.4792e-02,  9.2973e-02,\n",
       "           -6.5255e-02,  5.5479e-02, -2.6164e-02,  9.5290e-03,  5.9470e-03,\n",
       "            4.4912e-02,  3.8407e-02, -6.9121e-02, -1.8717e-03,  5.4405e-03,\n",
       "            7.9869e-02,  1.8706e-02,  5.1258e-02,  1.2849e-03,  2.8547e-02,\n",
       "            8.1578e-03, -1.0277e-01, -5.1942e-02,  1.4911e-02,  2.5798e-02,\n",
       "           -6.1167e-02, -1.1691e-02, -5.5279e-02, -2.9778e-02,  9.3656e-02,\n",
       "            9.8206e-02, -9.0899e-02,  3.5481e-03,  6.6941e-02, -5.3665e-02,\n",
       "           -1.6145e-02, -5.9621e-02, -8.1803e-02, -3.7865e-02, -2.7307e-03,\n",
       "           -1.5666e-02, -2.8116e-02,  4.8921e-02, -3.0069e-02,  3.1303e-02,\n",
       "            2.4888e-02, -5.3694e-03,  3.4835e-02, -9.0283e-02, -5.7231e-02,\n",
       "            7.0443e-02, -5.8853e-02,  3.5310e-02, -2.0232e-02,  1.1763e-02,\n",
       "            5.8539e-02,  1.8210e-02,  4.8749e-02,  3.5548e-02,  1.1073e-01,\n",
       "            7.5270e-02, -1.6428e-02, -4.5882e-02, -4.5539e-02, -5.1937e-02,\n",
       "            1.7278e-02,  2.0272e-02, -4.4563e-02,  5.6149e-02,  1.1663e-02,\n",
       "            1.3277e-02,  6.0892e-02,  3.1474e-02,  3.6013e-03,  2.4774e-03,\n",
       "           -3.3154e-03,  1.4958e-02,  4.0293e-05, -9.8397e-03,  4.2319e-02,\n",
       "           -8.3301e-02,  7.5860e-02, -2.6363e-02,  2.3192e-02,  2.0559e-02,\n",
       "            6.5630e-02,  1.4292e-02,  3.1185e-03, -4.5719e-02,  3.1989e-02,\n",
       "            4.3393e-02,  3.3955e-02,  6.5635e-03,  2.6976e-02, -2.5217e-02,\n",
       "           -2.9711e-02,  3.0321e-02, -1.1546e-01, -8.0459e-02, -5.1714e-02,\n",
       "           -1.0534e-04, -3.7787e-02,  6.6001e-03, -7.7310e-02,  4.1418e-02,\n",
       "            4.4890e-02,  2.2460e-02,  3.3971e-02, -1.5422e-02, -5.8027e-02,\n",
       "            7.6572e-02,  7.1863e-02, -1.4428e-02, -3.4654e-02,  1.9463e-02,\n",
       "            4.1262e-02,  3.3376e-03, -4.1931e-02,  3.2135e-02, -2.0671e-02,\n",
       "            8.7272e-02, -2.3757e-02, -8.7127e-03,  3.5929e-02, -1.2094e-02,\n",
       "           -5.1759e-02, -3.4640e-02,  4.5631e-02,  5.9641e-02,  1.4980e-02,\n",
       "            4.5150e-02, -7.2822e-03, -1.1096e-01,  8.1557e-02, -5.7700e-02,\n",
       "           -7.9931e-02,  4.4025e-02,  2.2163e-02, -4.0877e-02, -9.7650e-02,\n",
       "           -3.2839e-02,  5.0170e-02, -3.9254e-02, -4.0260e-02, -4.1244e-02,\n",
       "            4.6728e-02, -5.3567e-02,  4.7744e-02,  3.1778e-02,  1.3953e-02,\n",
       "           -1.9384e-02,  3.3217e-02, -5.3512e-02, -2.8149e-02, -9.6355e-03,\n",
       "           -6.7332e-02,  9.6103e-02,  1.1842e-02,  8.9449e-02,  6.3440e-02,\n",
       "            7.4916e-02, -1.1427e-02,  6.7556e-02, -1.5565e-02, -2.3005e-02,\n",
       "           -9.0922e-02,  2.5804e-02, -2.9209e-02, -3.3676e-02, -1.0720e-01,\n",
       "            3.6956e-02,  2.7628e-02,  7.8418e-02,  3.3944e-02,  4.7833e-02,\n",
       "           -3.3844e-02,  4.6938e-02,  2.8452e-02,  2.8620e-02,  4.2548e-02,\n",
       "            1.0873e-02, -2.7580e-02, -3.5360e-02,  7.4458e-03, -7.9566e-02,\n",
       "            7.5090e-02,  4.2027e-02, -1.9778e-02, -5.5405e-02, -8.3890e-02,\n",
       "           -8.1115e-03, -5.4407e-02,  5.5203e-02, -8.6583e-03, -2.4522e-02,\n",
       "           -2.8113e-02,  2.4407e-02, -4.1071e-04, -6.9563e-02, -6.1577e-02,\n",
       "            9.1605e-03, -7.9941e-02, -5.3594e-02,  8.4310e-02, -2.1605e-02,\n",
       "           -1.1000e-01,  7.9183e-02,  4.4496e-02,  9.4571e-02,  1.6848e-02,\n",
       "           -2.8022e-02,  3.6122e-02,  4.2409e-03, -1.1149e-02, -2.8197e-02,\n",
       "            2.3994e-02, -5.7827e-02,  3.4352e-04,  3.5027e-02, -9.0622e-02,\n",
       "           -8.7519e-02, -3.6121e-02, -3.9539e-03,  8.8696e-02,  7.1507e-02,\n",
       "            5.6270e-02, -4.6268e-02,  7.3466e-02,  7.8303e-02,  5.6817e-02,\n",
       "           -9.6682e-04]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pretrained_embedding_layer(char_to_vec,char_to_idx)(torch.LongTensor([112]))\n",
    "x=x.view(-1,1,100).float()\n",
    "rnn_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42e222aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:16.062642Z",
     "start_time": "2021-07-09T13:44:16.048631Z"
    }
   },
   "outputs": [],
   "source": [
    "# 搭建rnn模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,rnn_layer,vocab_size,char_to_vec,char_to_idx):\n",
    "        super(RNNModel,self).__init__()\n",
    "        self.embedding = pretrained_embedding_layer(char_to_vec,char_to_idx)\n",
    "        self.rnn = rnn_layer\n",
    "        self.hidden_size = rnn_layer.hidden_size*(2 if rnn_layer.bidirectional else 1)\n",
    "        self.vocab_size = vocab_size+1\n",
    "        self.dense = nn.Linear(self.hidden_size,vocab_size+1)\n",
    "        self.state = None\n",
    "    \n",
    "    def forward(self,inputs,state): # input:(batch,seq_len)\n",
    "        X = self.embedding(torch.LongTensor(inputs.numpy())) # 1*100维的LongTensor\n",
    "                           \n",
    "        Y, self.state = self.rnn(X.view(-1,1,100).float(),state)\n",
    "        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\n",
    "        # 形状为(num_steps * batch_size, vocab_size)\n",
    "        output = self.dense(Y.view(-1, Y.shape[-1]))\n",
    "        return output, self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3af44c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:16.689406Z",
     "start_time": "2021-07-09T13:44:16.679826Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size,idx_to_char,\n",
    "                      char_to_idx):\n",
    "    state = None\n",
    "    output = [char_to_idx[prefix[0]]] # output会记录prefix加上输出\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = torch.tensor([output[-1]]).view(1, 1)\n",
    "        \n",
    "        if state is not None:\n",
    "            if isinstance(state, tuple): # LSTM, state:(h, c)  \n",
    "                state = (state[0], state[1])\n",
    "            else:   \n",
    "                state = state\n",
    "            \n",
    "        (Y, state) = model(X.view(-1,), state)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20275153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:17.346150Z",
     "start_time": "2021-07-09T13:44:17.320095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开溜溜忽棠棠棠棠棠棠棠'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(rnn_layer, vocab_size,char_to_vec,char_to_idx)\n",
    "predict_rnn_pytorch('分开', 10, model, vocab_size, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d10cbb2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:18.270229Z",
     "start_time": "2021-07-09T13:44:18.264240Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta):\n",
    "    norm = torch.tensor([0.0])\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta / norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3525914c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:44:19.268985Z",
     "start_time": "2021-07-09T13:44:19.252469Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size,\n",
    "                                corpus_indices, idx_to_char, char_to_idx,\n",
    "                                num_epochs, num_steps, lr, clipping_theta,\n",
    "                                batch_size, pred_period, pred_len, prefixes):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    state = None\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps) # 相邻采样\n",
    "        for X, Y in data_iter:\n",
    "            if state is not None:\n",
    "                # 使用detach函数从计算图分离隐藏状态, 这是为了\n",
    "                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\n",
    "                if isinstance (state, tuple): # LSTM, state:(h, c)  \n",
    "                    state = (state[0].detach(), state[1].detach())\n",
    "                else:   \n",
    "                    state = state.detach()\n",
    "    \n",
    "            (output, state) = model(X, state) # output: 形状为(num_steps * batch_size, vocab_size)\n",
    "            \n",
    "            # Y的形状是(batch_size, num_steps)，转置后再变成长度为\n",
    "            # batch * num_steps 的向量，这样跟输出的行一一对应\n",
    "            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "            l = loss(output, y.long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "            optimizer.step()\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        \n",
    "        try:\n",
    "            perplexity = math.exp(l_sum / n)\n",
    "        except OverflowError:\n",
    "            perplexity = float('inf')\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "                epoch + 1, perplexity, time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn_pytorch(\n",
    "                    prefix, pred_len, model, vocab_size, idx_to_char,\n",
    "                    char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22614b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:23:12.608521Z",
     "start_time": "2021-07-09T12:46:37.803733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, perplexity 68.777427, time 9.08 sec\n",
      " - 下雨他岩\"，子这。，的条了，，的的是，，我的也的，我我；，，，的的。，。我，也！，。的是，的是，的的，，\n",
      " - 明天当我，们说，我的也的，是，的也\"，，而；，。的，是，我我的有，，的说不这的有的也我，，一的。，是我的\n",
      "epoch 60, perplexity 11.361779, time 9.30 sec\n",
      " - 下雨他岩\"缀漾岩我上他了，，鲜这南！的，是人友；的人；然国 子有们婚这，本。，以谓不上的的有，是的。这但\n",
      " - 明天当却他很是他了野的了，也地的。一她我着人\"的有是像那一人。，过讲未等总了起我的，是，佛忙电伯他见的无\n",
      "epoch 90, perplexity 4.587910, time 9.06 sec\n",
      " - 下雨如一的一大学出么的；风。；生。，物。。我的有，，我线实等倒这说上我，见记来。多地看，不\"不的钱。—象\n",
      " - 明天当却他很是：人说弄他我，哭是欢也。着\"他韦恰叶律。！，，的可—是往船。垂来的》了成看怀。，而\"\"，客\n",
      "epoch 120, perplexity 2.800148, time 8.95 sec\n",
      " - 下雨怕岩\"系它我的他之件所住说像未别他\"， 头看一是月起的！生的做使给我很呢梦应的这 。—谓\"物的说为我\n",
      " - 明天当苏里。\"\"一的辉欢父这我的糊，子看天他的主要。道我立泪他便近这\"微中道我的的是笼唉北位；的和肯没责\n",
      "epoch 150, perplexity 2.073169, time 10.18 sec\n",
      " - 下雨如一那一。\"出死会，的说眼！，了。一；认那我的着的受个， 你用已了好，得。会，慢，了以；\"船已说好我\n",
      " - 明天当却他尽是但票。听的不书说我可们子对住的渐茫回尔将桥可，；信人的钱二阿经晚不脸月被了觉上，中\"见我生\n",
      "epoch 180, perplexity 1.724087, time 9.11 sec\n",
      " - 下雨如一那一。\"门，女住卖唱得神国种右道不\"，吧有。；。花在\"如了，出在使，是一个样人很的上；只各，来照\n",
      " - 明天角买里醒异些秦？梦还的我的了热但定桥晚名的见了那之里来她，\"\"别说正了齐于，，而的做—来些脸的呢从我\n",
      "epoch 210, perplexity 1.467351, time 9.20 sec\n",
      " - 下雨如一那一在\"得是才，是后。，\"仍么着心异人和没明！极有学二，到很阿\"一太些住教有学不，得平句望地听冷\n",
      " - 明天当苏里一光。一。；是不我！在\"是少\"！人说诗，的有。\"。是上很身因；《时。她白报回老以那又过时人，的\n",
      "epoch 240, perplexity 1.353037, time 8.76 sec\n",
      " - 下雨如一那一。回实见方他水，！了她子女脸。有下有的为了。衣她死么\"一；是，便一在改去不们，在好友常正正若\n",
      " - 明天当苏里，意了她叫。达所的河时那—声可，小还，，\"微。事去面疏的学或车\"一\"，也上又看无你，大我，\"得\n"
     ]
    }
   ],
   "source": [
    "num_epochs, batch_size, lr, clipping_theta = 240, 32, 1e-3, 1e-2 # 注意这里的学习率设置\n",
    "pred_period, pred_len, prefixes = 30, 50, ['下雨', '明天']\n",
    "train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size,\n",
    "                            corpus_indices, idx_to_char, char_to_idx,\n",
    "                            num_epochs, num_steps, lr, clipping_theta,\n",
    "                            batch_size, pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bfeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
