{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c48c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb4cfa",
   "metadata": {},
   "source": [
    "### 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128\n",
    "lr = 0.0002          #adam: learning rate\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "latent_dim = 100      #隐藏层神经元数\n",
    "img_size = 64         #生成图片的大小\n",
    "channels = 3          #图片通道\n",
    "sample_interval =400  #打印图片间隔\n",
    "savepath = \"images\"   #存放图片地址"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2cdbc",
   "metadata": {},
   "source": [
    "### 若有GPU，后面方便to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92eadc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0c907",
   "metadata": {},
   "source": [
    "### 定义初始化权重函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63fbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)   \n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)    \n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bfbfc",
   "metadata": {},
   "source": [
    "### 定义生成器\n",
    "\n",
    "BN + 上采用 + 卷积 + BN + ReLU + 上采用 + 卷积 + BN + ReLU + 卷积   最后用tanh返回-1 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df615164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)   #从一维变成size*size的二维\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bdfa9",
   "metadata": {},
   "source": [
    "### 定义分类器\n",
    "\n",
    "(卷积 + ReLU + Dropout)*4 + FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4eb4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3,stride = 2, padding=1), \n",
    "                     nn.LeakyReLU(0.2, inplace=True), \n",
    "                     nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size ** 2, 1), \n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)    #铺平参数\n",
    "        validity = self.adv_layer(out)     #全连接层，sigmoid计算概率\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618a5bb",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a62d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bbd4b",
   "metadata": {},
   "source": [
    "### 初始化生成器和分类器，并将其扔进GPU里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee410ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "#放入GPU中，为了无GPU也能跑，直接to device\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "adversarial_loss.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e6a846d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=32768, bias=True)\n",
       "  )\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#初始化生成器和分类器的权重\n",
    "generator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c0aabc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d988861",
   "metadata": {},
   "source": [
    "### 创建动漫图片的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cf0ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "dataset = ImageFolder(r'dd',transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fca225",
   "metadata": {},
   "source": [
    "### 将数据集打包进dataloader里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb8cbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e720d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   MNIST数据集的dataloader\n",
    "os.makedirs(\"mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = 4,\n",
    "    pin_memory=True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56163bc",
   "metadata": {},
   "source": [
    "### 设置优化器（Adam）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "834e14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9aa2c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor   #方便调用cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ee857",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89c51002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global generator,discriminator,optimizer_G,optimizer_D,dataloader,adversarial_loss,epochs,sample_interval\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "            # 创建ground truth\n",
    "            valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            # 输入真实图片\n",
    "            real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "            # -----------------\n",
    "            #  训练生成器\n",
    "            # -----------------\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # 随机创建生成器的输入噪声（0.1）\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "            # 通过生成器生成假图片\n",
    "            gen_imgs = generator(z)\n",
    "\n",
    "            # 损失函数计算\n",
    "            g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  训练分类器\n",
    "            # ---------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # 计算损失，优化权重\n",
    "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "\n",
    "            # 保存图片，方便看\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "            batches_done = epoch * len(dataloader) + i\n",
    "            if batches_done % sample_interval == 0:\n",
    "                save_image(gen_imgs.data[:25], savepath+\"/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9c48f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/169] [D loss: 0.693130] [G loss: 0.686500]\n",
      "[Epoch 0/200] [Batch 1/169] [D loss: 0.693037] [G loss: 0.687133]\n",
      "[Epoch 0/200] [Batch 2/169] [D loss: 0.692899] [G loss: 0.687740]\n",
      "[Epoch 0/200] [Batch 3/169] [D loss: 0.692831] [G loss: 0.688273]\n",
      "[Epoch 0/200] [Batch 4/169] [D loss: 0.692640] [G loss: 0.688865]\n",
      "[Epoch 0/200] [Batch 5/169] [D loss: 0.692474] [G loss: 0.689406]\n",
      "[Epoch 0/200] [Batch 6/169] [D loss: 0.692090] [G loss: 0.689783]\n",
      "[Epoch 0/200] [Batch 7/169] [D loss: 0.691623] [G loss: 0.690319]\n",
      "[Epoch 0/200] [Batch 8/169] [D loss: 0.691029] [G loss: 0.690791]\n",
      "[Epoch 0/200] [Batch 9/169] [D loss: 0.690317] [G loss: 0.691211]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-acd13e2ff54d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# 创建ground truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m    150\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2766f9",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b47d1e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 0.09508609771728516 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "torch.save({\n",
    "            'generator': generator,\n",
    "            'discriminator': discriminator,\n",
    "            'optimizer_G': optimizer_G,\n",
    "            'optimizer_D': optimizer_D\n",
    "            }, 'net_model.pth')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Running time: %s seconds\"%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3db4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7e26beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 0.0790715217590332 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "load = torch.load('net_model.pth')\n",
    "test_G = load['generator']\n",
    "import matplotlib.pyplot as plt\n",
    "dm = test_G(z).data[1].cpu().clone()\n",
    "unloader = transforms.ToPILImage()\n",
    "dm = unloader(dm)\n",
    "plt.imshow(dm)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Running time: %s seconds\"%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378c0c2",
   "metadata": {},
   "source": [
    "### 保存状态字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d65fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 0.10709762573242188 seconds\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "torch.save({\n",
    "            'generator': generator.state_dict(),\n",
    "            'discriminator': discriminator.state_dict(),\n",
    "            'optimizer_G': optimizer_G.state_dict(),\n",
    "            'optimizer_D': optimizer_D.state_dict(),\n",
    "            'epoch':epochs,\n",
    "            'g_loss': g_loss,\n",
    "            'd_loss': d_loss            \n",
    "            }, 'net_state_dict.pth')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Running time: %s seconds\"%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "27d4b4dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 0.09808802604675293 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "load2 = torch.load('net_state_dict.pth')\n",
    "test_G2 = Generator()\n",
    "test_G2.load_state_dict(load2['generator'])\n",
    "dm2 = test_G(z).data[1].cpu().clone()\n",
    "unloader = transforms.ToPILImage()\n",
    "dm2 = unloader(dm2)\n",
    "plt.imshow(dm2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Running time: %s seconds\"%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c46106",
   "metadata": {},
   "source": [
    "### G保留卷积，D不处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d83568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cov(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Linear\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)   \n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)    \n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3f9d784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/169] [D loss: 0.632618] [G loss: 0.877133]\n",
      "[Epoch 0/200] [Batch 1/169] [D loss: 0.611297] [G loss: 0.897165]\n",
      "[Epoch 0/200] [Batch 2/169] [D loss: 0.599713] [G loss: 0.849502]\n",
      "[Epoch 0/200] [Batch 3/169] [D loss: 0.585015] [G loss: 0.791918]\n",
      "[Epoch 0/200] [Batch 4/169] [D loss: 0.553896] [G loss: 0.815664]\n",
      "[Epoch 0/200] [Batch 5/169] [D loss: 0.572937] [G loss: 0.802559]\n",
      "[Epoch 0/200] [Batch 6/169] [D loss: 0.545147] [G loss: 0.801511]\n",
      "[Epoch 0/200] [Batch 7/169] [D loss: 0.529386] [G loss: 0.779198]\n",
      "[Epoch 0/200] [Batch 8/169] [D loss: 0.504741] [G loss: 0.838539]\n",
      "[Epoch 0/200] [Batch 9/169] [D loss: 0.490808] [G loss: 0.874229]\n",
      "[Epoch 0/200] [Batch 10/169] [D loss: 0.476541] [G loss: 0.851168]\n",
      "[Epoch 0/200] [Batch 11/169] [D loss: 0.458099] [G loss: 0.838353]\n",
      "[Epoch 0/200] [Batch 12/169] [D loss: 0.476399] [G loss: 0.846403]\n",
      "[Epoch 0/200] [Batch 13/169] [D loss: 0.423827] [G loss: 0.953564]\n",
      "[Epoch 0/200] [Batch 14/169] [D loss: 0.403720] [G loss: 1.121097]\n",
      "[Epoch 0/200] [Batch 15/169] [D loss: 0.349093] [G loss: 1.285278]\n",
      "[Epoch 0/200] [Batch 16/169] [D loss: 0.376168] [G loss: 1.109858]\n",
      "[Epoch 0/200] [Batch 17/169] [D loss: 0.383210] [G loss: 1.046233]\n",
      "[Epoch 0/200] [Batch 18/169] [D loss: 0.328050] [G loss: 1.243209]\n",
      "[Epoch 0/200] [Batch 19/169] [D loss: 0.373921] [G loss: 1.086715]\n",
      "[Epoch 0/200] [Batch 20/169] [D loss: 0.425537] [G loss: 1.103911]\n",
      "[Epoch 0/200] [Batch 21/169] [D loss: 0.303365] [G loss: 1.777714]\n",
      "[Epoch 0/200] [Batch 22/169] [D loss: 0.376376] [G loss: 1.832255]\n",
      "[Epoch 0/200] [Batch 23/169] [D loss: 0.879063] [G loss: 0.581474]\n",
      "[Epoch 0/200] [Batch 24/169] [D loss: 0.865609] [G loss: 1.011465]\n",
      "[Epoch 0/200] [Batch 25/169] [D loss: 1.355809] [G loss: 0.291009]\n",
      "[Epoch 0/200] [Batch 26/169] [D loss: 0.759958] [G loss: 1.693972]\n",
      "[Epoch 0/200] [Batch 27/169] [D loss: 0.500633] [G loss: 2.734928]\n",
      "[Epoch 0/200] [Batch 28/169] [D loss: 0.378821] [G loss: 2.246696]\n",
      "[Epoch 0/200] [Batch 29/169] [D loss: 0.338629] [G loss: 1.665859]\n",
      "[Epoch 0/200] [Batch 30/169] [D loss: 0.349507] [G loss: 1.313707]\n",
      "[Epoch 0/200] [Batch 31/169] [D loss: 0.341344] [G loss: 1.239520]\n",
      "[Epoch 0/200] [Batch 32/169] [D loss: 0.302471] [G loss: 1.343646]\n",
      "[Epoch 0/200] [Batch 33/169] [D loss: 0.400432] [G loss: 1.173616]\n",
      "[Epoch 0/200] [Batch 34/169] [D loss: 0.431933] [G loss: 1.102540]\n",
      "[Epoch 0/200] [Batch 35/169] [D loss: 0.447608] [G loss: 1.226575]\n",
      "[Epoch 0/200] [Batch 36/169] [D loss: 0.471494] [G loss: 1.225701]\n",
      "[Epoch 0/200] [Batch 37/169] [D loss: 0.517460] [G loss: 1.240770]\n",
      "[Epoch 0/200] [Batch 38/169] [D loss: 0.497598] [G loss: 1.531318]\n",
      "[Epoch 0/200] [Batch 39/169] [D loss: 0.436548] [G loss: 1.652509]\n",
      "[Epoch 0/200] [Batch 40/169] [D loss: 0.634693] [G loss: 0.931242]\n",
      "[Epoch 0/200] [Batch 41/169] [D loss: 0.635829] [G loss: 1.050244]\n",
      "[Epoch 0/200] [Batch 42/169] [D loss: 0.500130] [G loss: 1.195516]\n",
      "[Epoch 0/200] [Batch 43/169] [D loss: 0.601570] [G loss: 1.349382]\n",
      "[Epoch 0/200] [Batch 44/169] [D loss: 0.558813] [G loss: 1.197227]\n",
      "[Epoch 0/200] [Batch 45/169] [D loss: 0.570700] [G loss: 1.089222]\n",
      "[Epoch 0/200] [Batch 46/169] [D loss: 0.581604] [G loss: 0.996025]\n",
      "[Epoch 0/200] [Batch 47/169] [D loss: 0.639238] [G loss: 0.897711]\n",
      "[Epoch 0/200] [Batch 48/169] [D loss: 0.526236] [G loss: 0.972552]\n",
      "[Epoch 0/200] [Batch 49/169] [D loss: 0.471195] [G loss: 1.052652]\n",
      "[Epoch 0/200] [Batch 50/169] [D loss: 0.444350] [G loss: 1.267111]\n",
      "[Epoch 0/200] [Batch 51/169] [D loss: 0.457081] [G loss: 1.341211]\n",
      "[Epoch 0/200] [Batch 52/169] [D loss: 0.404258] [G loss: 1.343946]\n",
      "[Epoch 0/200] [Batch 53/169] [D loss: 0.392093] [G loss: 1.289757]\n",
      "[Epoch 0/200] [Batch 54/169] [D loss: 0.402307] [G loss: 1.520038]\n",
      "[Epoch 0/200] [Batch 55/169] [D loss: 0.414657] [G loss: 1.171039]\n",
      "[Epoch 0/200] [Batch 56/169] [D loss: 0.469552] [G loss: 1.021782]\n",
      "[Epoch 0/200] [Batch 57/169] [D loss: 0.519502] [G loss: 0.966516]\n",
      "[Epoch 0/200] [Batch 58/169] [D loss: 0.481974] [G loss: 1.014868]\n",
      "[Epoch 0/200] [Batch 59/169] [D loss: 0.456376] [G loss: 1.335990]\n",
      "[Epoch 0/200] [Batch 60/169] [D loss: 0.467476] [G loss: 1.189677]\n",
      "[Epoch 0/200] [Batch 61/169] [D loss: 0.533035] [G loss: 0.982358]\n",
      "[Epoch 0/200] [Batch 62/169] [D loss: 0.450688] [G loss: 1.199284]\n",
      "[Epoch 0/200] [Batch 63/169] [D loss: 0.453244] [G loss: 1.188637]\n",
      "[Epoch 0/200] [Batch 64/169] [D loss: 0.485653] [G loss: 1.206313]\n",
      "[Epoch 0/200] [Batch 65/169] [D loss: 0.481335] [G loss: 1.161575]\n",
      "[Epoch 0/200] [Batch 66/169] [D loss: 0.415588] [G loss: 1.300329]\n",
      "[Epoch 0/200] [Batch 67/169] [D loss: 0.471807] [G loss: 1.132828]\n",
      "[Epoch 0/200] [Batch 68/169] [D loss: 0.466618] [G loss: 1.086440]\n",
      "[Epoch 0/200] [Batch 69/169] [D loss: 0.409696] [G loss: 1.197710]\n",
      "[Epoch 0/200] [Batch 70/169] [D loss: 0.436144] [G loss: 1.228396]\n",
      "[Epoch 0/200] [Batch 71/169] [D loss: 0.471321] [G loss: 1.098024]\n",
      "[Epoch 0/200] [Batch 72/169] [D loss: 0.464789] [G loss: 1.006552]\n",
      "[Epoch 0/200] [Batch 73/169] [D loss: 0.375777] [G loss: 1.319231]\n",
      "[Epoch 0/200] [Batch 74/169] [D loss: 0.444845] [G loss: 1.282203]\n",
      "[Epoch 0/200] [Batch 75/169] [D loss: 0.602647] [G loss: 1.091851]\n",
      "[Epoch 0/200] [Batch 76/169] [D loss: 0.615134] [G loss: 1.319579]\n",
      "[Epoch 0/200] [Batch 77/169] [D loss: 0.639736] [G loss: 1.827987]\n",
      "[Epoch 0/200] [Batch 78/169] [D loss: 0.748262] [G loss: 1.377868]\n",
      "[Epoch 0/200] [Batch 79/169] [D loss: 0.680692] [G loss: 1.052385]\n",
      "[Epoch 0/200] [Batch 80/169] [D loss: 0.466249] [G loss: 2.163560]\n",
      "[Epoch 0/200] [Batch 81/169] [D loss: 0.491413] [G loss: 1.555584]\n",
      "[Epoch 0/200] [Batch 82/169] [D loss: 0.352200] [G loss: 1.477489]\n",
      "[Epoch 0/200] [Batch 83/169] [D loss: 0.317793] [G loss: 1.711599]\n",
      "[Epoch 0/200] [Batch 84/169] [D loss: 0.309020] [G loss: 2.309306]\n",
      "[Epoch 0/200] [Batch 85/169] [D loss: 0.346173] [G loss: 1.837104]\n",
      "[Epoch 0/200] [Batch 86/169] [D loss: 0.352947] [G loss: 1.331225]\n",
      "[Epoch 0/200] [Batch 87/169] [D loss: 0.408122] [G loss: 1.465250]\n",
      "[Epoch 0/200] [Batch 88/169] [D loss: 0.391888] [G loss: 1.511869]\n",
      "[Epoch 0/200] [Batch 89/169] [D loss: 0.509596] [G loss: 1.248132]\n",
      "[Epoch 0/200] [Batch 90/169] [D loss: 0.757876] [G loss: 0.806911]\n",
      "[Epoch 0/200] [Batch 91/169] [D loss: 0.819907] [G loss: 0.752804]\n",
      "[Epoch 0/200] [Batch 92/169] [D loss: 0.597095] [G loss: 1.100772]\n",
      "[Epoch 0/200] [Batch 93/169] [D loss: 0.322022] [G loss: 1.764987]\n",
      "[Epoch 0/200] [Batch 94/169] [D loss: 0.396520] [G loss: 1.259527]\n",
      "[Epoch 0/200] [Batch 95/169] [D loss: 0.443963] [G loss: 1.049505]\n",
      "[Epoch 0/200] [Batch 96/169] [D loss: 0.439179] [G loss: 1.231781]\n",
      "[Epoch 0/200] [Batch 97/169] [D loss: 0.398443] [G loss: 1.243371]\n",
      "[Epoch 0/200] [Batch 98/169] [D loss: 0.398907] [G loss: 1.167067]\n",
      "[Epoch 0/200] [Batch 99/169] [D loss: 0.436156] [G loss: 1.189009]\n",
      "[Epoch 0/200] [Batch 100/169] [D loss: 0.515055] [G loss: 1.300115]\n",
      "[Epoch 0/200] [Batch 101/169] [D loss: 0.659861] [G loss: 1.164119]\n",
      "[Epoch 0/200] [Batch 102/169] [D loss: 0.702003] [G loss: 0.895607]\n",
      "[Epoch 0/200] [Batch 103/169] [D loss: 0.724520] [G loss: 1.080011]\n",
      "[Epoch 0/200] [Batch 104/169] [D loss: 0.796236] [G loss: 1.032681]\n",
      "[Epoch 0/200] [Batch 105/169] [D loss: 0.762295] [G loss: 0.810644]\n",
      "[Epoch 0/200] [Batch 106/169] [D loss: 0.805236] [G loss: 0.740590]\n",
      "[Epoch 0/200] [Batch 107/169] [D loss: 0.704650] [G loss: 1.383053]\n",
      "[Epoch 0/200] [Batch 108/169] [D loss: 0.576337] [G loss: 1.249714]\n",
      "[Epoch 0/200] [Batch 109/169] [D loss: 0.640212] [G loss: 0.958760]\n",
      "[Epoch 0/200] [Batch 110/169] [D loss: 0.617635] [G loss: 1.036632]\n",
      "[Epoch 0/200] [Batch 111/169] [D loss: 0.594589] [G loss: 1.106801]\n",
      "[Epoch 0/200] [Batch 112/169] [D loss: 0.596241] [G loss: 1.305277]\n",
      "[Epoch 0/200] [Batch 113/169] [D loss: 0.497517] [G loss: 1.441411]\n",
      "[Epoch 0/200] [Batch 114/169] [D loss: 0.457246] [G loss: 1.515627]\n",
      "[Epoch 0/200] [Batch 115/169] [D loss: 0.393421] [G loss: 1.542517]\n",
      "[Epoch 0/200] [Batch 116/169] [D loss: 0.367296] [G loss: 1.548547]\n",
      "[Epoch 0/200] [Batch 117/169] [D loss: 0.344419] [G loss: 1.496507]\n",
      "[Epoch 0/200] [Batch 118/169] [D loss: 0.367503] [G loss: 1.694451]\n",
      "[Epoch 0/200] [Batch 119/169] [D loss: 0.280933] [G loss: 1.549475]\n",
      "[Epoch 0/200] [Batch 120/169] [D loss: 0.290859] [G loss: 1.634769]\n",
      "[Epoch 0/200] [Batch 121/169] [D loss: 0.252336] [G loss: 1.696585]\n",
      "[Epoch 0/200] [Batch 122/169] [D loss: 0.298184] [G loss: 1.457945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 123/169] [D loss: 0.446768] [G loss: 1.103964]\n",
      "[Epoch 0/200] [Batch 124/169] [D loss: 0.469226] [G loss: 1.350018]\n",
      "[Epoch 0/200] [Batch 125/169] [D loss: 0.381127] [G loss: 1.323951]\n",
      "[Epoch 0/200] [Batch 126/169] [D loss: 0.366112] [G loss: 1.385244]\n",
      "[Epoch 0/200] [Batch 127/169] [D loss: 0.380668] [G loss: 1.409130]\n",
      "[Epoch 0/200] [Batch 128/169] [D loss: 0.408825] [G loss: 1.202634]\n",
      "[Epoch 0/200] [Batch 129/169] [D loss: 0.318637] [G loss: 1.311230]\n",
      "[Epoch 0/200] [Batch 130/169] [D loss: 0.277686] [G loss: 1.694232]\n",
      "[Epoch 0/200] [Batch 131/169] [D loss: 0.234580] [G loss: 2.055645]\n",
      "[Epoch 0/200] [Batch 132/169] [D loss: 0.274899] [G loss: 1.751404]\n",
      "[Epoch 0/200] [Batch 133/169] [D loss: 0.351201] [G loss: 1.523997]\n",
      "[Epoch 0/200] [Batch 134/169] [D loss: 0.569095] [G loss: 0.924770]\n",
      "[Epoch 0/200] [Batch 135/169] [D loss: 0.732103] [G loss: 0.682388]\n",
      "[Epoch 0/200] [Batch 136/169] [D loss: 0.546956] [G loss: 1.388353]\n",
      "[Epoch 0/200] [Batch 137/169] [D loss: 0.598043] [G loss: 1.444310]\n",
      "[Epoch 0/200] [Batch 138/169] [D loss: 0.670132] [G loss: 1.302828]\n",
      "[Epoch 0/200] [Batch 139/169] [D loss: 0.556582] [G loss: 1.588609]\n",
      "[Epoch 0/200] [Batch 140/169] [D loss: 0.487534] [G loss: 1.678354]\n",
      "[Epoch 0/200] [Batch 141/169] [D loss: 0.500691] [G loss: 1.726157]\n",
      "[Epoch 0/200] [Batch 142/169] [D loss: 0.594682] [G loss: 1.483667]\n",
      "[Epoch 0/200] [Batch 143/169] [D loss: 0.476732] [G loss: 1.371063]\n",
      "[Epoch 0/200] [Batch 144/169] [D loss: 0.511252] [G loss: 1.504641]\n",
      "[Epoch 0/200] [Batch 145/169] [D loss: 0.467293] [G loss: 1.971631]\n",
      "[Epoch 0/200] [Batch 146/169] [D loss: 0.532791] [G loss: 1.824583]\n",
      "[Epoch 0/200] [Batch 147/169] [D loss: 0.565248] [G loss: 1.362264]\n",
      "[Epoch 0/200] [Batch 148/169] [D loss: 0.643701] [G loss: 1.387117]\n",
      "[Epoch 0/200] [Batch 149/169] [D loss: 0.775509] [G loss: 0.881364]\n",
      "[Epoch 0/200] [Batch 150/169] [D loss: 0.774002] [G loss: 1.058940]\n",
      "[Epoch 0/200] [Batch 151/169] [D loss: 0.679867] [G loss: 0.983139]\n",
      "[Epoch 0/200] [Batch 152/169] [D loss: 0.738329] [G loss: 0.894166]\n",
      "[Epoch 0/200] [Batch 153/169] [D loss: 0.635178] [G loss: 0.893198]\n",
      "[Epoch 0/200] [Batch 154/169] [D loss: 0.543189] [G loss: 1.196362]\n",
      "[Epoch 0/200] [Batch 155/169] [D loss: 0.471203] [G loss: 1.174438]\n",
      "[Epoch 0/200] [Batch 156/169] [D loss: 0.439940] [G loss: 1.172715]\n",
      "[Epoch 0/200] [Batch 157/169] [D loss: 0.596599] [G loss: 1.074902]\n",
      "[Epoch 0/200] [Batch 158/169] [D loss: 0.518551] [G loss: 1.044374]\n",
      "[Epoch 0/200] [Batch 159/169] [D loss: 0.640823] [G loss: 0.994859]\n",
      "[Epoch 0/200] [Batch 160/169] [D loss: 0.560965] [G loss: 1.270494]\n",
      "[Epoch 0/200] [Batch 161/169] [D loss: 0.559802] [G loss: 1.107609]\n",
      "[Epoch 0/200] [Batch 162/169] [D loss: 0.522673] [G loss: 1.100980]\n",
      "[Epoch 0/200] [Batch 163/169] [D loss: 0.506111] [G loss: 1.048714]\n",
      "[Epoch 0/200] [Batch 164/169] [D loss: 0.456380] [G loss: 1.118741]\n",
      "[Epoch 0/200] [Batch 165/169] [D loss: 0.502885] [G loss: 1.141992]\n",
      "[Epoch 0/200] [Batch 166/169] [D loss: 0.469162] [G loss: 1.152236]\n",
      "[Epoch 0/200] [Batch 167/169] [D loss: 0.462908] [G loss: 1.124962]\n",
      "[Epoch 0/200] [Batch 168/169] [D loss: 0.400614] [G loss: 1.107071]\n",
      "[Epoch 1/200] [Batch 0/169] [D loss: 0.423846] [G loss: 1.138260]\n",
      "[Epoch 1/200] [Batch 1/169] [D loss: 0.397914] [G loss: 1.211749]\n",
      "[Epoch 1/200] [Batch 2/169] [D loss: 0.405583] [G loss: 1.337781]\n",
      "[Epoch 1/200] [Batch 3/169] [D loss: 0.517955] [G loss: 1.057797]\n",
      "[Epoch 1/200] [Batch 4/169] [D loss: 0.504322] [G loss: 1.131570]\n",
      "[Epoch 1/200] [Batch 5/169] [D loss: 0.561373] [G loss: 1.123111]\n",
      "[Epoch 1/200] [Batch 6/169] [D loss: 0.517240] [G loss: 1.003018]\n",
      "[Epoch 1/200] [Batch 7/169] [D loss: 0.429152] [G loss: 1.258642]\n",
      "[Epoch 1/200] [Batch 8/169] [D loss: 0.441946] [G loss: 1.158513]\n",
      "[Epoch 1/200] [Batch 9/169] [D loss: 0.485262] [G loss: 1.170934]\n",
      "[Epoch 1/200] [Batch 10/169] [D loss: 0.451344] [G loss: 1.320570]\n",
      "[Epoch 1/200] [Batch 11/169] [D loss: 0.462786] [G loss: 1.476921]\n",
      "[Epoch 1/200] [Batch 12/169] [D loss: 0.492221] [G loss: 1.270555]\n",
      "[Epoch 1/200] [Batch 13/169] [D loss: 0.420825] [G loss: 1.286280]\n",
      "[Epoch 1/200] [Batch 14/169] [D loss: 0.468501] [G loss: 1.233896]\n",
      "[Epoch 1/200] [Batch 15/169] [D loss: 0.436874] [G loss: 1.198640]\n",
      "[Epoch 1/200] [Batch 16/169] [D loss: 0.437361] [G loss: 1.244944]\n",
      "[Epoch 1/200] [Batch 17/169] [D loss: 0.480647] [G loss: 1.246230]\n",
      "[Epoch 1/200] [Batch 18/169] [D loss: 0.494373] [G loss: 1.155304]\n",
      "[Epoch 1/200] [Batch 19/169] [D loss: 0.453324] [G loss: 1.436024]\n",
      "[Epoch 1/200] [Batch 20/169] [D loss: 0.542742] [G loss: 1.272379]\n",
      "[Epoch 1/200] [Batch 21/169] [D loss: 0.572627] [G loss: 1.350326]\n",
      "[Epoch 1/200] [Batch 22/169] [D loss: 0.547146] [G loss: 1.239045]\n",
      "[Epoch 1/200] [Batch 23/169] [D loss: 0.559758] [G loss: 1.097846]\n",
      "[Epoch 1/200] [Batch 24/169] [D loss: 0.477209] [G loss: 1.038770]\n",
      "[Epoch 1/200] [Batch 25/169] [D loss: 0.537132] [G loss: 1.089161]\n",
      "[Epoch 1/200] [Batch 26/169] [D loss: 0.507366] [G loss: 0.946004]\n",
      "[Epoch 1/200] [Batch 27/169] [D loss: 0.556378] [G loss: 1.006720]\n",
      "[Epoch 1/200] [Batch 28/169] [D loss: 0.486164] [G loss: 0.892996]\n",
      "[Epoch 1/200] [Batch 29/169] [D loss: 0.549081] [G loss: 0.868523]\n",
      "[Epoch 1/200] [Batch 30/169] [D loss: 0.653687] [G loss: 0.837795]\n",
      "[Epoch 1/200] [Batch 31/169] [D loss: 0.536689] [G loss: 1.017465]\n",
      "[Epoch 1/200] [Batch 32/169] [D loss: 0.449754] [G loss: 1.111208]\n",
      "[Epoch 1/200] [Batch 33/169] [D loss: 0.603430] [G loss: 1.041535]\n",
      "[Epoch 1/200] [Batch 34/169] [D loss: 0.561623] [G loss: 1.184877]\n",
      "[Epoch 1/200] [Batch 35/169] [D loss: 0.485757] [G loss: 1.265936]\n",
      "[Epoch 1/200] [Batch 36/169] [D loss: 0.461024] [G loss: 1.192277]\n",
      "[Epoch 1/200] [Batch 37/169] [D loss: 0.480119] [G loss: 1.088217]\n",
      "[Epoch 1/200] [Batch 38/169] [D loss: 0.415416] [G loss: 1.140347]\n",
      "[Epoch 1/200] [Batch 39/169] [D loss: 0.507418] [G loss: 1.049910]\n",
      "[Epoch 1/200] [Batch 40/169] [D loss: 0.390991] [G loss: 1.011455]\n",
      "[Epoch 1/200] [Batch 41/169] [D loss: 0.507948] [G loss: 0.907861]\n",
      "[Epoch 1/200] [Batch 42/169] [D loss: 0.585809] [G loss: 0.994751]\n",
      "[Epoch 1/200] [Batch 43/169] [D loss: 0.556035] [G loss: 0.930744]\n",
      "[Epoch 1/200] [Batch 44/169] [D loss: 0.548644] [G loss: 1.197446]\n",
      "[Epoch 1/200] [Batch 45/169] [D loss: 0.532276] [G loss: 1.063804]\n",
      "[Epoch 1/200] [Batch 46/169] [D loss: 0.563333] [G loss: 1.158957]\n",
      "[Epoch 1/200] [Batch 47/169] [D loss: 0.520999] [G loss: 1.134244]\n",
      "[Epoch 1/200] [Batch 48/169] [D loss: 0.455738] [G loss: 1.136424]\n",
      "[Epoch 1/200] [Batch 49/169] [D loss: 0.436336] [G loss: 1.085683]\n",
      "[Epoch 1/200] [Batch 50/169] [D loss: 0.504183] [G loss: 1.010273]\n",
      "[Epoch 1/200] [Batch 51/169] [D loss: 0.497027] [G loss: 1.038268]\n",
      "[Epoch 1/200] [Batch 52/169] [D loss: 0.530106] [G loss: 1.003856]\n",
      "[Epoch 1/200] [Batch 53/169] [D loss: 0.573847] [G loss: 1.031285]\n",
      "[Epoch 1/200] [Batch 54/169] [D loss: 0.553583] [G loss: 0.878725]\n",
      "[Epoch 1/200] [Batch 55/169] [D loss: 0.515982] [G loss: 0.977089]\n",
      "[Epoch 1/200] [Batch 56/169] [D loss: 0.572018] [G loss: 0.945208]\n",
      "[Epoch 1/200] [Batch 57/169] [D loss: 0.599669] [G loss: 1.018274]\n",
      "[Epoch 1/200] [Batch 58/169] [D loss: 0.564181] [G loss: 0.980282]\n",
      "[Epoch 1/200] [Batch 59/169] [D loss: 0.571533] [G loss: 1.039653]\n",
      "[Epoch 1/200] [Batch 60/169] [D loss: 0.566411] [G loss: 0.936733]\n",
      "[Epoch 1/200] [Batch 61/169] [D loss: 0.519711] [G loss: 1.226689]\n",
      "[Epoch 1/200] [Batch 62/169] [D loss: 0.538939] [G loss: 0.920026]\n",
      "[Epoch 1/200] [Batch 63/169] [D loss: 0.567367] [G loss: 1.200684]\n",
      "[Epoch 1/200] [Batch 64/169] [D loss: 0.568680] [G loss: 1.175303]\n",
      "[Epoch 1/200] [Batch 65/169] [D loss: 0.564771] [G loss: 1.014269]\n",
      "[Epoch 1/200] [Batch 66/169] [D loss: 0.540024] [G loss: 1.119491]\n",
      "[Epoch 1/200] [Batch 67/169] [D loss: 0.537655] [G loss: 1.026397]\n",
      "[Epoch 1/200] [Batch 68/169] [D loss: 0.533245] [G loss: 0.958369]\n",
      "[Epoch 1/200] [Batch 69/169] [D loss: 0.528971] [G loss: 1.037862]\n",
      "[Epoch 1/200] [Batch 70/169] [D loss: 0.515712] [G loss: 1.234621]\n",
      "[Epoch 1/200] [Batch 71/169] [D loss: 0.511397] [G loss: 1.178787]\n",
      "[Epoch 1/200] [Batch 72/169] [D loss: 0.453619] [G loss: 1.080159]\n",
      "[Epoch 1/200] [Batch 73/169] [D loss: 0.454698] [G loss: 1.152672]\n",
      "[Epoch 1/200] [Batch 74/169] [D loss: 0.424588] [G loss: 1.186025]\n",
      "[Epoch 1/200] [Batch 75/169] [D loss: 0.464900] [G loss: 1.171055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 76/169] [D loss: 0.425317] [G loss: 1.346895]\n",
      "[Epoch 1/200] [Batch 77/169] [D loss: 0.413117] [G loss: 1.225811]\n",
      "[Epoch 1/200] [Batch 78/169] [D loss: 0.438852] [G loss: 1.146242]\n",
      "[Epoch 1/200] [Batch 79/169] [D loss: 0.410465] [G loss: 0.989287]\n",
      "[Epoch 1/200] [Batch 80/169] [D loss: 0.436997] [G loss: 1.206028]\n",
      "[Epoch 1/200] [Batch 81/169] [D loss: 0.444312] [G loss: 1.234114]\n",
      "[Epoch 1/200] [Batch 82/169] [D loss: 0.455893] [G loss: 1.154181]\n",
      "[Epoch 1/200] [Batch 83/169] [D loss: 0.451498] [G loss: 1.002437]\n",
      "[Epoch 1/200] [Batch 84/169] [D loss: 0.481442] [G loss: 1.142560]\n",
      "[Epoch 1/200] [Batch 85/169] [D loss: 0.498527] [G loss: 1.126913]\n",
      "[Epoch 1/200] [Batch 86/169] [D loss: 0.517869] [G loss: 0.977017]\n",
      "[Epoch 1/200] [Batch 87/169] [D loss: 0.503821] [G loss: 1.046855]\n",
      "[Epoch 1/200] [Batch 88/169] [D loss: 0.530214] [G loss: 1.127064]\n",
      "[Epoch 1/200] [Batch 89/169] [D loss: 0.481113] [G loss: 1.282714]\n",
      "[Epoch 1/200] [Batch 90/169] [D loss: 0.464378] [G loss: 1.240567]\n",
      "[Epoch 1/200] [Batch 91/169] [D loss: 0.454591] [G loss: 1.283808]\n",
      "[Epoch 1/200] [Batch 92/169] [D loss: 0.396456] [G loss: 1.430624]\n",
      "[Epoch 1/200] [Batch 93/169] [D loss: 0.417732] [G loss: 1.466800]\n",
      "[Epoch 1/200] [Batch 94/169] [D loss: 0.460447] [G loss: 1.502204]\n",
      "[Epoch 1/200] [Batch 95/169] [D loss: 0.412632] [G loss: 1.553622]\n",
      "[Epoch 1/200] [Batch 96/169] [D loss: 0.430701] [G loss: 1.298483]\n",
      "[Epoch 1/200] [Batch 97/169] [D loss: 0.483376] [G loss: 1.279491]\n",
      "[Epoch 1/200] [Batch 98/169] [D loss: 0.401852] [G loss: 1.223741]\n",
      "[Epoch 1/200] [Batch 99/169] [D loss: 0.423527] [G loss: 1.306483]\n",
      "[Epoch 1/200] [Batch 100/169] [D loss: 0.390200] [G loss: 1.361390]\n",
      "[Epoch 1/200] [Batch 101/169] [D loss: 0.393938] [G loss: 1.269683]\n",
      "[Epoch 1/200] [Batch 102/169] [D loss: 0.437524] [G loss: 1.313614]\n",
      "[Epoch 1/200] [Batch 103/169] [D loss: 0.432727] [G loss: 1.197130]\n",
      "[Epoch 1/200] [Batch 104/169] [D loss: 0.436807] [G loss: 1.196551]\n",
      "[Epoch 1/200] [Batch 105/169] [D loss: 0.467162] [G loss: 1.106376]\n",
      "[Epoch 1/200] [Batch 106/169] [D loss: 0.479498] [G loss: 1.060536]\n",
      "[Epoch 1/200] [Batch 107/169] [D loss: 0.463662] [G loss: 0.982792]\n",
      "[Epoch 1/200] [Batch 108/169] [D loss: 0.471512] [G loss: 1.131753]\n",
      "[Epoch 1/200] [Batch 109/169] [D loss: 0.480699] [G loss: 1.148889]\n",
      "[Epoch 1/200] [Batch 110/169] [D loss: 0.442065] [G loss: 1.187333]\n",
      "[Epoch 1/200] [Batch 111/169] [D loss: 0.474982] [G loss: 1.096930]\n",
      "[Epoch 1/200] [Batch 112/169] [D loss: 0.510101] [G loss: 1.076471]\n",
      "[Epoch 1/200] [Batch 113/169] [D loss: 0.473001] [G loss: 1.202347]\n",
      "[Epoch 1/200] [Batch 114/169] [D loss: 0.508717] [G loss: 1.134471]\n",
      "[Epoch 1/200] [Batch 115/169] [D loss: 0.463510] [G loss: 1.127270]\n",
      "[Epoch 1/200] [Batch 116/169] [D loss: 0.548671] [G loss: 1.142444]\n",
      "[Epoch 1/200] [Batch 117/169] [D loss: 0.479060] [G loss: 1.069795]\n",
      "[Epoch 1/200] [Batch 118/169] [D loss: 0.450926] [G loss: 1.125942]\n",
      "[Epoch 1/200] [Batch 119/169] [D loss: 0.484994] [G loss: 1.247316]\n",
      "[Epoch 1/200] [Batch 120/169] [D loss: 0.516780] [G loss: 1.183368]\n",
      "[Epoch 1/200] [Batch 121/169] [D loss: 0.514868] [G loss: 1.004078]\n",
      "[Epoch 1/200] [Batch 122/169] [D loss: 0.486905] [G loss: 1.163057]\n",
      "[Epoch 1/200] [Batch 123/169] [D loss: 0.502801] [G loss: 1.372732]\n",
      "[Epoch 1/200] [Batch 124/169] [D loss: 0.502809] [G loss: 1.098870]\n",
      "[Epoch 1/200] [Batch 125/169] [D loss: 0.556793] [G loss: 1.118638]\n",
      "[Epoch 1/200] [Batch 126/169] [D loss: 0.537052] [G loss: 1.053274]\n",
      "[Epoch 1/200] [Batch 127/169] [D loss: 0.496395] [G loss: 1.313488]\n",
      "[Epoch 1/200] [Batch 128/169] [D loss: 0.493507] [G loss: 1.277479]\n",
      "[Epoch 1/200] [Batch 129/169] [D loss: 0.591636] [G loss: 1.196783]\n",
      "[Epoch 1/200] [Batch 130/169] [D loss: 0.511153] [G loss: 1.098301]\n",
      "[Epoch 1/200] [Batch 131/169] [D loss: 0.530381] [G loss: 1.315413]\n",
      "[Epoch 1/200] [Batch 132/169] [D loss: 0.574614] [G loss: 1.204262]\n",
      "[Epoch 1/200] [Batch 133/169] [D loss: 0.433699] [G loss: 1.337237]\n",
      "[Epoch 1/200] [Batch 134/169] [D loss: 0.458528] [G loss: 1.413882]\n",
      "[Epoch 1/200] [Batch 135/169] [D loss: 0.401683] [G loss: 1.268703]\n",
      "[Epoch 1/200] [Batch 136/169] [D loss: 0.400623] [G loss: 1.200123]\n",
      "[Epoch 1/200] [Batch 137/169] [D loss: 0.386095] [G loss: 1.242740]\n",
      "[Epoch 1/200] [Batch 138/169] [D loss: 0.436670] [G loss: 1.359833]\n",
      "[Epoch 1/200] [Batch 139/169] [D loss: 0.379895] [G loss: 1.158441]\n",
      "[Epoch 1/200] [Batch 140/169] [D loss: 0.465809] [G loss: 1.126470]\n",
      "[Epoch 1/200] [Batch 141/169] [D loss: 0.498186] [G loss: 1.052898]\n",
      "[Epoch 1/200] [Batch 142/169] [D loss: 0.509009] [G loss: 1.319338]\n",
      "[Epoch 1/200] [Batch 143/169] [D loss: 0.476537] [G loss: 1.223145]\n",
      "[Epoch 1/200] [Batch 144/169] [D loss: 0.536130] [G loss: 1.324152]\n",
      "[Epoch 1/200] [Batch 145/169] [D loss: 0.505808] [G loss: 1.090753]\n",
      "[Epoch 1/200] [Batch 146/169] [D loss: 0.544516] [G loss: 1.004039]\n",
      "[Epoch 1/200] [Batch 147/169] [D loss: 0.518303] [G loss: 1.002333]\n",
      "[Epoch 1/200] [Batch 148/169] [D loss: 0.555236] [G loss: 0.904623]\n",
      "[Epoch 1/200] [Batch 149/169] [D loss: 0.443729] [G loss: 1.119134]\n",
      "[Epoch 1/200] [Batch 150/169] [D loss: 0.477978] [G loss: 1.191831]\n",
      "[Epoch 1/200] [Batch 151/169] [D loss: 0.548331] [G loss: 1.317880]\n",
      "[Epoch 1/200] [Batch 152/169] [D loss: 0.517036] [G loss: 1.005073]\n",
      "[Epoch 1/200] [Batch 153/169] [D loss: 0.520266] [G loss: 0.936557]\n",
      "[Epoch 1/200] [Batch 154/169] [D loss: 0.499696] [G loss: 1.069043]\n",
      "[Epoch 1/200] [Batch 155/169] [D loss: 0.497066] [G loss: 1.013743]\n",
      "[Epoch 1/200] [Batch 156/169] [D loss: 0.524974] [G loss: 1.202469]\n",
      "[Epoch 1/200] [Batch 157/169] [D loss: 0.468117] [G loss: 1.012539]\n",
      "[Epoch 1/200] [Batch 158/169] [D loss: 0.462980] [G loss: 1.215821]\n",
      "[Epoch 1/200] [Batch 159/169] [D loss: 0.452927] [G loss: 1.409227]\n",
      "[Epoch 1/200] [Batch 160/169] [D loss: 0.471518] [G loss: 1.315210]\n",
      "[Epoch 1/200] [Batch 161/169] [D loss: 0.455869] [G loss: 1.238888]\n",
      "[Epoch 1/200] [Batch 162/169] [D loss: 0.394224] [G loss: 1.355888]\n",
      "[Epoch 1/200] [Batch 163/169] [D loss: 0.384304] [G loss: 1.489962]\n",
      "[Epoch 1/200] [Batch 164/169] [D loss: 0.424593] [G loss: 1.466883]\n",
      "[Epoch 1/200] [Batch 165/169] [D loss: 0.446697] [G loss: 1.535974]\n",
      "[Epoch 1/200] [Batch 166/169] [D loss: 0.422615] [G loss: 1.467667]\n",
      "[Epoch 1/200] [Batch 167/169] [D loss: 0.377357] [G loss: 1.375798]\n",
      "[Epoch 1/200] [Batch 168/169] [D loss: 0.400090] [G loss: 1.356487]\n",
      "[Epoch 2/200] [Batch 0/169] [D loss: 0.413237] [G loss: 1.357438]\n",
      "[Epoch 2/200] [Batch 1/169] [D loss: 0.517675] [G loss: 1.211076]\n",
      "[Epoch 2/200] [Batch 2/169] [D loss: 0.412892] [G loss: 1.135076]\n",
      "[Epoch 2/200] [Batch 3/169] [D loss: 0.471771] [G loss: 1.111873]\n",
      "[Epoch 2/200] [Batch 4/169] [D loss: 0.470015] [G loss: 1.066613]\n",
      "[Epoch 2/200] [Batch 5/169] [D loss: 0.470782] [G loss: 1.178460]\n",
      "[Epoch 2/200] [Batch 6/169] [D loss: 0.487710] [G loss: 1.221772]\n",
      "[Epoch 2/200] [Batch 7/169] [D loss: 0.522602] [G loss: 1.212115]\n",
      "[Epoch 2/200] [Batch 8/169] [D loss: 0.557747] [G loss: 1.387431]\n",
      "[Epoch 2/200] [Batch 9/169] [D loss: 0.461901] [G loss: 1.197228]\n",
      "[Epoch 2/200] [Batch 10/169] [D loss: 0.466972] [G loss: 1.256851]\n",
      "[Epoch 2/200] [Batch 11/169] [D loss: 0.399824] [G loss: 1.364192]\n",
      "[Epoch 2/200] [Batch 12/169] [D loss: 0.408840] [G loss: 1.427711]\n",
      "[Epoch 2/200] [Batch 13/169] [D loss: 0.423627] [G loss: 1.460197]\n",
      "[Epoch 2/200] [Batch 14/169] [D loss: 0.422062] [G loss: 1.322263]\n",
      "[Epoch 2/200] [Batch 15/169] [D loss: 0.474616] [G loss: 1.018686]\n",
      "[Epoch 2/200] [Batch 16/169] [D loss: 0.438699] [G loss: 1.187471]\n",
      "[Epoch 2/200] [Batch 17/169] [D loss: 0.381548] [G loss: 1.240805]\n",
      "[Epoch 2/200] [Batch 18/169] [D loss: 0.408958] [G loss: 1.326790]\n",
      "[Epoch 2/200] [Batch 19/169] [D loss: 0.536625] [G loss: 1.379168]\n",
      "[Epoch 2/200] [Batch 20/169] [D loss: 0.419288] [G loss: 1.344844]\n",
      "[Epoch 2/200] [Batch 21/169] [D loss: 0.389463] [G loss: 1.040926]\n",
      "[Epoch 2/200] [Batch 22/169] [D loss: 0.477459] [G loss: 1.240172]\n",
      "[Epoch 2/200] [Batch 23/169] [D loss: 0.497212] [G loss: 1.068066]\n",
      "[Epoch 2/200] [Batch 24/169] [D loss: 0.470445] [G loss: 1.127467]\n",
      "[Epoch 2/200] [Batch 25/169] [D loss: 0.423307] [G loss: 1.419762]\n",
      "[Epoch 2/200] [Batch 26/169] [D loss: 0.445002] [G loss: 1.545287]\n",
      "[Epoch 2/200] [Batch 27/169] [D loss: 0.454730] [G loss: 1.424139]\n",
      "[Epoch 2/200] [Batch 28/169] [D loss: 0.404144] [G loss: 1.305468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 29/169] [D loss: 0.347208] [G loss: 1.369420]\n",
      "[Epoch 2/200] [Batch 30/169] [D loss: 0.376777] [G loss: 1.398186]\n",
      "[Epoch 2/200] [Batch 31/169] [D loss: 0.422605] [G loss: 1.217917]\n",
      "[Epoch 2/200] [Batch 32/169] [D loss: 0.479337] [G loss: 1.158295]\n",
      "[Epoch 2/200] [Batch 33/169] [D loss: 0.529152] [G loss: 0.916237]\n",
      "[Epoch 2/200] [Batch 34/169] [D loss: 0.554950] [G loss: 1.178490]\n",
      "[Epoch 2/200] [Batch 35/169] [D loss: 0.457481] [G loss: 1.296301]\n",
      "[Epoch 2/200] [Batch 36/169] [D loss: 0.360989] [G loss: 1.417593]\n",
      "[Epoch 2/200] [Batch 37/169] [D loss: 0.350824] [G loss: 1.368347]\n",
      "[Epoch 2/200] [Batch 38/169] [D loss: 0.345252] [G loss: 1.232623]\n",
      "[Epoch 2/200] [Batch 39/169] [D loss: 0.445396] [G loss: 1.383200]\n",
      "[Epoch 2/200] [Batch 40/169] [D loss: 0.441278] [G loss: 1.226698]\n",
      "[Epoch 2/200] [Batch 41/169] [D loss: 0.448108] [G loss: 1.147378]\n",
      "[Epoch 2/200] [Batch 42/169] [D loss: 0.482209] [G loss: 1.057613]\n",
      "[Epoch 2/200] [Batch 43/169] [D loss: 0.466947] [G loss: 1.250442]\n",
      "[Epoch 2/200] [Batch 44/169] [D loss: 0.521593] [G loss: 1.312717]\n",
      "[Epoch 2/200] [Batch 45/169] [D loss: 0.479834] [G loss: 1.185199]\n",
      "[Epoch 2/200] [Batch 46/169] [D loss: 0.577043] [G loss: 1.325290]\n",
      "[Epoch 2/200] [Batch 47/169] [D loss: 0.480378] [G loss: 1.241905]\n",
      "[Epoch 2/200] [Batch 48/169] [D loss: 0.548534] [G loss: 1.232376]\n",
      "[Epoch 2/200] [Batch 49/169] [D loss: 0.536166] [G loss: 1.430408]\n",
      "[Epoch 2/200] [Batch 50/169] [D loss: 0.449614] [G loss: 1.387153]\n",
      "[Epoch 2/200] [Batch 51/169] [D loss: 0.462414] [G loss: 1.447361]\n",
      "[Epoch 2/200] [Batch 52/169] [D loss: 0.493806] [G loss: 1.305506]\n",
      "[Epoch 2/200] [Batch 53/169] [D loss: 0.502671] [G loss: 1.303880]\n",
      "[Epoch 2/200] [Batch 54/169] [D loss: 0.497776] [G loss: 1.325499]\n",
      "[Epoch 2/200] [Batch 55/169] [D loss: 0.475953] [G loss: 1.264863]\n",
      "[Epoch 2/200] [Batch 56/169] [D loss: 0.530461] [G loss: 1.024040]\n",
      "[Epoch 2/200] [Batch 57/169] [D loss: 0.540286] [G loss: 1.105080]\n",
      "[Epoch 2/200] [Batch 58/169] [D loss: 0.614812] [G loss: 1.261993]\n",
      "[Epoch 2/200] [Batch 59/169] [D loss: 0.574775] [G loss: 1.234006]\n",
      "[Epoch 2/200] [Batch 60/169] [D loss: 0.463422] [G loss: 1.335291]\n",
      "[Epoch 2/200] [Batch 61/169] [D loss: 0.470431] [G loss: 1.171950]\n",
      "[Epoch 2/200] [Batch 62/169] [D loss: 0.539848] [G loss: 1.324585]\n",
      "[Epoch 2/200] [Batch 63/169] [D loss: 0.577913] [G loss: 1.082195]\n",
      "[Epoch 2/200] [Batch 64/169] [D loss: 0.546598] [G loss: 1.300802]\n",
      "[Epoch 2/200] [Batch 65/169] [D loss: 0.485084] [G loss: 1.374237]\n",
      "[Epoch 2/200] [Batch 66/169] [D loss: 0.481140] [G loss: 1.132995]\n",
      "[Epoch 2/200] [Batch 67/169] [D loss: 0.546896] [G loss: 1.396181]\n",
      "[Epoch 2/200] [Batch 68/169] [D loss: 0.440457] [G loss: 1.311358]\n",
      "[Epoch 2/200] [Batch 69/169] [D loss: 0.435267] [G loss: 1.806159]\n",
      "[Epoch 2/200] [Batch 70/169] [D loss: 0.436277] [G loss: 1.382631]\n",
      "[Epoch 2/200] [Batch 71/169] [D loss: 0.431318] [G loss: 1.420021]\n",
      "[Epoch 2/200] [Batch 72/169] [D loss: 0.431216] [G loss: 1.577780]\n",
      "[Epoch 2/200] [Batch 73/169] [D loss: 0.426262] [G loss: 1.416979]\n",
      "[Epoch 2/200] [Batch 74/169] [D loss: 0.527025] [G loss: 1.239806]\n",
      "[Epoch 2/200] [Batch 75/169] [D loss: 0.521213] [G loss: 1.447567]\n",
      "[Epoch 2/200] [Batch 76/169] [D loss: 0.548828] [G loss: 1.089466]\n",
      "[Epoch 2/200] [Batch 77/169] [D loss: 0.590235] [G loss: 1.175615]\n",
      "[Epoch 2/200] [Batch 78/169] [D loss: 0.697021] [G loss: 1.073160]\n",
      "[Epoch 2/200] [Batch 79/169] [D loss: 0.473105] [G loss: 1.098478]\n",
      "[Epoch 2/200] [Batch 80/169] [D loss: 0.497314] [G loss: 1.169211]\n",
      "[Epoch 2/200] [Batch 81/169] [D loss: 0.538548] [G loss: 1.162512]\n",
      "[Epoch 2/200] [Batch 82/169] [D loss: 0.471059] [G loss: 1.169701]\n",
      "[Epoch 2/200] [Batch 83/169] [D loss: 0.475588] [G loss: 1.217403]\n",
      "[Epoch 2/200] [Batch 84/169] [D loss: 0.454233] [G loss: 1.368644]\n",
      "[Epoch 2/200] [Batch 85/169] [D loss: 0.444385] [G loss: 1.129617]\n",
      "[Epoch 2/200] [Batch 86/169] [D loss: 0.500409] [G loss: 0.986110]\n",
      "[Epoch 2/200] [Batch 87/169] [D loss: 0.439403] [G loss: 1.426905]\n",
      "[Epoch 2/200] [Batch 88/169] [D loss: 0.409954] [G loss: 1.167518]\n",
      "[Epoch 2/200] [Batch 89/169] [D loss: 0.442242] [G loss: 1.149255]\n",
      "[Epoch 2/200] [Batch 90/169] [D loss: 0.531923] [G loss: 1.165035]\n",
      "[Epoch 2/200] [Batch 91/169] [D loss: 0.550313] [G loss: 1.292332]\n",
      "[Epoch 2/200] [Batch 92/169] [D loss: 0.543214] [G loss: 1.246253]\n",
      "[Epoch 2/200] [Batch 93/169] [D loss: 0.471777] [G loss: 1.294163]\n",
      "[Epoch 2/200] [Batch 94/169] [D loss: 0.464439] [G loss: 1.346021]\n",
      "[Epoch 2/200] [Batch 95/169] [D loss: 0.426683] [G loss: 1.477705]\n",
      "[Epoch 2/200] [Batch 96/169] [D loss: 0.454701] [G loss: 1.364046]\n",
      "[Epoch 2/200] [Batch 97/169] [D loss: 0.457213] [G loss: 1.375515]\n",
      "[Epoch 2/200] [Batch 98/169] [D loss: 0.401311] [G loss: 1.470473]\n",
      "[Epoch 2/200] [Batch 99/169] [D loss: 0.347486] [G loss: 1.535369]\n",
      "[Epoch 2/200] [Batch 100/169] [D loss: 0.460744] [G loss: 1.365601]\n",
      "[Epoch 2/200] [Batch 101/169] [D loss: 0.387484] [G loss: 1.358416]\n",
      "[Epoch 2/200] [Batch 102/169] [D loss: 0.470560] [G loss: 1.168503]\n",
      "[Epoch 2/200] [Batch 103/169] [D loss: 0.495868] [G loss: 1.161564]\n",
      "[Epoch 2/200] [Batch 104/169] [D loss: 0.472929] [G loss: 1.018890]\n",
      "[Epoch 2/200] [Batch 105/169] [D loss: 0.487200] [G loss: 1.136793]\n",
      "[Epoch 2/200] [Batch 106/169] [D loss: 0.517421] [G loss: 1.254780]\n",
      "[Epoch 2/200] [Batch 107/169] [D loss: 0.471983] [G loss: 0.940375]\n",
      "[Epoch 2/200] [Batch 108/169] [D loss: 0.589275] [G loss: 1.182916]\n",
      "[Epoch 2/200] [Batch 109/169] [D loss: 0.482548] [G loss: 1.125504]\n",
      "[Epoch 2/200] [Batch 110/169] [D loss: 0.564772] [G loss: 1.129318]\n",
      "[Epoch 2/200] [Batch 111/169] [D loss: 0.644260] [G loss: 0.979754]\n",
      "[Epoch 2/200] [Batch 112/169] [D loss: 0.514297] [G loss: 1.279888]\n",
      "[Epoch 2/200] [Batch 113/169] [D loss: 0.527866] [G loss: 1.168763]\n",
      "[Epoch 2/200] [Batch 114/169] [D loss: 0.479263] [G loss: 1.200686]\n",
      "[Epoch 2/200] [Batch 115/169] [D loss: 0.434181] [G loss: 1.175328]\n",
      "[Epoch 2/200] [Batch 116/169] [D loss: 0.549383] [G loss: 1.190683]\n",
      "[Epoch 2/200] [Batch 117/169] [D loss: 0.460783] [G loss: 0.982793]\n",
      "[Epoch 2/200] [Batch 118/169] [D loss: 0.490459] [G loss: 1.058415]\n",
      "[Epoch 2/200] [Batch 119/169] [D loss: 0.501489] [G loss: 1.059614]\n",
      "[Epoch 2/200] [Batch 120/169] [D loss: 0.477107] [G loss: 1.088639]\n",
      "[Epoch 2/200] [Batch 121/169] [D loss: 0.460822] [G loss: 1.073195]\n",
      "[Epoch 2/200] [Batch 122/169] [D loss: 0.456805] [G loss: 1.066611]\n",
      "[Epoch 2/200] [Batch 123/169] [D loss: 0.438424] [G loss: 1.250335]\n",
      "[Epoch 2/200] [Batch 124/169] [D loss: 0.428125] [G loss: 1.222512]\n",
      "[Epoch 2/200] [Batch 125/169] [D loss: 0.490692] [G loss: 1.229661]\n",
      "[Epoch 2/200] [Batch 126/169] [D loss: 0.439018] [G loss: 1.112283]\n",
      "[Epoch 2/200] [Batch 127/169] [D loss: 0.460158] [G loss: 1.154923]\n",
      "[Epoch 2/200] [Batch 128/169] [D loss: 0.560256] [G loss: 1.164555]\n",
      "[Epoch 2/200] [Batch 129/169] [D loss: 0.448302] [G loss: 1.096523]\n",
      "[Epoch 2/200] [Batch 130/169] [D loss: 0.459070] [G loss: 1.009884]\n",
      "[Epoch 2/200] [Batch 131/169] [D loss: 0.503207] [G loss: 1.212687]\n",
      "[Epoch 2/200] [Batch 132/169] [D loss: 0.502374] [G loss: 1.146236]\n",
      "[Epoch 2/200] [Batch 133/169] [D loss: 0.514905] [G loss: 1.185731]\n",
      "[Epoch 2/200] [Batch 134/169] [D loss: 0.463481] [G loss: 1.128771]\n",
      "[Epoch 2/200] [Batch 135/169] [D loss: 0.512250] [G loss: 1.184062]\n",
      "[Epoch 2/200] [Batch 136/169] [D loss: 0.520981] [G loss: 1.228956]\n",
      "[Epoch 2/200] [Batch 137/169] [D loss: 0.510118] [G loss: 1.170409]\n",
      "[Epoch 2/200] [Batch 138/169] [D loss: 0.561025] [G loss: 1.201036]\n",
      "[Epoch 2/200] [Batch 139/169] [D loss: 0.624727] [G loss: 1.156717]\n",
      "[Epoch 2/200] [Batch 140/169] [D loss: 0.491893] [G loss: 1.531075]\n",
      "[Epoch 2/200] [Batch 141/169] [D loss: 0.418464] [G loss: 1.360945]\n",
      "[Epoch 2/200] [Batch 142/169] [D loss: 0.538466] [G loss: 1.111448]\n",
      "[Epoch 2/200] [Batch 143/169] [D loss: 0.456178] [G loss: 1.219410]\n",
      "[Epoch 2/200] [Batch 144/169] [D loss: 0.502777] [G loss: 1.340394]\n",
      "[Epoch 2/200] [Batch 145/169] [D loss: 0.462609] [G loss: 1.002401]\n",
      "[Epoch 2/200] [Batch 146/169] [D loss: 0.477567] [G loss: 1.344591]\n",
      "[Epoch 2/200] [Batch 147/169] [D loss: 0.462778] [G loss: 1.296645]\n",
      "[Epoch 2/200] [Batch 148/169] [D loss: 0.471828] [G loss: 1.239385]\n",
      "[Epoch 2/200] [Batch 149/169] [D loss: 0.492442] [G loss: 1.032820]\n",
      "[Epoch 2/200] [Batch 150/169] [D loss: 0.537295] [G loss: 1.180965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 151/169] [D loss: 0.474120] [G loss: 1.256877]\n",
      "[Epoch 2/200] [Batch 152/169] [D loss: 0.437528] [G loss: 1.222133]\n",
      "[Epoch 2/200] [Batch 153/169] [D loss: 0.512201] [G loss: 1.177409]\n",
      "[Epoch 2/200] [Batch 154/169] [D loss: 0.521503] [G loss: 1.193933]\n",
      "[Epoch 2/200] [Batch 155/169] [D loss: 0.466974] [G loss: 1.199101]\n",
      "[Epoch 2/200] [Batch 156/169] [D loss: 0.539478] [G loss: 0.940223]\n",
      "[Epoch 2/200] [Batch 157/169] [D loss: 0.467590] [G loss: 1.120696]\n",
      "[Epoch 2/200] [Batch 158/169] [D loss: 0.553359] [G loss: 1.202187]\n",
      "[Epoch 2/200] [Batch 159/169] [D loss: 0.517321] [G loss: 1.260950]\n",
      "[Epoch 2/200] [Batch 160/169] [D loss: 0.558452] [G loss: 1.373047]\n",
      "[Epoch 2/200] [Batch 161/169] [D loss: 0.464315] [G loss: 1.050379]\n",
      "[Epoch 2/200] [Batch 162/169] [D loss: 0.387521] [G loss: 1.361759]\n",
      "[Epoch 2/200] [Batch 163/169] [D loss: 0.400312] [G loss: 1.756005]\n",
      "[Epoch 2/200] [Batch 164/169] [D loss: 0.408189] [G loss: 1.383717]\n",
      "[Epoch 2/200] [Batch 165/169] [D loss: 0.450272] [G loss: 1.242180]\n",
      "[Epoch 2/200] [Batch 166/169] [D loss: 0.421720] [G loss: 1.205134]\n",
      "[Epoch 2/200] [Batch 167/169] [D loss: 0.489512] [G loss: 1.106573]\n",
      "[Epoch 2/200] [Batch 168/169] [D loss: 0.540311] [G loss: 1.237054]\n",
      "[Epoch 3/200] [Batch 0/169] [D loss: 0.399990] [G loss: 1.301569]\n",
      "[Epoch 3/200] [Batch 1/169] [D loss: 0.444040] [G loss: 1.279636]\n",
      "[Epoch 3/200] [Batch 2/169] [D loss: 0.596630] [G loss: 0.940767]\n",
      "[Epoch 3/200] [Batch 3/169] [D loss: 0.519757] [G loss: 1.168517]\n",
      "[Epoch 3/200] [Batch 4/169] [D loss: 0.624028] [G loss: 1.106282]\n",
      "[Epoch 3/200] [Batch 5/169] [D loss: 0.655015] [G loss: 1.218471]\n",
      "[Epoch 3/200] [Batch 6/169] [D loss: 0.572272] [G loss: 1.349940]\n",
      "[Epoch 3/200] [Batch 7/169] [D loss: 0.573114] [G loss: 1.060951]\n",
      "[Epoch 3/200] [Batch 8/169] [D loss: 0.580971] [G loss: 0.873061]\n",
      "[Epoch 3/200] [Batch 9/169] [D loss: 0.484456] [G loss: 1.282338]\n",
      "[Epoch 3/200] [Batch 10/169] [D loss: 0.518897] [G loss: 1.210254]\n",
      "[Epoch 3/200] [Batch 11/169] [D loss: 0.444541] [G loss: 1.333880]\n",
      "[Epoch 3/200] [Batch 12/169] [D loss: 0.480312] [G loss: 1.247070]\n",
      "[Epoch 3/200] [Batch 13/169] [D loss: 0.414270] [G loss: 1.173092]\n",
      "[Epoch 3/200] [Batch 14/169] [D loss: 0.376650] [G loss: 1.284666]\n",
      "[Epoch 3/200] [Batch 15/169] [D loss: 0.400712] [G loss: 1.212772]\n",
      "[Epoch 3/200] [Batch 16/169] [D loss: 0.429291] [G loss: 1.112273]\n",
      "[Epoch 3/200] [Batch 17/169] [D loss: 0.518626] [G loss: 1.217633]\n",
      "[Epoch 3/200] [Batch 18/169] [D loss: 0.422491] [G loss: 1.189495]\n",
      "[Epoch 3/200] [Batch 19/169] [D loss: 0.392133] [G loss: 1.087579]\n",
      "[Epoch 3/200] [Batch 20/169] [D loss: 0.426886] [G loss: 1.115612]\n",
      "[Epoch 3/200] [Batch 21/169] [D loss: 0.403095] [G loss: 1.238722]\n",
      "[Epoch 3/200] [Batch 22/169] [D loss: 0.499178] [G loss: 1.242260]\n",
      "[Epoch 3/200] [Batch 23/169] [D loss: 0.431742] [G loss: 1.297676]\n",
      "[Epoch 3/200] [Batch 24/169] [D loss: 0.486754] [G loss: 1.211819]\n",
      "[Epoch 3/200] [Batch 25/169] [D loss: 0.407574] [G loss: 1.260499]\n",
      "[Epoch 3/200] [Batch 26/169] [D loss: 0.461156] [G loss: 1.445195]\n",
      "[Epoch 3/200] [Batch 27/169] [D loss: 0.476986] [G loss: 1.358188]\n",
      "[Epoch 3/200] [Batch 28/169] [D loss: 0.478620] [G loss: 1.331658]\n",
      "[Epoch 3/200] [Batch 29/169] [D loss: 0.501464] [G loss: 1.279672]\n",
      "[Epoch 3/200] [Batch 30/169] [D loss: 0.577958] [G loss: 1.255373]\n",
      "[Epoch 3/200] [Batch 31/169] [D loss: 0.597863] [G loss: 1.314719]\n",
      "[Epoch 3/200] [Batch 32/169] [D loss: 0.497780] [G loss: 1.094119]\n",
      "[Epoch 3/200] [Batch 33/169] [D loss: 0.457861] [G loss: 1.438354]\n",
      "[Epoch 3/200] [Batch 34/169] [D loss: 0.490653] [G loss: 1.422361]\n",
      "[Epoch 3/200] [Batch 35/169] [D loss: 0.523688] [G loss: 0.990488]\n",
      "[Epoch 3/200] [Batch 36/169] [D loss: 0.522428] [G loss: 0.934866]\n",
      "[Epoch 3/200] [Batch 37/169] [D loss: 0.491192] [G loss: 1.060951]\n",
      "[Epoch 3/200] [Batch 38/169] [D loss: 0.450744] [G loss: 1.185529]\n",
      "[Epoch 3/200] [Batch 39/169] [D loss: 0.465395] [G loss: 1.351598]\n",
      "[Epoch 3/200] [Batch 40/169] [D loss: 0.496734] [G loss: 1.250386]\n",
      "[Epoch 3/200] [Batch 41/169] [D loss: 0.488409] [G loss: 1.121502]\n",
      "[Epoch 3/200] [Batch 42/169] [D loss: 0.546112] [G loss: 1.302413]\n",
      "[Epoch 3/200] [Batch 43/169] [D loss: 0.500781] [G loss: 1.173964]\n",
      "[Epoch 3/200] [Batch 44/169] [D loss: 0.469256] [G loss: 1.184075]\n",
      "[Epoch 3/200] [Batch 45/169] [D loss: 0.490883] [G loss: 1.222440]\n",
      "[Epoch 3/200] [Batch 46/169] [D loss: 0.549464] [G loss: 1.071084]\n",
      "[Epoch 3/200] [Batch 47/169] [D loss: 0.469863] [G loss: 1.325144]\n",
      "[Epoch 3/200] [Batch 48/169] [D loss: 0.551500] [G loss: 1.284240]\n",
      "[Epoch 3/200] [Batch 49/169] [D loss: 0.587987] [G loss: 1.038362]\n",
      "[Epoch 3/200] [Batch 50/169] [D loss: 0.507250] [G loss: 1.136644]\n",
      "[Epoch 3/200] [Batch 51/169] [D loss: 0.488621] [G loss: 1.151130]\n",
      "[Epoch 3/200] [Batch 52/169] [D loss: 0.477188] [G loss: 1.056491]\n",
      "[Epoch 3/200] [Batch 53/169] [D loss: 0.500390] [G loss: 1.346702]\n",
      "[Epoch 3/200] [Batch 54/169] [D loss: 0.471016] [G loss: 1.524084]\n",
      "[Epoch 3/200] [Batch 55/169] [D loss: 0.474049] [G loss: 1.501757]\n",
      "[Epoch 3/200] [Batch 56/169] [D loss: 0.522730] [G loss: 1.309319]\n",
      "[Epoch 3/200] [Batch 57/169] [D loss: 0.415096] [G loss: 1.375722]\n",
      "[Epoch 3/200] [Batch 58/169] [D loss: 0.507925] [G loss: 1.440228]\n",
      "[Epoch 3/200] [Batch 59/169] [D loss: 0.463385] [G loss: 1.327984]\n",
      "[Epoch 3/200] [Batch 60/169] [D loss: 0.425653] [G loss: 1.175497]\n",
      "[Epoch 3/200] [Batch 61/169] [D loss: 0.492583] [G loss: 1.188647]\n",
      "[Epoch 3/200] [Batch 62/169] [D loss: 0.420857] [G loss: 1.472359]\n",
      "[Epoch 3/200] [Batch 63/169] [D loss: 0.492253] [G loss: 1.377784]\n",
      "[Epoch 3/200] [Batch 64/169] [D loss: 0.557672] [G loss: 1.234357]\n",
      "[Epoch 3/200] [Batch 65/169] [D loss: 0.512369] [G loss: 1.270122]\n",
      "[Epoch 3/200] [Batch 66/169] [D loss: 0.566559] [G loss: 1.048751]\n",
      "[Epoch 3/200] [Batch 67/169] [D loss: 0.647507] [G loss: 1.225299]\n",
      "[Epoch 3/200] [Batch 68/169] [D loss: 0.498525] [G loss: 1.271405]\n",
      "[Epoch 3/200] [Batch 69/169] [D loss: 0.511246] [G loss: 1.241710]\n",
      "[Epoch 3/200] [Batch 70/169] [D loss: 0.493696] [G loss: 1.323751]\n",
      "[Epoch 3/200] [Batch 71/169] [D loss: 0.555815] [G loss: 1.400205]\n",
      "[Epoch 3/200] [Batch 72/169] [D loss: 0.416109] [G loss: 1.242023]\n",
      "[Epoch 3/200] [Batch 73/169] [D loss: 0.471743] [G loss: 1.220493]\n",
      "[Epoch 3/200] [Batch 74/169] [D loss: 0.422166] [G loss: 1.170567]\n",
      "[Epoch 3/200] [Batch 75/169] [D loss: 0.473635] [G loss: 1.121858]\n",
      "[Epoch 3/200] [Batch 76/169] [D loss: 0.459944] [G loss: 1.087771]\n",
      "[Epoch 3/200] [Batch 77/169] [D loss: 0.419598] [G loss: 1.198337]\n",
      "[Epoch 3/200] [Batch 78/169] [D loss: 0.556969] [G loss: 1.224783]\n",
      "[Epoch 3/200] [Batch 79/169] [D loss: 0.494320] [G loss: 1.170295]\n",
      "[Epoch 3/200] [Batch 80/169] [D loss: 0.474374] [G loss: 1.394198]\n",
      "[Epoch 3/200] [Batch 81/169] [D loss: 0.569254] [G loss: 1.249980]\n",
      "[Epoch 3/200] [Batch 82/169] [D loss: 0.545325] [G loss: 1.267079]\n",
      "[Epoch 3/200] [Batch 83/169] [D loss: 0.485043] [G loss: 1.003779]\n",
      "[Epoch 3/200] [Batch 84/169] [D loss: 0.497479] [G loss: 1.023145]\n",
      "[Epoch 3/200] [Batch 85/169] [D loss: 0.450654] [G loss: 0.985686]\n",
      "[Epoch 3/200] [Batch 86/169] [D loss: 0.492240] [G loss: 0.976569]\n",
      "[Epoch 3/200] [Batch 87/169] [D loss: 0.451586] [G loss: 1.432881]\n",
      "[Epoch 3/200] [Batch 88/169] [D loss: 0.385058] [G loss: 1.348920]\n",
      "[Epoch 3/200] [Batch 89/169] [D loss: 0.414248] [G loss: 1.411834]\n",
      "[Epoch 3/200] [Batch 90/169] [D loss: 0.405598] [G loss: 1.300358]\n",
      "[Epoch 3/200] [Batch 91/169] [D loss: 0.460569] [G loss: 1.275435]\n",
      "[Epoch 3/200] [Batch 92/169] [D loss: 0.492829] [G loss: 1.023747]\n",
      "[Epoch 3/200] [Batch 93/169] [D loss: 0.466099] [G loss: 1.093949]\n",
      "[Epoch 3/200] [Batch 94/169] [D loss: 0.421723] [G loss: 1.133252]\n",
      "[Epoch 3/200] [Batch 95/169] [D loss: 0.489103] [G loss: 1.268426]\n",
      "[Epoch 3/200] [Batch 96/169] [D loss: 0.476076] [G loss: 1.330409]\n",
      "[Epoch 3/200] [Batch 97/169] [D loss: 0.496727] [G loss: 1.349158]\n",
      "[Epoch 3/200] [Batch 98/169] [D loss: 0.429001] [G loss: 1.243401]\n",
      "[Epoch 3/200] [Batch 99/169] [D loss: 0.475652] [G loss: 1.236214]\n",
      "[Epoch 3/200] [Batch 100/169] [D loss: 0.442791] [G loss: 1.263415]\n",
      "[Epoch 3/200] [Batch 101/169] [D loss: 0.501882] [G loss: 1.315936]\n",
      "[Epoch 3/200] [Batch 102/169] [D loss: 0.497940] [G loss: 1.243708]\n",
      "[Epoch 3/200] [Batch 103/169] [D loss: 0.472948] [G loss: 1.154229]\n",
      "[Epoch 3/200] [Batch 104/169] [D loss: 0.466590] [G loss: 1.092737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 105/169] [D loss: 0.496527] [G loss: 1.325549]\n",
      "[Epoch 3/200] [Batch 106/169] [D loss: 0.424088] [G loss: 1.340690]\n",
      "[Epoch 3/200] [Batch 107/169] [D loss: 0.455951] [G loss: 1.165860]\n",
      "[Epoch 3/200] [Batch 108/169] [D loss: 0.417066] [G loss: 1.427244]\n",
      "[Epoch 3/200] [Batch 109/169] [D loss: 0.419821] [G loss: 1.323749]\n",
      "[Epoch 3/200] [Batch 110/169] [D loss: 0.430138] [G loss: 1.234249]\n",
      "[Epoch 3/200] [Batch 111/169] [D loss: 0.399492] [G loss: 1.238026]\n",
      "[Epoch 3/200] [Batch 112/169] [D loss: 0.398928] [G loss: 1.187296]\n",
      "[Epoch 3/200] [Batch 113/169] [D loss: 0.458102] [G loss: 1.316561]\n",
      "[Epoch 3/200] [Batch 114/169] [D loss: 0.531448] [G loss: 1.439157]\n",
      "[Epoch 3/200] [Batch 115/169] [D loss: 0.442730] [G loss: 1.266426]\n",
      "[Epoch 3/200] [Batch 116/169] [D loss: 0.431110] [G loss: 1.211081]\n",
      "[Epoch 3/200] [Batch 117/169] [D loss: 0.490963] [G loss: 1.116223]\n",
      "[Epoch 3/200] [Batch 118/169] [D loss: 0.391874] [G loss: 1.273553]\n",
      "[Epoch 3/200] [Batch 119/169] [D loss: 0.521484] [G loss: 1.482883]\n",
      "[Epoch 3/200] [Batch 120/169] [D loss: 0.513054] [G loss: 1.311325]\n",
      "[Epoch 3/200] [Batch 121/169] [D loss: 0.470110] [G loss: 1.477637]\n",
      "[Epoch 3/200] [Batch 122/169] [D loss: 0.372945] [G loss: 1.680557]\n",
      "[Epoch 3/200] [Batch 123/169] [D loss: 0.338147] [G loss: 1.662434]\n",
      "[Epoch 3/200] [Batch 124/169] [D loss: 0.392753] [G loss: 1.555324]\n",
      "[Epoch 3/200] [Batch 125/169] [D loss: 0.539634] [G loss: 1.006000]\n",
      "[Epoch 3/200] [Batch 126/169] [D loss: 0.558874] [G loss: 0.952836]\n",
      "[Epoch 3/200] [Batch 127/169] [D loss: 0.579654] [G loss: 1.070002]\n",
      "[Epoch 3/200] [Batch 128/169] [D loss: 0.645140] [G loss: 1.164306]\n",
      "[Epoch 3/200] [Batch 129/169] [D loss: 0.659049] [G loss: 1.076011]\n",
      "[Epoch 3/200] [Batch 130/169] [D loss: 0.634027] [G loss: 0.953638]\n",
      "[Epoch 3/200] [Batch 131/169] [D loss: 0.570002] [G loss: 1.015184]\n",
      "[Epoch 3/200] [Batch 132/169] [D loss: 0.600317] [G loss: 1.249006]\n",
      "[Epoch 3/200] [Batch 133/169] [D loss: 0.605448] [G loss: 1.365814]\n",
      "[Epoch 3/200] [Batch 134/169] [D loss: 0.607543] [G loss: 1.081092]\n",
      "[Epoch 3/200] [Batch 135/169] [D loss: 0.505803] [G loss: 1.108452]\n",
      "[Epoch 3/200] [Batch 136/169] [D loss: 0.558960] [G loss: 0.902598]\n",
      "[Epoch 3/200] [Batch 137/169] [D loss: 0.637294] [G loss: 1.206753]\n",
      "[Epoch 3/200] [Batch 138/169] [D loss: 0.516989] [G loss: 1.242319]\n",
      "[Epoch 3/200] [Batch 139/169] [D loss: 0.570396] [G loss: 1.271249]\n",
      "[Epoch 3/200] [Batch 140/169] [D loss: 0.466145] [G loss: 1.047960]\n",
      "[Epoch 3/200] [Batch 141/169] [D loss: 0.673178] [G loss: 1.067225]\n",
      "[Epoch 3/200] [Batch 142/169] [D loss: 0.716454] [G loss: 0.986502]\n",
      "[Epoch 3/200] [Batch 143/169] [D loss: 0.633949] [G loss: 0.930946]\n",
      "[Epoch 3/200] [Batch 144/169] [D loss: 0.673461] [G loss: 1.141930]\n",
      "[Epoch 3/200] [Batch 145/169] [D loss: 0.669329] [G loss: 0.998469]\n",
      "[Epoch 3/200] [Batch 146/169] [D loss: 0.710161] [G loss: 1.107049]\n",
      "[Epoch 3/200] [Batch 147/169] [D loss: 0.607056] [G loss: 1.128547]\n",
      "[Epoch 3/200] [Batch 148/169] [D loss: 0.465037] [G loss: 1.024531]\n",
      "[Epoch 3/200] [Batch 149/169] [D loss: 0.464896] [G loss: 1.200543]\n",
      "[Epoch 3/200] [Batch 150/169] [D loss: 0.434350] [G loss: 1.126467]\n",
      "[Epoch 3/200] [Batch 151/169] [D loss: 0.479340] [G loss: 1.319681]\n",
      "[Epoch 3/200] [Batch 152/169] [D loss: 0.409575] [G loss: 1.354062]\n",
      "[Epoch 3/200] [Batch 153/169] [D loss: 0.449417] [G loss: 1.285366]\n",
      "[Epoch 3/200] [Batch 154/169] [D loss: 0.451802] [G loss: 1.355688]\n",
      "[Epoch 3/200] [Batch 155/169] [D loss: 0.404574] [G loss: 1.042467]\n",
      "[Epoch 3/200] [Batch 156/169] [D loss: 0.446259] [G loss: 1.157872]\n",
      "[Epoch 3/200] [Batch 157/169] [D loss: 0.434314] [G loss: 1.275868]\n",
      "[Epoch 3/200] [Batch 158/169] [D loss: 0.426896] [G loss: 1.287525]\n",
      "[Epoch 3/200] [Batch 159/169] [D loss: 0.447564] [G loss: 1.149378]\n",
      "[Epoch 3/200] [Batch 160/169] [D loss: 0.441348] [G loss: 1.145590]\n",
      "[Epoch 3/200] [Batch 161/169] [D loss: 0.460342] [G loss: 1.157554]\n",
      "[Epoch 3/200] [Batch 162/169] [D loss: 0.506635] [G loss: 1.162146]\n",
      "[Epoch 3/200] [Batch 163/169] [D loss: 0.486489] [G loss: 1.329773]\n",
      "[Epoch 3/200] [Batch 164/169] [D loss: 0.524575] [G loss: 1.064030]\n",
      "[Epoch 3/200] [Batch 165/169] [D loss: 0.535058] [G loss: 1.082842]\n",
      "[Epoch 3/200] [Batch 166/169] [D loss: 0.554184] [G loss: 1.187438]\n",
      "[Epoch 3/200] [Batch 167/169] [D loss: 0.479995] [G loss: 1.172757]\n",
      "[Epoch 3/200] [Batch 168/169] [D loss: 0.515506] [G loss: 1.008543]\n",
      "[Epoch 4/200] [Batch 0/169] [D loss: 0.572425] [G loss: 1.191483]\n",
      "[Epoch 4/200] [Batch 1/169] [D loss: 0.531035] [G loss: 1.160937]\n",
      "[Epoch 4/200] [Batch 2/169] [D loss: 0.487396] [G loss: 1.364158]\n",
      "[Epoch 4/200] [Batch 3/169] [D loss: 0.630279] [G loss: 1.020098]\n",
      "[Epoch 4/200] [Batch 4/169] [D loss: 0.508625] [G loss: 1.427315]\n",
      "[Epoch 4/200] [Batch 5/169] [D loss: 0.555346] [G loss: 1.098342]\n",
      "[Epoch 4/200] [Batch 6/169] [D loss: 0.539920] [G loss: 1.388822]\n",
      "[Epoch 4/200] [Batch 7/169] [D loss: 0.432592] [G loss: 1.136632]\n",
      "[Epoch 4/200] [Batch 8/169] [D loss: 0.517944] [G loss: 0.895820]\n",
      "[Epoch 4/200] [Batch 9/169] [D loss: 0.555289] [G loss: 1.199534]\n",
      "[Epoch 4/200] [Batch 10/169] [D loss: 0.533627] [G loss: 1.223325]\n",
      "[Epoch 4/200] [Batch 11/169] [D loss: 0.593776] [G loss: 1.066086]\n",
      "[Epoch 4/200] [Batch 12/169] [D loss: 0.620725] [G loss: 1.206718]\n",
      "[Epoch 4/200] [Batch 13/169] [D loss: 0.550767] [G loss: 1.041860]\n",
      "[Epoch 4/200] [Batch 14/169] [D loss: 0.586253] [G loss: 1.178129]\n",
      "[Epoch 4/200] [Batch 15/169] [D loss: 0.519173] [G loss: 1.168037]\n",
      "[Epoch 4/200] [Batch 16/169] [D loss: 0.538058] [G loss: 1.250723]\n",
      "[Epoch 4/200] [Batch 17/169] [D loss: 0.572718] [G loss: 1.160146]\n",
      "[Epoch 4/200] [Batch 18/169] [D loss: 0.613618] [G loss: 1.090714]\n",
      "[Epoch 4/200] [Batch 19/169] [D loss: 0.479964] [G loss: 1.298209]\n",
      "[Epoch 4/200] [Batch 20/169] [D loss: 0.497268] [G loss: 1.237890]\n",
      "[Epoch 4/200] [Batch 21/169] [D loss: 0.434649] [G loss: 1.154734]\n",
      "[Epoch 4/200] [Batch 22/169] [D loss: 0.413480] [G loss: 1.034573]\n",
      "[Epoch 4/200] [Batch 23/169] [D loss: 0.491921] [G loss: 1.575793]\n",
      "[Epoch 4/200] [Batch 24/169] [D loss: 0.520121] [G loss: 1.390155]\n",
      "[Epoch 4/200] [Batch 25/169] [D loss: 0.465007] [G loss: 1.303481]\n",
      "[Epoch 4/200] [Batch 26/169] [D loss: 0.505405] [G loss: 1.331026]\n",
      "[Epoch 4/200] [Batch 27/169] [D loss: 0.432959] [G loss: 1.292982]\n",
      "[Epoch 4/200] [Batch 28/169] [D loss: 0.498611] [G loss: 1.160412]\n",
      "[Epoch 4/200] [Batch 29/169] [D loss: 0.427476] [G loss: 1.241410]\n",
      "[Epoch 4/200] [Batch 30/169] [D loss: 0.485372] [G loss: 1.297133]\n",
      "[Epoch 4/200] [Batch 31/169] [D loss: 0.450314] [G loss: 1.238601]\n",
      "[Epoch 4/200] [Batch 32/169] [D loss: 0.403533] [G loss: 1.323812]\n",
      "[Epoch 4/200] [Batch 33/169] [D loss: 0.475232] [G loss: 1.180386]\n",
      "[Epoch 4/200] [Batch 34/169] [D loss: 0.591103] [G loss: 1.016376]\n",
      "[Epoch 4/200] [Batch 35/169] [D loss: 0.509601] [G loss: 1.060230]\n",
      "[Epoch 4/200] [Batch 36/169] [D loss: 0.666466] [G loss: 1.173055]\n",
      "[Epoch 4/200] [Batch 37/169] [D loss: 0.550658] [G loss: 1.157574]\n",
      "[Epoch 4/200] [Batch 38/169] [D loss: 0.493115] [G loss: 1.002029]\n",
      "[Epoch 4/200] [Batch 39/169] [D loss: 0.482719] [G loss: 1.105693]\n",
      "[Epoch 4/200] [Batch 40/169] [D loss: 0.562580] [G loss: 0.911144]\n",
      "[Epoch 4/200] [Batch 41/169] [D loss: 0.596301] [G loss: 1.146486]\n",
      "[Epoch 4/200] [Batch 42/169] [D loss: 0.591948] [G loss: 1.111285]\n",
      "[Epoch 4/200] [Batch 43/169] [D loss: 0.598037] [G loss: 1.257510]\n",
      "[Epoch 4/200] [Batch 44/169] [D loss: 0.575447] [G loss: 1.098997]\n",
      "[Epoch 4/200] [Batch 45/169] [D loss: 0.513645] [G loss: 1.117725]\n",
      "[Epoch 4/200] [Batch 46/169] [D loss: 0.595556] [G loss: 0.852881]\n",
      "[Epoch 4/200] [Batch 47/169] [D loss: 0.563721] [G loss: 1.231245]\n",
      "[Epoch 4/200] [Batch 48/169] [D loss: 0.520216] [G loss: 0.946893]\n",
      "[Epoch 4/200] [Batch 49/169] [D loss: 0.478529] [G loss: 1.154823]\n",
      "[Epoch 4/200] [Batch 50/169] [D loss: 0.569401] [G loss: 1.178622]\n",
      "[Epoch 4/200] [Batch 51/169] [D loss: 0.517723] [G loss: 0.929654]\n",
      "[Epoch 4/200] [Batch 52/169] [D loss: 0.526056] [G loss: 1.014052]\n",
      "[Epoch 4/200] [Batch 53/169] [D loss: 0.475549] [G loss: 1.149504]\n",
      "[Epoch 4/200] [Batch 54/169] [D loss: 0.496343] [G loss: 1.085723]\n",
      "[Epoch 4/200] [Batch 55/169] [D loss: 0.536408] [G loss: 1.054868]\n",
      "[Epoch 4/200] [Batch 56/169] [D loss: 0.512514] [G loss: 1.310515]\n",
      "[Epoch 4/200] [Batch 57/169] [D loss: 0.495388] [G loss: 1.174977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 58/169] [D loss: 0.459804] [G loss: 1.139495]\n",
      "[Epoch 4/200] [Batch 59/169] [D loss: 0.510644] [G loss: 0.941976]\n",
      "[Epoch 4/200] [Batch 60/169] [D loss: 0.541718] [G loss: 1.175361]\n",
      "[Epoch 4/200] [Batch 61/169] [D loss: 0.537049] [G loss: 1.238907]\n",
      "[Epoch 4/200] [Batch 62/169] [D loss: 0.488345] [G loss: 1.008180]\n",
      "[Epoch 4/200] [Batch 63/169] [D loss: 0.577425] [G loss: 1.146655]\n",
      "[Epoch 4/200] [Batch 64/169] [D loss: 0.534820] [G loss: 1.209145]\n",
      "[Epoch 4/200] [Batch 65/169] [D loss: 0.521695] [G loss: 1.056037]\n",
      "[Epoch 4/200] [Batch 66/169] [D loss: 0.466594] [G loss: 1.161083]\n",
      "[Epoch 4/200] [Batch 67/169] [D loss: 0.489805] [G loss: 1.248984]\n",
      "[Epoch 4/200] [Batch 68/169] [D loss: 0.515610] [G loss: 1.153428]\n",
      "[Epoch 4/200] [Batch 69/169] [D loss: 0.489062] [G loss: 0.934608]\n",
      "[Epoch 4/200] [Batch 70/169] [D loss: 0.483757] [G loss: 1.132715]\n",
      "[Epoch 4/200] [Batch 71/169] [D loss: 0.498535] [G loss: 1.074770]\n",
      "[Epoch 4/200] [Batch 72/169] [D loss: 0.487036] [G loss: 1.049506]\n",
      "[Epoch 4/200] [Batch 73/169] [D loss: 0.454648] [G loss: 1.105461]\n",
      "[Epoch 4/200] [Batch 74/169] [D loss: 0.562994] [G loss: 1.332373]\n",
      "[Epoch 4/200] [Batch 75/169] [D loss: 0.502650] [G loss: 1.361259]\n",
      "[Epoch 4/200] [Batch 76/169] [D loss: 0.450419] [G loss: 1.282822]\n",
      "[Epoch 4/200] [Batch 77/169] [D loss: 0.520199] [G loss: 0.861654]\n",
      "[Epoch 4/200] [Batch 78/169] [D loss: 0.526708] [G loss: 0.958346]\n",
      "[Epoch 4/200] [Batch 79/169] [D loss: 0.547746] [G loss: 1.209908]\n",
      "[Epoch 4/200] [Batch 80/169] [D loss: 0.565984] [G loss: 1.150168]\n",
      "[Epoch 4/200] [Batch 81/169] [D loss: 0.501572] [G loss: 1.302958]\n",
      "[Epoch 4/200] [Batch 82/169] [D loss: 0.436227] [G loss: 1.402332]\n",
      "[Epoch 4/200] [Batch 83/169] [D loss: 0.542850] [G loss: 1.475559]\n",
      "[Epoch 4/200] [Batch 84/169] [D loss: 0.544580] [G loss: 1.243852]\n",
      "[Epoch 4/200] [Batch 85/169] [D loss: 0.499582] [G loss: 1.396774]\n",
      "[Epoch 4/200] [Batch 86/169] [D loss: 0.545213] [G loss: 1.305327]\n",
      "[Epoch 4/200] [Batch 87/169] [D loss: 0.486068] [G loss: 0.981285]\n",
      "[Epoch 4/200] [Batch 88/169] [D loss: 0.531842] [G loss: 1.097954]\n",
      "[Epoch 4/200] [Batch 89/169] [D loss: 0.536516] [G loss: 1.244981]\n",
      "[Epoch 4/200] [Batch 90/169] [D loss: 0.498576] [G loss: 1.257217]\n",
      "[Epoch 4/200] [Batch 91/169] [D loss: 0.542111] [G loss: 1.215272]\n",
      "[Epoch 4/200] [Batch 92/169] [D loss: 0.467988] [G loss: 1.080215]\n",
      "[Epoch 4/200] [Batch 93/169] [D loss: 0.495166] [G loss: 0.965124]\n",
      "[Epoch 4/200] [Batch 94/169] [D loss: 0.452251] [G loss: 0.983334]\n",
      "[Epoch 4/200] [Batch 95/169] [D loss: 0.521013] [G loss: 1.104265]\n",
      "[Epoch 4/200] [Batch 96/169] [D loss: 0.538185] [G loss: 1.228664]\n",
      "[Epoch 4/200] [Batch 97/169] [D loss: 0.526059] [G loss: 1.009196]\n",
      "[Epoch 4/200] [Batch 98/169] [D loss: 0.575365] [G loss: 0.874998]\n",
      "[Epoch 4/200] [Batch 99/169] [D loss: 0.603349] [G loss: 1.021689]\n",
      "[Epoch 4/200] [Batch 100/169] [D loss: 0.571959] [G loss: 0.941131]\n",
      "[Epoch 4/200] [Batch 101/169] [D loss: 0.551793] [G loss: 1.075435]\n",
      "[Epoch 4/200] [Batch 102/169] [D loss: 0.448162] [G loss: 1.048484]\n",
      "[Epoch 4/200] [Batch 103/169] [D loss: 0.473824] [G loss: 1.335976]\n",
      "[Epoch 4/200] [Batch 104/169] [D loss: 0.372752] [G loss: 1.283566]\n",
      "[Epoch 4/200] [Batch 105/169] [D loss: 0.473012] [G loss: 1.079231]\n",
      "[Epoch 4/200] [Batch 106/169] [D loss: 0.422059] [G loss: 1.163516]\n",
      "[Epoch 4/200] [Batch 107/169] [D loss: 0.449003] [G loss: 1.479564]\n",
      "[Epoch 4/200] [Batch 108/169] [D loss: 0.423416] [G loss: 1.405601]\n",
      "[Epoch 4/200] [Batch 109/169] [D loss: 0.439448] [G loss: 1.304490]\n",
      "[Epoch 4/200] [Batch 110/169] [D loss: 0.460256] [G loss: 1.102952]\n",
      "[Epoch 4/200] [Batch 111/169] [D loss: 0.448492] [G loss: 1.035167]\n",
      "[Epoch 4/200] [Batch 112/169] [D loss: 0.611744] [G loss: 1.123684]\n",
      "[Epoch 4/200] [Batch 113/169] [D loss: 0.568273] [G loss: 1.208440]\n",
      "[Epoch 4/200] [Batch 114/169] [D loss: 0.596752] [G loss: 1.105060]\n",
      "[Epoch 4/200] [Batch 115/169] [D loss: 0.655165] [G loss: 1.113537]\n",
      "[Epoch 4/200] [Batch 116/169] [D loss: 0.525433] [G loss: 1.130320]\n",
      "[Epoch 4/200] [Batch 117/169] [D loss: 0.555837] [G loss: 1.003721]\n",
      "[Epoch 4/200] [Batch 118/169] [D loss: 0.549600] [G loss: 1.058301]\n",
      "[Epoch 4/200] [Batch 119/169] [D loss: 0.594182] [G loss: 1.202026]\n",
      "[Epoch 4/200] [Batch 120/169] [D loss: 0.534664] [G loss: 1.150156]\n",
      "[Epoch 4/200] [Batch 121/169] [D loss: 0.523293] [G loss: 1.101248]\n",
      "[Epoch 4/200] [Batch 122/169] [D loss: 0.492669] [G loss: 1.003287]\n",
      "[Epoch 4/200] [Batch 123/169] [D loss: 0.493943] [G loss: 0.956342]\n",
      "[Epoch 4/200] [Batch 124/169] [D loss: 0.639492] [G loss: 1.269987]\n",
      "[Epoch 4/200] [Batch 125/169] [D loss: 0.597494] [G loss: 1.252211]\n",
      "[Epoch 4/200] [Batch 126/169] [D loss: 0.584121] [G loss: 1.060083]\n",
      "[Epoch 4/200] [Batch 127/169] [D loss: 0.534008] [G loss: 1.167896]\n",
      "[Epoch 4/200] [Batch 128/169] [D loss: 0.476619] [G loss: 1.135050]\n",
      "[Epoch 4/200] [Batch 129/169] [D loss: 0.542024] [G loss: 1.189935]\n",
      "[Epoch 4/200] [Batch 130/169] [D loss: 0.501014] [G loss: 1.195620]\n",
      "[Epoch 4/200] [Batch 131/169] [D loss: 0.542117] [G loss: 1.069298]\n",
      "[Epoch 4/200] [Batch 132/169] [D loss: 0.466950] [G loss: 0.999465]\n",
      "[Epoch 4/200] [Batch 133/169] [D loss: 0.539318] [G loss: 1.070491]\n",
      "[Epoch 4/200] [Batch 134/169] [D loss: 0.555452] [G loss: 0.987987]\n",
      "[Epoch 4/200] [Batch 135/169] [D loss: 0.553493] [G loss: 1.205320]\n",
      "[Epoch 4/200] [Batch 136/169] [D loss: 0.525416] [G loss: 1.210409]\n",
      "[Epoch 4/200] [Batch 137/169] [D loss: 0.573238] [G loss: 1.180835]\n",
      "[Epoch 4/200] [Batch 138/169] [D loss: 0.510292] [G loss: 1.168244]\n",
      "[Epoch 4/200] [Batch 139/169] [D loss: 0.559002] [G loss: 1.085849]\n",
      "[Epoch 4/200] [Batch 140/169] [D loss: 0.528871] [G loss: 0.936144]\n",
      "[Epoch 4/200] [Batch 141/169] [D loss: 0.471803] [G loss: 0.924074]\n",
      "[Epoch 4/200] [Batch 142/169] [D loss: 0.538627] [G loss: 1.125665]\n",
      "[Epoch 4/200] [Batch 143/169] [D loss: 0.591615] [G loss: 1.065830]\n",
      "[Epoch 4/200] [Batch 144/169] [D loss: 0.506590] [G loss: 1.209966]\n",
      "[Epoch 4/200] [Batch 145/169] [D loss: 0.551345] [G loss: 1.003370]\n",
      "[Epoch 4/200] [Batch 146/169] [D loss: 0.569544] [G loss: 1.056887]\n",
      "[Epoch 4/200] [Batch 147/169] [D loss: 0.597325] [G loss: 1.183809]\n",
      "[Epoch 4/200] [Batch 148/169] [D loss: 0.530747] [G loss: 1.084789]\n",
      "[Epoch 4/200] [Batch 149/169] [D loss: 0.547295] [G loss: 1.305266]\n",
      "[Epoch 4/200] [Batch 150/169] [D loss: 0.505681] [G loss: 1.281171]\n",
      "[Epoch 4/200] [Batch 151/169] [D loss: 0.555436] [G loss: 1.181390]\n",
      "[Epoch 4/200] [Batch 152/169] [D loss: 0.516360] [G loss: 1.115091]\n",
      "[Epoch 4/200] [Batch 153/169] [D loss: 0.505182] [G loss: 1.080665]\n",
      "[Epoch 4/200] [Batch 154/169] [D loss: 0.611788] [G loss: 1.188264]\n",
      "[Epoch 4/200] [Batch 155/169] [D loss: 0.542253] [G loss: 0.902667]\n",
      "[Epoch 4/200] [Batch 156/169] [D loss: 0.565744] [G loss: 1.117891]\n",
      "[Epoch 4/200] [Batch 157/169] [D loss: 0.547464] [G loss: 1.239561]\n",
      "[Epoch 4/200] [Batch 158/169] [D loss: 0.538524] [G loss: 1.254800]\n",
      "[Epoch 4/200] [Batch 159/169] [D loss: 0.562855] [G loss: 0.914654]\n",
      "[Epoch 4/200] [Batch 160/169] [D loss: 0.571857] [G loss: 1.114470]\n",
      "[Epoch 4/200] [Batch 161/169] [D loss: 0.551969] [G loss: 0.922691]\n",
      "[Epoch 4/200] [Batch 162/169] [D loss: 0.510660] [G loss: 1.029320]\n",
      "[Epoch 4/200] [Batch 163/169] [D loss: 0.558061] [G loss: 1.150586]\n",
      "[Epoch 4/200] [Batch 164/169] [D loss: 0.566718] [G loss: 1.222332]\n",
      "[Epoch 4/200] [Batch 165/169] [D loss: 0.553425] [G loss: 1.317075]\n",
      "[Epoch 4/200] [Batch 166/169] [D loss: 0.541636] [G loss: 1.138736]\n",
      "[Epoch 4/200] [Batch 167/169] [D loss: 0.492379] [G loss: 0.879507]\n",
      "[Epoch 4/200] [Batch 168/169] [D loss: 0.607710] [G loss: 1.166202]\n",
      "[Epoch 5/200] [Batch 0/169] [D loss: 0.524994] [G loss: 1.030056]\n",
      "[Epoch 5/200] [Batch 1/169] [D loss: 0.563786] [G loss: 1.182669]\n",
      "[Epoch 5/200] [Batch 2/169] [D loss: 0.521784] [G loss: 1.225524]\n",
      "[Epoch 5/200] [Batch 3/169] [D loss: 0.469591] [G loss: 1.240396]\n",
      "[Epoch 5/200] [Batch 4/169] [D loss: 0.552628] [G loss: 1.055763]\n",
      "[Epoch 5/200] [Batch 5/169] [D loss: 0.650092] [G loss: 1.015544]\n",
      "[Epoch 5/200] [Batch 6/169] [D loss: 0.579347] [G loss: 0.885032]\n",
      "[Epoch 5/200] [Batch 7/169] [D loss: 0.562504] [G loss: 1.039597]\n",
      "[Epoch 5/200] [Batch 8/169] [D loss: 0.588281] [G loss: 1.195734]\n",
      "[Epoch 5/200] [Batch 9/169] [D loss: 0.514544] [G loss: 1.192505]\n",
      "[Epoch 5/200] [Batch 10/169] [D loss: 0.607933] [G loss: 1.103569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 11/169] [D loss: 0.515226] [G loss: 1.236914]\n",
      "[Epoch 5/200] [Batch 12/169] [D loss: 0.523283] [G loss: 1.053095]\n",
      "[Epoch 5/200] [Batch 13/169] [D loss: 0.519721] [G loss: 1.026459]\n",
      "[Epoch 5/200] [Batch 14/169] [D loss: 0.535618] [G loss: 0.933345]\n",
      "[Epoch 5/200] [Batch 15/169] [D loss: 0.494777] [G loss: 1.199399]\n",
      "[Epoch 5/200] [Batch 16/169] [D loss: 0.515052] [G loss: 1.320972]\n",
      "[Epoch 5/200] [Batch 17/169] [D loss: 0.542214] [G loss: 1.144801]\n",
      "[Epoch 5/200] [Batch 18/169] [D loss: 0.530194] [G loss: 1.194192]\n",
      "[Epoch 5/200] [Batch 19/169] [D loss: 0.544249] [G loss: 1.226152]\n",
      "[Epoch 5/200] [Batch 20/169] [D loss: 0.519623] [G loss: 0.904651]\n",
      "[Epoch 5/200] [Batch 21/169] [D loss: 0.577477] [G loss: 1.147313]\n",
      "[Epoch 5/200] [Batch 22/169] [D loss: 0.472804] [G loss: 1.072255]\n",
      "[Epoch 5/200] [Batch 23/169] [D loss: 0.495926] [G loss: 1.060905]\n",
      "[Epoch 5/200] [Batch 24/169] [D loss: 0.561184] [G loss: 1.065502]\n",
      "[Epoch 5/200] [Batch 25/169] [D loss: 0.569089] [G loss: 1.081791]\n",
      "[Epoch 5/200] [Batch 26/169] [D loss: 0.479996] [G loss: 0.967520]\n",
      "[Epoch 5/200] [Batch 27/169] [D loss: 0.528665] [G loss: 1.049945]\n",
      "[Epoch 5/200] [Batch 28/169] [D loss: 0.506697] [G loss: 0.975553]\n",
      "[Epoch 5/200] [Batch 29/169] [D loss: 0.502858] [G loss: 1.019067]\n",
      "[Epoch 5/200] [Batch 30/169] [D loss: 0.496566] [G loss: 1.026638]\n",
      "[Epoch 5/200] [Batch 31/169] [D loss: 0.528190] [G loss: 1.242698]\n",
      "[Epoch 5/200] [Batch 32/169] [D loss: 0.502065] [G loss: 0.956247]\n",
      "[Epoch 5/200] [Batch 33/169] [D loss: 0.512078] [G loss: 1.252476]\n",
      "[Epoch 5/200] [Batch 34/169] [D loss: 0.531201] [G loss: 1.247417]\n",
      "[Epoch 5/200] [Batch 35/169] [D loss: 0.497358] [G loss: 1.145294]\n",
      "[Epoch 5/200] [Batch 36/169] [D loss: 0.447381] [G loss: 1.202176]\n",
      "[Epoch 5/200] [Batch 37/169] [D loss: 0.551715] [G loss: 1.104704]\n",
      "[Epoch 5/200] [Batch 38/169] [D loss: 0.488394] [G loss: 1.134650]\n",
      "[Epoch 5/200] [Batch 39/169] [D loss: 0.529882] [G loss: 1.113381]\n",
      "[Epoch 5/200] [Batch 40/169] [D loss: 0.474066] [G loss: 1.389174]\n",
      "[Epoch 5/200] [Batch 41/169] [D loss: 0.548754] [G loss: 1.073935]\n",
      "[Epoch 5/200] [Batch 42/169] [D loss: 0.538663] [G loss: 0.991333]\n",
      "[Epoch 5/200] [Batch 43/169] [D loss: 0.503570] [G loss: 1.233402]\n",
      "[Epoch 5/200] [Batch 44/169] [D loss: 0.464223] [G loss: 1.111805]\n",
      "[Epoch 5/200] [Batch 45/169] [D loss: 0.488410] [G loss: 1.187515]\n",
      "[Epoch 5/200] [Batch 46/169] [D loss: 0.542615] [G loss: 1.232882]\n",
      "[Epoch 5/200] [Batch 47/169] [D loss: 0.494628] [G loss: 1.023507]\n",
      "[Epoch 5/200] [Batch 48/169] [D loss: 0.454542] [G loss: 1.369982]\n",
      "[Epoch 5/200] [Batch 49/169] [D loss: 0.527504] [G loss: 0.978115]\n",
      "[Epoch 5/200] [Batch 50/169] [D loss: 0.518751] [G loss: 1.177516]\n",
      "[Epoch 5/200] [Batch 51/169] [D loss: 0.537730] [G loss: 1.046631]\n",
      "[Epoch 5/200] [Batch 52/169] [D loss: 0.480795] [G loss: 1.263619]\n",
      "[Epoch 5/200] [Batch 53/169] [D loss: 0.483379] [G loss: 1.412770]\n",
      "[Epoch 5/200] [Batch 54/169] [D loss: 0.506427] [G loss: 1.164534]\n",
      "[Epoch 5/200] [Batch 55/169] [D loss: 0.561384] [G loss: 1.172186]\n",
      "[Epoch 5/200] [Batch 56/169] [D loss: 0.500459] [G loss: 1.066481]\n",
      "[Epoch 5/200] [Batch 57/169] [D loss: 0.551123] [G loss: 1.164502]\n",
      "[Epoch 5/200] [Batch 58/169] [D loss: 0.498821] [G loss: 1.044865]\n",
      "[Epoch 5/200] [Batch 59/169] [D loss: 0.514063] [G loss: 1.018480]\n",
      "[Epoch 5/200] [Batch 60/169] [D loss: 0.585977] [G loss: 0.963858]\n",
      "[Epoch 5/200] [Batch 61/169] [D loss: 0.496144] [G loss: 1.081434]\n",
      "[Epoch 5/200] [Batch 62/169] [D loss: 0.495694] [G loss: 1.071446]\n",
      "[Epoch 5/200] [Batch 63/169] [D loss: 0.554339] [G loss: 1.096346]\n",
      "[Epoch 5/200] [Batch 64/169] [D loss: 0.463619] [G loss: 1.091149]\n",
      "[Epoch 5/200] [Batch 65/169] [D loss: 0.548681] [G loss: 1.007482]\n",
      "[Epoch 5/200] [Batch 66/169] [D loss: 0.498136] [G loss: 1.073464]\n",
      "[Epoch 5/200] [Batch 67/169] [D loss: 0.523369] [G loss: 1.120654]\n",
      "[Epoch 5/200] [Batch 68/169] [D loss: 0.502602] [G loss: 1.169973]\n",
      "[Epoch 5/200] [Batch 69/169] [D loss: 0.526208] [G loss: 1.157021]\n",
      "[Epoch 5/200] [Batch 70/169] [D loss: 0.533979] [G loss: 1.226316]\n",
      "[Epoch 5/200] [Batch 71/169] [D loss: 0.566249] [G loss: 1.105284]\n",
      "[Epoch 5/200] [Batch 72/169] [D loss: 0.556975] [G loss: 1.165684]\n",
      "[Epoch 5/200] [Batch 73/169] [D loss: 0.530109] [G loss: 1.240107]\n",
      "[Epoch 5/200] [Batch 74/169] [D loss: 0.497893] [G loss: 1.111327]\n",
      "[Epoch 5/200] [Batch 75/169] [D loss: 0.570360] [G loss: 1.001940]\n",
      "[Epoch 5/200] [Batch 76/169] [D loss: 0.518901] [G loss: 1.097726]\n",
      "[Epoch 5/200] [Batch 77/169] [D loss: 0.516306] [G loss: 1.209294]\n",
      "[Epoch 5/200] [Batch 78/169] [D loss: 0.568706] [G loss: 1.178479]\n",
      "[Epoch 5/200] [Batch 79/169] [D loss: 0.545759] [G loss: 1.158407]\n",
      "[Epoch 5/200] [Batch 80/169] [D loss: 0.490449] [G loss: 0.975961]\n",
      "[Epoch 5/200] [Batch 81/169] [D loss: 0.591796] [G loss: 1.157483]\n",
      "[Epoch 5/200] [Batch 82/169] [D loss: 0.482180] [G loss: 1.372588]\n",
      "[Epoch 5/200] [Batch 83/169] [D loss: 0.448772] [G loss: 1.242782]\n",
      "[Epoch 5/200] [Batch 84/169] [D loss: 0.442216] [G loss: 1.076358]\n",
      "[Epoch 5/200] [Batch 85/169] [D loss: 0.542076] [G loss: 1.106015]\n",
      "[Epoch 5/200] [Batch 86/169] [D loss: 0.510444] [G loss: 1.080840]\n",
      "[Epoch 5/200] [Batch 87/169] [D loss: 0.531514] [G loss: 1.115839]\n",
      "[Epoch 5/200] [Batch 88/169] [D loss: 0.513268] [G loss: 1.310231]\n",
      "[Epoch 5/200] [Batch 89/169] [D loss: 0.505951] [G loss: 1.209303]\n",
      "[Epoch 5/200] [Batch 90/169] [D loss: 0.486358] [G loss: 1.032535]\n",
      "[Epoch 5/200] [Batch 91/169] [D loss: 0.553234] [G loss: 0.924704]\n",
      "[Epoch 5/200] [Batch 92/169] [D loss: 0.527682] [G loss: 1.032850]\n",
      "[Epoch 5/200] [Batch 93/169] [D loss: 0.593019] [G loss: 1.140808]\n",
      "[Epoch 5/200] [Batch 94/169] [D loss: 0.507697] [G loss: 1.118876]\n",
      "[Epoch 5/200] [Batch 95/169] [D loss: 0.460291] [G loss: 1.271636]\n",
      "[Epoch 5/200] [Batch 96/169] [D loss: 0.567242] [G loss: 1.260800]\n",
      "[Epoch 5/200] [Batch 97/169] [D loss: 0.470727] [G loss: 1.101684]\n",
      "[Epoch 5/200] [Batch 98/169] [D loss: 0.559484] [G loss: 1.247400]\n",
      "[Epoch 5/200] [Batch 99/169] [D loss: 0.518650] [G loss: 1.128526]\n",
      "[Epoch 5/200] [Batch 100/169] [D loss: 0.479111] [G loss: 1.000508]\n",
      "[Epoch 5/200] [Batch 101/169] [D loss: 0.580153] [G loss: 1.121031]\n",
      "[Epoch 5/200] [Batch 102/169] [D loss: 0.522228] [G loss: 1.048791]\n",
      "[Epoch 5/200] [Batch 103/169] [D loss: 0.507160] [G loss: 0.959198]\n",
      "[Epoch 5/200] [Batch 104/169] [D loss: 0.507996] [G loss: 1.103291]\n",
      "[Epoch 5/200] [Batch 105/169] [D loss: 0.550440] [G loss: 0.898146]\n",
      "[Epoch 5/200] [Batch 106/169] [D loss: 0.560283] [G loss: 0.940877]\n",
      "[Epoch 5/200] [Batch 107/169] [D loss: 0.583705] [G loss: 0.963275]\n",
      "[Epoch 5/200] [Batch 108/169] [D loss: 0.571449] [G loss: 0.979641]\n",
      "[Epoch 5/200] [Batch 109/169] [D loss: 0.567847] [G loss: 1.050477]\n",
      "[Epoch 5/200] [Batch 110/169] [D loss: 0.535744] [G loss: 1.079579]\n",
      "[Epoch 5/200] [Batch 111/169] [D loss: 0.705092] [G loss: 0.967518]\n",
      "[Epoch 5/200] [Batch 112/169] [D loss: 0.548484] [G loss: 0.883853]\n",
      "[Epoch 5/200] [Batch 113/169] [D loss: 0.592295] [G loss: 1.112949]\n",
      "[Epoch 5/200] [Batch 114/169] [D loss: 0.490985] [G loss: 1.325490]\n",
      "[Epoch 5/200] [Batch 115/169] [D loss: 0.508125] [G loss: 1.424775]\n",
      "[Epoch 5/200] [Batch 116/169] [D loss: 0.495171] [G loss: 1.682008]\n",
      "[Epoch 5/200] [Batch 117/169] [D loss: 0.513820] [G loss: 1.271026]\n",
      "[Epoch 5/200] [Batch 118/169] [D loss: 0.502549] [G loss: 1.239379]\n",
      "[Epoch 5/200] [Batch 119/169] [D loss: 0.505247] [G loss: 0.916565]\n",
      "[Epoch 5/200] [Batch 120/169] [D loss: 0.565132] [G loss: 0.785663]\n",
      "[Epoch 5/200] [Batch 121/169] [D loss: 0.557051] [G loss: 0.960204]\n",
      "[Epoch 5/200] [Batch 122/169] [D loss: 0.600444] [G loss: 0.975823]\n",
      "[Epoch 5/200] [Batch 123/169] [D loss: 0.554089] [G loss: 1.226047]\n",
      "[Epoch 5/200] [Batch 124/169] [D loss: 0.503381] [G loss: 1.212248]\n",
      "[Epoch 5/200] [Batch 125/169] [D loss: 0.561691] [G loss: 1.054623]\n",
      "[Epoch 5/200] [Batch 126/169] [D loss: 0.467297] [G loss: 1.228017]\n",
      "[Epoch 5/200] [Batch 127/169] [D loss: 0.581926] [G loss: 1.128434]\n",
      "[Epoch 5/200] [Batch 128/169] [D loss: 0.507455] [G loss: 1.002793]\n",
      "[Epoch 5/200] [Batch 129/169] [D loss: 0.589661] [G loss: 1.085141]\n",
      "[Epoch 5/200] [Batch 130/169] [D loss: 0.551996] [G loss: 1.159894]\n",
      "[Epoch 5/200] [Batch 131/169] [D loss: 0.541828] [G loss: 1.122602]\n",
      "[Epoch 5/200] [Batch 132/169] [D loss: 0.568554] [G loss: 1.119997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 133/169] [D loss: 0.570557] [G loss: 1.090564]\n",
      "[Epoch 5/200] [Batch 134/169] [D loss: 0.529400] [G loss: 1.164801]\n",
      "[Epoch 5/200] [Batch 135/169] [D loss: 0.512588] [G loss: 1.017322]\n",
      "[Epoch 5/200] [Batch 136/169] [D loss: 0.488371] [G loss: 1.073961]\n",
      "[Epoch 5/200] [Batch 137/169] [D loss: 0.523481] [G loss: 1.051050]\n",
      "[Epoch 5/200] [Batch 138/169] [D loss: 0.523330] [G loss: 0.993196]\n",
      "[Epoch 5/200] [Batch 139/169] [D loss: 0.549156] [G loss: 1.260045]\n",
      "[Epoch 5/200] [Batch 140/169] [D loss: 0.620564] [G loss: 1.072214]\n",
      "[Epoch 5/200] [Batch 141/169] [D loss: 0.611525] [G loss: 1.035319]\n",
      "[Epoch 5/200] [Batch 142/169] [D loss: 0.565983] [G loss: 1.041776]\n",
      "[Epoch 5/200] [Batch 143/169] [D loss: 0.510758] [G loss: 0.988162]\n",
      "[Epoch 5/200] [Batch 144/169] [D loss: 0.507815] [G loss: 0.893444]\n",
      "[Epoch 5/200] [Batch 145/169] [D loss: 0.479684] [G loss: 1.006768]\n",
      "[Epoch 5/200] [Batch 146/169] [D loss: 0.530029] [G loss: 1.135927]\n",
      "[Epoch 5/200] [Batch 147/169] [D loss: 0.582418] [G loss: 1.015578]\n",
      "[Epoch 5/200] [Batch 148/169] [D loss: 0.566551] [G loss: 0.922906]\n",
      "[Epoch 5/200] [Batch 149/169] [D loss: 0.557914] [G loss: 1.186411]\n",
      "[Epoch 5/200] [Batch 150/169] [D loss: 0.520057] [G loss: 1.135215]\n",
      "[Epoch 5/200] [Batch 151/169] [D loss: 0.591020] [G loss: 1.055089]\n",
      "[Epoch 5/200] [Batch 152/169] [D loss: 0.537680] [G loss: 1.079392]\n",
      "[Epoch 5/200] [Batch 153/169] [D loss: 0.501466] [G loss: 1.150076]\n",
      "[Epoch 5/200] [Batch 154/169] [D loss: 0.497701] [G loss: 1.068517]\n",
      "[Epoch 5/200] [Batch 155/169] [D loss: 0.531159] [G loss: 0.934043]\n",
      "[Epoch 5/200] [Batch 156/169] [D loss: 0.506952] [G loss: 1.069693]\n",
      "[Epoch 5/200] [Batch 157/169] [D loss: 0.521104] [G loss: 1.101381]\n",
      "[Epoch 5/200] [Batch 158/169] [D loss: 0.525555] [G loss: 1.053228]\n",
      "[Epoch 5/200] [Batch 159/169] [D loss: 0.524050] [G loss: 1.202647]\n",
      "[Epoch 5/200] [Batch 160/169] [D loss: 0.605305] [G loss: 1.150852]\n",
      "[Epoch 5/200] [Batch 161/169] [D loss: 0.549203] [G loss: 1.180973]\n",
      "[Epoch 5/200] [Batch 162/169] [D loss: 0.522061] [G loss: 1.196425]\n",
      "[Epoch 5/200] [Batch 163/169] [D loss: 0.539721] [G loss: 1.075099]\n",
      "[Epoch 5/200] [Batch 164/169] [D loss: 0.538925] [G loss: 1.218260]\n",
      "[Epoch 5/200] [Batch 165/169] [D loss: 0.540580] [G loss: 1.044668]\n",
      "[Epoch 5/200] [Batch 166/169] [D loss: 0.483235] [G loss: 1.104534]\n",
      "[Epoch 5/200] [Batch 167/169] [D loss: 0.505318] [G loss: 1.082920]\n",
      "[Epoch 5/200] [Batch 168/169] [D loss: 0.658484] [G loss: 1.133997]\n",
      "[Epoch 6/200] [Batch 0/169] [D loss: 0.506379] [G loss: 1.152596]\n",
      "[Epoch 6/200] [Batch 1/169] [D loss: 0.506783] [G loss: 1.406527]\n",
      "[Epoch 6/200] [Batch 2/169] [D loss: 0.518691] [G loss: 1.115866]\n",
      "[Epoch 6/200] [Batch 3/169] [D loss: 0.533663] [G loss: 0.993412]\n",
      "[Epoch 6/200] [Batch 4/169] [D loss: 0.588514] [G loss: 0.991858]\n",
      "[Epoch 6/200] [Batch 5/169] [D loss: 0.554453] [G loss: 0.895003]\n",
      "[Epoch 6/200] [Batch 6/169] [D loss: 0.497432] [G loss: 1.030082]\n",
      "[Epoch 6/200] [Batch 7/169] [D loss: 0.556273] [G loss: 1.199622]\n",
      "[Epoch 6/200] [Batch 8/169] [D loss: 0.535082] [G loss: 0.987560]\n",
      "[Epoch 6/200] [Batch 9/169] [D loss: 0.504908] [G loss: 1.285865]\n",
      "[Epoch 6/200] [Batch 10/169] [D loss: 0.512328] [G loss: 1.370546]\n",
      "[Epoch 6/200] [Batch 11/169] [D loss: 0.546389] [G loss: 1.050381]\n",
      "[Epoch 6/200] [Batch 12/169] [D loss: 0.578959] [G loss: 1.337774]\n",
      "[Epoch 6/200] [Batch 13/169] [D loss: 0.517679] [G loss: 0.988643]\n",
      "[Epoch 6/200] [Batch 14/169] [D loss: 0.458013] [G loss: 1.132121]\n",
      "[Epoch 6/200] [Batch 15/169] [D loss: 0.521089] [G loss: 1.030779]\n",
      "[Epoch 6/200] [Batch 16/169] [D loss: 0.518872] [G loss: 1.151199]\n",
      "[Epoch 6/200] [Batch 17/169] [D loss: 0.444343] [G loss: 1.238547]\n",
      "[Epoch 6/200] [Batch 18/169] [D loss: 0.492939] [G loss: 1.130738]\n",
      "[Epoch 6/200] [Batch 19/169] [D loss: 0.511966] [G loss: 1.173262]\n",
      "[Epoch 6/200] [Batch 20/169] [D loss: 0.514248] [G loss: 1.156806]\n",
      "[Epoch 6/200] [Batch 21/169] [D loss: 0.491003] [G loss: 0.892707]\n",
      "[Epoch 6/200] [Batch 22/169] [D loss: 0.507607] [G loss: 1.025456]\n",
      "[Epoch 6/200] [Batch 23/169] [D loss: 0.578965] [G loss: 1.032166]\n",
      "[Epoch 6/200] [Batch 24/169] [D loss: 0.540736] [G loss: 1.206522]\n",
      "[Epoch 6/200] [Batch 25/169] [D loss: 0.432631] [G loss: 1.114963]\n",
      "[Epoch 6/200] [Batch 26/169] [D loss: 0.502678] [G loss: 1.114366]\n",
      "[Epoch 6/200] [Batch 27/169] [D loss: 0.567455] [G loss: 1.141631]\n",
      "[Epoch 6/200] [Batch 28/169] [D loss: 0.562997] [G loss: 1.110668]\n",
      "[Epoch 6/200] [Batch 29/169] [D loss: 0.465450] [G loss: 1.017955]\n",
      "[Epoch 6/200] [Batch 30/169] [D loss: 0.456960] [G loss: 1.002504]\n",
      "[Epoch 6/200] [Batch 31/169] [D loss: 0.519111] [G loss: 1.145984]\n",
      "[Epoch 6/200] [Batch 32/169] [D loss: 0.505781] [G loss: 0.935500]\n",
      "[Epoch 6/200] [Batch 33/169] [D loss: 0.413101] [G loss: 1.107990]\n",
      "[Epoch 6/200] [Batch 34/169] [D loss: 0.547241] [G loss: 0.951204]\n",
      "[Epoch 6/200] [Batch 35/169] [D loss: 0.548000] [G loss: 1.257071]\n",
      "[Epoch 6/200] [Batch 36/169] [D loss: 0.490392] [G loss: 1.138710]\n",
      "[Epoch 6/200] [Batch 37/169] [D loss: 0.453633] [G loss: 1.319111]\n",
      "[Epoch 6/200] [Batch 38/169] [D loss: 0.428635] [G loss: 1.169914]\n",
      "[Epoch 6/200] [Batch 39/169] [D loss: 0.491751] [G loss: 1.143770]\n",
      "[Epoch 6/200] [Batch 40/169] [D loss: 0.526615] [G loss: 1.141343]\n",
      "[Epoch 6/200] [Batch 41/169] [D loss: 0.526425] [G loss: 1.200289]\n",
      "[Epoch 6/200] [Batch 42/169] [D loss: 0.543819] [G loss: 1.228772]\n",
      "[Epoch 6/200] [Batch 43/169] [D loss: 0.507439] [G loss: 1.134911]\n",
      "[Epoch 6/200] [Batch 44/169] [D loss: 0.534550] [G loss: 1.168962]\n",
      "[Epoch 6/200] [Batch 45/169] [D loss: 0.498081] [G loss: 1.157079]\n",
      "[Epoch 6/200] [Batch 46/169] [D loss: 0.585527] [G loss: 1.054487]\n",
      "[Epoch 6/200] [Batch 47/169] [D loss: 0.548605] [G loss: 0.982716]\n",
      "[Epoch 6/200] [Batch 48/169] [D loss: 0.595915] [G loss: 0.947260]\n",
      "[Epoch 6/200] [Batch 49/169] [D loss: 0.589718] [G loss: 0.906679]\n",
      "[Epoch 6/200] [Batch 50/169] [D loss: 0.625371] [G loss: 0.927097]\n",
      "[Epoch 6/200] [Batch 51/169] [D loss: 0.604486] [G loss: 0.924057]\n",
      "[Epoch 6/200] [Batch 52/169] [D loss: 0.544687] [G loss: 0.908400]\n",
      "[Epoch 6/200] [Batch 53/169] [D loss: 0.536464] [G loss: 1.065037]\n",
      "[Epoch 6/200] [Batch 54/169] [D loss: 0.447866] [G loss: 0.958542]\n",
      "[Epoch 6/200] [Batch 55/169] [D loss: 0.604015] [G loss: 1.061953]\n",
      "[Epoch 6/200] [Batch 56/169] [D loss: 0.507929] [G loss: 1.020516]\n",
      "[Epoch 6/200] [Batch 57/169] [D loss: 0.499277] [G loss: 0.987614]\n",
      "[Epoch 6/200] [Batch 58/169] [D loss: 0.444618] [G loss: 1.185022]\n",
      "[Epoch 6/200] [Batch 59/169] [D loss: 0.464247] [G loss: 1.086173]\n",
      "[Epoch 6/200] [Batch 60/169] [D loss: 0.451457] [G loss: 0.996705]\n",
      "[Epoch 6/200] [Batch 61/169] [D loss: 0.575681] [G loss: 1.070473]\n",
      "[Epoch 6/200] [Batch 62/169] [D loss: 0.509089] [G loss: 1.126322]\n",
      "[Epoch 6/200] [Batch 63/169] [D loss: 0.572968] [G loss: 1.142519]\n",
      "[Epoch 6/200] [Batch 64/169] [D loss: 0.545307] [G loss: 0.998809]\n",
      "[Epoch 6/200] [Batch 65/169] [D loss: 0.552559] [G loss: 1.006465]\n",
      "[Epoch 6/200] [Batch 66/169] [D loss: 0.607312] [G loss: 1.064473]\n",
      "[Epoch 6/200] [Batch 67/169] [D loss: 0.615829] [G loss: 1.042936]\n",
      "[Epoch 6/200] [Batch 68/169] [D loss: 0.524412] [G loss: 1.265011]\n",
      "[Epoch 6/200] [Batch 69/169] [D loss: 0.566832] [G loss: 1.164189]\n",
      "[Epoch 6/200] [Batch 70/169] [D loss: 0.582255] [G loss: 0.930912]\n",
      "[Epoch 6/200] [Batch 71/169] [D loss: 0.486595] [G loss: 1.258020]\n",
      "[Epoch 6/200] [Batch 72/169] [D loss: 0.575089] [G loss: 1.133913]\n",
      "[Epoch 6/200] [Batch 73/169] [D loss: 0.606794] [G loss: 1.079419]\n",
      "[Epoch 6/200] [Batch 74/169] [D loss: 0.558199] [G loss: 0.935808]\n",
      "[Epoch 6/200] [Batch 75/169] [D loss: 0.596839] [G loss: 0.952920]\n",
      "[Epoch 6/200] [Batch 76/169] [D loss: 0.516666] [G loss: 1.117135]\n",
      "[Epoch 6/200] [Batch 77/169] [D loss: 0.542702] [G loss: 1.069850]\n",
      "[Epoch 6/200] [Batch 78/169] [D loss: 0.608049] [G loss: 1.118866]\n",
      "[Epoch 6/200] [Batch 79/169] [D loss: 0.509041] [G loss: 0.877882]\n",
      "[Epoch 6/200] [Batch 80/169] [D loss: 0.499948] [G loss: 1.095307]\n",
      "[Epoch 6/200] [Batch 81/169] [D loss: 0.521695] [G loss: 0.998252]\n",
      "[Epoch 6/200] [Batch 82/169] [D loss: 0.495012] [G loss: 1.113062]\n",
      "[Epoch 6/200] [Batch 83/169] [D loss: 0.554797] [G loss: 1.279445]\n",
      "[Epoch 6/200] [Batch 84/169] [D loss: 0.596426] [G loss: 0.934945]\n",
      "[Epoch 6/200] [Batch 85/169] [D loss: 0.616359] [G loss: 1.090625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 86/169] [D loss: 0.530808] [G loss: 1.164933]\n",
      "[Epoch 6/200] [Batch 87/169] [D loss: 0.506691] [G loss: 1.146908]\n",
      "[Epoch 6/200] [Batch 88/169] [D loss: 0.509386] [G loss: 1.102808]\n",
      "[Epoch 6/200] [Batch 89/169] [D loss: 0.510248] [G loss: 1.069929]\n",
      "[Epoch 6/200] [Batch 90/169] [D loss: 0.472812] [G loss: 1.172777]\n",
      "[Epoch 6/200] [Batch 91/169] [D loss: 0.460531] [G loss: 1.242897]\n",
      "[Epoch 6/200] [Batch 92/169] [D loss: 0.498517] [G loss: 1.208761]\n",
      "[Epoch 6/200] [Batch 93/169] [D loss: 0.465976] [G loss: 1.141811]\n",
      "[Epoch 6/200] [Batch 94/169] [D loss: 0.492697] [G loss: 1.133975]\n",
      "[Epoch 6/200] [Batch 95/169] [D loss: 0.492430] [G loss: 1.017207]\n",
      "[Epoch 6/200] [Batch 96/169] [D loss: 0.468138] [G loss: 0.883600]\n",
      "[Epoch 6/200] [Batch 97/169] [D loss: 0.553576] [G loss: 1.088908]\n",
      "[Epoch 6/200] [Batch 98/169] [D loss: 0.541318] [G loss: 0.940075]\n",
      "[Epoch 6/200] [Batch 99/169] [D loss: 0.572758] [G loss: 1.004861]\n",
      "[Epoch 6/200] [Batch 100/169] [D loss: 0.649197] [G loss: 1.092896]\n",
      "[Epoch 6/200] [Batch 101/169] [D loss: 0.569159] [G loss: 1.026020]\n",
      "[Epoch 6/200] [Batch 102/169] [D loss: 0.510780] [G loss: 1.090194]\n",
      "[Epoch 6/200] [Batch 103/169] [D loss: 0.632193] [G loss: 1.092909]\n",
      "[Epoch 6/200] [Batch 104/169] [D loss: 0.511484] [G loss: 0.946245]\n",
      "[Epoch 6/200] [Batch 105/169] [D loss: 0.540809] [G loss: 1.071563]\n",
      "[Epoch 6/200] [Batch 106/169] [D loss: 0.581610] [G loss: 0.973120]\n",
      "[Epoch 6/200] [Batch 107/169] [D loss: 0.578082] [G loss: 0.912920]\n",
      "[Epoch 6/200] [Batch 108/169] [D loss: 0.562808] [G loss: 0.976485]\n",
      "[Epoch 6/200] [Batch 109/169] [D loss: 0.584782] [G loss: 1.055945]\n",
      "[Epoch 6/200] [Batch 110/169] [D loss: 0.577509] [G loss: 0.997904]\n",
      "[Epoch 6/200] [Batch 111/169] [D loss: 0.569413] [G loss: 1.088100]\n",
      "[Epoch 6/200] [Batch 112/169] [D loss: 0.538480] [G loss: 0.960733]\n",
      "[Epoch 6/200] [Batch 113/169] [D loss: 0.563636] [G loss: 1.117256]\n",
      "[Epoch 6/200] [Batch 114/169] [D loss: 0.556498] [G loss: 0.950079]\n",
      "[Epoch 6/200] [Batch 115/169] [D loss: 0.554425] [G loss: 1.126299]\n",
      "[Epoch 6/200] [Batch 116/169] [D loss: 0.453067] [G loss: 1.296881]\n",
      "[Epoch 6/200] [Batch 117/169] [D loss: 0.520740] [G loss: 1.160092]\n",
      "[Epoch 6/200] [Batch 118/169] [D loss: 0.543271] [G loss: 1.049441]\n",
      "[Epoch 6/200] [Batch 119/169] [D loss: 0.486164] [G loss: 1.083246]\n",
      "[Epoch 6/200] [Batch 120/169] [D loss: 0.607448] [G loss: 1.239697]\n",
      "[Epoch 6/200] [Batch 121/169] [D loss: 0.475235] [G loss: 0.988352]\n",
      "[Epoch 6/200] [Batch 122/169] [D loss: 0.489048] [G loss: 1.115547]\n",
      "[Epoch 6/200] [Batch 123/169] [D loss: 0.512682] [G loss: 1.148219]\n",
      "[Epoch 6/200] [Batch 124/169] [D loss: 0.530178] [G loss: 1.011887]\n",
      "[Epoch 6/200] [Batch 125/169] [D loss: 0.614214] [G loss: 1.055755]\n",
      "[Epoch 6/200] [Batch 126/169] [D loss: 0.566374] [G loss: 0.798889]\n",
      "[Epoch 6/200] [Batch 127/169] [D loss: 0.534131] [G loss: 0.952234]\n",
      "[Epoch 6/200] [Batch 128/169] [D loss: 0.569855] [G loss: 1.119019]\n",
      "[Epoch 6/200] [Batch 129/169] [D loss: 0.573477] [G loss: 1.208044]\n",
      "[Epoch 6/200] [Batch 130/169] [D loss: 0.514018] [G loss: 1.067662]\n",
      "[Epoch 6/200] [Batch 131/169] [D loss: 0.561968] [G loss: 1.012609]\n",
      "[Epoch 6/200] [Batch 132/169] [D loss: 0.541659] [G loss: 0.952630]\n",
      "[Epoch 6/200] [Batch 133/169] [D loss: 0.498968] [G loss: 1.093816]\n",
      "[Epoch 6/200] [Batch 134/169] [D loss: 0.544964] [G loss: 1.164326]\n",
      "[Epoch 6/200] [Batch 135/169] [D loss: 0.597280] [G loss: 1.177722]\n",
      "[Epoch 6/200] [Batch 136/169] [D loss: 0.510164] [G loss: 1.318257]\n",
      "[Epoch 6/200] [Batch 137/169] [D loss: 0.491887] [G loss: 1.380745]\n",
      "[Epoch 6/200] [Batch 138/169] [D loss: 0.568534] [G loss: 1.112460]\n",
      "[Epoch 6/200] [Batch 139/169] [D loss: 0.573582] [G loss: 1.003355]\n",
      "[Epoch 6/200] [Batch 140/169] [D loss: 0.494129] [G loss: 1.127516]\n",
      "[Epoch 6/200] [Batch 141/169] [D loss: 0.566381] [G loss: 1.158009]\n",
      "[Epoch 6/200] [Batch 142/169] [D loss: 0.522643] [G loss: 0.962654]\n",
      "[Epoch 6/200] [Batch 143/169] [D loss: 0.556107] [G loss: 0.890000]\n",
      "[Epoch 6/200] [Batch 144/169] [D loss: 0.556960] [G loss: 1.008655]\n",
      "[Epoch 6/200] [Batch 145/169] [D loss: 0.494014] [G loss: 1.013007]\n",
      "[Epoch 6/200] [Batch 146/169] [D loss: 0.541451] [G loss: 1.184103]\n",
      "[Epoch 6/200] [Batch 147/169] [D loss: 0.532495] [G loss: 1.018919]\n",
      "[Epoch 6/200] [Batch 148/169] [D loss: 0.566213] [G loss: 1.045537]\n",
      "[Epoch 6/200] [Batch 149/169] [D loss: 0.586680] [G loss: 0.865814]\n",
      "[Epoch 6/200] [Batch 150/169] [D loss: 0.612616] [G loss: 0.909751]\n",
      "[Epoch 6/200] [Batch 151/169] [D loss: 0.619075] [G loss: 0.928120]\n",
      "[Epoch 6/200] [Batch 152/169] [D loss: 0.597202] [G loss: 1.252157]\n",
      "[Epoch 6/200] [Batch 153/169] [D loss: 0.573743] [G loss: 1.044471]\n",
      "[Epoch 6/200] [Batch 154/169] [D loss: 0.542597] [G loss: 1.032334]\n",
      "[Epoch 6/200] [Batch 155/169] [D loss: 0.501976] [G loss: 0.883683]\n",
      "[Epoch 6/200] [Batch 156/169] [D loss: 0.573180] [G loss: 1.306370]\n",
      "[Epoch 6/200] [Batch 157/169] [D loss: 0.531010] [G loss: 1.304726]\n",
      "[Epoch 6/200] [Batch 158/169] [D loss: 0.467777] [G loss: 1.195047]\n",
      "[Epoch 6/200] [Batch 159/169] [D loss: 0.611220] [G loss: 1.071645]\n",
      "[Epoch 6/200] [Batch 160/169] [D loss: 0.535053] [G loss: 1.225204]\n",
      "[Epoch 6/200] [Batch 161/169] [D loss: 0.517169] [G loss: 1.093008]\n",
      "[Epoch 6/200] [Batch 162/169] [D loss: 0.442182] [G loss: 1.327851]\n",
      "[Epoch 6/200] [Batch 163/169] [D loss: 0.511419] [G loss: 1.067274]\n",
      "[Epoch 6/200] [Batch 164/169] [D loss: 0.541148] [G loss: 1.046690]\n",
      "[Epoch 6/200] [Batch 165/169] [D loss: 0.514575] [G loss: 1.093370]\n",
      "[Epoch 6/200] [Batch 166/169] [D loss: 0.608428] [G loss: 0.890497]\n",
      "[Epoch 6/200] [Batch 167/169] [D loss: 0.501304] [G loss: 1.084845]\n",
      "[Epoch 6/200] [Batch 168/169] [D loss: 0.560441] [G loss: 1.071874]\n",
      "[Epoch 7/200] [Batch 0/169] [D loss: 0.504380] [G loss: 0.767365]\n",
      "[Epoch 7/200] [Batch 1/169] [D loss: 0.562516] [G loss: 0.963756]\n",
      "[Epoch 7/200] [Batch 2/169] [D loss: 0.542324] [G loss: 1.311194]\n",
      "[Epoch 7/200] [Batch 3/169] [D loss: 0.563492] [G loss: 1.195876]\n",
      "[Epoch 7/200] [Batch 4/169] [D loss: 0.626050] [G loss: 1.227637]\n",
      "[Epoch 7/200] [Batch 5/169] [D loss: 0.515356] [G loss: 1.033401]\n",
      "[Epoch 7/200] [Batch 6/169] [D loss: 0.507202] [G loss: 1.048776]\n",
      "[Epoch 7/200] [Batch 7/169] [D loss: 0.535367] [G loss: 1.312206]\n",
      "[Epoch 7/200] [Batch 8/169] [D loss: 0.521528] [G loss: 1.060920]\n",
      "[Epoch 7/200] [Batch 9/169] [D loss: 0.564015] [G loss: 0.964720]\n",
      "[Epoch 7/200] [Batch 10/169] [D loss: 0.481642] [G loss: 1.094635]\n",
      "[Epoch 7/200] [Batch 11/169] [D loss: 0.571318] [G loss: 0.933162]\n",
      "[Epoch 7/200] [Batch 12/169] [D loss: 0.499851] [G loss: 1.103290]\n",
      "[Epoch 7/200] [Batch 13/169] [D loss: 0.507769] [G loss: 0.818405]\n",
      "[Epoch 7/200] [Batch 14/169] [D loss: 0.460918] [G loss: 1.137519]\n",
      "[Epoch 7/200] [Batch 15/169] [D loss: 0.545174] [G loss: 1.262213]\n",
      "[Epoch 7/200] [Batch 16/169] [D loss: 0.580502] [G loss: 1.245615]\n",
      "[Epoch 7/200] [Batch 17/169] [D loss: 0.524238] [G loss: 0.849774]\n",
      "[Epoch 7/200] [Batch 18/169] [D loss: 0.501274] [G loss: 1.049135]\n",
      "[Epoch 7/200] [Batch 19/169] [D loss: 0.475881] [G loss: 0.981741]\n",
      "[Epoch 7/200] [Batch 20/169] [D loss: 0.581766] [G loss: 1.112774]\n",
      "[Epoch 7/200] [Batch 21/169] [D loss: 0.594555] [G loss: 0.840124]\n",
      "[Epoch 7/200] [Batch 22/169] [D loss: 0.482591] [G loss: 0.915566]\n",
      "[Epoch 7/200] [Batch 23/169] [D loss: 0.586118] [G loss: 1.040266]\n",
      "[Epoch 7/200] [Batch 24/169] [D loss: 0.605615] [G loss: 0.881520]\n",
      "[Epoch 7/200] [Batch 25/169] [D loss: 0.537982] [G loss: 1.197058]\n",
      "[Epoch 7/200] [Batch 26/169] [D loss: 0.516728] [G loss: 1.147403]\n",
      "[Epoch 7/200] [Batch 27/169] [D loss: 0.495201] [G loss: 1.015344]\n",
      "[Epoch 7/200] [Batch 28/169] [D loss: 0.432242] [G loss: 1.059408]\n",
      "[Epoch 7/200] [Batch 29/169] [D loss: 0.500226] [G loss: 0.935175]\n",
      "[Epoch 7/200] [Batch 30/169] [D loss: 0.457618] [G loss: 1.077315]\n",
      "[Epoch 7/200] [Batch 31/169] [D loss: 0.557983] [G loss: 1.016695]\n",
      "[Epoch 7/200] [Batch 32/169] [D loss: 0.489413] [G loss: 1.081195]\n",
      "[Epoch 7/200] [Batch 33/169] [D loss: 0.505867] [G loss: 1.139963]\n",
      "[Epoch 7/200] [Batch 34/169] [D loss: 0.494323] [G loss: 0.963206]\n",
      "[Epoch 7/200] [Batch 35/169] [D loss: 0.516518] [G loss: 0.853658]\n",
      "[Epoch 7/200] [Batch 36/169] [D loss: 0.489196] [G loss: 1.013308]\n",
      "[Epoch 7/200] [Batch 37/169] [D loss: 0.575173] [G loss: 1.039611]\n",
      "[Epoch 7/200] [Batch 38/169] [D loss: 0.552969] [G loss: 1.208494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 39/169] [D loss: 0.562182] [G loss: 1.289651]\n",
      "[Epoch 7/200] [Batch 40/169] [D loss: 0.504942] [G loss: 1.203583]\n",
      "[Epoch 7/200] [Batch 41/169] [D loss: 0.551693] [G loss: 1.113991]\n",
      "[Epoch 7/200] [Batch 42/169] [D loss: 0.571550] [G loss: 1.104942]\n",
      "[Epoch 7/200] [Batch 43/169] [D loss: 0.505198] [G loss: 1.115973]\n",
      "[Epoch 7/200] [Batch 44/169] [D loss: 0.562258] [G loss: 0.931489]\n",
      "[Epoch 7/200] [Batch 45/169] [D loss: 0.518193] [G loss: 1.120256]\n",
      "[Epoch 7/200] [Batch 46/169] [D loss: 0.615416] [G loss: 0.846265]\n",
      "[Epoch 7/200] [Batch 47/169] [D loss: 0.701868] [G loss: 1.042831]\n",
      "[Epoch 7/200] [Batch 48/169] [D loss: 0.716601] [G loss: 0.821873]\n",
      "[Epoch 7/200] [Batch 49/169] [D loss: 0.757347] [G loss: 1.047590]\n",
      "[Epoch 7/200] [Batch 50/169] [D loss: 0.722589] [G loss: 0.736889]\n",
      "[Epoch 7/200] [Batch 51/169] [D loss: 0.734338] [G loss: 0.849213]\n",
      "[Epoch 7/200] [Batch 52/169] [D loss: 0.646464] [G loss: 0.865990]\n",
      "[Epoch 7/200] [Batch 53/169] [D loss: 0.580482] [G loss: 0.967682]\n",
      "[Epoch 7/200] [Batch 54/169] [D loss: 0.499122] [G loss: 1.251774]\n",
      "[Epoch 7/200] [Batch 55/169] [D loss: 0.416693] [G loss: 1.336828]\n",
      "[Epoch 7/200] [Batch 56/169] [D loss: 0.433528] [G loss: 1.393603]\n",
      "[Epoch 7/200] [Batch 57/169] [D loss: 0.395371] [G loss: 1.295315]\n",
      "[Epoch 7/200] [Batch 58/169] [D loss: 0.476501] [G loss: 1.097354]\n",
      "[Epoch 7/200] [Batch 59/169] [D loss: 0.501393] [G loss: 1.064497]\n",
      "[Epoch 7/200] [Batch 60/169] [D loss: 0.516066] [G loss: 1.047806]\n",
      "[Epoch 7/200] [Batch 61/169] [D loss: 0.549610] [G loss: 1.104718]\n",
      "[Epoch 7/200] [Batch 62/169] [D loss: 0.486733] [G loss: 1.130647]\n",
      "[Epoch 7/200] [Batch 63/169] [D loss: 0.507568] [G loss: 1.252643]\n",
      "[Epoch 7/200] [Batch 64/169] [D loss: 0.487521] [G loss: 1.062402]\n",
      "[Epoch 7/200] [Batch 65/169] [D loss: 0.457615] [G loss: 1.194750]\n",
      "[Epoch 7/200] [Batch 66/169] [D loss: 0.456607] [G loss: 1.162736]\n",
      "[Epoch 7/200] [Batch 67/169] [D loss: 0.591951] [G loss: 1.169058]\n",
      "[Epoch 7/200] [Batch 68/169] [D loss: 0.534168] [G loss: 1.166264]\n",
      "[Epoch 7/200] [Batch 69/169] [D loss: 0.463553] [G loss: 1.085362]\n",
      "[Epoch 7/200] [Batch 70/169] [D loss: 0.590211] [G loss: 0.747098]\n",
      "[Epoch 7/200] [Batch 71/169] [D loss: 0.613328] [G loss: 0.897983]\n",
      "[Epoch 7/200] [Batch 72/169] [D loss: 0.580348] [G loss: 1.109074]\n",
      "[Epoch 7/200] [Batch 73/169] [D loss: 0.615157] [G loss: 1.065856]\n",
      "[Epoch 7/200] [Batch 74/169] [D loss: 0.596324] [G loss: 0.897390]\n",
      "[Epoch 7/200] [Batch 75/169] [D loss: 0.685322] [G loss: 1.035276]\n",
      "[Epoch 7/200] [Batch 76/169] [D loss: 0.606663] [G loss: 0.797940]\n",
      "[Epoch 7/200] [Batch 77/169] [D loss: 0.669707] [G loss: 0.931345]\n",
      "[Epoch 7/200] [Batch 78/169] [D loss: 0.584444] [G loss: 0.965783]\n",
      "[Epoch 7/200] [Batch 79/169] [D loss: 0.652896] [G loss: 1.170712]\n",
      "[Epoch 7/200] [Batch 80/169] [D loss: 0.656361] [G loss: 0.896572]\n",
      "[Epoch 7/200] [Batch 81/169] [D loss: 0.592253] [G loss: 1.126047]\n",
      "[Epoch 7/200] [Batch 82/169] [D loss: 0.674876] [G loss: 0.940150]\n",
      "[Epoch 7/200] [Batch 83/169] [D loss: 0.555225] [G loss: 1.151178]\n",
      "[Epoch 7/200] [Batch 84/169] [D loss: 0.529631] [G loss: 1.139176]\n",
      "[Epoch 7/200] [Batch 85/169] [D loss: 0.499324] [G loss: 1.048075]\n",
      "[Epoch 7/200] [Batch 86/169] [D loss: 0.510065] [G loss: 0.952909]\n",
      "[Epoch 7/200] [Batch 87/169] [D loss: 0.543961] [G loss: 1.139077]\n",
      "[Epoch 7/200] [Batch 88/169] [D loss: 0.562825] [G loss: 0.906810]\n",
      "[Epoch 7/200] [Batch 89/169] [D loss: 0.558964] [G loss: 0.926680]\n",
      "[Epoch 7/200] [Batch 90/169] [D loss: 0.594484] [G loss: 0.960093]\n",
      "[Epoch 7/200] [Batch 91/169] [D loss: 0.550480] [G loss: 0.898344]\n",
      "[Epoch 7/200] [Batch 92/169] [D loss: 0.540566] [G loss: 1.010824]\n",
      "[Epoch 7/200] [Batch 93/169] [D loss: 0.491618] [G loss: 1.152372]\n",
      "[Epoch 7/200] [Batch 94/169] [D loss: 0.477660] [G loss: 1.070970]\n",
      "[Epoch 7/200] [Batch 95/169] [D loss: 0.469299] [G loss: 1.053412]\n",
      "[Epoch 7/200] [Batch 96/169] [D loss: 0.522511] [G loss: 1.134427]\n",
      "[Epoch 7/200] [Batch 97/169] [D loss: 0.480535] [G loss: 1.060778]\n",
      "[Epoch 7/200] [Batch 98/169] [D loss: 0.460609] [G loss: 1.146619]\n",
      "[Epoch 7/200] [Batch 99/169] [D loss: 0.582711] [G loss: 0.895721]\n",
      "[Epoch 7/200] [Batch 100/169] [D loss: 0.535761] [G loss: 1.050414]\n",
      "[Epoch 7/200] [Batch 101/169] [D loss: 0.549704] [G loss: 1.041952]\n",
      "[Epoch 7/200] [Batch 102/169] [D loss: 0.555883] [G loss: 1.067690]\n",
      "[Epoch 7/200] [Batch 103/169] [D loss: 0.575721] [G loss: 0.949305]\n",
      "[Epoch 7/200] [Batch 104/169] [D loss: 0.540956] [G loss: 0.956226]\n",
      "[Epoch 7/200] [Batch 105/169] [D loss: 0.587931] [G loss: 0.849296]\n",
      "[Epoch 7/200] [Batch 106/169] [D loss: 0.557900] [G loss: 1.005337]\n",
      "[Epoch 7/200] [Batch 107/169] [D loss: 0.623274] [G loss: 1.242211]\n",
      "[Epoch 7/200] [Batch 108/169] [D loss: 0.596517] [G loss: 1.205401]\n",
      "[Epoch 7/200] [Batch 109/169] [D loss: 0.557377] [G loss: 0.902886]\n",
      "[Epoch 7/200] [Batch 110/169] [D loss: 0.564911] [G loss: 0.995735]\n",
      "[Epoch 7/200] [Batch 111/169] [D loss: 0.582070] [G loss: 1.092873]\n",
      "[Epoch 7/200] [Batch 112/169] [D loss: 0.545983] [G loss: 1.144951]\n",
      "[Epoch 7/200] [Batch 113/169] [D loss: 0.549662] [G loss: 1.176402]\n",
      "[Epoch 7/200] [Batch 114/169] [D loss: 0.532590] [G loss: 1.159818]\n",
      "[Epoch 7/200] [Batch 115/169] [D loss: 0.554051] [G loss: 1.176292]\n",
      "[Epoch 7/200] [Batch 116/169] [D loss: 0.512195] [G loss: 1.058446]\n",
      "[Epoch 7/200] [Batch 117/169] [D loss: 0.586300] [G loss: 1.073562]\n",
      "[Epoch 7/200] [Batch 118/169] [D loss: 0.577323] [G loss: 1.131772]\n",
      "[Epoch 7/200] [Batch 119/169] [D loss: 0.517307] [G loss: 1.310070]\n",
      "[Epoch 7/200] [Batch 120/169] [D loss: 0.582065] [G loss: 1.098461]\n",
      "[Epoch 7/200] [Batch 121/169] [D loss: 0.546829] [G loss: 1.156998]\n",
      "[Epoch 7/200] [Batch 122/169] [D loss: 0.534714] [G loss: 1.032076]\n",
      "[Epoch 7/200] [Batch 123/169] [D loss: 0.575350] [G loss: 0.987749]\n",
      "[Epoch 7/200] [Batch 124/169] [D loss: 0.542900] [G loss: 1.060025]\n",
      "[Epoch 7/200] [Batch 125/169] [D loss: 0.551237] [G loss: 1.078406]\n",
      "[Epoch 7/200] [Batch 126/169] [D loss: 0.544416] [G loss: 1.138046]\n",
      "[Epoch 7/200] [Batch 127/169] [D loss: 0.446949] [G loss: 0.982077]\n",
      "[Epoch 7/200] [Batch 128/169] [D loss: 0.531927] [G loss: 1.324276]\n",
      "[Epoch 7/200] [Batch 129/169] [D loss: 0.541252] [G loss: 1.204096]\n",
      "[Epoch 7/200] [Batch 130/169] [D loss: 0.579549] [G loss: 0.957682]\n",
      "[Epoch 7/200] [Batch 131/169] [D loss: 0.588022] [G loss: 0.717956]\n",
      "[Epoch 7/200] [Batch 132/169] [D loss: 0.531271] [G loss: 1.072973]\n",
      "[Epoch 7/200] [Batch 133/169] [D loss: 0.594647] [G loss: 0.939712]\n",
      "[Epoch 7/200] [Batch 134/169] [D loss: 0.472930] [G loss: 1.151600]\n",
      "[Epoch 7/200] [Batch 135/169] [D loss: 0.505356] [G loss: 1.185608]\n",
      "[Epoch 7/200] [Batch 136/169] [D loss: 0.526806] [G loss: 1.046291]\n",
      "[Epoch 7/200] [Batch 137/169] [D loss: 0.487243] [G loss: 0.842709]\n",
      "[Epoch 7/200] [Batch 138/169] [D loss: 0.575039] [G loss: 1.019652]\n",
      "[Epoch 7/200] [Batch 139/169] [D loss: 0.558286] [G loss: 1.121576]\n",
      "[Epoch 7/200] [Batch 140/169] [D loss: 0.550528] [G loss: 1.084279]\n",
      "[Epoch 7/200] [Batch 141/169] [D loss: 0.595467] [G loss: 1.124943]\n",
      "[Epoch 7/200] [Batch 142/169] [D loss: 0.618859] [G loss: 1.078243]\n",
      "[Epoch 7/200] [Batch 143/169] [D loss: 0.439929] [G loss: 0.988189]\n",
      "[Epoch 7/200] [Batch 144/169] [D loss: 0.564642] [G loss: 0.929250]\n",
      "[Epoch 7/200] [Batch 145/169] [D loss: 0.533338] [G loss: 1.054503]\n",
      "[Epoch 7/200] [Batch 146/169] [D loss: 0.538455] [G loss: 1.029802]\n",
      "[Epoch 7/200] [Batch 147/169] [D loss: 0.534451] [G loss: 0.805911]\n",
      "[Epoch 7/200] [Batch 148/169] [D loss: 0.610240] [G loss: 1.001356]\n",
      "[Epoch 7/200] [Batch 149/169] [D loss: 0.486183] [G loss: 1.036648]\n",
      "[Epoch 7/200] [Batch 150/169] [D loss: 0.492404] [G loss: 1.025377]\n",
      "[Epoch 7/200] [Batch 151/169] [D loss: 0.589774] [G loss: 1.212781]\n",
      "[Epoch 7/200] [Batch 152/169] [D loss: 0.473731] [G loss: 0.970558]\n",
      "[Epoch 7/200] [Batch 153/169] [D loss: 0.580186] [G loss: 0.916143]\n",
      "[Epoch 7/200] [Batch 154/169] [D loss: 0.588843] [G loss: 1.069129]\n",
      "[Epoch 7/200] [Batch 155/169] [D loss: 0.554831] [G loss: 1.112870]\n",
      "[Epoch 7/200] [Batch 156/169] [D loss: 0.538570] [G loss: 0.975376]\n",
      "[Epoch 7/200] [Batch 157/169] [D loss: 0.544398] [G loss: 1.239084]\n",
      "[Epoch 7/200] [Batch 158/169] [D loss: 0.476507] [G loss: 1.532898]\n",
      "[Epoch 7/200] [Batch 159/169] [D loss: 0.545504] [G loss: 1.134187]\n",
      "[Epoch 7/200] [Batch 160/169] [D loss: 0.516183] [G loss: 0.957340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 161/169] [D loss: 0.569835] [G loss: 0.974259]\n",
      "[Epoch 7/200] [Batch 162/169] [D loss: 0.522572] [G loss: 1.268147]\n",
      "[Epoch 7/200] [Batch 163/169] [D loss: 0.637800] [G loss: 1.042285]\n",
      "[Epoch 7/200] [Batch 164/169] [D loss: 0.554345] [G loss: 1.157665]\n",
      "[Epoch 7/200] [Batch 165/169] [D loss: 0.677591] [G loss: 1.019156]\n",
      "[Epoch 7/200] [Batch 166/169] [D loss: 0.533469] [G loss: 1.093042]\n",
      "[Epoch 7/200] [Batch 167/169] [D loss: 0.678944] [G loss: 1.031387]\n",
      "[Epoch 7/200] [Batch 168/169] [D loss: 0.616042] [G loss: 1.137567]\n",
      "[Epoch 8/200] [Batch 0/169] [D loss: 0.534438] [G loss: 1.359935]\n",
      "[Epoch 8/200] [Batch 1/169] [D loss: 0.570934] [G loss: 1.110515]\n",
      "[Epoch 8/200] [Batch 2/169] [D loss: 0.626018] [G loss: 0.873840]\n",
      "[Epoch 8/200] [Batch 3/169] [D loss: 0.587521] [G loss: 1.152633]\n",
      "[Epoch 8/200] [Batch 4/169] [D loss: 0.633369] [G loss: 1.157026]\n",
      "[Epoch 8/200] [Batch 5/169] [D loss: 0.544097] [G loss: 1.077719]\n",
      "[Epoch 8/200] [Batch 6/169] [D loss: 0.457858] [G loss: 1.003422]\n",
      "[Epoch 8/200] [Batch 7/169] [D loss: 0.544708] [G loss: 1.285311]\n",
      "[Epoch 8/200] [Batch 8/169] [D loss: 0.603281] [G loss: 0.983251]\n",
      "[Epoch 8/200] [Batch 9/169] [D loss: 0.579107] [G loss: 0.973194]\n",
      "[Epoch 8/200] [Batch 10/169] [D loss: 0.562522] [G loss: 0.853709]\n",
      "[Epoch 8/200] [Batch 11/169] [D loss: 0.488241] [G loss: 0.986377]\n",
      "[Epoch 8/200] [Batch 12/169] [D loss: 0.429062] [G loss: 1.149639]\n",
      "[Epoch 8/200] [Batch 13/169] [D loss: 0.435439] [G loss: 1.192351]\n",
      "[Epoch 8/200] [Batch 14/169] [D loss: 0.515389] [G loss: 1.042387]\n",
      "[Epoch 8/200] [Batch 15/169] [D loss: 0.531802] [G loss: 0.991839]\n",
      "[Epoch 8/200] [Batch 16/169] [D loss: 0.492580] [G loss: 1.148540]\n",
      "[Epoch 8/200] [Batch 17/169] [D loss: 0.523998] [G loss: 1.169975]\n",
      "[Epoch 8/200] [Batch 18/169] [D loss: 0.578232] [G loss: 1.220895]\n",
      "[Epoch 8/200] [Batch 19/169] [D loss: 0.651127] [G loss: 0.992469]\n",
      "[Epoch 8/200] [Batch 20/169] [D loss: 0.615427] [G loss: 1.124956]\n",
      "[Epoch 8/200] [Batch 21/169] [D loss: 0.579225] [G loss: 1.197991]\n",
      "[Epoch 8/200] [Batch 22/169] [D loss: 0.576833] [G loss: 1.245223]\n",
      "[Epoch 8/200] [Batch 23/169] [D loss: 0.573958] [G loss: 1.302961]\n",
      "[Epoch 8/200] [Batch 24/169] [D loss: 0.558393] [G loss: 1.147871]\n",
      "[Epoch 8/200] [Batch 25/169] [D loss: 0.576724] [G loss: 1.053841]\n",
      "[Epoch 8/200] [Batch 26/169] [D loss: 0.484848] [G loss: 1.027459]\n",
      "[Epoch 8/200] [Batch 27/169] [D loss: 0.462830] [G loss: 1.085109]\n",
      "[Epoch 8/200] [Batch 28/169] [D loss: 0.530556] [G loss: 1.068604]\n",
      "[Epoch 8/200] [Batch 29/169] [D loss: 0.583816] [G loss: 0.946603]\n",
      "[Epoch 8/200] [Batch 30/169] [D loss: 0.541292] [G loss: 1.043152]\n",
      "[Epoch 8/200] [Batch 31/169] [D loss: 0.625248] [G loss: 1.031712]\n",
      "[Epoch 8/200] [Batch 32/169] [D loss: 0.609121] [G loss: 0.926911]\n",
      "[Epoch 8/200] [Batch 33/169] [D loss: 0.542860] [G loss: 1.040864]\n",
      "[Epoch 8/200] [Batch 34/169] [D loss: 0.526011] [G loss: 1.107482]\n",
      "[Epoch 8/200] [Batch 35/169] [D loss: 0.537405] [G loss: 0.920692]\n",
      "[Epoch 8/200] [Batch 36/169] [D loss: 0.601286] [G loss: 0.889624]\n",
      "[Epoch 8/200] [Batch 37/169] [D loss: 0.527119] [G loss: 1.059902]\n",
      "[Epoch 8/200] [Batch 38/169] [D loss: 0.549203] [G loss: 1.181108]\n",
      "[Epoch 8/200] [Batch 39/169] [D loss: 0.491140] [G loss: 1.184368]\n",
      "[Epoch 8/200] [Batch 40/169] [D loss: 0.591555] [G loss: 1.071886]\n",
      "[Epoch 8/200] [Batch 41/169] [D loss: 0.499055] [G loss: 0.969849]\n",
      "[Epoch 8/200] [Batch 42/169] [D loss: 0.570959] [G loss: 1.018972]\n",
      "[Epoch 8/200] [Batch 43/169] [D loss: 0.547629] [G loss: 1.050283]\n",
      "[Epoch 8/200] [Batch 44/169] [D loss: 0.577611] [G loss: 1.089444]\n",
      "[Epoch 8/200] [Batch 45/169] [D loss: 0.529821] [G loss: 0.930516]\n",
      "[Epoch 8/200] [Batch 46/169] [D loss: 0.613609] [G loss: 0.923970]\n",
      "[Epoch 8/200] [Batch 47/169] [D loss: 0.538958] [G loss: 1.058105]\n",
      "[Epoch 8/200] [Batch 48/169] [D loss: 0.524372] [G loss: 1.174339]\n",
      "[Epoch 8/200] [Batch 49/169] [D loss: 0.621514] [G loss: 1.104570]\n",
      "[Epoch 8/200] [Batch 50/169] [D loss: 0.566212] [G loss: 1.050613]\n",
      "[Epoch 8/200] [Batch 51/169] [D loss: 0.627523] [G loss: 1.005899]\n",
      "[Epoch 8/200] [Batch 52/169] [D loss: 0.541015] [G loss: 1.045643]\n",
      "[Epoch 8/200] [Batch 53/169] [D loss: 0.531789] [G loss: 0.890080]\n",
      "[Epoch 8/200] [Batch 54/169] [D loss: 0.578828] [G loss: 1.057426]\n",
      "[Epoch 8/200] [Batch 55/169] [D loss: 0.505152] [G loss: 1.174934]\n",
      "[Epoch 8/200] [Batch 56/169] [D loss: 0.551140] [G loss: 1.143079]\n",
      "[Epoch 8/200] [Batch 57/169] [D loss: 0.559537] [G loss: 1.156966]\n",
      "[Epoch 8/200] [Batch 58/169] [D loss: 0.535268] [G loss: 1.015114]\n",
      "[Epoch 8/200] [Batch 59/169] [D loss: 0.556687] [G loss: 1.115959]\n",
      "[Epoch 8/200] [Batch 60/169] [D loss: 0.528708] [G loss: 1.121712]\n",
      "[Epoch 8/200] [Batch 61/169] [D loss: 0.549524] [G loss: 1.075315]\n",
      "[Epoch 8/200] [Batch 62/169] [D loss: 0.666421] [G loss: 1.093041]\n",
      "[Epoch 8/200] [Batch 63/169] [D loss: 0.590270] [G loss: 1.095412]\n",
      "[Epoch 8/200] [Batch 64/169] [D loss: 0.644255] [G loss: 0.814580]\n",
      "[Epoch 8/200] [Batch 65/169] [D loss: 0.568586] [G loss: 0.985346]\n",
      "[Epoch 8/200] [Batch 66/169] [D loss: 0.651376] [G loss: 1.064330]\n",
      "[Epoch 8/200] [Batch 67/169] [D loss: 0.597521] [G loss: 1.202848]\n",
      "[Epoch 8/200] [Batch 68/169] [D loss: 0.619691] [G loss: 1.051307]\n",
      "[Epoch 8/200] [Batch 69/169] [D loss: 0.630286] [G loss: 0.869982]\n",
      "[Epoch 8/200] [Batch 70/169] [D loss: 0.590133] [G loss: 0.900922]\n",
      "[Epoch 8/200] [Batch 71/169] [D loss: 0.599471] [G loss: 1.082636]\n",
      "[Epoch 8/200] [Batch 72/169] [D loss: 0.505879] [G loss: 1.198211]\n",
      "[Epoch 8/200] [Batch 73/169] [D loss: 0.464224] [G loss: 1.080748]\n",
      "[Epoch 8/200] [Batch 74/169] [D loss: 0.469427] [G loss: 1.356188]\n",
      "[Epoch 8/200] [Batch 75/169] [D loss: 0.521644] [G loss: 1.302801]\n",
      "[Epoch 8/200] [Batch 76/169] [D loss: 0.544499] [G loss: 0.986250]\n",
      "[Epoch 8/200] [Batch 77/169] [D loss: 0.563463] [G loss: 0.980232]\n",
      "[Epoch 8/200] [Batch 78/169] [D loss: 0.568778] [G loss: 1.006087]\n",
      "[Epoch 8/200] [Batch 79/169] [D loss: 0.547595] [G loss: 1.049171]\n",
      "[Epoch 8/200] [Batch 80/169] [D loss: 0.478326] [G loss: 1.218293]\n",
      "[Epoch 8/200] [Batch 81/169] [D loss: 0.599395] [G loss: 1.257641]\n",
      "[Epoch 8/200] [Batch 82/169] [D loss: 0.539441] [G loss: 1.051597]\n",
      "[Epoch 8/200] [Batch 83/169] [D loss: 0.483151] [G loss: 1.064370]\n",
      "[Epoch 8/200] [Batch 84/169] [D loss: 0.504898] [G loss: 1.227771]\n",
      "[Epoch 8/200] [Batch 85/169] [D loss: 0.606805] [G loss: 0.881626]\n",
      "[Epoch 8/200] [Batch 86/169] [D loss: 0.599442] [G loss: 0.907830]\n",
      "[Epoch 8/200] [Batch 87/169] [D loss: 0.526471] [G loss: 1.220463]\n",
      "[Epoch 8/200] [Batch 88/169] [D loss: 0.490060] [G loss: 1.241992]\n",
      "[Epoch 8/200] [Batch 89/169] [D loss: 0.548029] [G loss: 1.110997]\n",
      "[Epoch 8/200] [Batch 90/169] [D loss: 0.556731] [G loss: 0.997304]\n",
      "[Epoch 8/200] [Batch 91/169] [D loss: 0.541403] [G loss: 0.946776]\n",
      "[Epoch 8/200] [Batch 92/169] [D loss: 0.507913] [G loss: 0.875931]\n",
      "[Epoch 8/200] [Batch 93/169] [D loss: 0.524358] [G loss: 0.942203]\n",
      "[Epoch 8/200] [Batch 94/169] [D loss: 0.529358] [G loss: 1.051811]\n",
      "[Epoch 8/200] [Batch 95/169] [D loss: 0.532505] [G loss: 1.189574]\n",
      "[Epoch 8/200] [Batch 96/169] [D loss: 0.564157] [G loss: 1.062340]\n",
      "[Epoch 8/200] [Batch 97/169] [D loss: 0.596003] [G loss: 1.008455]\n",
      "[Epoch 8/200] [Batch 98/169] [D loss: 0.586647] [G loss: 1.150030]\n",
      "[Epoch 8/200] [Batch 99/169] [D loss: 0.625004] [G loss: 1.155471]\n",
      "[Epoch 8/200] [Batch 100/169] [D loss: 0.569534] [G loss: 1.085777]\n",
      "[Epoch 8/200] [Batch 101/169] [D loss: 0.537610] [G loss: 1.039194]\n",
      "[Epoch 8/200] [Batch 102/169] [D loss: 0.607806] [G loss: 1.027465]\n",
      "[Epoch 8/200] [Batch 103/169] [D loss: 0.470366] [G loss: 1.042438]\n",
      "[Epoch 8/200] [Batch 104/169] [D loss: 0.512556] [G loss: 1.183280]\n",
      "[Epoch 8/200] [Batch 105/169] [D loss: 0.452428] [G loss: 1.316241]\n",
      "[Epoch 8/200] [Batch 106/169] [D loss: 0.454241] [G loss: 1.189606]\n",
      "[Epoch 8/200] [Batch 107/169] [D loss: 0.437948] [G loss: 1.125331]\n",
      "[Epoch 8/200] [Batch 108/169] [D loss: 0.449770] [G loss: 1.049671]\n",
      "[Epoch 8/200] [Batch 109/169] [D loss: 0.527339] [G loss: 0.928548]\n",
      "[Epoch 8/200] [Batch 110/169] [D loss: 0.491400] [G loss: 0.989502]\n",
      "[Epoch 8/200] [Batch 111/169] [D loss: 0.498905] [G loss: 1.094970]\n",
      "[Epoch 8/200] [Batch 112/169] [D loss: 0.553253] [G loss: 0.929709]\n",
      "[Epoch 8/200] [Batch 113/169] [D loss: 0.627583] [G loss: 0.971524]\n",
      "[Epoch 8/200] [Batch 114/169] [D loss: 0.676415] [G loss: 0.972290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 115/169] [D loss: 0.666644] [G loss: 0.821041]\n",
      "[Epoch 8/200] [Batch 116/169] [D loss: 0.589931] [G loss: 0.819690]\n",
      "[Epoch 8/200] [Batch 117/169] [D loss: 0.720178] [G loss: 1.053456]\n",
      "[Epoch 8/200] [Batch 118/169] [D loss: 0.633829] [G loss: 1.167297]\n",
      "[Epoch 8/200] [Batch 119/169] [D loss: 0.521511] [G loss: 1.249382]\n",
      "[Epoch 8/200] [Batch 120/169] [D loss: 0.550614] [G loss: 1.083667]\n",
      "[Epoch 8/200] [Batch 121/169] [D loss: 0.400380] [G loss: 1.451246]\n",
      "[Epoch 8/200] [Batch 122/169] [D loss: 0.578661] [G loss: 0.903726]\n",
      "[Epoch 8/200] [Batch 123/169] [D loss: 0.512152] [G loss: 0.779722]\n",
      "[Epoch 8/200] [Batch 124/169] [D loss: 0.560752] [G loss: 0.739482]\n",
      "[Epoch 8/200] [Batch 125/169] [D loss: 0.604749] [G loss: 0.923812]\n",
      "[Epoch 8/200] [Batch 126/169] [D loss: 0.605085] [G loss: 0.805895]\n",
      "[Epoch 8/200] [Batch 127/169] [D loss: 0.620535] [G loss: 1.101751]\n",
      "[Epoch 8/200] [Batch 128/169] [D loss: 0.590726] [G loss: 1.055071]\n",
      "[Epoch 8/200] [Batch 129/169] [D loss: 0.567712] [G loss: 0.986787]\n",
      "[Epoch 8/200] [Batch 130/169] [D loss: 0.567240] [G loss: 0.823394]\n",
      "[Epoch 8/200] [Batch 131/169] [D loss: 0.601237] [G loss: 0.983678]\n",
      "[Epoch 8/200] [Batch 132/169] [D loss: 0.579991] [G loss: 1.039900]\n",
      "[Epoch 8/200] [Batch 133/169] [D loss: 0.517216] [G loss: 1.477104]\n",
      "[Epoch 8/200] [Batch 134/169] [D loss: 0.570284] [G loss: 1.204859]\n",
      "[Epoch 8/200] [Batch 135/169] [D loss: 0.527868] [G loss: 1.013452]\n",
      "[Epoch 8/200] [Batch 136/169] [D loss: 0.592575] [G loss: 1.102545]\n",
      "[Epoch 8/200] [Batch 137/169] [D loss: 0.609986] [G loss: 1.090433]\n",
      "[Epoch 8/200] [Batch 138/169] [D loss: 0.585005] [G loss: 1.087430]\n",
      "[Epoch 8/200] [Batch 139/169] [D loss: 0.555713] [G loss: 1.234223]\n",
      "[Epoch 8/200] [Batch 140/169] [D loss: 0.660109] [G loss: 1.052454]\n",
      "[Epoch 8/200] [Batch 141/169] [D loss: 0.676267] [G loss: 1.036066]\n",
      "[Epoch 8/200] [Batch 142/169] [D loss: 0.577204] [G loss: 0.955947]\n",
      "[Epoch 8/200] [Batch 143/169] [D loss: 0.699735] [G loss: 0.777252]\n",
      "[Epoch 8/200] [Batch 144/169] [D loss: 0.598013] [G loss: 1.059664]\n",
      "[Epoch 8/200] [Batch 145/169] [D loss: 0.645043] [G loss: 0.889694]\n",
      "[Epoch 8/200] [Batch 146/169] [D loss: 0.556624] [G loss: 1.093844]\n",
      "[Epoch 8/200] [Batch 147/169] [D loss: 0.591174] [G loss: 1.294407]\n",
      "[Epoch 8/200] [Batch 148/169] [D loss: 0.583189] [G loss: 1.394030]\n",
      "[Epoch 8/200] [Batch 149/169] [D loss: 0.527849] [G loss: 0.970595]\n",
      "[Epoch 8/200] [Batch 150/169] [D loss: 0.499443] [G loss: 1.016097]\n",
      "[Epoch 8/200] [Batch 151/169] [D loss: 0.571248] [G loss: 1.157387]\n",
      "[Epoch 8/200] [Batch 152/169] [D loss: 0.547969] [G loss: 1.141159]\n",
      "[Epoch 8/200] [Batch 153/169] [D loss: 0.545479] [G loss: 1.019821]\n",
      "[Epoch 8/200] [Batch 154/169] [D loss: 0.586495] [G loss: 0.997616]\n",
      "[Epoch 8/200] [Batch 155/169] [D loss: 0.622846] [G loss: 1.138546]\n",
      "[Epoch 8/200] [Batch 156/169] [D loss: 0.596022] [G loss: 1.063255]\n",
      "[Epoch 8/200] [Batch 157/169] [D loss: 0.587399] [G loss: 1.170267]\n",
      "[Epoch 8/200] [Batch 158/169] [D loss: 0.638127] [G loss: 1.252526]\n",
      "[Epoch 8/200] [Batch 159/169] [D loss: 0.602112] [G loss: 1.010877]\n",
      "[Epoch 8/200] [Batch 160/169] [D loss: 0.622558] [G loss: 0.825967]\n",
      "[Epoch 8/200] [Batch 161/169] [D loss: 0.606936] [G loss: 1.061792]\n",
      "[Epoch 8/200] [Batch 162/169] [D loss: 0.519867] [G loss: 0.905113]\n",
      "[Epoch 8/200] [Batch 163/169] [D loss: 0.641532] [G loss: 1.088940]\n",
      "[Epoch 8/200] [Batch 164/169] [D loss: 0.611489] [G loss: 0.948198]\n",
      "[Epoch 8/200] [Batch 165/169] [D loss: 0.575626] [G loss: 0.946313]\n",
      "[Epoch 8/200] [Batch 166/169] [D loss: 0.533823] [G loss: 0.928161]\n",
      "[Epoch 8/200] [Batch 167/169] [D loss: 0.547205] [G loss: 1.150555]\n",
      "[Epoch 8/200] [Batch 168/169] [D loss: 0.721072] [G loss: 0.993958]\n",
      "[Epoch 9/200] [Batch 0/169] [D loss: 0.533966] [G loss: 0.767462]\n",
      "[Epoch 9/200] [Batch 1/169] [D loss: 0.587730] [G loss: 0.926909]\n",
      "[Epoch 9/200] [Batch 2/169] [D loss: 0.520242] [G loss: 0.968237]\n",
      "[Epoch 9/200] [Batch 3/169] [D loss: 0.543287] [G loss: 0.976908]\n",
      "[Epoch 9/200] [Batch 4/169] [D loss: 0.515724] [G loss: 1.163357]\n",
      "[Epoch 9/200] [Batch 5/169] [D loss: 0.569477] [G loss: 1.034322]\n",
      "[Epoch 9/200] [Batch 6/169] [D loss: 0.548241] [G loss: 1.124017]\n",
      "[Epoch 9/200] [Batch 7/169] [D loss: 0.559667] [G loss: 1.095271]\n",
      "[Epoch 9/200] [Batch 8/169] [D loss: 0.510916] [G loss: 1.166581]\n",
      "[Epoch 9/200] [Batch 9/169] [D loss: 0.555385] [G loss: 1.033200]\n",
      "[Epoch 9/200] [Batch 10/169] [D loss: 0.645542] [G loss: 0.920997]\n",
      "[Epoch 9/200] [Batch 11/169] [D loss: 0.622830] [G loss: 1.040891]\n",
      "[Epoch 9/200] [Batch 12/169] [D loss: 0.538784] [G loss: 1.114024]\n",
      "[Epoch 9/200] [Batch 13/169] [D loss: 0.532103] [G loss: 0.918043]\n",
      "[Epoch 9/200] [Batch 14/169] [D loss: 0.612988] [G loss: 0.931394]\n",
      "[Epoch 9/200] [Batch 15/169] [D loss: 0.572972] [G loss: 0.992988]\n",
      "[Epoch 9/200] [Batch 16/169] [D loss: 0.603933] [G loss: 0.966914]\n",
      "[Epoch 9/200] [Batch 17/169] [D loss: 0.601929] [G loss: 0.942675]\n",
      "[Epoch 9/200] [Batch 18/169] [D loss: 0.591754] [G loss: 0.982780]\n",
      "[Epoch 9/200] [Batch 19/169] [D loss: 0.542802] [G loss: 0.983198]\n",
      "[Epoch 9/200] [Batch 20/169] [D loss: 0.575965] [G loss: 0.988470]\n",
      "[Epoch 9/200] [Batch 21/169] [D loss: 0.549927] [G loss: 1.025495]\n",
      "[Epoch 9/200] [Batch 22/169] [D loss: 0.512036] [G loss: 1.196824]\n",
      "[Epoch 9/200] [Batch 23/169] [D loss: 0.605987] [G loss: 1.172615]\n",
      "[Epoch 9/200] [Batch 24/169] [D loss: 0.659529] [G loss: 0.974486]\n",
      "[Epoch 9/200] [Batch 25/169] [D loss: 0.654619] [G loss: 0.941381]\n",
      "[Epoch 9/200] [Batch 26/169] [D loss: 0.618093] [G loss: 1.162842]\n",
      "[Epoch 9/200] [Batch 27/169] [D loss: 0.612985] [G loss: 1.079286]\n",
      "[Epoch 9/200] [Batch 28/169] [D loss: 0.482796] [G loss: 1.183683]\n",
      "[Epoch 9/200] [Batch 29/169] [D loss: 0.670405] [G loss: 0.985226]\n",
      "[Epoch 9/200] [Batch 30/169] [D loss: 0.510698] [G loss: 1.078502]\n",
      "[Epoch 9/200] [Batch 31/169] [D loss: 0.601112] [G loss: 1.040547]\n",
      "[Epoch 9/200] [Batch 32/169] [D loss: 0.634301] [G loss: 1.000911]\n",
      "[Epoch 9/200] [Batch 33/169] [D loss: 0.582200] [G loss: 0.931656]\n",
      "[Epoch 9/200] [Batch 34/169] [D loss: 0.542974] [G loss: 0.984802]\n",
      "[Epoch 9/200] [Batch 35/169] [D loss: 0.498345] [G loss: 1.134072]\n",
      "[Epoch 9/200] [Batch 36/169] [D loss: 0.532042] [G loss: 1.117082]\n",
      "[Epoch 9/200] [Batch 37/169] [D loss: 0.543919] [G loss: 1.226158]\n",
      "[Epoch 9/200] [Batch 38/169] [D loss: 0.542257] [G loss: 1.055923]\n",
      "[Epoch 9/200] [Batch 39/169] [D loss: 0.541488] [G loss: 0.936757]\n",
      "[Epoch 9/200] [Batch 40/169] [D loss: 0.504221] [G loss: 0.924290]\n",
      "[Epoch 9/200] [Batch 41/169] [D loss: 0.480939] [G loss: 1.022382]\n",
      "[Epoch 9/200] [Batch 42/169] [D loss: 0.534436] [G loss: 1.208409]\n",
      "[Epoch 9/200] [Batch 43/169] [D loss: 0.553881] [G loss: 1.080161]\n",
      "[Epoch 9/200] [Batch 44/169] [D loss: 0.571286] [G loss: 1.168459]\n",
      "[Epoch 9/200] [Batch 45/169] [D loss: 0.559560] [G loss: 0.969170]\n",
      "[Epoch 9/200] [Batch 46/169] [D loss: 0.533440] [G loss: 0.896392]\n",
      "[Epoch 9/200] [Batch 47/169] [D loss: 0.632645] [G loss: 0.916997]\n",
      "[Epoch 9/200] [Batch 48/169] [D loss: 0.603706] [G loss: 1.132664]\n",
      "[Epoch 9/200] [Batch 49/169] [D loss: 0.658661] [G loss: 1.076991]\n",
      "[Epoch 9/200] [Batch 50/169] [D loss: 0.613857] [G loss: 0.842382]\n",
      "[Epoch 9/200] [Batch 51/169] [D loss: 0.580223] [G loss: 0.900125]\n",
      "[Epoch 9/200] [Batch 52/169] [D loss: 0.625986] [G loss: 1.038683]\n",
      "[Epoch 9/200] [Batch 53/169] [D loss: 0.606140] [G loss: 1.010180]\n",
      "[Epoch 9/200] [Batch 54/169] [D loss: 0.565707] [G loss: 1.091483]\n",
      "[Epoch 9/200] [Batch 55/169] [D loss: 0.586493] [G loss: 1.094093]\n",
      "[Epoch 9/200] [Batch 56/169] [D loss: 0.527039] [G loss: 0.884657]\n",
      "[Epoch 9/200] [Batch 57/169] [D loss: 0.527458] [G loss: 0.847458]\n",
      "[Epoch 9/200] [Batch 58/169] [D loss: 0.439382] [G loss: 0.997053]\n",
      "[Epoch 9/200] [Batch 59/169] [D loss: 0.531955] [G loss: 0.862518]\n",
      "[Epoch 9/200] [Batch 60/169] [D loss: 0.526220] [G loss: 0.901986]\n",
      "[Epoch 9/200] [Batch 61/169] [D loss: 0.532480] [G loss: 0.955264]\n",
      "[Epoch 9/200] [Batch 62/169] [D loss: 0.588034] [G loss: 0.941030]\n",
      "[Epoch 9/200] [Batch 63/169] [D loss: 0.542587] [G loss: 0.940141]\n",
      "[Epoch 9/200] [Batch 64/169] [D loss: 0.539104] [G loss: 1.130404]\n",
      "[Epoch 9/200] [Batch 65/169] [D loss: 0.528237] [G loss: 0.967512]\n",
      "[Epoch 9/200] [Batch 66/169] [D loss: 0.607481] [G loss: 1.119302]\n",
      "[Epoch 9/200] [Batch 67/169] [D loss: 0.612367] [G loss: 1.089190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 68/169] [D loss: 0.593202] [G loss: 0.976259]\n",
      "[Epoch 9/200] [Batch 69/169] [D loss: 0.579412] [G loss: 1.044728]\n",
      "[Epoch 9/200] [Batch 70/169] [D loss: 0.653229] [G loss: 1.210407]\n",
      "[Epoch 9/200] [Batch 71/169] [D loss: 0.589456] [G loss: 1.030360]\n",
      "[Epoch 9/200] [Batch 72/169] [D loss: 0.511924] [G loss: 0.967747]\n",
      "[Epoch 9/200] [Batch 73/169] [D loss: 0.639107] [G loss: 1.160894]\n",
      "[Epoch 9/200] [Batch 74/169] [D loss: 0.633352] [G loss: 1.135864]\n",
      "[Epoch 9/200] [Batch 75/169] [D loss: 0.602413] [G loss: 0.963951]\n",
      "[Epoch 9/200] [Batch 76/169] [D loss: 0.630199] [G loss: 0.912112]\n",
      "[Epoch 9/200] [Batch 77/169] [D loss: 0.645023] [G loss: 0.948208]\n",
      "[Epoch 9/200] [Batch 78/169] [D loss: 0.672244] [G loss: 0.887736]\n",
      "[Epoch 9/200] [Batch 79/169] [D loss: 0.580113] [G loss: 1.091523]\n",
      "[Epoch 9/200] [Batch 80/169] [D loss: 0.635071] [G loss: 1.194745]\n",
      "[Epoch 9/200] [Batch 81/169] [D loss: 0.674588] [G loss: 0.724761]\n",
      "[Epoch 9/200] [Batch 82/169] [D loss: 0.607041] [G loss: 0.810177]\n",
      "[Epoch 9/200] [Batch 83/169] [D loss: 0.575192] [G loss: 0.974203]\n",
      "[Epoch 9/200] [Batch 84/169] [D loss: 0.640633] [G loss: 1.250633]\n",
      "[Epoch 9/200] [Batch 85/169] [D loss: 0.637662] [G loss: 0.949599]\n",
      "[Epoch 9/200] [Batch 86/169] [D loss: 0.565607] [G loss: 0.983077]\n",
      "[Epoch 9/200] [Batch 87/169] [D loss: 0.587780] [G loss: 0.871140]\n",
      "[Epoch 9/200] [Batch 88/169] [D loss: 0.568984] [G loss: 0.857075]\n",
      "[Epoch 9/200] [Batch 89/169] [D loss: 0.655043] [G loss: 0.949812]\n",
      "[Epoch 9/200] [Batch 90/169] [D loss: 0.694246] [G loss: 0.800852]\n",
      "[Epoch 9/200] [Batch 91/169] [D loss: 0.666179] [G loss: 1.092572]\n",
      "[Epoch 9/200] [Batch 92/169] [D loss: 0.638357] [G loss: 1.037858]\n",
      "[Epoch 9/200] [Batch 93/169] [D loss: 0.561515] [G loss: 0.929712]\n",
      "[Epoch 9/200] [Batch 94/169] [D loss: 0.643109] [G loss: 0.922757]\n",
      "[Epoch 9/200] [Batch 95/169] [D loss: 0.587161] [G loss: 1.336658]\n",
      "[Epoch 9/200] [Batch 96/169] [D loss: 0.512377] [G loss: 1.399832]\n",
      "[Epoch 9/200] [Batch 97/169] [D loss: 0.554370] [G loss: 1.171863]\n",
      "[Epoch 9/200] [Batch 98/169] [D loss: 0.495023] [G loss: 1.142989]\n",
      "[Epoch 9/200] [Batch 99/169] [D loss: 0.552651] [G loss: 0.876481]\n",
      "[Epoch 9/200] [Batch 100/169] [D loss: 0.562748] [G loss: 1.244215]\n",
      "[Epoch 9/200] [Batch 101/169] [D loss: 0.582141] [G loss: 1.074949]\n",
      "[Epoch 9/200] [Batch 102/169] [D loss: 0.575794] [G loss: 1.004361]\n",
      "[Epoch 9/200] [Batch 103/169] [D loss: 0.561587] [G loss: 1.178871]\n",
      "[Epoch 9/200] [Batch 104/169] [D loss: 0.537835] [G loss: 1.236551]\n",
      "[Epoch 9/200] [Batch 105/169] [D loss: 0.609921] [G loss: 1.060214]\n",
      "[Epoch 9/200] [Batch 106/169] [D loss: 0.501696] [G loss: 1.053187]\n",
      "[Epoch 9/200] [Batch 107/169] [D loss: 0.601351] [G loss: 1.003357]\n",
      "[Epoch 9/200] [Batch 108/169] [D loss: 0.604331] [G loss: 0.808760]\n",
      "[Epoch 9/200] [Batch 109/169] [D loss: 0.567819] [G loss: 0.801245]\n",
      "[Epoch 9/200] [Batch 110/169] [D loss: 0.635054] [G loss: 1.126059]\n",
      "[Epoch 9/200] [Batch 111/169] [D loss: 0.490706] [G loss: 0.950667]\n",
      "[Epoch 9/200] [Batch 112/169] [D loss: 0.614241] [G loss: 0.931108]\n",
      "[Epoch 9/200] [Batch 113/169] [D loss: 0.506426] [G loss: 0.824606]\n",
      "[Epoch 9/200] [Batch 114/169] [D loss: 0.587443] [G loss: 0.939409]\n",
      "[Epoch 9/200] [Batch 115/169] [D loss: 0.571396] [G loss: 1.010200]\n",
      "[Epoch 9/200] [Batch 116/169] [D loss: 0.533174] [G loss: 1.009400]\n",
      "[Epoch 9/200] [Batch 117/169] [D loss: 0.650960] [G loss: 0.839210]\n",
      "[Epoch 9/200] [Batch 118/169] [D loss: 0.694066] [G loss: 1.062566]\n",
      "[Epoch 9/200] [Batch 119/169] [D loss: 0.685748] [G loss: 0.896732]\n",
      "[Epoch 9/200] [Batch 120/169] [D loss: 0.592546] [G loss: 0.946049]\n",
      "[Epoch 9/200] [Batch 121/169] [D loss: 0.567119] [G loss: 1.076007]\n",
      "[Epoch 9/200] [Batch 122/169] [D loss: 0.570158] [G loss: 1.133413]\n",
      "[Epoch 9/200] [Batch 123/169] [D loss: 0.525894] [G loss: 1.138653]\n",
      "[Epoch 9/200] [Batch 124/169] [D loss: 0.549203] [G loss: 1.145033]\n",
      "[Epoch 9/200] [Batch 125/169] [D loss: 0.508240] [G loss: 1.079451]\n",
      "[Epoch 9/200] [Batch 126/169] [D loss: 0.530104] [G loss: 1.152791]\n",
      "[Epoch 9/200] [Batch 127/169] [D loss: 0.519336] [G loss: 0.973531]\n",
      "[Epoch 9/200] [Batch 128/169] [D loss: 0.484738] [G loss: 0.928557]\n",
      "[Epoch 9/200] [Batch 129/169] [D loss: 0.453671] [G loss: 1.075511]\n",
      "[Epoch 9/200] [Batch 130/169] [D loss: 0.539184] [G loss: 1.034552]\n",
      "[Epoch 9/200] [Batch 131/169] [D loss: 0.505064] [G loss: 0.846136]\n",
      "[Epoch 9/200] [Batch 132/169] [D loss: 0.558053] [G loss: 0.885884]\n",
      "[Epoch 9/200] [Batch 133/169] [D loss: 0.657842] [G loss: 0.830766]\n",
      "[Epoch 9/200] [Batch 134/169] [D loss: 0.617211] [G loss: 1.072641]\n",
      "[Epoch 9/200] [Batch 135/169] [D loss: 0.587197] [G loss: 0.969917]\n",
      "[Epoch 9/200] [Batch 136/169] [D loss: 0.559469] [G loss: 0.925555]\n",
      "[Epoch 9/200] [Batch 137/169] [D loss: 0.606294] [G loss: 1.004467]\n",
      "[Epoch 9/200] [Batch 138/169] [D loss: 0.642507] [G loss: 0.975162]\n",
      "[Epoch 9/200] [Batch 139/169] [D loss: 0.573360] [G loss: 0.966215]\n",
      "[Epoch 9/200] [Batch 140/169] [D loss: 0.628397] [G loss: 1.047210]\n",
      "[Epoch 9/200] [Batch 141/169] [D loss: 0.593827] [G loss: 0.834225]\n",
      "[Epoch 9/200] [Batch 142/169] [D loss: 0.620034] [G loss: 1.032159]\n",
      "[Epoch 9/200] [Batch 143/169] [D loss: 0.658107] [G loss: 1.035296]\n",
      "[Epoch 9/200] [Batch 144/169] [D loss: 0.649540] [G loss: 0.889140]\n",
      "[Epoch 9/200] [Batch 145/169] [D loss: 0.564680] [G loss: 0.974057]\n",
      "[Epoch 9/200] [Batch 146/169] [D loss: 0.612962] [G loss: 1.055734]\n",
      "[Epoch 9/200] [Batch 147/169] [D loss: 0.594764] [G loss: 0.958118]\n",
      "[Epoch 9/200] [Batch 148/169] [D loss: 0.599739] [G loss: 1.220719]\n",
      "[Epoch 9/200] [Batch 149/169] [D loss: 0.541930] [G loss: 1.052591]\n",
      "[Epoch 9/200] [Batch 150/169] [D loss: 0.599246] [G loss: 0.999871]\n",
      "[Epoch 9/200] [Batch 151/169] [D loss: 0.508970] [G loss: 1.031272]\n",
      "[Epoch 9/200] [Batch 152/169] [D loss: 0.503315] [G loss: 1.288015]\n",
      "[Epoch 9/200] [Batch 153/169] [D loss: 0.565123] [G loss: 1.076238]\n",
      "[Epoch 9/200] [Batch 154/169] [D loss: 0.575530] [G loss: 0.974828]\n",
      "[Epoch 9/200] [Batch 155/169] [D loss: 0.545376] [G loss: 1.002005]\n",
      "[Epoch 9/200] [Batch 156/169] [D loss: 0.540822] [G loss: 1.055374]\n",
      "[Epoch 9/200] [Batch 157/169] [D loss: 0.562393] [G loss: 0.849357]\n",
      "[Epoch 9/200] [Batch 158/169] [D loss: 0.513788] [G loss: 1.008612]\n",
      "[Epoch 9/200] [Batch 159/169] [D loss: 0.565137] [G loss: 0.979529]\n",
      "[Epoch 9/200] [Batch 160/169] [D loss: 0.522915] [G loss: 0.917123]\n",
      "[Epoch 9/200] [Batch 161/169] [D loss: 0.541655] [G loss: 1.050712]\n",
      "[Epoch 9/200] [Batch 162/169] [D loss: 0.519289] [G loss: 0.864776]\n",
      "[Epoch 9/200] [Batch 163/169] [D loss: 0.474972] [G loss: 0.979434]\n",
      "[Epoch 9/200] [Batch 164/169] [D loss: 0.530206] [G loss: 1.071316]\n",
      "[Epoch 9/200] [Batch 165/169] [D loss: 0.499255] [G loss: 1.239233]\n",
      "[Epoch 9/200] [Batch 166/169] [D loss: 0.516666] [G loss: 0.989398]\n",
      "[Epoch 9/200] [Batch 167/169] [D loss: 0.577894] [G loss: 1.059128]\n",
      "[Epoch 9/200] [Batch 168/169] [D loss: 0.483804] [G loss: 1.200104]\n",
      "[Epoch 10/200] [Batch 0/169] [D loss: 0.508053] [G loss: 1.367767]\n",
      "[Epoch 10/200] [Batch 1/169] [D loss: 0.530531] [G loss: 1.135956]\n",
      "[Epoch 10/200] [Batch 2/169] [D loss: 0.562121] [G loss: 1.112739]\n",
      "[Epoch 10/200] [Batch 3/169] [D loss: 0.517211] [G loss: 1.118195]\n",
      "[Epoch 10/200] [Batch 4/169] [D loss: 0.494119] [G loss: 1.226084]\n",
      "[Epoch 10/200] [Batch 5/169] [D loss: 0.480625] [G loss: 1.046179]\n",
      "[Epoch 10/200] [Batch 6/169] [D loss: 0.501235] [G loss: 1.061509]\n",
      "[Epoch 10/200] [Batch 7/169] [D loss: 0.509000] [G loss: 0.985331]\n",
      "[Epoch 10/200] [Batch 8/169] [D loss: 0.576999] [G loss: 1.038738]\n",
      "[Epoch 10/200] [Batch 9/169] [D loss: 0.619383] [G loss: 1.204292]\n",
      "[Epoch 10/200] [Batch 10/169] [D loss: 0.504576] [G loss: 1.002664]\n",
      "[Epoch 10/200] [Batch 11/169] [D loss: 0.575682] [G loss: 0.863677]\n",
      "[Epoch 10/200] [Batch 12/169] [D loss: 0.572102] [G loss: 0.877624]\n",
      "[Epoch 10/200] [Batch 13/169] [D loss: 0.559395] [G loss: 1.249890]\n",
      "[Epoch 10/200] [Batch 14/169] [D loss: 0.636842] [G loss: 0.982916]\n",
      "[Epoch 10/200] [Batch 15/169] [D loss: 0.595312] [G loss: 1.118787]\n",
      "[Epoch 10/200] [Batch 16/169] [D loss: 0.581719] [G loss: 1.087293]\n",
      "[Epoch 10/200] [Batch 17/169] [D loss: 0.672499] [G loss: 1.272156]\n",
      "[Epoch 10/200] [Batch 18/169] [D loss: 0.616824] [G loss: 1.206567]\n",
      "[Epoch 10/200] [Batch 19/169] [D loss: 0.650869] [G loss: 1.281681]\n",
      "[Epoch 10/200] [Batch 20/169] [D loss: 0.518624] [G loss: 1.061213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 21/169] [D loss: 0.609617] [G loss: 1.016627]\n",
      "[Epoch 10/200] [Batch 22/169] [D loss: 0.571683] [G loss: 1.096793]\n",
      "[Epoch 10/200] [Batch 23/169] [D loss: 0.541966] [G loss: 1.003515]\n",
      "[Epoch 10/200] [Batch 24/169] [D loss: 0.571420] [G loss: 1.195824]\n",
      "[Epoch 10/200] [Batch 25/169] [D loss: 0.558205] [G loss: 1.023997]\n",
      "[Epoch 10/200] [Batch 26/169] [D loss: 0.618968] [G loss: 1.063749]\n",
      "[Epoch 10/200] [Batch 27/169] [D loss: 0.637837] [G loss: 0.840756]\n",
      "[Epoch 10/200] [Batch 28/169] [D loss: 0.586611] [G loss: 0.714776]\n",
      "[Epoch 10/200] [Batch 29/169] [D loss: 0.631717] [G loss: 0.866539]\n",
      "[Epoch 10/200] [Batch 30/169] [D loss: 0.568800] [G loss: 0.825864]\n",
      "[Epoch 10/200] [Batch 31/169] [D loss: 0.548076] [G loss: 1.074355]\n",
      "[Epoch 10/200] [Batch 32/169] [D loss: 0.544914] [G loss: 1.098344]\n",
      "[Epoch 10/200] [Batch 33/169] [D loss: 0.598858] [G loss: 1.059024]\n",
      "[Epoch 10/200] [Batch 34/169] [D loss: 0.570325] [G loss: 1.010720]\n",
      "[Epoch 10/200] [Batch 35/169] [D loss: 0.536623] [G loss: 0.899179]\n",
      "[Epoch 10/200] [Batch 36/169] [D loss: 0.541294] [G loss: 1.174154]\n",
      "[Epoch 10/200] [Batch 37/169] [D loss: 0.668961] [G loss: 0.973823]\n",
      "[Epoch 10/200] [Batch 38/169] [D loss: 0.585611] [G loss: 1.181865]\n",
      "[Epoch 10/200] [Batch 39/169] [D loss: 0.557097] [G loss: 1.045661]\n",
      "[Epoch 10/200] [Batch 40/169] [D loss: 0.636868] [G loss: 0.904453]\n",
      "[Epoch 10/200] [Batch 41/169] [D loss: 0.581840] [G loss: 0.788488]\n",
      "[Epoch 10/200] [Batch 42/169] [D loss: 0.612003] [G loss: 1.106924]\n",
      "[Epoch 10/200] [Batch 43/169] [D loss: 0.709191] [G loss: 1.071383]\n",
      "[Epoch 10/200] [Batch 44/169] [D loss: 0.647445] [G loss: 0.907860]\n",
      "[Epoch 10/200] [Batch 45/169] [D loss: 0.641564] [G loss: 0.771124]\n",
      "[Epoch 10/200] [Batch 46/169] [D loss: 0.534347] [G loss: 1.038410]\n",
      "[Epoch 10/200] [Batch 47/169] [D loss: 0.564161] [G loss: 0.936344]\n",
      "[Epoch 10/200] [Batch 48/169] [D loss: 0.592192] [G loss: 1.004150]\n",
      "[Epoch 10/200] [Batch 49/169] [D loss: 0.640400] [G loss: 1.070194]\n",
      "[Epoch 10/200] [Batch 50/169] [D loss: 0.661671] [G loss: 0.843535]\n",
      "[Epoch 10/200] [Batch 51/169] [D loss: 0.597072] [G loss: 0.870039]\n",
      "[Epoch 10/200] [Batch 52/169] [D loss: 0.582906] [G loss: 1.018923]\n",
      "[Epoch 10/200] [Batch 53/169] [D loss: 0.596708] [G loss: 1.123930]\n",
      "[Epoch 10/200] [Batch 54/169] [D loss: 0.470867] [G loss: 0.966017]\n",
      "[Epoch 10/200] [Batch 55/169] [D loss: 0.589255] [G loss: 0.927728]\n",
      "[Epoch 10/200] [Batch 56/169] [D loss: 0.533700] [G loss: 1.195924]\n",
      "[Epoch 10/200] [Batch 57/169] [D loss: 0.611413] [G loss: 1.286554]\n",
      "[Epoch 10/200] [Batch 58/169] [D loss: 0.551919] [G loss: 0.993625]\n",
      "[Epoch 10/200] [Batch 59/169] [D loss: 0.555867] [G loss: 1.072037]\n",
      "[Epoch 10/200] [Batch 60/169] [D loss: 0.552583] [G loss: 1.052784]\n",
      "[Epoch 10/200] [Batch 61/169] [D loss: 0.591083] [G loss: 1.189897]\n",
      "[Epoch 10/200] [Batch 62/169] [D loss: 0.532776] [G loss: 1.124340]\n",
      "[Epoch 10/200] [Batch 63/169] [D loss: 0.555290] [G loss: 1.136428]\n",
      "[Epoch 10/200] [Batch 64/169] [D loss: 0.573697] [G loss: 1.007356]\n",
      "[Epoch 10/200] [Batch 65/169] [D loss: 0.498525] [G loss: 0.986925]\n",
      "[Epoch 10/200] [Batch 66/169] [D loss: 0.571204] [G loss: 1.043949]\n",
      "[Epoch 10/200] [Batch 67/169] [D loss: 0.498357] [G loss: 0.901385]\n",
      "[Epoch 10/200] [Batch 68/169] [D loss: 0.522337] [G loss: 1.122076]\n",
      "[Epoch 10/200] [Batch 69/169] [D loss: 0.559743] [G loss: 0.901806]\n",
      "[Epoch 10/200] [Batch 70/169] [D loss: 0.516978] [G loss: 0.963753]\n",
      "[Epoch 10/200] [Batch 71/169] [D loss: 0.522991] [G loss: 1.065381]\n",
      "[Epoch 10/200] [Batch 72/169] [D loss: 0.618314] [G loss: 1.140927]\n",
      "[Epoch 10/200] [Batch 73/169] [D loss: 0.668167] [G loss: 0.899333]\n",
      "[Epoch 10/200] [Batch 74/169] [D loss: 0.567360] [G loss: 0.969806]\n",
      "[Epoch 10/200] [Batch 75/169] [D loss: 0.610275] [G loss: 0.864185]\n",
      "[Epoch 10/200] [Batch 76/169] [D loss: 0.542584] [G loss: 0.985616]\n",
      "[Epoch 10/200] [Batch 77/169] [D loss: 0.639873] [G loss: 0.880596]\n",
      "[Epoch 10/200] [Batch 78/169] [D loss: 0.573124] [G loss: 1.027637]\n",
      "[Epoch 10/200] [Batch 79/169] [D loss: 0.563802] [G loss: 1.068614]\n",
      "[Epoch 10/200] [Batch 80/169] [D loss: 0.542589] [G loss: 1.031693]\n",
      "[Epoch 10/200] [Batch 81/169] [D loss: 0.685895] [G loss: 0.856796]\n",
      "[Epoch 10/200] [Batch 82/169] [D loss: 0.760557] [G loss: 0.781284]\n",
      "[Epoch 10/200] [Batch 83/169] [D loss: 0.625893] [G loss: 0.988137]\n",
      "[Epoch 10/200] [Batch 84/169] [D loss: 0.687810] [G loss: 0.890139]\n",
      "[Epoch 10/200] [Batch 85/169] [D loss: 0.594067] [G loss: 1.311291]\n",
      "[Epoch 10/200] [Batch 86/169] [D loss: 0.580703] [G loss: 1.294765]\n",
      "[Epoch 10/200] [Batch 87/169] [D loss: 0.548146] [G loss: 1.009281]\n",
      "[Epoch 10/200] [Batch 88/169] [D loss: 0.541348] [G loss: 1.236742]\n",
      "[Epoch 10/200] [Batch 89/169] [D loss: 0.528552] [G loss: 1.115008]\n",
      "[Epoch 10/200] [Batch 90/169] [D loss: 0.549550] [G loss: 0.908132]\n",
      "[Epoch 10/200] [Batch 91/169] [D loss: 0.549044] [G loss: 0.903208]\n",
      "[Epoch 10/200] [Batch 92/169] [D loss: 0.564215] [G loss: 1.041061]\n",
      "[Epoch 10/200] [Batch 93/169] [D loss: 0.573405] [G loss: 0.853911]\n",
      "[Epoch 10/200] [Batch 94/169] [D loss: 0.653976] [G loss: 0.971447]\n",
      "[Epoch 10/200] [Batch 95/169] [D loss: 0.597381] [G loss: 0.987119]\n",
      "[Epoch 10/200] [Batch 96/169] [D loss: 0.614282] [G loss: 1.105331]\n",
      "[Epoch 10/200] [Batch 97/169] [D loss: 0.647886] [G loss: 0.936391]\n",
      "[Epoch 10/200] [Batch 98/169] [D loss: 0.648391] [G loss: 0.972600]\n",
      "[Epoch 10/200] [Batch 99/169] [D loss: 0.612600] [G loss: 1.073320]\n",
      "[Epoch 10/200] [Batch 100/169] [D loss: 0.554170] [G loss: 1.125913]\n",
      "[Epoch 10/200] [Batch 101/169] [D loss: 0.590870] [G loss: 1.134623]\n",
      "[Epoch 10/200] [Batch 102/169] [D loss: 0.555898] [G loss: 1.060221]\n",
      "[Epoch 10/200] [Batch 103/169] [D loss: 0.601979] [G loss: 0.864991]\n",
      "[Epoch 10/200] [Batch 104/169] [D loss: 0.497626] [G loss: 1.362769]\n",
      "[Epoch 10/200] [Batch 105/169] [D loss: 0.579613] [G loss: 1.107285]\n",
      "[Epoch 10/200] [Batch 106/169] [D loss: 0.576841] [G loss: 1.136312]\n",
      "[Epoch 10/200] [Batch 107/169] [D loss: 0.567553] [G loss: 0.989845]\n",
      "[Epoch 10/200] [Batch 108/169] [D loss: 0.575458] [G loss: 0.933017]\n",
      "[Epoch 10/200] [Batch 109/169] [D loss: 0.626734] [G loss: 1.005722]\n",
      "[Epoch 10/200] [Batch 110/169] [D loss: 0.559294] [G loss: 1.056598]\n",
      "[Epoch 10/200] [Batch 111/169] [D loss: 0.546408] [G loss: 0.938127]\n",
      "[Epoch 10/200] [Batch 112/169] [D loss: 0.596750] [G loss: 0.973667]\n",
      "[Epoch 10/200] [Batch 113/169] [D loss: 0.577473] [G loss: 1.023545]\n",
      "[Epoch 10/200] [Batch 114/169] [D loss: 0.495428] [G loss: 0.920161]\n",
      "[Epoch 10/200] [Batch 115/169] [D loss: 0.588643] [G loss: 1.133466]\n",
      "[Epoch 10/200] [Batch 116/169] [D loss: 0.592296] [G loss: 0.924451]\n",
      "[Epoch 10/200] [Batch 117/169] [D loss: 0.533468] [G loss: 1.126729]\n",
      "[Epoch 10/200] [Batch 118/169] [D loss: 0.597476] [G loss: 0.856816]\n",
      "[Epoch 10/200] [Batch 119/169] [D loss: 0.612325] [G loss: 0.994959]\n",
      "[Epoch 10/200] [Batch 120/169] [D loss: 0.536485] [G loss: 1.272666]\n",
      "[Epoch 10/200] [Batch 121/169] [D loss: 0.573675] [G loss: 1.035958]\n",
      "[Epoch 10/200] [Batch 122/169] [D loss: 0.507956] [G loss: 0.958403]\n",
      "[Epoch 10/200] [Batch 123/169] [D loss: 0.553719] [G loss: 0.964078]\n",
      "[Epoch 10/200] [Batch 124/169] [D loss: 0.629953] [G loss: 0.967885]\n",
      "[Epoch 10/200] [Batch 125/169] [D loss: 0.635111] [G loss: 0.918518]\n",
      "[Epoch 10/200] [Batch 126/169] [D loss: 0.629694] [G loss: 0.962570]\n",
      "[Epoch 10/200] [Batch 127/169] [D loss: 0.573789] [G loss: 0.966507]\n",
      "[Epoch 10/200] [Batch 128/169] [D loss: 0.620559] [G loss: 0.986857]\n",
      "[Epoch 10/200] [Batch 129/169] [D loss: 0.538050] [G loss: 0.907238]\n",
      "[Epoch 10/200] [Batch 130/169] [D loss: 0.536947] [G loss: 1.067029]\n",
      "[Epoch 10/200] [Batch 131/169] [D loss: 0.571816] [G loss: 1.004555]\n",
      "[Epoch 10/200] [Batch 132/169] [D loss: 0.561313] [G loss: 1.085565]\n",
      "[Epoch 10/200] [Batch 133/169] [D loss: 0.553911] [G loss: 1.056779]\n",
      "[Epoch 10/200] [Batch 134/169] [D loss: 0.551475] [G loss: 1.114516]\n",
      "[Epoch 10/200] [Batch 135/169] [D loss: 0.561893] [G loss: 0.969952]\n",
      "[Epoch 10/200] [Batch 136/169] [D loss: 0.602096] [G loss: 1.052906]\n",
      "[Epoch 10/200] [Batch 137/169] [D loss: 0.566144] [G loss: 0.872472]\n",
      "[Epoch 10/200] [Batch 138/169] [D loss: 0.518595] [G loss: 0.894171]\n",
      "[Epoch 10/200] [Batch 139/169] [D loss: 0.635221] [G loss: 1.005362]\n",
      "[Epoch 10/200] [Batch 140/169] [D loss: 0.591110] [G loss: 1.193880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 141/169] [D loss: 0.555416] [G loss: 0.996407]\n",
      "[Epoch 10/200] [Batch 142/169] [D loss: 0.604893] [G loss: 0.912513]\n",
      "[Epoch 10/200] [Batch 143/169] [D loss: 0.604975] [G loss: 1.080710]\n",
      "[Epoch 10/200] [Batch 144/169] [D loss: 0.593850] [G loss: 0.778568]\n",
      "[Epoch 10/200] [Batch 145/169] [D loss: 0.627196] [G loss: 0.898029]\n",
      "[Epoch 10/200] [Batch 146/169] [D loss: 0.661937] [G loss: 0.990554]\n",
      "[Epoch 10/200] [Batch 147/169] [D loss: 0.596649] [G loss: 1.007113]\n",
      "[Epoch 10/200] [Batch 148/169] [D loss: 0.539033] [G loss: 1.088514]\n",
      "[Epoch 10/200] [Batch 149/169] [D loss: 0.635422] [G loss: 1.219337]\n",
      "[Epoch 10/200] [Batch 150/169] [D loss: 0.579107] [G loss: 1.024012]\n",
      "[Epoch 10/200] [Batch 151/169] [D loss: 0.579256] [G loss: 1.031120]\n",
      "[Epoch 10/200] [Batch 152/169] [D loss: 0.546231] [G loss: 1.094738]\n",
      "[Epoch 10/200] [Batch 153/169] [D loss: 0.570625] [G loss: 1.039950]\n",
      "[Epoch 10/200] [Batch 154/169] [D loss: 0.606004] [G loss: 1.011290]\n",
      "[Epoch 10/200] [Batch 155/169] [D loss: 0.601886] [G loss: 1.110845]\n",
      "[Epoch 10/200] [Batch 156/169] [D loss: 0.593287] [G loss: 1.135573]\n",
      "[Epoch 10/200] [Batch 157/169] [D loss: 0.551338] [G loss: 0.900926]\n",
      "[Epoch 10/200] [Batch 158/169] [D loss: 0.492094] [G loss: 1.008086]\n",
      "[Epoch 10/200] [Batch 159/169] [D loss: 0.596459] [G loss: 0.813978]\n",
      "[Epoch 10/200] [Batch 160/169] [D loss: 0.645442] [G loss: 1.060971]\n",
      "[Epoch 10/200] [Batch 161/169] [D loss: 0.557530] [G loss: 0.999366]\n",
      "[Epoch 10/200] [Batch 162/169] [D loss: 0.580938] [G loss: 0.936771]\n",
      "[Epoch 10/200] [Batch 163/169] [D loss: 0.607443] [G loss: 1.009294]\n",
      "[Epoch 10/200] [Batch 164/169] [D loss: 0.584897] [G loss: 0.985314]\n",
      "[Epoch 10/200] [Batch 165/169] [D loss: 0.600401] [G loss: 1.133210]\n",
      "[Epoch 10/200] [Batch 166/169] [D loss: 0.648940] [G loss: 0.951354]\n",
      "[Epoch 10/200] [Batch 167/169] [D loss: 0.551326] [G loss: 0.957545]\n",
      "[Epoch 10/200] [Batch 168/169] [D loss: 0.598545] [G loss: 1.009879]\n",
      "[Epoch 11/200] [Batch 0/169] [D loss: 0.592362] [G loss: 0.970114]\n",
      "[Epoch 11/200] [Batch 1/169] [D loss: 0.524736] [G loss: 1.030491]\n",
      "[Epoch 11/200] [Batch 2/169] [D loss: 0.574848] [G loss: 1.174282]\n",
      "[Epoch 11/200] [Batch 3/169] [D loss: 0.537553] [G loss: 1.033374]\n",
      "[Epoch 11/200] [Batch 4/169] [D loss: 0.652501] [G loss: 1.076630]\n",
      "[Epoch 11/200] [Batch 5/169] [D loss: 0.594122] [G loss: 1.150249]\n",
      "[Epoch 11/200] [Batch 6/169] [D loss: 0.523234] [G loss: 0.988420]\n",
      "[Epoch 11/200] [Batch 7/169] [D loss: 0.619900] [G loss: 1.040708]\n",
      "[Epoch 11/200] [Batch 8/169] [D loss: 0.537373] [G loss: 0.984240]\n",
      "[Epoch 11/200] [Batch 9/169] [D loss: 0.571807] [G loss: 0.988558]\n",
      "[Epoch 11/200] [Batch 10/169] [D loss: 0.528753] [G loss: 1.094298]\n",
      "[Epoch 11/200] [Batch 11/169] [D loss: 0.531453] [G loss: 1.020012]\n",
      "[Epoch 11/200] [Batch 12/169] [D loss: 0.541039] [G loss: 0.964098]\n",
      "[Epoch 11/200] [Batch 13/169] [D loss: 0.537333] [G loss: 1.129423]\n",
      "[Epoch 11/200] [Batch 14/169] [D loss: 0.610530] [G loss: 0.853902]\n",
      "[Epoch 11/200] [Batch 15/169] [D loss: 0.514741] [G loss: 1.090081]\n",
      "[Epoch 11/200] [Batch 16/169] [D loss: 0.509490] [G loss: 0.973649]\n",
      "[Epoch 11/200] [Batch 17/169] [D loss: 0.548644] [G loss: 1.004905]\n",
      "[Epoch 11/200] [Batch 18/169] [D loss: 0.516999] [G loss: 1.031125]\n",
      "[Epoch 11/200] [Batch 19/169] [D loss: 0.599864] [G loss: 1.078256]\n",
      "[Epoch 11/200] [Batch 20/169] [D loss: 0.563326] [G loss: 0.811376]\n",
      "[Epoch 11/200] [Batch 21/169] [D loss: 0.559271] [G loss: 0.882195]\n",
      "[Epoch 11/200] [Batch 22/169] [D loss: 0.567132] [G loss: 0.986532]\n",
      "[Epoch 11/200] [Batch 23/169] [D loss: 0.520304] [G loss: 1.044914]\n",
      "[Epoch 11/200] [Batch 24/169] [D loss: 0.664451] [G loss: 1.076938]\n",
      "[Epoch 11/200] [Batch 25/169] [D loss: 0.693128] [G loss: 0.936579]\n",
      "[Epoch 11/200] [Batch 26/169] [D loss: 0.638351] [G loss: 0.942298]\n",
      "[Epoch 11/200] [Batch 27/169] [D loss: 0.537847] [G loss: 1.124227]\n",
      "[Epoch 11/200] [Batch 28/169] [D loss: 0.592510] [G loss: 1.043555]\n",
      "[Epoch 11/200] [Batch 29/169] [D loss: 0.594894] [G loss: 0.939075]\n",
      "[Epoch 11/200] [Batch 30/169] [D loss: 0.498462] [G loss: 1.017539]\n",
      "[Epoch 11/200] [Batch 31/169] [D loss: 0.564640] [G loss: 0.903173]\n",
      "[Epoch 11/200] [Batch 32/169] [D loss: 0.527004] [G loss: 0.921046]\n",
      "[Epoch 11/200] [Batch 33/169] [D loss: 0.546803] [G loss: 0.903329]\n",
      "[Epoch 11/200] [Batch 34/169] [D loss: 0.580943] [G loss: 0.902887]\n",
      "[Epoch 11/200] [Batch 35/169] [D loss: 0.582529] [G loss: 0.872065]\n",
      "[Epoch 11/200] [Batch 36/169] [D loss: 0.572749] [G loss: 0.926965]\n",
      "[Epoch 11/200] [Batch 37/169] [D loss: 0.566078] [G loss: 0.973231]\n",
      "[Epoch 11/200] [Batch 38/169] [D loss: 0.524723] [G loss: 0.950433]\n",
      "[Epoch 11/200] [Batch 39/169] [D loss: 0.505213] [G loss: 1.193335]\n",
      "[Epoch 11/200] [Batch 40/169] [D loss: 0.582773] [G loss: 1.136356]\n",
      "[Epoch 11/200] [Batch 41/169] [D loss: 0.528753] [G loss: 0.955848]\n",
      "[Epoch 11/200] [Batch 42/169] [D loss: 0.566909] [G loss: 0.927942]\n",
      "[Epoch 11/200] [Batch 43/169] [D loss: 0.547797] [G loss: 1.142034]\n",
      "[Epoch 11/200] [Batch 44/169] [D loss: 0.553305] [G loss: 0.920439]\n",
      "[Epoch 11/200] [Batch 45/169] [D loss: 0.646299] [G loss: 0.943927]\n",
      "[Epoch 11/200] [Batch 46/169] [D loss: 0.655755] [G loss: 1.027429]\n",
      "[Epoch 11/200] [Batch 47/169] [D loss: 0.568916] [G loss: 1.090555]\n",
      "[Epoch 11/200] [Batch 48/169] [D loss: 0.500556] [G loss: 1.043633]\n",
      "[Epoch 11/200] [Batch 49/169] [D loss: 0.511203] [G loss: 0.933707]\n",
      "[Epoch 11/200] [Batch 50/169] [D loss: 0.574875] [G loss: 1.073611]\n",
      "[Epoch 11/200] [Batch 51/169] [D loss: 0.503033] [G loss: 0.946284]\n",
      "[Epoch 11/200] [Batch 52/169] [D loss: 0.604371] [G loss: 0.931940]\n",
      "[Epoch 11/200] [Batch 53/169] [D loss: 0.517552] [G loss: 1.037467]\n",
      "[Epoch 11/200] [Batch 54/169] [D loss: 0.454656] [G loss: 1.081993]\n",
      "[Epoch 11/200] [Batch 55/169] [D loss: 0.561148] [G loss: 0.947628]\n",
      "[Epoch 11/200] [Batch 56/169] [D loss: 0.601095] [G loss: 1.030925]\n",
      "[Epoch 11/200] [Batch 57/169] [D loss: 0.566925] [G loss: 0.923217]\n",
      "[Epoch 11/200] [Batch 58/169] [D loss: 0.585770] [G loss: 0.887350]\n",
      "[Epoch 11/200] [Batch 59/169] [D loss: 0.592905] [G loss: 0.854113]\n",
      "[Epoch 11/200] [Batch 60/169] [D loss: 0.560954] [G loss: 0.998734]\n",
      "[Epoch 11/200] [Batch 61/169] [D loss: 0.520500] [G loss: 0.847681]\n",
      "[Epoch 11/200] [Batch 62/169] [D loss: 0.558556] [G loss: 0.876579]\n",
      "[Epoch 11/200] [Batch 63/169] [D loss: 0.616859] [G loss: 1.094650]\n",
      "[Epoch 11/200] [Batch 64/169] [D loss: 0.517813] [G loss: 1.079525]\n",
      "[Epoch 11/200] [Batch 65/169] [D loss: 0.599765] [G loss: 1.181955]\n",
      "[Epoch 11/200] [Batch 66/169] [D loss: 0.555746] [G loss: 1.242019]\n",
      "[Epoch 11/200] [Batch 67/169] [D loss: 0.516781] [G loss: 1.069843]\n",
      "[Epoch 11/200] [Batch 68/169] [D loss: 0.535423] [G loss: 0.962580]\n",
      "[Epoch 11/200] [Batch 69/169] [D loss: 0.508797] [G loss: 0.896810]\n",
      "[Epoch 11/200] [Batch 70/169] [D loss: 0.555835] [G loss: 0.900685]\n",
      "[Epoch 11/200] [Batch 71/169] [D loss: 0.584911] [G loss: 1.041171]\n",
      "[Epoch 11/200] [Batch 72/169] [D loss: 0.503664] [G loss: 1.067994]\n",
      "[Epoch 11/200] [Batch 73/169] [D loss: 0.614450] [G loss: 1.131335]\n",
      "[Epoch 11/200] [Batch 74/169] [D loss: 0.526797] [G loss: 0.826697]\n",
      "[Epoch 11/200] [Batch 75/169] [D loss: 0.537259] [G loss: 0.942726]\n",
      "[Epoch 11/200] [Batch 76/169] [D loss: 0.564655] [G loss: 1.046970]\n",
      "[Epoch 11/200] [Batch 77/169] [D loss: 0.560837] [G loss: 0.997404]\n",
      "[Epoch 11/200] [Batch 78/169] [D loss: 0.525318] [G loss: 1.058577]\n",
      "[Epoch 11/200] [Batch 79/169] [D loss: 0.632163] [G loss: 1.001623]\n",
      "[Epoch 11/200] [Batch 80/169] [D loss: 0.508286] [G loss: 1.210186]\n",
      "[Epoch 11/200] [Batch 81/169] [D loss: 0.561447] [G loss: 0.948618]\n",
      "[Epoch 11/200] [Batch 82/169] [D loss: 0.581950] [G loss: 0.880313]\n",
      "[Epoch 11/200] [Batch 83/169] [D loss: 0.582526] [G loss: 0.964044]\n",
      "[Epoch 11/200] [Batch 84/169] [D loss: 0.607490] [G loss: 1.122356]\n",
      "[Epoch 11/200] [Batch 85/169] [D loss: 0.660141] [G loss: 1.027927]\n",
      "[Epoch 11/200] [Batch 86/169] [D loss: 0.627255] [G loss: 1.109299]\n",
      "[Epoch 11/200] [Batch 87/169] [D loss: 0.586649] [G loss: 0.968656]\n",
      "[Epoch 11/200] [Batch 88/169] [D loss: 0.658392] [G loss: 0.693975]\n",
      "[Epoch 11/200] [Batch 89/169] [D loss: 0.559898] [G loss: 0.994292]\n",
      "[Epoch 11/200] [Batch 90/169] [D loss: 0.502889] [G loss: 1.147347]\n",
      "[Epoch 11/200] [Batch 91/169] [D loss: 0.535304] [G loss: 1.273162]\n",
      "[Epoch 11/200] [Batch 92/169] [D loss: 0.544630] [G loss: 1.163622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 93/169] [D loss: 0.673670] [G loss: 0.787581]\n",
      "[Epoch 11/200] [Batch 94/169] [D loss: 0.637334] [G loss: 0.751176]\n",
      "[Epoch 11/200] [Batch 95/169] [D loss: 0.643359] [G loss: 0.878118]\n",
      "[Epoch 11/200] [Batch 96/169] [D loss: 0.638985] [G loss: 0.846507]\n",
      "[Epoch 11/200] [Batch 97/169] [D loss: 0.605037] [G loss: 0.893900]\n",
      "[Epoch 11/200] [Batch 98/169] [D loss: 0.569045] [G loss: 0.817327]\n",
      "[Epoch 11/200] [Batch 99/169] [D loss: 0.699050] [G loss: 0.965618]\n",
      "[Epoch 11/200] [Batch 100/169] [D loss: 0.513046] [G loss: 0.989777]\n",
      "[Epoch 11/200] [Batch 101/169] [D loss: 0.581081] [G loss: 0.976429]\n",
      "[Epoch 11/200] [Batch 102/169] [D loss: 0.621312] [G loss: 0.926049]\n",
      "[Epoch 11/200] [Batch 103/169] [D loss: 0.609087] [G loss: 0.937230]\n",
      "[Epoch 11/200] [Batch 104/169] [D loss: 0.599059] [G loss: 0.805748]\n",
      "[Epoch 11/200] [Batch 105/169] [D loss: 0.644927] [G loss: 1.007493]\n",
      "[Epoch 11/200] [Batch 106/169] [D loss: 0.704082] [G loss: 0.967355]\n",
      "[Epoch 11/200] [Batch 107/169] [D loss: 0.576372] [G loss: 0.916854]\n",
      "[Epoch 11/200] [Batch 108/169] [D loss: 0.636638] [G loss: 0.996705]\n",
      "[Epoch 11/200] [Batch 109/169] [D loss: 0.522322] [G loss: 0.791758]\n",
      "[Epoch 11/200] [Batch 110/169] [D loss: 0.606608] [G loss: 0.992990]\n",
      "[Epoch 11/200] [Batch 111/169] [D loss: 0.630511] [G loss: 0.944423]\n",
      "[Epoch 11/200] [Batch 112/169] [D loss: 0.588504] [G loss: 1.021407]\n",
      "[Epoch 11/200] [Batch 113/169] [D loss: 0.618937] [G loss: 1.048187]\n",
      "[Epoch 11/200] [Batch 114/169] [D loss: 0.609518] [G loss: 1.034522]\n",
      "[Epoch 11/200] [Batch 115/169] [D loss: 0.560306] [G loss: 0.909261]\n",
      "[Epoch 11/200] [Batch 116/169] [D loss: 0.587820] [G loss: 0.906046]\n",
      "[Epoch 11/200] [Batch 117/169] [D loss: 0.565737] [G loss: 0.884186]\n",
      "[Epoch 11/200] [Batch 118/169] [D loss: 0.600386] [G loss: 0.926324]\n",
      "[Epoch 11/200] [Batch 119/169] [D loss: 0.671659] [G loss: 0.978698]\n",
      "[Epoch 11/200] [Batch 120/169] [D loss: 0.546468] [G loss: 1.162346]\n",
      "[Epoch 11/200] [Batch 121/169] [D loss: 0.617679] [G loss: 1.194350]\n",
      "[Epoch 11/200] [Batch 122/169] [D loss: 0.571865] [G loss: 1.010482]\n",
      "[Epoch 11/200] [Batch 123/169] [D loss: 0.565584] [G loss: 0.952104]\n",
      "[Epoch 11/200] [Batch 124/169] [D loss: 0.550823] [G loss: 0.891347]\n",
      "[Epoch 11/200] [Batch 125/169] [D loss: 0.530163] [G loss: 1.007631]\n",
      "[Epoch 11/200] [Batch 126/169] [D loss: 0.617446] [G loss: 1.163575]\n",
      "[Epoch 11/200] [Batch 127/169] [D loss: 0.594849] [G loss: 0.872685]\n",
      "[Epoch 11/200] [Batch 128/169] [D loss: 0.617770] [G loss: 1.012142]\n",
      "[Epoch 11/200] [Batch 129/169] [D loss: 0.564935] [G loss: 1.054509]\n",
      "[Epoch 11/200] [Batch 130/169] [D loss: 0.620994] [G loss: 0.958706]\n",
      "[Epoch 11/200] [Batch 131/169] [D loss: 0.540086] [G loss: 1.156955]\n",
      "[Epoch 11/200] [Batch 132/169] [D loss: 0.544732] [G loss: 1.081425]\n",
      "[Epoch 11/200] [Batch 133/169] [D loss: 0.572729] [G loss: 1.058885]\n",
      "[Epoch 11/200] [Batch 134/169] [D loss: 0.555296] [G loss: 1.106096]\n",
      "[Epoch 11/200] [Batch 135/169] [D loss: 0.550801] [G loss: 1.012129]\n",
      "[Epoch 11/200] [Batch 136/169] [D loss: 0.598196] [G loss: 1.006506]\n",
      "[Epoch 11/200] [Batch 137/169] [D loss: 0.561557] [G loss: 1.057168]\n",
      "[Epoch 11/200] [Batch 138/169] [D loss: 0.557972] [G loss: 0.996563]\n",
      "[Epoch 11/200] [Batch 139/169] [D loss: 0.550041] [G loss: 0.978590]\n",
      "[Epoch 11/200] [Batch 140/169] [D loss: 0.601297] [G loss: 0.803914]\n",
      "[Epoch 11/200] [Batch 141/169] [D loss: 0.646720] [G loss: 1.073167]\n",
      "[Epoch 11/200] [Batch 142/169] [D loss: 0.550763] [G loss: 1.168657]\n",
      "[Epoch 11/200] [Batch 143/169] [D loss: 0.573865] [G loss: 0.971216]\n",
      "[Epoch 11/200] [Batch 144/169] [D loss: 0.606724] [G loss: 0.998508]\n",
      "[Epoch 11/200] [Batch 145/169] [D loss: 0.589903] [G loss: 0.969003]\n",
      "[Epoch 11/200] [Batch 146/169] [D loss: 0.480446] [G loss: 0.904080]\n",
      "[Epoch 11/200] [Batch 147/169] [D loss: 0.604225] [G loss: 1.127602]\n",
      "[Epoch 11/200] [Batch 148/169] [D loss: 0.590043] [G loss: 1.050959]\n",
      "[Epoch 11/200] [Batch 149/169] [D loss: 0.592728] [G loss: 0.938532]\n",
      "[Epoch 11/200] [Batch 150/169] [D loss: 0.557467] [G loss: 0.893917]\n",
      "[Epoch 11/200] [Batch 151/169] [D loss: 0.580833] [G loss: 0.947046]\n",
      "[Epoch 11/200] [Batch 152/169] [D loss: 0.557810] [G loss: 0.807365]\n",
      "[Epoch 11/200] [Batch 153/169] [D loss: 0.506037] [G loss: 1.062331]\n",
      "[Epoch 11/200] [Batch 154/169] [D loss: 0.554919] [G loss: 1.029356]\n",
      "[Epoch 11/200] [Batch 155/169] [D loss: 0.595083] [G loss: 1.286262]\n",
      "[Epoch 11/200] [Batch 156/169] [D loss: 0.580262] [G loss: 1.179888]\n",
      "[Epoch 11/200] [Batch 157/169] [D loss: 0.571938] [G loss: 0.935945]\n",
      "[Epoch 11/200] [Batch 158/169] [D loss: 0.541388] [G loss: 0.991131]\n",
      "[Epoch 11/200] [Batch 159/169] [D loss: 0.569251] [G loss: 0.939786]\n",
      "[Epoch 11/200] [Batch 160/169] [D loss: 0.572029] [G loss: 0.979976]\n",
      "[Epoch 11/200] [Batch 161/169] [D loss: 0.565919] [G loss: 1.093513]\n",
      "[Epoch 11/200] [Batch 162/169] [D loss: 0.560581] [G loss: 1.098218]\n",
      "[Epoch 11/200] [Batch 163/169] [D loss: 0.473672] [G loss: 1.125289]\n",
      "[Epoch 11/200] [Batch 164/169] [D loss: 0.515502] [G loss: 1.034827]\n",
      "[Epoch 11/200] [Batch 165/169] [D loss: 0.524554] [G loss: 1.077490]\n",
      "[Epoch 11/200] [Batch 166/169] [D loss: 0.530296] [G loss: 1.048385]\n",
      "[Epoch 11/200] [Batch 167/169] [D loss: 0.517321] [G loss: 0.961320]\n",
      "[Epoch 11/200] [Batch 168/169] [D loss: 0.563740] [G loss: 1.038122]\n",
      "[Epoch 12/200] [Batch 0/169] [D loss: 0.651377] [G loss: 0.929767]\n",
      "[Epoch 12/200] [Batch 1/169] [D loss: 0.603850] [G loss: 0.772410]\n",
      "[Epoch 12/200] [Batch 2/169] [D loss: 0.586288] [G loss: 0.899262]\n",
      "[Epoch 12/200] [Batch 3/169] [D loss: 0.486543] [G loss: 0.942726]\n",
      "[Epoch 12/200] [Batch 4/169] [D loss: 0.539199] [G loss: 1.052924]\n",
      "[Epoch 12/200] [Batch 5/169] [D loss: 0.632647] [G loss: 1.079974]\n",
      "[Epoch 12/200] [Batch 6/169] [D loss: 0.559863] [G loss: 0.987414]\n",
      "[Epoch 12/200] [Batch 7/169] [D loss: 0.604179] [G loss: 0.988780]\n",
      "[Epoch 12/200] [Batch 8/169] [D loss: 0.514980] [G loss: 1.061579]\n",
      "[Epoch 12/200] [Batch 9/169] [D loss: 0.536470] [G loss: 1.142302]\n",
      "[Epoch 12/200] [Batch 10/169] [D loss: 0.541428] [G loss: 1.079613]\n",
      "[Epoch 12/200] [Batch 11/169] [D loss: 0.598020] [G loss: 1.036263]\n",
      "[Epoch 12/200] [Batch 12/169] [D loss: 0.589593] [G loss: 1.072961]\n",
      "[Epoch 12/200] [Batch 13/169] [D loss: 0.503379] [G loss: 0.997928]\n",
      "[Epoch 12/200] [Batch 14/169] [D loss: 0.566777] [G loss: 0.965859]\n",
      "[Epoch 12/200] [Batch 15/169] [D loss: 0.572635] [G loss: 1.177589]\n",
      "[Epoch 12/200] [Batch 16/169] [D loss: 0.579543] [G loss: 1.076283]\n",
      "[Epoch 12/200] [Batch 17/169] [D loss: 0.532557] [G loss: 0.868068]\n",
      "[Epoch 12/200] [Batch 18/169] [D loss: 0.577500] [G loss: 1.033719]\n",
      "[Epoch 12/200] [Batch 19/169] [D loss: 0.503127] [G loss: 1.087134]\n",
      "[Epoch 12/200] [Batch 20/169] [D loss: 0.622000] [G loss: 0.941130]\n",
      "[Epoch 12/200] [Batch 21/169] [D loss: 0.579034] [G loss: 0.945936]\n",
      "[Epoch 12/200] [Batch 22/169] [D loss: 0.639822] [G loss: 1.140181]\n",
      "[Epoch 12/200] [Batch 23/169] [D loss: 0.586087] [G loss: 1.156478]\n",
      "[Epoch 12/200] [Batch 24/169] [D loss: 0.583196] [G loss: 1.032441]\n",
      "[Epoch 12/200] [Batch 25/169] [D loss: 0.532973] [G loss: 0.740972]\n",
      "[Epoch 12/200] [Batch 26/169] [D loss: 0.579212] [G loss: 0.908569]\n",
      "[Epoch 12/200] [Batch 27/169] [D loss: 0.741183] [G loss: 1.068961]\n",
      "[Epoch 12/200] [Batch 28/169] [D loss: 0.533094] [G loss: 1.098045]\n",
      "[Epoch 12/200] [Batch 29/169] [D loss: 0.645016] [G loss: 1.158220]\n",
      "[Epoch 12/200] [Batch 30/169] [D loss: 0.555612] [G loss: 1.174936]\n",
      "[Epoch 12/200] [Batch 31/169] [D loss: 0.582305] [G loss: 1.033806]\n",
      "[Epoch 12/200] [Batch 32/169] [D loss: 0.510118] [G loss: 1.087745]\n",
      "[Epoch 12/200] [Batch 33/169] [D loss: 0.577914] [G loss: 1.008987]\n",
      "[Epoch 12/200] [Batch 34/169] [D loss: 0.579100] [G loss: 1.009125]\n",
      "[Epoch 12/200] [Batch 35/169] [D loss: 0.491932] [G loss: 0.937443]\n",
      "[Epoch 12/200] [Batch 36/169] [D loss: 0.554756] [G loss: 0.765701]\n",
      "[Epoch 12/200] [Batch 37/169] [D loss: 0.590709] [G loss: 0.979207]\n",
      "[Epoch 12/200] [Batch 38/169] [D loss: 0.619791] [G loss: 0.958007]\n",
      "[Epoch 12/200] [Batch 39/169] [D loss: 0.577823] [G loss: 0.977042]\n",
      "[Epoch 12/200] [Batch 40/169] [D loss: 0.575937] [G loss: 0.954236]\n",
      "[Epoch 12/200] [Batch 41/169] [D loss: 0.553763] [G loss: 1.151714]\n",
      "[Epoch 12/200] [Batch 42/169] [D loss: 0.584544] [G loss: 0.852561]\n",
      "[Epoch 12/200] [Batch 43/169] [D loss: 0.543553] [G loss: 0.970556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 44/169] [D loss: 0.547235] [G loss: 1.213462]\n",
      "[Epoch 12/200] [Batch 45/169] [D loss: 0.546737] [G loss: 1.106593]\n",
      "[Epoch 12/200] [Batch 46/169] [D loss: 0.589981] [G loss: 1.068954]\n",
      "[Epoch 12/200] [Batch 47/169] [D loss: 0.687094] [G loss: 0.996995]\n",
      "[Epoch 12/200] [Batch 48/169] [D loss: 0.642777] [G loss: 0.982173]\n",
      "[Epoch 12/200] [Batch 49/169] [D loss: 0.583744] [G loss: 0.850279]\n",
      "[Epoch 12/200] [Batch 50/169] [D loss: 0.582685] [G loss: 1.055396]\n",
      "[Epoch 12/200] [Batch 51/169] [D loss: 0.617519] [G loss: 1.058091]\n",
      "[Epoch 12/200] [Batch 52/169] [D loss: 0.640266] [G loss: 0.906410]\n",
      "[Epoch 12/200] [Batch 53/169] [D loss: 0.599584] [G loss: 0.990796]\n",
      "[Epoch 12/200] [Batch 54/169] [D loss: 0.556371] [G loss: 0.910007]\n",
      "[Epoch 12/200] [Batch 55/169] [D loss: 0.591602] [G loss: 1.056597]\n",
      "[Epoch 12/200] [Batch 56/169] [D loss: 0.635627] [G loss: 1.193032]\n",
      "[Epoch 12/200] [Batch 57/169] [D loss: 0.506154] [G loss: 1.062923]\n",
      "[Epoch 12/200] [Batch 58/169] [D loss: 0.615358] [G loss: 0.897899]\n",
      "[Epoch 12/200] [Batch 59/169] [D loss: 0.508098] [G loss: 1.018139]\n",
      "[Epoch 12/200] [Batch 60/169] [D loss: 0.571997] [G loss: 1.013579]\n",
      "[Epoch 12/200] [Batch 61/169] [D loss: 0.567168] [G loss: 0.861650]\n",
      "[Epoch 12/200] [Batch 62/169] [D loss: 0.535200] [G loss: 1.145213]\n",
      "[Epoch 12/200] [Batch 63/169] [D loss: 0.592354] [G loss: 1.142281]\n",
      "[Epoch 12/200] [Batch 64/169] [D loss: 0.474110] [G loss: 0.970958]\n",
      "[Epoch 12/200] [Batch 65/169] [D loss: 0.514382] [G loss: 1.000602]\n",
      "[Epoch 12/200] [Batch 66/169] [D loss: 0.577511] [G loss: 0.937306]\n",
      "[Epoch 12/200] [Batch 67/169] [D loss: 0.529260] [G loss: 1.114711]\n",
      "[Epoch 12/200] [Batch 68/169] [D loss: 0.615210] [G loss: 1.048926]\n",
      "[Epoch 12/200] [Batch 69/169] [D loss: 0.701216] [G loss: 1.160963]\n",
      "[Epoch 12/200] [Batch 70/169] [D loss: 0.535188] [G loss: 0.957186]\n",
      "[Epoch 12/200] [Batch 71/169] [D loss: 0.632768] [G loss: 0.882562]\n",
      "[Epoch 12/200] [Batch 72/169] [D loss: 0.530030] [G loss: 1.032079]\n",
      "[Epoch 12/200] [Batch 73/169] [D loss: 0.610553] [G loss: 0.906653]\n",
      "[Epoch 12/200] [Batch 74/169] [D loss: 0.627262] [G loss: 1.005104]\n",
      "[Epoch 12/200] [Batch 75/169] [D loss: 0.606608] [G loss: 0.869525]\n",
      "[Epoch 12/200] [Batch 76/169] [D loss: 0.681294] [G loss: 0.924745]\n",
      "[Epoch 12/200] [Batch 77/169] [D loss: 0.633356] [G loss: 1.131275]\n",
      "[Epoch 12/200] [Batch 78/169] [D loss: 0.654950] [G loss: 0.962682]\n",
      "[Epoch 12/200] [Batch 79/169] [D loss: 0.668919] [G loss: 1.233937]\n",
      "[Epoch 12/200] [Batch 80/169] [D loss: 0.511533] [G loss: 1.209864]\n",
      "[Epoch 12/200] [Batch 81/169] [D loss: 0.529559] [G loss: 1.122495]\n",
      "[Epoch 12/200] [Batch 82/169] [D loss: 0.569430] [G loss: 1.132848]\n",
      "[Epoch 12/200] [Batch 83/169] [D loss: 0.604462] [G loss: 1.076266]\n",
      "[Epoch 12/200] [Batch 84/169] [D loss: 0.599662] [G loss: 1.038448]\n",
      "[Epoch 12/200] [Batch 85/169] [D loss: 0.662435] [G loss: 0.889713]\n",
      "[Epoch 12/200] [Batch 86/169] [D loss: 0.595545] [G loss: 0.869780]\n",
      "[Epoch 12/200] [Batch 87/169] [D loss: 0.559211] [G loss: 0.769770]\n",
      "[Epoch 12/200] [Batch 88/169] [D loss: 0.533985] [G loss: 1.118776]\n",
      "[Epoch 12/200] [Batch 89/169] [D loss: 0.635521] [G loss: 0.913646]\n",
      "[Epoch 12/200] [Batch 90/169] [D loss: 0.562976] [G loss: 1.024265]\n",
      "[Epoch 12/200] [Batch 91/169] [D loss: 0.616570] [G loss: 0.929555]\n",
      "[Epoch 12/200] [Batch 92/169] [D loss: 0.528451] [G loss: 0.803637]\n",
      "[Epoch 12/200] [Batch 93/169] [D loss: 0.583633] [G loss: 0.846832]\n",
      "[Epoch 12/200] [Batch 94/169] [D loss: 0.545357] [G loss: 1.022973]\n",
      "[Epoch 12/200] [Batch 95/169] [D loss: 0.581093] [G loss: 1.023034]\n",
      "[Epoch 12/200] [Batch 96/169] [D loss: 0.613734] [G loss: 1.009151]\n",
      "[Epoch 12/200] [Batch 97/169] [D loss: 0.553609] [G loss: 0.978977]\n",
      "[Epoch 12/200] [Batch 98/169] [D loss: 0.563055] [G loss: 0.992901]\n",
      "[Epoch 12/200] [Batch 99/169] [D loss: 0.604045] [G loss: 1.023025]\n",
      "[Epoch 12/200] [Batch 100/169] [D loss: 0.580440] [G loss: 1.048253]\n",
      "[Epoch 12/200] [Batch 101/169] [D loss: 0.544988] [G loss: 1.173320]\n",
      "[Epoch 12/200] [Batch 102/169] [D loss: 0.559040] [G loss: 1.191398]\n",
      "[Epoch 12/200] [Batch 103/169] [D loss: 0.563034] [G loss: 0.793921]\n",
      "[Epoch 12/200] [Batch 104/169] [D loss: 0.517252] [G loss: 1.126742]\n",
      "[Epoch 12/200] [Batch 105/169] [D loss: 0.579734] [G loss: 1.145617]\n",
      "[Epoch 12/200] [Batch 106/169] [D loss: 0.579951] [G loss: 1.046144]\n",
      "[Epoch 12/200] [Batch 107/169] [D loss: 0.584508] [G loss: 1.173767]\n",
      "[Epoch 12/200] [Batch 108/169] [D loss: 0.633125] [G loss: 0.853041]\n",
      "[Epoch 12/200] [Batch 109/169] [D loss: 0.578225] [G loss: 0.774578]\n",
      "[Epoch 12/200] [Batch 110/169] [D loss: 0.668122] [G loss: 1.063174]\n",
      "[Epoch 12/200] [Batch 111/169] [D loss: 0.571836] [G loss: 1.148213]\n",
      "[Epoch 12/200] [Batch 112/169] [D loss: 0.486646] [G loss: 0.872721]\n",
      "[Epoch 12/200] [Batch 113/169] [D loss: 0.643190] [G loss: 1.042214]\n",
      "[Epoch 12/200] [Batch 114/169] [D loss: 0.560219] [G loss: 0.929796]\n",
      "[Epoch 12/200] [Batch 115/169] [D loss: 0.571214] [G loss: 0.688182]\n",
      "[Epoch 12/200] [Batch 116/169] [D loss: 0.619648] [G loss: 0.909021]\n",
      "[Epoch 12/200] [Batch 117/169] [D loss: 0.587735] [G loss: 1.099891]\n",
      "[Epoch 12/200] [Batch 118/169] [D loss: 0.591527] [G loss: 1.122965]\n",
      "[Epoch 12/200] [Batch 119/169] [D loss: 0.588574] [G loss: 0.955644]\n",
      "[Epoch 12/200] [Batch 120/169] [D loss: 0.589501] [G loss: 0.785077]\n",
      "[Epoch 12/200] [Batch 121/169] [D loss: 0.587623] [G loss: 0.848194]\n",
      "[Epoch 12/200] [Batch 122/169] [D loss: 0.521854] [G loss: 0.968185]\n",
      "[Epoch 12/200] [Batch 123/169] [D loss: 0.596807] [G loss: 0.988465]\n",
      "[Epoch 12/200] [Batch 124/169] [D loss: 0.548851] [G loss: 0.898643]\n",
      "[Epoch 12/200] [Batch 125/169] [D loss: 0.558738] [G loss: 0.767613]\n",
      "[Epoch 12/200] [Batch 126/169] [D loss: 0.605897] [G loss: 0.826534]\n",
      "[Epoch 12/200] [Batch 127/169] [D loss: 0.550688] [G loss: 1.244215]\n",
      "[Epoch 12/200] [Batch 128/169] [D loss: 0.622721] [G loss: 1.207423]\n",
      "[Epoch 12/200] [Batch 129/169] [D loss: 0.529480] [G loss: 0.996712]\n",
      "[Epoch 12/200] [Batch 130/169] [D loss: 0.624376] [G loss: 1.105185]\n",
      "[Epoch 12/200] [Batch 131/169] [D loss: 0.552441] [G loss: 0.839118]\n",
      "[Epoch 12/200] [Batch 132/169] [D loss: 0.566672] [G loss: 1.004451]\n",
      "[Epoch 12/200] [Batch 133/169] [D loss: 0.574375] [G loss: 1.100323]\n",
      "[Epoch 12/200] [Batch 134/169] [D loss: 0.595612] [G loss: 0.807011]\n",
      "[Epoch 12/200] [Batch 135/169] [D loss: 0.696582] [G loss: 1.114755]\n",
      "[Epoch 12/200] [Batch 136/169] [D loss: 0.547451] [G loss: 0.918108]\n",
      "[Epoch 12/200] [Batch 137/169] [D loss: 0.532042] [G loss: 1.196893]\n",
      "[Epoch 12/200] [Batch 138/169] [D loss: 0.651800] [G loss: 1.011483]\n",
      "[Epoch 12/200] [Batch 139/169] [D loss: 0.614881] [G loss: 0.953743]\n",
      "[Epoch 12/200] [Batch 140/169] [D loss: 0.560015] [G loss: 0.803880]\n",
      "[Epoch 12/200] [Batch 141/169] [D loss: 0.711943] [G loss: 0.753091]\n",
      "[Epoch 12/200] [Batch 142/169] [D loss: 0.585798] [G loss: 1.182565]\n",
      "[Epoch 12/200] [Batch 143/169] [D loss: 0.617233] [G loss: 1.167118]\n",
      "[Epoch 12/200] [Batch 144/169] [D loss: 0.619195] [G loss: 1.030570]\n",
      "[Epoch 12/200] [Batch 145/169] [D loss: 0.618435] [G loss: 0.989989]\n",
      "[Epoch 12/200] [Batch 146/169] [D loss: 0.591445] [G loss: 1.074486]\n",
      "[Epoch 12/200] [Batch 147/169] [D loss: 0.552984] [G loss: 1.113024]\n",
      "[Epoch 12/200] [Batch 148/169] [D loss: 0.475368] [G loss: 1.186154]\n",
      "[Epoch 12/200] [Batch 149/169] [D loss: 0.490032] [G loss: 1.045223]\n",
      "[Epoch 12/200] [Batch 150/169] [D loss: 0.548669] [G loss: 1.111078]\n",
      "[Epoch 12/200] [Batch 151/169] [D loss: 0.579895] [G loss: 0.928035]\n",
      "[Epoch 12/200] [Batch 152/169] [D loss: 0.516540] [G loss: 0.950337]\n",
      "[Epoch 12/200] [Batch 153/169] [D loss: 0.441383] [G loss: 1.264494]\n",
      "[Epoch 12/200] [Batch 154/169] [D loss: 0.492000] [G loss: 1.217730]\n",
      "[Epoch 12/200] [Batch 155/169] [D loss: 0.513830] [G loss: 1.116717]\n",
      "[Epoch 12/200] [Batch 156/169] [D loss: 0.424753] [G loss: 0.965912]\n",
      "[Epoch 12/200] [Batch 157/169] [D loss: 0.478273] [G loss: 0.942439]\n",
      "[Epoch 12/200] [Batch 158/169] [D loss: 0.523032] [G loss: 1.074384]\n",
      "[Epoch 12/200] [Batch 159/169] [D loss: 0.438484] [G loss: 0.942335]\n",
      "[Epoch 12/200] [Batch 160/169] [D loss: 0.485340] [G loss: 1.024246]\n",
      "[Epoch 12/200] [Batch 161/169] [D loss: 0.523056] [G loss: 1.081311]\n",
      "[Epoch 12/200] [Batch 162/169] [D loss: 0.431537] [G loss: 0.938593]\n",
      "[Epoch 12/200] [Batch 163/169] [D loss: 0.589513] [G loss: 1.046247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 164/169] [D loss: 0.604441] [G loss: 1.018763]\n",
      "[Epoch 12/200] [Batch 165/169] [D loss: 0.737135] [G loss: 0.770154]\n",
      "[Epoch 12/200] [Batch 166/169] [D loss: 0.648328] [G loss: 0.982560]\n",
      "[Epoch 12/200] [Batch 167/169] [D loss: 0.612971] [G loss: 1.150991]\n",
      "[Epoch 12/200] [Batch 168/169] [D loss: 0.721237] [G loss: 0.962701]\n",
      "[Epoch 13/200] [Batch 0/169] [D loss: 0.707469] [G loss: 0.779818]\n",
      "[Epoch 13/200] [Batch 1/169] [D loss: 0.608387] [G loss: 1.089892]\n",
      "[Epoch 13/200] [Batch 2/169] [D loss: 0.534409] [G loss: 1.205296]\n",
      "[Epoch 13/200] [Batch 3/169] [D loss: 0.582670] [G loss: 1.197287]\n",
      "[Epoch 13/200] [Batch 4/169] [D loss: 0.543452] [G loss: 0.925258]\n",
      "[Epoch 13/200] [Batch 5/169] [D loss: 0.622160] [G loss: 0.719671]\n",
      "[Epoch 13/200] [Batch 6/169] [D loss: 0.706596] [G loss: 0.821834]\n",
      "[Epoch 13/200] [Batch 7/169] [D loss: 0.611757] [G loss: 0.970493]\n",
      "[Epoch 13/200] [Batch 8/169] [D loss: 0.662591] [G loss: 1.200159]\n",
      "[Epoch 13/200] [Batch 9/169] [D loss: 0.541294] [G loss: 1.005756]\n",
      "[Epoch 13/200] [Batch 10/169] [D loss: 0.626086] [G loss: 0.867206]\n",
      "[Epoch 13/200] [Batch 11/169] [D loss: 0.630571] [G loss: 0.964042]\n",
      "[Epoch 13/200] [Batch 12/169] [D loss: 0.626040] [G loss: 0.959593]\n",
      "[Epoch 13/200] [Batch 13/169] [D loss: 0.695439] [G loss: 0.962919]\n",
      "[Epoch 13/200] [Batch 14/169] [D loss: 0.722231] [G loss: 0.835834]\n",
      "[Epoch 13/200] [Batch 15/169] [D loss: 0.679501] [G loss: 0.924116]\n",
      "[Epoch 13/200] [Batch 16/169] [D loss: 0.688758] [G loss: 0.810491]\n",
      "[Epoch 13/200] [Batch 17/169] [D loss: 0.666431] [G loss: 0.869319]\n",
      "[Epoch 13/200] [Batch 18/169] [D loss: 0.600437] [G loss: 1.181618]\n",
      "[Epoch 13/200] [Batch 19/169] [D loss: 0.676663] [G loss: 1.149673]\n",
      "[Epoch 13/200] [Batch 20/169] [D loss: 0.584361] [G loss: 0.908958]\n",
      "[Epoch 13/200] [Batch 21/169] [D loss: 0.553679] [G loss: 1.059375]\n",
      "[Epoch 13/200] [Batch 22/169] [D loss: 0.594931] [G loss: 0.988829]\n",
      "[Epoch 13/200] [Batch 23/169] [D loss: 0.554037] [G loss: 0.986678]\n",
      "[Epoch 13/200] [Batch 24/169] [D loss: 0.540678] [G loss: 1.101940]\n",
      "[Epoch 13/200] [Batch 25/169] [D loss: 0.535683] [G loss: 1.154137]\n",
      "[Epoch 13/200] [Batch 26/169] [D loss: 0.532207] [G loss: 1.127564]\n",
      "[Epoch 13/200] [Batch 27/169] [D loss: 0.683878] [G loss: 0.960968]\n",
      "[Epoch 13/200] [Batch 28/169] [D loss: 0.605745] [G loss: 0.849899]\n",
      "[Epoch 13/200] [Batch 29/169] [D loss: 0.562544] [G loss: 0.939525]\n",
      "[Epoch 13/200] [Batch 30/169] [D loss: 0.548413] [G loss: 1.146405]\n",
      "[Epoch 13/200] [Batch 31/169] [D loss: 0.526720] [G loss: 1.019368]\n",
      "[Epoch 13/200] [Batch 32/169] [D loss: 0.567478] [G loss: 0.928801]\n",
      "[Epoch 13/200] [Batch 33/169] [D loss: 0.547646] [G loss: 0.947077]\n",
      "[Epoch 13/200] [Batch 34/169] [D loss: 0.554820] [G loss: 0.861944]\n",
      "[Epoch 13/200] [Batch 35/169] [D loss: 0.566707] [G loss: 0.902793]\n",
      "[Epoch 13/200] [Batch 36/169] [D loss: 0.533813] [G loss: 0.948990]\n",
      "[Epoch 13/200] [Batch 37/169] [D loss: 0.554676] [G loss: 0.912186]\n",
      "[Epoch 13/200] [Batch 38/169] [D loss: 0.623904] [G loss: 0.847412]\n",
      "[Epoch 13/200] [Batch 39/169] [D loss: 0.631665] [G loss: 0.978935]\n",
      "[Epoch 13/200] [Batch 40/169] [D loss: 0.659004] [G loss: 1.044456]\n",
      "[Epoch 13/200] [Batch 41/169] [D loss: 0.706670] [G loss: 0.811184]\n",
      "[Epoch 13/200] [Batch 42/169] [D loss: 0.638316] [G loss: 0.860750]\n",
      "[Epoch 13/200] [Batch 43/169] [D loss: 0.617589] [G loss: 0.998993]\n",
      "[Epoch 13/200] [Batch 44/169] [D loss: 0.648589] [G loss: 0.937766]\n",
      "[Epoch 13/200] [Batch 45/169] [D loss: 0.590325] [G loss: 1.073770]\n",
      "[Epoch 13/200] [Batch 46/169] [D loss: 0.558175] [G loss: 1.150829]\n",
      "[Epoch 13/200] [Batch 47/169] [D loss: 0.553239] [G loss: 0.886812]\n",
      "[Epoch 13/200] [Batch 48/169] [D loss: 0.542116] [G loss: 1.152088]\n",
      "[Epoch 13/200] [Batch 49/169] [D loss: 0.602804] [G loss: 1.037591]\n",
      "[Epoch 13/200] [Batch 50/169] [D loss: 0.546575] [G loss: 1.071500]\n",
      "[Epoch 13/200] [Batch 51/169] [D loss: 0.647250] [G loss: 1.141552]\n",
      "[Epoch 13/200] [Batch 52/169] [D loss: 0.577506] [G loss: 1.021363]\n",
      "[Epoch 13/200] [Batch 53/169] [D loss: 0.604443] [G loss: 0.897661]\n",
      "[Epoch 13/200] [Batch 54/169] [D loss: 0.637852] [G loss: 0.999983]\n",
      "[Epoch 13/200] [Batch 55/169] [D loss: 0.566584] [G loss: 0.946127]\n",
      "[Epoch 13/200] [Batch 56/169] [D loss: 0.578930] [G loss: 1.117152]\n",
      "[Epoch 13/200] [Batch 57/169] [D loss: 0.674753] [G loss: 1.036368]\n",
      "[Epoch 13/200] [Batch 58/169] [D loss: 0.598202] [G loss: 0.941514]\n",
      "[Epoch 13/200] [Batch 59/169] [D loss: 0.572379] [G loss: 0.863471]\n",
      "[Epoch 13/200] [Batch 60/169] [D loss: 0.595354] [G loss: 0.852314]\n",
      "[Epoch 13/200] [Batch 61/169] [D loss: 0.546913] [G loss: 0.810187]\n",
      "[Epoch 13/200] [Batch 62/169] [D loss: 0.606120] [G loss: 1.021647]\n",
      "[Epoch 13/200] [Batch 63/169] [D loss: 0.624246] [G loss: 0.941028]\n",
      "[Epoch 13/200] [Batch 64/169] [D loss: 0.657310] [G loss: 0.959752]\n",
      "[Epoch 13/200] [Batch 65/169] [D loss: 0.609061] [G loss: 0.999996]\n",
      "[Epoch 13/200] [Batch 66/169] [D loss: 0.584853] [G loss: 0.858805]\n",
      "[Epoch 13/200] [Batch 67/169] [D loss: 0.618001] [G loss: 0.870619]\n",
      "[Epoch 13/200] [Batch 68/169] [D loss: 0.655722] [G loss: 0.878494]\n",
      "[Epoch 13/200] [Batch 69/169] [D loss: 0.637472] [G loss: 0.758411]\n",
      "[Epoch 13/200] [Batch 70/169] [D loss: 0.593340] [G loss: 0.904723]\n",
      "[Epoch 13/200] [Batch 71/169] [D loss: 0.564465] [G loss: 0.859247]\n",
      "[Epoch 13/200] [Batch 72/169] [D loss: 0.586691] [G loss: 0.879019]\n",
      "[Epoch 13/200] [Batch 73/169] [D loss: 0.575098] [G loss: 0.930518]\n",
      "[Epoch 13/200] [Batch 74/169] [D loss: 0.605289] [G loss: 1.086385]\n",
      "[Epoch 13/200] [Batch 75/169] [D loss: 0.543609] [G loss: 0.872246]\n",
      "[Epoch 13/200] [Batch 76/169] [D loss: 0.592732] [G loss: 0.899748]\n",
      "[Epoch 13/200] [Batch 77/169] [D loss: 0.621502] [G loss: 0.940051]\n",
      "[Epoch 13/200] [Batch 78/169] [D loss: 0.585785] [G loss: 0.850757]\n",
      "[Epoch 13/200] [Batch 79/169] [D loss: 0.564415] [G loss: 0.989547]\n",
      "[Epoch 13/200] [Batch 80/169] [D loss: 0.555820] [G loss: 1.016500]\n",
      "[Epoch 13/200] [Batch 81/169] [D loss: 0.504834] [G loss: 0.953057]\n",
      "[Epoch 13/200] [Batch 82/169] [D loss: 0.663572] [G loss: 1.032623]\n",
      "[Epoch 13/200] [Batch 83/169] [D loss: 0.644810] [G loss: 0.985681]\n",
      "[Epoch 13/200] [Batch 84/169] [D loss: 0.617083] [G loss: 1.004695]\n",
      "[Epoch 13/200] [Batch 85/169] [D loss: 0.492692] [G loss: 1.049842]\n",
      "[Epoch 13/200] [Batch 86/169] [D loss: 0.519834] [G loss: 0.984184]\n",
      "[Epoch 13/200] [Batch 87/169] [D loss: 0.642270] [G loss: 0.938373]\n",
      "[Epoch 13/200] [Batch 88/169] [D loss: 0.565898] [G loss: 0.885649]\n",
      "[Epoch 13/200] [Batch 89/169] [D loss: 0.539584] [G loss: 1.019667]\n",
      "[Epoch 13/200] [Batch 90/169] [D loss: 0.588460] [G loss: 1.082813]\n",
      "[Epoch 13/200] [Batch 91/169] [D loss: 0.578637] [G loss: 1.046700]\n",
      "[Epoch 13/200] [Batch 92/169] [D loss: 0.546941] [G loss: 0.825432]\n",
      "[Epoch 13/200] [Batch 93/169] [D loss: 0.585428] [G loss: 0.897319]\n",
      "[Epoch 13/200] [Batch 94/169] [D loss: 0.615733] [G loss: 0.890242]\n",
      "[Epoch 13/200] [Batch 95/169] [D loss: 0.574587] [G loss: 1.028471]\n",
      "[Epoch 13/200] [Batch 96/169] [D loss: 0.600964] [G loss: 0.884354]\n",
      "[Epoch 13/200] [Batch 97/169] [D loss: 0.458718] [G loss: 0.989613]\n",
      "[Epoch 13/200] [Batch 98/169] [D loss: 0.555256] [G loss: 0.964168]\n",
      "[Epoch 13/200] [Batch 99/169] [D loss: 0.597921] [G loss: 1.080577]\n",
      "[Epoch 13/200] [Batch 100/169] [D loss: 0.593601] [G loss: 0.940104]\n",
      "[Epoch 13/200] [Batch 101/169] [D loss: 0.634996] [G loss: 1.115399]\n",
      "[Epoch 13/200] [Batch 102/169] [D loss: 0.589744] [G loss: 0.827133]\n",
      "[Epoch 13/200] [Batch 103/169] [D loss: 0.581602] [G loss: 0.851687]\n",
      "[Epoch 13/200] [Batch 104/169] [D loss: 0.645851] [G loss: 0.931127]\n",
      "[Epoch 13/200] [Batch 105/169] [D loss: 0.618254] [G loss: 0.937413]\n",
      "[Epoch 13/200] [Batch 106/169] [D loss: 0.608164] [G loss: 1.131339]\n",
      "[Epoch 13/200] [Batch 107/169] [D loss: 0.563494] [G loss: 0.891048]\n",
      "[Epoch 13/200] [Batch 108/169] [D loss: 0.582848] [G loss: 0.846743]\n",
      "[Epoch 13/200] [Batch 109/169] [D loss: 0.598142] [G loss: 0.908797]\n",
      "[Epoch 13/200] [Batch 110/169] [D loss: 0.609710] [G loss: 0.933294]\n",
      "[Epoch 13/200] [Batch 111/169] [D loss: 0.545385] [G loss: 1.060774]\n",
      "[Epoch 13/200] [Batch 112/169] [D loss: 0.652169] [G loss: 1.027541]\n",
      "[Epoch 13/200] [Batch 113/169] [D loss: 0.573993] [G loss: 0.902936]\n",
      "[Epoch 13/200] [Batch 114/169] [D loss: 0.623826] [G loss: 0.837220]\n",
      "[Epoch 13/200] [Batch 115/169] [D loss: 0.739987] [G loss: 0.819558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 116/169] [D loss: 0.652986] [G loss: 0.929356]\n",
      "[Epoch 13/200] [Batch 117/169] [D loss: 0.693142] [G loss: 1.083025]\n",
      "[Epoch 13/200] [Batch 118/169] [D loss: 0.689308] [G loss: 1.148791]\n",
      "[Epoch 13/200] [Batch 119/169] [D loss: 0.691989] [G loss: 1.007993]\n",
      "[Epoch 13/200] [Batch 120/169] [D loss: 0.614511] [G loss: 0.757556]\n",
      "[Epoch 13/200] [Batch 121/169] [D loss: 0.589284] [G loss: 0.949663]\n",
      "[Epoch 13/200] [Batch 122/169] [D loss: 0.547139] [G loss: 0.873453]\n",
      "[Epoch 13/200] [Batch 123/169] [D loss: 0.627460] [G loss: 0.866760]\n",
      "[Epoch 13/200] [Batch 124/169] [D loss: 0.657822] [G loss: 0.872197]\n",
      "[Epoch 13/200] [Batch 125/169] [D loss: 0.696123] [G loss: 1.007483]\n",
      "[Epoch 13/200] [Batch 126/169] [D loss: 0.644670] [G loss: 0.752566]\n",
      "[Epoch 13/200] [Batch 127/169] [D loss: 0.555923] [G loss: 0.856929]\n",
      "[Epoch 13/200] [Batch 128/169] [D loss: 0.643884] [G loss: 0.993937]\n",
      "[Epoch 13/200] [Batch 129/169] [D loss: 0.546633] [G loss: 0.858033]\n",
      "[Epoch 13/200] [Batch 130/169] [D loss: 0.621397] [G loss: 0.926707]\n",
      "[Epoch 13/200] [Batch 131/169] [D loss: 0.657817] [G loss: 0.746861]\n",
      "[Epoch 13/200] [Batch 132/169] [D loss: 0.673606] [G loss: 0.949596]\n",
      "[Epoch 13/200] [Batch 133/169] [D loss: 0.662207] [G loss: 1.062331]\n",
      "[Epoch 13/200] [Batch 134/169] [D loss: 0.601789] [G loss: 0.848788]\n",
      "[Epoch 13/200] [Batch 135/169] [D loss: 0.555721] [G loss: 0.911536]\n",
      "[Epoch 13/200] [Batch 136/169] [D loss: 0.564415] [G loss: 0.993153]\n",
      "[Epoch 13/200] [Batch 137/169] [D loss: 0.645399] [G loss: 0.929171]\n",
      "[Epoch 13/200] [Batch 138/169] [D loss: 0.584945] [G loss: 0.745287]\n",
      "[Epoch 13/200] [Batch 139/169] [D loss: 0.590178] [G loss: 1.134934]\n",
      "[Epoch 13/200] [Batch 140/169] [D loss: 0.620344] [G loss: 1.019718]\n",
      "[Epoch 13/200] [Batch 141/169] [D loss: 0.641157] [G loss: 0.982968]\n",
      "[Epoch 13/200] [Batch 142/169] [D loss: 0.750924] [G loss: 0.829133]\n",
      "[Epoch 13/200] [Batch 143/169] [D loss: 0.650384] [G loss: 1.006104]\n",
      "[Epoch 13/200] [Batch 144/169] [D loss: 0.590319] [G loss: 0.965508]\n",
      "[Epoch 13/200] [Batch 145/169] [D loss: 0.604457] [G loss: 1.143900]\n",
      "[Epoch 13/200] [Batch 146/169] [D loss: 0.533072] [G loss: 0.974815]\n",
      "[Epoch 13/200] [Batch 147/169] [D loss: 0.589767] [G loss: 1.008570]\n",
      "[Epoch 13/200] [Batch 148/169] [D loss: 0.617554] [G loss: 1.024103]\n",
      "[Epoch 13/200] [Batch 149/169] [D loss: 0.690167] [G loss: 1.005769]\n",
      "[Epoch 13/200] [Batch 150/169] [D loss: 0.580151] [G loss: 1.089138]\n",
      "[Epoch 13/200] [Batch 151/169] [D loss: 0.565041] [G loss: 1.033297]\n",
      "[Epoch 13/200] [Batch 152/169] [D loss: 0.573227] [G loss: 1.134779]\n",
      "[Epoch 13/200] [Batch 153/169] [D loss: 0.546147] [G loss: 1.182452]\n",
      "[Epoch 13/200] [Batch 154/169] [D loss: 0.574893] [G loss: 1.092247]\n",
      "[Epoch 13/200] [Batch 155/169] [D loss: 0.682119] [G loss: 0.690305]\n",
      "[Epoch 13/200] [Batch 156/169] [D loss: 0.609796] [G loss: 0.796566]\n",
      "[Epoch 13/200] [Batch 157/169] [D loss: 0.654709] [G loss: 0.906738]\n",
      "[Epoch 13/200] [Batch 158/169] [D loss: 0.625037] [G loss: 0.896291]\n",
      "[Epoch 13/200] [Batch 159/169] [D loss: 0.549570] [G loss: 1.036486]\n",
      "[Epoch 13/200] [Batch 160/169] [D loss: 0.611798] [G loss: 1.105871]\n",
      "[Epoch 13/200] [Batch 161/169] [D loss: 0.599883] [G loss: 1.031751]\n",
      "[Epoch 13/200] [Batch 162/169] [D loss: 0.596726] [G loss: 0.883063]\n",
      "[Epoch 13/200] [Batch 163/169] [D loss: 0.630310] [G loss: 0.861112]\n",
      "[Epoch 13/200] [Batch 164/169] [D loss: 0.529365] [G loss: 0.858505]\n",
      "[Epoch 13/200] [Batch 165/169] [D loss: 0.622753] [G loss: 0.833823]\n",
      "[Epoch 13/200] [Batch 166/169] [D loss: 0.679178] [G loss: 0.902770]\n",
      "[Epoch 13/200] [Batch 167/169] [D loss: 0.587307] [G loss: 1.005751]\n",
      "[Epoch 13/200] [Batch 168/169] [D loss: 0.657016] [G loss: 1.094471]\n",
      "[Epoch 14/200] [Batch 0/169] [D loss: 0.737417] [G loss: 0.921049]\n",
      "[Epoch 14/200] [Batch 1/169] [D loss: 0.697400] [G loss: 0.992009]\n",
      "[Epoch 14/200] [Batch 2/169] [D loss: 0.726098] [G loss: 0.861578]\n",
      "[Epoch 14/200] [Batch 3/169] [D loss: 0.583184] [G loss: 1.255255]\n",
      "[Epoch 14/200] [Batch 4/169] [D loss: 0.659329] [G loss: 0.975930]\n",
      "[Epoch 14/200] [Batch 5/169] [D loss: 0.575357] [G loss: 0.883666]\n",
      "[Epoch 14/200] [Batch 6/169] [D loss: 0.676433] [G loss: 0.954247]\n",
      "[Epoch 14/200] [Batch 7/169] [D loss: 0.610365] [G loss: 0.904942]\n",
      "[Epoch 14/200] [Batch 8/169] [D loss: 0.631347] [G loss: 1.035612]\n",
      "[Epoch 14/200] [Batch 9/169] [D loss: 0.567294] [G loss: 0.884969]\n",
      "[Epoch 14/200] [Batch 10/169] [D loss: 0.640605] [G loss: 0.950763]\n",
      "[Epoch 14/200] [Batch 11/169] [D loss: 0.641937] [G loss: 0.892646]\n",
      "[Epoch 14/200] [Batch 12/169] [D loss: 0.655792] [G loss: 0.969444]\n",
      "[Epoch 14/200] [Batch 13/169] [D loss: 0.563338] [G loss: 1.072551]\n",
      "[Epoch 14/200] [Batch 14/169] [D loss: 0.621457] [G loss: 0.960757]\n",
      "[Epoch 14/200] [Batch 15/169] [D loss: 0.604780] [G loss: 0.842539]\n",
      "[Epoch 14/200] [Batch 16/169] [D loss: 0.690928] [G loss: 0.958917]\n",
      "[Epoch 14/200] [Batch 17/169] [D loss: 0.635226] [G loss: 0.962983]\n",
      "[Epoch 14/200] [Batch 18/169] [D loss: 0.608320] [G loss: 1.071376]\n",
      "[Epoch 14/200] [Batch 19/169] [D loss: 0.588687] [G loss: 1.016637]\n",
      "[Epoch 14/200] [Batch 20/169] [D loss: 0.541303] [G loss: 0.985800]\n",
      "[Epoch 14/200] [Batch 21/169] [D loss: 0.555132] [G loss: 0.788394]\n",
      "[Epoch 14/200] [Batch 22/169] [D loss: 0.579401] [G loss: 0.748002]\n",
      "[Epoch 14/200] [Batch 23/169] [D loss: 0.619731] [G loss: 0.871874]\n",
      "[Epoch 14/200] [Batch 24/169] [D loss: 0.598912] [G loss: 0.933001]\n",
      "[Epoch 14/200] [Batch 25/169] [D loss: 0.588783] [G loss: 0.841877]\n",
      "[Epoch 14/200] [Batch 26/169] [D loss: 0.600584] [G loss: 1.012701]\n",
      "[Epoch 14/200] [Batch 27/169] [D loss: 0.616197] [G loss: 0.795611]\n",
      "[Epoch 14/200] [Batch 28/169] [D loss: 0.611814] [G loss: 1.045317]\n",
      "[Epoch 14/200] [Batch 29/169] [D loss: 0.612557] [G loss: 0.943953]\n",
      "[Epoch 14/200] [Batch 30/169] [D loss: 0.562459] [G loss: 0.899329]\n",
      "[Epoch 14/200] [Batch 31/169] [D loss: 0.543083] [G loss: 1.057296]\n",
      "[Epoch 14/200] [Batch 32/169] [D loss: 0.542746] [G loss: 0.968381]\n",
      "[Epoch 14/200] [Batch 33/169] [D loss: 0.633884] [G loss: 0.870509]\n",
      "[Epoch 14/200] [Batch 34/169] [D loss: 0.453561] [G loss: 0.931196]\n",
      "[Epoch 14/200] [Batch 35/169] [D loss: 0.640286] [G loss: 0.948299]\n",
      "[Epoch 14/200] [Batch 36/169] [D loss: 0.615565] [G loss: 0.926902]\n",
      "[Epoch 14/200] [Batch 37/169] [D loss: 0.636263] [G loss: 0.975999]\n",
      "[Epoch 14/200] [Batch 38/169] [D loss: 0.572134] [G loss: 0.885169]\n",
      "[Epoch 14/200] [Batch 39/169] [D loss: 0.549576] [G loss: 0.880052]\n",
      "[Epoch 14/200] [Batch 40/169] [D loss: 0.663466] [G loss: 0.864637]\n",
      "[Epoch 14/200] [Batch 41/169] [D loss: 0.552117] [G loss: 0.857611]\n",
      "[Epoch 14/200] [Batch 42/169] [D loss: 0.540233] [G loss: 0.920813]\n",
      "[Epoch 14/200] [Batch 43/169] [D loss: 0.618560] [G loss: 1.062612]\n",
      "[Epoch 14/200] [Batch 44/169] [D loss: 0.601745] [G loss: 0.973197]\n",
      "[Epoch 14/200] [Batch 45/169] [D loss: 0.636866] [G loss: 1.061758]\n",
      "[Epoch 14/200] [Batch 46/169] [D loss: 0.519180] [G loss: 0.967653]\n",
      "[Epoch 14/200] [Batch 47/169] [D loss: 0.546857] [G loss: 0.940346]\n",
      "[Epoch 14/200] [Batch 48/169] [D loss: 0.625224] [G loss: 0.893377]\n",
      "[Epoch 14/200] [Batch 49/169] [D loss: 0.590548] [G loss: 0.942947]\n",
      "[Epoch 14/200] [Batch 50/169] [D loss: 0.595517] [G loss: 0.985286]\n",
      "[Epoch 14/200] [Batch 51/169] [D loss: 0.601448] [G loss: 1.179307]\n",
      "[Epoch 14/200] [Batch 52/169] [D loss: 0.644054] [G loss: 0.898943]\n",
      "[Epoch 14/200] [Batch 53/169] [D loss: 0.619126] [G loss: 0.770864]\n",
      "[Epoch 14/200] [Batch 54/169] [D loss: 0.630298] [G loss: 0.942235]\n",
      "[Epoch 14/200] [Batch 55/169] [D loss: 0.551280] [G loss: 1.101018]\n",
      "[Epoch 14/200] [Batch 56/169] [D loss: 0.650511] [G loss: 1.162190]\n",
      "[Epoch 14/200] [Batch 57/169] [D loss: 0.532451] [G loss: 1.188061]\n",
      "[Epoch 14/200] [Batch 58/169] [D loss: 0.650498] [G loss: 0.976570]\n",
      "[Epoch 14/200] [Batch 59/169] [D loss: 0.629181] [G loss: 0.989693]\n",
      "[Epoch 14/200] [Batch 60/169] [D loss: 0.571826] [G loss: 0.943936]\n",
      "[Epoch 14/200] [Batch 61/169] [D loss: 0.554251] [G loss: 0.978113]\n",
      "[Epoch 14/200] [Batch 62/169] [D loss: 0.574165] [G loss: 1.154773]\n",
      "[Epoch 14/200] [Batch 63/169] [D loss: 0.688584] [G loss: 0.997585]\n",
      "[Epoch 14/200] [Batch 64/169] [D loss: 0.497832] [G loss: 1.082156]\n",
      "[Epoch 14/200] [Batch 65/169] [D loss: 0.650090] [G loss: 1.024454]\n",
      "[Epoch 14/200] [Batch 66/169] [D loss: 0.562126] [G loss: 0.979228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 67/169] [D loss: 0.584148] [G loss: 0.961323]\n",
      "[Epoch 14/200] [Batch 68/169] [D loss: 0.549646] [G loss: 0.953048]\n",
      "[Epoch 14/200] [Batch 69/169] [D loss: 0.562899] [G loss: 0.957810]\n",
      "[Epoch 14/200] [Batch 70/169] [D loss: 0.637143] [G loss: 0.773812]\n",
      "[Epoch 14/200] [Batch 71/169] [D loss: 0.624034] [G loss: 0.976057]\n",
      "[Epoch 14/200] [Batch 72/169] [D loss: 0.613928] [G loss: 0.939028]\n",
      "[Epoch 14/200] [Batch 73/169] [D loss: 0.536086] [G loss: 1.017677]\n",
      "[Epoch 14/200] [Batch 74/169] [D loss: 0.676094] [G loss: 0.783602]\n",
      "[Epoch 14/200] [Batch 75/169] [D loss: 0.651095] [G loss: 0.971158]\n",
      "[Epoch 14/200] [Batch 76/169] [D loss: 0.624838] [G loss: 0.899081]\n",
      "[Epoch 14/200] [Batch 77/169] [D loss: 0.643992] [G loss: 1.099472]\n",
      "[Epoch 14/200] [Batch 78/169] [D loss: 0.632893] [G loss: 0.964718]\n",
      "[Epoch 14/200] [Batch 79/169] [D loss: 0.626527] [G loss: 0.772312]\n",
      "[Epoch 14/200] [Batch 80/169] [D loss: 0.579701] [G loss: 0.833560]\n",
      "[Epoch 14/200] [Batch 81/169] [D loss: 0.632146] [G loss: 1.031938]\n",
      "[Epoch 14/200] [Batch 82/169] [D loss: 0.543242] [G loss: 1.043281]\n",
      "[Epoch 14/200] [Batch 83/169] [D loss: 0.647854] [G loss: 0.938567]\n",
      "[Epoch 14/200] [Batch 84/169] [D loss: 0.605015] [G loss: 0.897942]\n",
      "[Epoch 14/200] [Batch 85/169] [D loss: 0.591033] [G loss: 0.825418]\n",
      "[Epoch 14/200] [Batch 86/169] [D loss: 0.666297] [G loss: 0.928485]\n",
      "[Epoch 14/200] [Batch 87/169] [D loss: 0.677816] [G loss: 0.877428]\n",
      "[Epoch 14/200] [Batch 88/169] [D loss: 0.605400] [G loss: 0.903222]\n",
      "[Epoch 14/200] [Batch 89/169] [D loss: 0.564586] [G loss: 0.974767]\n",
      "[Epoch 14/200] [Batch 90/169] [D loss: 0.630778] [G loss: 1.003080]\n",
      "[Epoch 14/200] [Batch 91/169] [D loss: 0.674071] [G loss: 0.843813]\n",
      "[Epoch 14/200] [Batch 92/169] [D loss: 0.641947] [G loss: 0.781611]\n",
      "[Epoch 14/200] [Batch 93/169] [D loss: 0.636338] [G loss: 0.756884]\n",
      "[Epoch 14/200] [Batch 94/169] [D loss: 0.679753] [G loss: 1.026773]\n",
      "[Epoch 14/200] [Batch 95/169] [D loss: 0.649956] [G loss: 1.028882]\n",
      "[Epoch 14/200] [Batch 96/169] [D loss: 0.664583] [G loss: 0.902896]\n",
      "[Epoch 14/200] [Batch 97/169] [D loss: 0.680510] [G loss: 0.913939]\n",
      "[Epoch 14/200] [Batch 98/169] [D loss: 0.597336] [G loss: 0.759663]\n",
      "[Epoch 14/200] [Batch 99/169] [D loss: 0.667739] [G loss: 0.893117]\n",
      "[Epoch 14/200] [Batch 100/169] [D loss: 0.573072] [G loss: 0.814934]\n",
      "[Epoch 14/200] [Batch 101/169] [D loss: 0.669115] [G loss: 0.890279]\n",
      "[Epoch 14/200] [Batch 102/169] [D loss: 0.539982] [G loss: 1.111021]\n",
      "[Epoch 14/200] [Batch 103/169] [D loss: 0.580895] [G loss: 1.048303]\n",
      "[Epoch 14/200] [Batch 104/169] [D loss: 0.606187] [G loss: 1.168182]\n",
      "[Epoch 14/200] [Batch 105/169] [D loss: 0.580781] [G loss: 0.868261]\n",
      "[Epoch 14/200] [Batch 106/169] [D loss: 0.562751] [G loss: 0.887501]\n",
      "[Epoch 14/200] [Batch 107/169] [D loss: 0.547782] [G loss: 0.978227]\n",
      "[Epoch 14/200] [Batch 108/169] [D loss: 0.539113] [G loss: 0.783352]\n",
      "[Epoch 14/200] [Batch 109/169] [D loss: 0.606312] [G loss: 0.829673]\n",
      "[Epoch 14/200] [Batch 110/169] [D loss: 0.588573] [G loss: 0.847158]\n",
      "[Epoch 14/200] [Batch 111/169] [D loss: 0.532284] [G loss: 1.008990]\n",
      "[Epoch 14/200] [Batch 112/169] [D loss: 0.511655] [G loss: 1.007283]\n",
      "[Epoch 14/200] [Batch 113/169] [D loss: 0.616841] [G loss: 1.053161]\n",
      "[Epoch 14/200] [Batch 114/169] [D loss: 0.653475] [G loss: 1.066360]\n",
      "[Epoch 14/200] [Batch 115/169] [D loss: 0.592579] [G loss: 0.904525]\n",
      "[Epoch 14/200] [Batch 116/169] [D loss: 0.595598] [G loss: 0.969020]\n",
      "[Epoch 14/200] [Batch 117/169] [D loss: 0.570053] [G loss: 0.981655]\n",
      "[Epoch 14/200] [Batch 118/169] [D loss: 0.585125] [G loss: 1.079224]\n",
      "[Epoch 14/200] [Batch 119/169] [D loss: 0.606493] [G loss: 1.075463]\n",
      "[Epoch 14/200] [Batch 120/169] [D loss: 0.616106] [G loss: 0.946811]\n",
      "[Epoch 14/200] [Batch 121/169] [D loss: 0.623170] [G loss: 0.933645]\n",
      "[Epoch 14/200] [Batch 122/169] [D loss: 0.610064] [G loss: 0.959164]\n",
      "[Epoch 14/200] [Batch 123/169] [D loss: 0.586161] [G loss: 0.984577]\n",
      "[Epoch 14/200] [Batch 124/169] [D loss: 0.522093] [G loss: 0.919335]\n",
      "[Epoch 14/200] [Batch 125/169] [D loss: 0.494232] [G loss: 0.883852]\n",
      "[Epoch 14/200] [Batch 126/169] [D loss: 0.515596] [G loss: 1.051507]\n",
      "[Epoch 14/200] [Batch 127/169] [D loss: 0.561704] [G loss: 0.921213]\n",
      "[Epoch 14/200] [Batch 128/169] [D loss: 0.582952] [G loss: 0.900010]\n",
      "[Epoch 14/200] [Batch 129/169] [D loss: 0.552364] [G loss: 0.975183]\n",
      "[Epoch 14/200] [Batch 130/169] [D loss: 0.728276] [G loss: 1.054919]\n",
      "[Epoch 14/200] [Batch 131/169] [D loss: 0.622687] [G loss: 0.972496]\n",
      "[Epoch 14/200] [Batch 132/169] [D loss: 0.648160] [G loss: 0.830239]\n",
      "[Epoch 14/200] [Batch 133/169] [D loss: 0.654888] [G loss: 0.766134]\n",
      "[Epoch 14/200] [Batch 134/169] [D loss: 0.704655] [G loss: 0.942217]\n",
      "[Epoch 14/200] [Batch 135/169] [D loss: 0.663563] [G loss: 0.736506]\n",
      "[Epoch 14/200] [Batch 136/169] [D loss: 0.596564] [G loss: 0.891473]\n",
      "[Epoch 14/200] [Batch 137/169] [D loss: 0.646182] [G loss: 0.892000]\n",
      "[Epoch 14/200] [Batch 138/169] [D loss: 0.547543] [G loss: 0.841550]\n",
      "[Epoch 14/200] [Batch 139/169] [D loss: 0.675941] [G loss: 0.987409]\n",
      "[Epoch 14/200] [Batch 140/169] [D loss: 0.654825] [G loss: 1.163111]\n",
      "[Epoch 14/200] [Batch 141/169] [D loss: 0.601803] [G loss: 1.135791]\n",
      "[Epoch 14/200] [Batch 142/169] [D loss: 0.649455] [G loss: 0.855364]\n",
      "[Epoch 14/200] [Batch 143/169] [D loss: 0.520367] [G loss: 0.990574]\n",
      "[Epoch 14/200] [Batch 144/169] [D loss: 0.665890] [G loss: 0.794455]\n",
      "[Epoch 14/200] [Batch 145/169] [D loss: 0.642334] [G loss: 0.706637]\n",
      "[Epoch 14/200] [Batch 146/169] [D loss: 0.686913] [G loss: 0.639335]\n",
      "[Epoch 14/200] [Batch 147/169] [D loss: 0.659870] [G loss: 0.814247]\n",
      "[Epoch 14/200] [Batch 148/169] [D loss: 0.630574] [G loss: 0.812133]\n",
      "[Epoch 14/200] [Batch 149/169] [D loss: 0.608175] [G loss: 0.930309]\n",
      "[Epoch 14/200] [Batch 150/169] [D loss: 0.694447] [G loss: 0.754426]\n",
      "[Epoch 14/200] [Batch 151/169] [D loss: 0.660826] [G loss: 0.869670]\n",
      "[Epoch 14/200] [Batch 152/169] [D loss: 0.635414] [G loss: 1.104448]\n",
      "[Epoch 14/200] [Batch 153/169] [D loss: 0.623181] [G loss: 0.969334]\n",
      "[Epoch 14/200] [Batch 154/169] [D loss: 0.686975] [G loss: 1.048519]\n",
      "[Epoch 14/200] [Batch 155/169] [D loss: 0.602569] [G loss: 0.884306]\n",
      "[Epoch 14/200] [Batch 156/169] [D loss: 0.661637] [G loss: 0.921798]\n",
      "[Epoch 14/200] [Batch 157/169] [D loss: 0.633112] [G loss: 0.995327]\n",
      "[Epoch 14/200] [Batch 158/169] [D loss: 0.694161] [G loss: 1.084104]\n",
      "[Epoch 14/200] [Batch 159/169] [D loss: 0.602131] [G loss: 1.130822]\n",
      "[Epoch 14/200] [Batch 160/169] [D loss: 0.637870] [G loss: 0.995215]\n",
      "[Epoch 14/200] [Batch 161/169] [D loss: 0.566890] [G loss: 0.731464]\n",
      "[Epoch 14/200] [Batch 162/169] [D loss: 0.549158] [G loss: 0.900776]\n",
      "[Epoch 14/200] [Batch 163/169] [D loss: 0.579718] [G loss: 1.283059]\n",
      "[Epoch 14/200] [Batch 164/169] [D loss: 0.696877] [G loss: 1.142468]\n",
      "[Epoch 14/200] [Batch 165/169] [D loss: 0.603923] [G loss: 0.974676]\n",
      "[Epoch 14/200] [Batch 166/169] [D loss: 0.622461] [G loss: 0.818931]\n",
      "[Epoch 14/200] [Batch 167/169] [D loss: 0.655169] [G loss: 0.883369]\n",
      "[Epoch 14/200] [Batch 168/169] [D loss: 0.624311] [G loss: 0.919145]\n",
      "[Epoch 15/200] [Batch 0/169] [D loss: 0.585860] [G loss: 0.801281]\n",
      "[Epoch 15/200] [Batch 1/169] [D loss: 0.576991] [G loss: 0.924915]\n",
      "[Epoch 15/200] [Batch 2/169] [D loss: 0.592574] [G loss: 1.086878]\n",
      "[Epoch 15/200] [Batch 3/169] [D loss: 0.601131] [G loss: 1.286688]\n",
      "[Epoch 15/200] [Batch 4/169] [D loss: 0.636483] [G loss: 1.105112]\n",
      "[Epoch 15/200] [Batch 5/169] [D loss: 0.592083] [G loss: 1.009564]\n",
      "[Epoch 15/200] [Batch 6/169] [D loss: 0.531434] [G loss: 0.972022]\n",
      "[Epoch 15/200] [Batch 7/169] [D loss: 0.553165] [G loss: 1.010270]\n",
      "[Epoch 15/200] [Batch 8/169] [D loss: 0.550814] [G loss: 0.882511]\n",
      "[Epoch 15/200] [Batch 9/169] [D loss: 0.569793] [G loss: 0.931294]\n",
      "[Epoch 15/200] [Batch 10/169] [D loss: 0.570373] [G loss: 0.996124]\n",
      "[Epoch 15/200] [Batch 11/169] [D loss: 0.476124] [G loss: 1.041278]\n",
      "[Epoch 15/200] [Batch 12/169] [D loss: 0.571761] [G loss: 1.061149]\n",
      "[Epoch 15/200] [Batch 13/169] [D loss: 0.592202] [G loss: 0.924891]\n",
      "[Epoch 15/200] [Batch 14/169] [D loss: 0.551488] [G loss: 0.768365]\n",
      "[Epoch 15/200] [Batch 15/169] [D loss: 0.655077] [G loss: 0.868774]\n",
      "[Epoch 15/200] [Batch 16/169] [D loss: 0.609887] [G loss: 1.064048]\n",
      "[Epoch 15/200] [Batch 17/169] [D loss: 0.570509] [G loss: 1.181343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 18/169] [D loss: 0.567769] [G loss: 1.075715]\n",
      "[Epoch 15/200] [Batch 19/169] [D loss: 0.543836] [G loss: 0.970950]\n",
      "[Epoch 15/200] [Batch 20/169] [D loss: 0.580381] [G loss: 0.911730]\n",
      "[Epoch 15/200] [Batch 21/169] [D loss: 0.572160] [G loss: 0.882929]\n",
      "[Epoch 15/200] [Batch 22/169] [D loss: 0.550895] [G loss: 0.914494]\n",
      "[Epoch 15/200] [Batch 23/169] [D loss: 0.582282] [G loss: 1.033518]\n",
      "[Epoch 15/200] [Batch 24/169] [D loss: 0.642606] [G loss: 1.040784]\n",
      "[Epoch 15/200] [Batch 25/169] [D loss: 0.560637] [G loss: 0.933025]\n",
      "[Epoch 15/200] [Batch 26/169] [D loss: 0.621415] [G loss: 0.822153]\n",
      "[Epoch 15/200] [Batch 27/169] [D loss: 0.633366] [G loss: 0.791002]\n",
      "[Epoch 15/200] [Batch 28/169] [D loss: 0.720376] [G loss: 0.817704]\n",
      "[Epoch 15/200] [Batch 29/169] [D loss: 0.627797] [G loss: 0.811639]\n",
      "[Epoch 15/200] [Batch 30/169] [D loss: 0.774457] [G loss: 0.844193]\n",
      "[Epoch 15/200] [Batch 31/169] [D loss: 0.743722] [G loss: 0.945169]\n",
      "[Epoch 15/200] [Batch 32/169] [D loss: 0.634007] [G loss: 0.765608]\n",
      "[Epoch 15/200] [Batch 33/169] [D loss: 0.721240] [G loss: 0.811236]\n",
      "[Epoch 15/200] [Batch 34/169] [D loss: 0.570542] [G loss: 0.950906]\n",
      "[Epoch 15/200] [Batch 35/169] [D loss: 0.516977] [G loss: 1.172693]\n",
      "[Epoch 15/200] [Batch 36/169] [D loss: 0.585262] [G loss: 0.931307]\n",
      "[Epoch 15/200] [Batch 37/169] [D loss: 0.603958] [G loss: 0.978021]\n",
      "[Epoch 15/200] [Batch 38/169] [D loss: 0.557936] [G loss: 1.004043]\n",
      "[Epoch 15/200] [Batch 39/169] [D loss: 0.577748] [G loss: 0.858591]\n",
      "[Epoch 15/200] [Batch 40/169] [D loss: 0.611260] [G loss: 0.827416]\n",
      "[Epoch 15/200] [Batch 41/169] [D loss: 0.620729] [G loss: 0.925048]\n",
      "[Epoch 15/200] [Batch 42/169] [D loss: 0.571524] [G loss: 0.775543]\n",
      "[Epoch 15/200] [Batch 43/169] [D loss: 0.566675] [G loss: 0.797624]\n",
      "[Epoch 15/200] [Batch 44/169] [D loss: 0.468074] [G loss: 0.918004]\n",
      "[Epoch 15/200] [Batch 45/169] [D loss: 0.570641] [G loss: 0.820839]\n",
      "[Epoch 15/200] [Batch 46/169] [D loss: 0.599752] [G loss: 0.823227]\n",
      "[Epoch 15/200] [Batch 47/169] [D loss: 0.655054] [G loss: 0.795107]\n",
      "[Epoch 15/200] [Batch 48/169] [D loss: 0.643309] [G loss: 0.939618]\n",
      "[Epoch 15/200] [Batch 49/169] [D loss: 0.596322] [G loss: 0.934208]\n",
      "[Epoch 15/200] [Batch 50/169] [D loss: 0.627616] [G loss: 0.974106]\n",
      "[Epoch 15/200] [Batch 51/169] [D loss: 0.622764] [G loss: 1.255043]\n",
      "[Epoch 15/200] [Batch 52/169] [D loss: 0.619020] [G loss: 1.004195]\n",
      "[Epoch 15/200] [Batch 53/169] [D loss: 0.693907] [G loss: 0.845400]\n",
      "[Epoch 15/200] [Batch 54/169] [D loss: 0.585080] [G loss: 1.002965]\n",
      "[Epoch 15/200] [Batch 55/169] [D loss: 0.592741] [G loss: 0.935574]\n",
      "[Epoch 15/200] [Batch 56/169] [D loss: 0.621608] [G loss: 0.974501]\n",
      "[Epoch 15/200] [Batch 57/169] [D loss: 0.607187] [G loss: 0.880966]\n",
      "[Epoch 15/200] [Batch 58/169] [D loss: 0.546669] [G loss: 1.057905]\n",
      "[Epoch 15/200] [Batch 59/169] [D loss: 0.636743] [G loss: 1.023490]\n",
      "[Epoch 15/200] [Batch 60/169] [D loss: 0.520555] [G loss: 1.066102]\n",
      "[Epoch 15/200] [Batch 61/169] [D loss: 0.564867] [G loss: 1.036754]\n",
      "[Epoch 15/200] [Batch 62/169] [D loss: 0.610962] [G loss: 0.935550]\n",
      "[Epoch 15/200] [Batch 63/169] [D loss: 0.528339] [G loss: 1.033673]\n",
      "[Epoch 15/200] [Batch 64/169] [D loss: 0.580212] [G loss: 0.889309]\n",
      "[Epoch 15/200] [Batch 65/169] [D loss: 0.653655] [G loss: 1.068939]\n",
      "[Epoch 15/200] [Batch 66/169] [D loss: 0.581197] [G loss: 1.012561]\n",
      "[Epoch 15/200] [Batch 67/169] [D loss: 0.588218] [G loss: 0.974820]\n",
      "[Epoch 15/200] [Batch 68/169] [D loss: 0.574379] [G loss: 0.933995]\n",
      "[Epoch 15/200] [Batch 69/169] [D loss: 0.595899] [G loss: 0.801898]\n",
      "[Epoch 15/200] [Batch 70/169] [D loss: 0.623415] [G loss: 0.877770]\n",
      "[Epoch 15/200] [Batch 71/169] [D loss: 0.557552] [G loss: 0.986917]\n",
      "[Epoch 15/200] [Batch 72/169] [D loss: 0.586013] [G loss: 0.884996]\n",
      "[Epoch 15/200] [Batch 73/169] [D loss: 0.596301] [G loss: 0.935806]\n",
      "[Epoch 15/200] [Batch 74/169] [D loss: 0.615188] [G loss: 0.908859]\n",
      "[Epoch 15/200] [Batch 75/169] [D loss: 0.649961] [G loss: 0.918404]\n",
      "[Epoch 15/200] [Batch 76/169] [D loss: 0.578893] [G loss: 0.968141]\n",
      "[Epoch 15/200] [Batch 77/169] [D loss: 0.623276] [G loss: 1.035926]\n",
      "[Epoch 15/200] [Batch 78/169] [D loss: 0.634388] [G loss: 0.921801]\n",
      "[Epoch 15/200] [Batch 79/169] [D loss: 0.625385] [G loss: 1.001023]\n",
      "[Epoch 15/200] [Batch 80/169] [D loss: 0.637169] [G loss: 0.750899]\n",
      "[Epoch 15/200] [Batch 81/169] [D loss: 0.659085] [G loss: 0.991054]\n",
      "[Epoch 15/200] [Batch 82/169] [D loss: 0.608321] [G loss: 1.085540]\n",
      "[Epoch 15/200] [Batch 83/169] [D loss: 0.630351] [G loss: 1.159395]\n",
      "[Epoch 15/200] [Batch 84/169] [D loss: 0.659824] [G loss: 0.750729]\n",
      "[Epoch 15/200] [Batch 85/169] [D loss: 0.714353] [G loss: 0.964736]\n",
      "[Epoch 15/200] [Batch 86/169] [D loss: 0.656519] [G loss: 0.963962]\n",
      "[Epoch 15/200] [Batch 87/169] [D loss: 0.672876] [G loss: 1.034352]\n",
      "[Epoch 15/200] [Batch 88/169] [D loss: 0.575959] [G loss: 0.895523]\n",
      "[Epoch 15/200] [Batch 89/169] [D loss: 0.729460] [G loss: 0.930813]\n",
      "[Epoch 15/200] [Batch 90/169] [D loss: 0.660243] [G loss: 0.848895]\n",
      "[Epoch 15/200] [Batch 91/169] [D loss: 0.627294] [G loss: 0.788733]\n",
      "[Epoch 15/200] [Batch 92/169] [D loss: 0.624140] [G loss: 0.850619]\n",
      "[Epoch 15/200] [Batch 93/169] [D loss: 0.640298] [G loss: 0.897663]\n",
      "[Epoch 15/200] [Batch 94/169] [D loss: 0.573775] [G loss: 0.831621]\n",
      "[Epoch 15/200] [Batch 95/169] [D loss: 0.540623] [G loss: 1.007414]\n",
      "[Epoch 15/200] [Batch 96/169] [D loss: 0.649017] [G loss: 0.990887]\n",
      "[Epoch 15/200] [Batch 97/169] [D loss: 0.602958] [G loss: 0.925282]\n",
      "[Epoch 15/200] [Batch 98/169] [D loss: 0.662860] [G loss: 0.877851]\n",
      "[Epoch 15/200] [Batch 99/169] [D loss: 0.580327] [G loss: 0.937465]\n",
      "[Epoch 15/200] [Batch 100/169] [D loss: 0.527709] [G loss: 0.898911]\n",
      "[Epoch 15/200] [Batch 101/169] [D loss: 0.576186] [G loss: 0.928908]\n",
      "[Epoch 15/200] [Batch 102/169] [D loss: 0.521861] [G loss: 0.891881]\n",
      "[Epoch 15/200] [Batch 103/169] [D loss: 0.678098] [G loss: 1.061026]\n",
      "[Epoch 15/200] [Batch 104/169] [D loss: 0.548710] [G loss: 0.846651]\n",
      "[Epoch 15/200] [Batch 105/169] [D loss: 0.583215] [G loss: 1.049906]\n",
      "[Epoch 15/200] [Batch 106/169] [D loss: 0.621283] [G loss: 0.756575]\n",
      "[Epoch 15/200] [Batch 107/169] [D loss: 0.611500] [G loss: 1.013966]\n",
      "[Epoch 15/200] [Batch 108/169] [D loss: 0.576141] [G loss: 1.103783]\n",
      "[Epoch 15/200] [Batch 109/169] [D loss: 0.653250] [G loss: 0.887337]\n",
      "[Epoch 15/200] [Batch 110/169] [D loss: 0.521108] [G loss: 1.058812]\n",
      "[Epoch 15/200] [Batch 111/169] [D loss: 0.575038] [G loss: 0.870230]\n",
      "[Epoch 15/200] [Batch 112/169] [D loss: 0.670891] [G loss: 1.010038]\n",
      "[Epoch 15/200] [Batch 113/169] [D loss: 0.548038] [G loss: 0.949782]\n",
      "[Epoch 15/200] [Batch 114/169] [D loss: 0.608859] [G loss: 0.965229]\n",
      "[Epoch 15/200] [Batch 115/169] [D loss: 0.608580] [G loss: 0.845583]\n",
      "[Epoch 15/200] [Batch 116/169] [D loss: 0.626174] [G loss: 1.023080]\n",
      "[Epoch 15/200] [Batch 117/169] [D loss: 0.552016] [G loss: 0.839234]\n",
      "[Epoch 15/200] [Batch 118/169] [D loss: 0.692134] [G loss: 0.909717]\n",
      "[Epoch 15/200] [Batch 119/169] [D loss: 0.650233] [G loss: 0.859389]\n",
      "[Epoch 15/200] [Batch 120/169] [D loss: 0.548831] [G loss: 0.852055]\n",
      "[Epoch 15/200] [Batch 121/169] [D loss: 0.599709] [G loss: 0.845583]\n",
      "[Epoch 15/200] [Batch 122/169] [D loss: 0.584086] [G loss: 0.892945]\n",
      "[Epoch 15/200] [Batch 123/169] [D loss: 0.614808] [G loss: 0.940592]\n",
      "[Epoch 15/200] [Batch 124/169] [D loss: 0.578019] [G loss: 0.996778]\n",
      "[Epoch 15/200] [Batch 125/169] [D loss: 0.670581] [G loss: 0.934502]\n",
      "[Epoch 15/200] [Batch 126/169] [D loss: 0.656383] [G loss: 0.919381]\n",
      "[Epoch 15/200] [Batch 127/169] [D loss: 0.555786] [G loss: 0.876396]\n",
      "[Epoch 15/200] [Batch 128/169] [D loss: 0.538558] [G loss: 0.956238]\n",
      "[Epoch 15/200] [Batch 129/169] [D loss: 0.600961] [G loss: 0.912283]\n",
      "[Epoch 15/200] [Batch 130/169] [D loss: 0.623092] [G loss: 0.969452]\n",
      "[Epoch 15/200] [Batch 131/169] [D loss: 0.567724] [G loss: 1.063318]\n",
      "[Epoch 15/200] [Batch 132/169] [D loss: 0.563313] [G loss: 1.034820]\n",
      "[Epoch 15/200] [Batch 133/169] [D loss: 0.634900] [G loss: 1.033172]\n",
      "[Epoch 15/200] [Batch 134/169] [D loss: 0.511787] [G loss: 0.840252]\n",
      "[Epoch 15/200] [Batch 135/169] [D loss: 0.616858] [G loss: 0.817764]\n",
      "[Epoch 15/200] [Batch 136/169] [D loss: 0.684243] [G loss: 1.025552]\n",
      "[Epoch 15/200] [Batch 137/169] [D loss: 0.619674] [G loss: 0.859635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 138/169] [D loss: 0.586401] [G loss: 1.013102]\n",
      "[Epoch 15/200] [Batch 139/169] [D loss: 0.577832] [G loss: 0.820634]\n",
      "[Epoch 15/200] [Batch 140/169] [D loss: 0.588507] [G loss: 0.876953]\n",
      "[Epoch 15/200] [Batch 141/169] [D loss: 0.606912] [G loss: 0.935601]\n",
      "[Epoch 15/200] [Batch 142/169] [D loss: 0.636998] [G loss: 0.959370]\n",
      "[Epoch 15/200] [Batch 143/169] [D loss: 0.636858] [G loss: 0.889704]\n",
      "[Epoch 15/200] [Batch 144/169] [D loss: 0.556883] [G loss: 0.781362]\n",
      "[Epoch 15/200] [Batch 145/169] [D loss: 0.648567] [G loss: 0.868272]\n",
      "[Epoch 15/200] [Batch 146/169] [D loss: 0.622762] [G loss: 0.980942]\n",
      "[Epoch 15/200] [Batch 147/169] [D loss: 0.622267] [G loss: 0.885860]\n",
      "[Epoch 15/200] [Batch 148/169] [D loss: 0.687290] [G loss: 0.787119]\n",
      "[Epoch 15/200] [Batch 149/169] [D loss: 0.665170] [G loss: 0.955528]\n",
      "[Epoch 15/200] [Batch 150/169] [D loss: 0.660410] [G loss: 0.905804]\n",
      "[Epoch 15/200] [Batch 151/169] [D loss: 0.680130] [G loss: 0.860054]\n",
      "[Epoch 15/200] [Batch 152/169] [D loss: 0.685026] [G loss: 0.825343]\n",
      "[Epoch 15/200] [Batch 153/169] [D loss: 0.745323] [G loss: 0.856529]\n",
      "[Epoch 15/200] [Batch 154/169] [D loss: 0.711895] [G loss: 0.901676]\n",
      "[Epoch 15/200] [Batch 155/169] [D loss: 0.614222] [G loss: 1.079837]\n",
      "[Epoch 15/200] [Batch 156/169] [D loss: 0.571946] [G loss: 0.826966]\n",
      "[Epoch 15/200] [Batch 157/169] [D loss: 0.680246] [G loss: 0.760223]\n",
      "[Epoch 15/200] [Batch 158/169] [D loss: 0.614459] [G loss: 0.944650]\n",
      "[Epoch 15/200] [Batch 159/169] [D loss: 0.646110] [G loss: 0.992491]\n",
      "[Epoch 15/200] [Batch 160/169] [D loss: 0.564687] [G loss: 0.889472]\n",
      "[Epoch 15/200] [Batch 161/169] [D loss: 0.625131] [G loss: 0.831722]\n",
      "[Epoch 15/200] [Batch 162/169] [D loss: 0.672559] [G loss: 0.689217]\n",
      "[Epoch 15/200] [Batch 163/169] [D loss: 0.684524] [G loss: 0.749118]\n",
      "[Epoch 15/200] [Batch 164/169] [D loss: 0.626768] [G loss: 0.868807]\n",
      "[Epoch 15/200] [Batch 165/169] [D loss: 0.641768] [G loss: 0.842867]\n",
      "[Epoch 15/200] [Batch 166/169] [D loss: 0.535315] [G loss: 1.004757]\n",
      "[Epoch 15/200] [Batch 167/169] [D loss: 0.545793] [G loss: 0.978083]\n",
      "[Epoch 15/200] [Batch 168/169] [D loss: 0.609936] [G loss: 0.869554]\n",
      "[Epoch 16/200] [Batch 0/169] [D loss: 0.595568] [G loss: 0.934925]\n",
      "[Epoch 16/200] [Batch 1/169] [D loss: 0.625636] [G loss: 0.999350]\n",
      "[Epoch 16/200] [Batch 2/169] [D loss: 0.589192] [G loss: 0.987891]\n",
      "[Epoch 16/200] [Batch 3/169] [D loss: 0.522254] [G loss: 0.972926]\n",
      "[Epoch 16/200] [Batch 4/169] [D loss: 0.572775] [G loss: 0.938324]\n",
      "[Epoch 16/200] [Batch 5/169] [D loss: 0.507881] [G loss: 0.926187]\n",
      "[Epoch 16/200] [Batch 6/169] [D loss: 0.520433] [G loss: 0.927381]\n",
      "[Epoch 16/200] [Batch 7/169] [D loss: 0.561376] [G loss: 0.885477]\n",
      "[Epoch 16/200] [Batch 8/169] [D loss: 0.630140] [G loss: 0.753353]\n",
      "[Epoch 16/200] [Batch 9/169] [D loss: 0.533994] [G loss: 0.877069]\n",
      "[Epoch 16/200] [Batch 10/169] [D loss: 0.553069] [G loss: 1.102673]\n",
      "[Epoch 16/200] [Batch 11/169] [D loss: 0.513707] [G loss: 1.031199]\n",
      "[Epoch 16/200] [Batch 12/169] [D loss: 0.541691] [G loss: 1.038349]\n",
      "[Epoch 16/200] [Batch 13/169] [D loss: 0.585812] [G loss: 0.831372]\n",
      "[Epoch 16/200] [Batch 14/169] [D loss: 0.588973] [G loss: 1.148933]\n",
      "[Epoch 16/200] [Batch 15/169] [D loss: 0.453415] [G loss: 1.076202]\n",
      "[Epoch 16/200] [Batch 16/169] [D loss: 0.492008] [G loss: 0.989739]\n",
      "[Epoch 16/200] [Batch 17/169] [D loss: 0.533547] [G loss: 0.961808]\n",
      "[Epoch 16/200] [Batch 18/169] [D loss: 0.514122] [G loss: 1.104697]\n",
      "[Epoch 16/200] [Batch 19/169] [D loss: 0.565255] [G loss: 1.058326]\n",
      "[Epoch 16/200] [Batch 20/169] [D loss: 0.572001] [G loss: 1.066847]\n",
      "[Epoch 16/200] [Batch 21/169] [D loss: 0.568185] [G loss: 1.023544]\n",
      "[Epoch 16/200] [Batch 22/169] [D loss: 0.482165] [G loss: 1.003740]\n",
      "[Epoch 16/200] [Batch 23/169] [D loss: 0.529093] [G loss: 1.047994]\n",
      "[Epoch 16/200] [Batch 24/169] [D loss: 0.533858] [G loss: 0.917764]\n",
      "[Epoch 16/200] [Batch 25/169] [D loss: 0.532391] [G loss: 0.936959]\n",
      "[Epoch 16/200] [Batch 26/169] [D loss: 0.669524] [G loss: 0.972834]\n",
      "[Epoch 16/200] [Batch 27/169] [D loss: 0.626962] [G loss: 1.077213]\n",
      "[Epoch 16/200] [Batch 28/169] [D loss: 0.619387] [G loss: 1.090924]\n",
      "[Epoch 16/200] [Batch 29/169] [D loss: 0.672505] [G loss: 0.993396]\n",
      "[Epoch 16/200] [Batch 30/169] [D loss: 0.712565] [G loss: 0.861044]\n",
      "[Epoch 16/200] [Batch 31/169] [D loss: 0.671202] [G loss: 0.905133]\n",
      "[Epoch 16/200] [Batch 32/169] [D loss: 0.736519] [G loss: 0.862064]\n",
      "[Epoch 16/200] [Batch 33/169] [D loss: 0.707239] [G loss: 0.926945]\n",
      "[Epoch 16/200] [Batch 34/169] [D loss: 0.783085] [G loss: 0.597474]\n",
      "[Epoch 16/200] [Batch 35/169] [D loss: 0.681686] [G loss: 0.856690]\n",
      "[Epoch 16/200] [Batch 36/169] [D loss: 0.725881] [G loss: 0.637178]\n",
      "[Epoch 16/200] [Batch 37/169] [D loss: 0.733675] [G loss: 0.703354]\n",
      "[Epoch 16/200] [Batch 38/169] [D loss: 0.548344] [G loss: 0.732729]\n",
      "[Epoch 16/200] [Batch 39/169] [D loss: 0.686260] [G loss: 0.827203]\n",
      "[Epoch 16/200] [Batch 40/169] [D loss: 0.636176] [G loss: 0.961603]\n",
      "[Epoch 16/200] [Batch 41/169] [D loss: 0.538168] [G loss: 0.904888]\n",
      "[Epoch 16/200] [Batch 42/169] [D loss: 0.537607] [G loss: 0.893676]\n",
      "[Epoch 16/200] [Batch 43/169] [D loss: 0.556731] [G loss: 1.045999]\n",
      "[Epoch 16/200] [Batch 44/169] [D loss: 0.622662] [G loss: 0.890246]\n",
      "[Epoch 16/200] [Batch 45/169] [D loss: 0.618890] [G loss: 0.908969]\n",
      "[Epoch 16/200] [Batch 46/169] [D loss: 0.701528] [G loss: 0.862842]\n",
      "[Epoch 16/200] [Batch 47/169] [D loss: 0.556987] [G loss: 1.045949]\n",
      "[Epoch 16/200] [Batch 48/169] [D loss: 0.567164] [G loss: 1.150427]\n",
      "[Epoch 16/200] [Batch 49/169] [D loss: 0.621648] [G loss: 0.914467]\n",
      "[Epoch 16/200] [Batch 50/169] [D loss: 0.669045] [G loss: 0.873737]\n",
      "[Epoch 16/200] [Batch 51/169] [D loss: 0.684572] [G loss: 0.821754]\n",
      "[Epoch 16/200] [Batch 52/169] [D loss: 0.690100] [G loss: 1.052116]\n",
      "[Epoch 16/200] [Batch 53/169] [D loss: 0.549588] [G loss: 1.132214]\n",
      "[Epoch 16/200] [Batch 54/169] [D loss: 0.599459] [G loss: 1.103892]\n",
      "[Epoch 16/200] [Batch 55/169] [D loss: 0.616717] [G loss: 0.915207]\n",
      "[Epoch 16/200] [Batch 56/169] [D loss: 0.556048] [G loss: 0.993662]\n",
      "[Epoch 16/200] [Batch 57/169] [D loss: 0.527952] [G loss: 1.027247]\n",
      "[Epoch 16/200] [Batch 58/169] [D loss: 0.595641] [G loss: 1.147552]\n",
      "[Epoch 16/200] [Batch 59/169] [D loss: 0.578206] [G loss: 1.210427]\n",
      "[Epoch 16/200] [Batch 60/169] [D loss: 0.598677] [G loss: 0.881332]\n",
      "[Epoch 16/200] [Batch 61/169] [D loss: 0.565233] [G loss: 0.796979]\n",
      "[Epoch 16/200] [Batch 62/169] [D loss: 0.633613] [G loss: 0.968241]\n",
      "[Epoch 16/200] [Batch 63/169] [D loss: 0.582830] [G loss: 0.991580]\n",
      "[Epoch 16/200] [Batch 64/169] [D loss: 0.629875] [G loss: 0.848343]\n",
      "[Epoch 16/200] [Batch 65/169] [D loss: 0.563571] [G loss: 0.821614]\n",
      "[Epoch 16/200] [Batch 66/169] [D loss: 0.624862] [G loss: 0.820954]\n",
      "[Epoch 16/200] [Batch 67/169] [D loss: 0.595044] [G loss: 0.826287]\n",
      "[Epoch 16/200] [Batch 68/169] [D loss: 0.599126] [G loss: 0.833394]\n",
      "[Epoch 16/200] [Batch 69/169] [D loss: 0.550975] [G loss: 0.835914]\n",
      "[Epoch 16/200] [Batch 70/169] [D loss: 0.653234] [G loss: 1.049384]\n",
      "[Epoch 16/200] [Batch 71/169] [D loss: 0.651268] [G loss: 1.095499]\n",
      "[Epoch 16/200] [Batch 72/169] [D loss: 0.628439] [G loss: 0.860858]\n",
      "[Epoch 16/200] [Batch 73/169] [D loss: 0.575562] [G loss: 0.955162]\n",
      "[Epoch 16/200] [Batch 74/169] [D loss: 0.651410] [G loss: 0.803827]\n",
      "[Epoch 16/200] [Batch 75/169] [D loss: 0.671412] [G loss: 0.802324]\n",
      "[Epoch 16/200] [Batch 76/169] [D loss: 0.687478] [G loss: 0.839791]\n",
      "[Epoch 16/200] [Batch 77/169] [D loss: 0.608610] [G loss: 0.916992]\n",
      "[Epoch 16/200] [Batch 78/169] [D loss: 0.581841] [G loss: 1.136055]\n",
      "[Epoch 16/200] [Batch 79/169] [D loss: 0.633783] [G loss: 1.062432]\n",
      "[Epoch 16/200] [Batch 80/169] [D loss: 0.601674] [G loss: 1.061418]\n",
      "[Epoch 16/200] [Batch 81/169] [D loss: 0.636845] [G loss: 0.849608]\n",
      "[Epoch 16/200] [Batch 82/169] [D loss: 0.600929] [G loss: 0.827483]\n",
      "[Epoch 16/200] [Batch 83/169] [D loss: 0.640162] [G loss: 0.852471]\n",
      "[Epoch 16/200] [Batch 84/169] [D loss: 0.591103] [G loss: 0.809219]\n",
      "[Epoch 16/200] [Batch 85/169] [D loss: 0.540372] [G loss: 0.957132]\n",
      "[Epoch 16/200] [Batch 86/169] [D loss: 0.597494] [G loss: 1.037346]\n",
      "[Epoch 16/200] [Batch 87/169] [D loss: 0.637134] [G loss: 1.088892]\n",
      "[Epoch 16/200] [Batch 88/169] [D loss: 0.566622] [G loss: 1.079739]\n",
      "[Epoch 16/200] [Batch 89/169] [D loss: 0.718565] [G loss: 0.961807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 90/169] [D loss: 0.574514] [G loss: 0.719843]\n",
      "[Epoch 16/200] [Batch 91/169] [D loss: 0.635901] [G loss: 1.024879]\n",
      "[Epoch 16/200] [Batch 92/169] [D loss: 0.621653] [G loss: 0.876608]\n",
      "[Epoch 16/200] [Batch 93/169] [D loss: 0.624285] [G loss: 1.040370]\n",
      "[Epoch 16/200] [Batch 94/169] [D loss: 0.622109] [G loss: 0.987043]\n",
      "[Epoch 16/200] [Batch 95/169] [D loss: 0.642080] [G loss: 1.260003]\n",
      "[Epoch 16/200] [Batch 96/169] [D loss: 0.569519] [G loss: 0.923107]\n",
      "[Epoch 16/200] [Batch 97/169] [D loss: 0.546780] [G loss: 0.999953]\n",
      "[Epoch 16/200] [Batch 98/169] [D loss: 0.579167] [G loss: 0.883667]\n",
      "[Epoch 16/200] [Batch 99/169] [D loss: 0.583578] [G loss: 0.856824]\n",
      "[Epoch 16/200] [Batch 100/169] [D loss: 0.639751] [G loss: 0.894557]\n",
      "[Epoch 16/200] [Batch 101/169] [D loss: 0.613905] [G loss: 1.035528]\n",
      "[Epoch 16/200] [Batch 102/169] [D loss: 0.632876] [G loss: 1.043569]\n",
      "[Epoch 16/200] [Batch 103/169] [D loss: 0.640819] [G loss: 1.104089]\n",
      "[Epoch 16/200] [Batch 104/169] [D loss: 0.598144] [G loss: 0.912251]\n",
      "[Epoch 16/200] [Batch 105/169] [D loss: 0.638014] [G loss: 0.836833]\n",
      "[Epoch 16/200] [Batch 106/169] [D loss: 0.609100] [G loss: 0.976231]\n",
      "[Epoch 16/200] [Batch 107/169] [D loss: 0.607542] [G loss: 0.981640]\n",
      "[Epoch 16/200] [Batch 108/169] [D loss: 0.560418] [G loss: 0.974447]\n",
      "[Epoch 16/200] [Batch 109/169] [D loss: 0.623232] [G loss: 0.973507]\n",
      "[Epoch 16/200] [Batch 110/169] [D loss: 0.546188] [G loss: 1.049806]\n",
      "[Epoch 16/200] [Batch 111/169] [D loss: 0.617267] [G loss: 0.934933]\n",
      "[Epoch 16/200] [Batch 112/169] [D loss: 0.615381] [G loss: 0.981631]\n",
      "[Epoch 16/200] [Batch 113/169] [D loss: 0.626783] [G loss: 1.051060]\n",
      "[Epoch 16/200] [Batch 114/169] [D loss: 0.604882] [G loss: 0.956659]\n",
      "[Epoch 16/200] [Batch 115/169] [D loss: 0.682633] [G loss: 0.865574]\n",
      "[Epoch 16/200] [Batch 116/169] [D loss: 0.551438] [G loss: 0.883914]\n",
      "[Epoch 16/200] [Batch 117/169] [D loss: 0.616025] [G loss: 0.812433]\n",
      "[Epoch 16/200] [Batch 118/169] [D loss: 0.597423] [G loss: 0.957330]\n",
      "[Epoch 16/200] [Batch 119/169] [D loss: 0.525157] [G loss: 0.720193]\n",
      "[Epoch 16/200] [Batch 120/169] [D loss: 0.558730] [G loss: 0.995283]\n",
      "[Epoch 16/200] [Batch 121/169] [D loss: 0.505984] [G loss: 1.024235]\n",
      "[Epoch 16/200] [Batch 122/169] [D loss: 0.574854] [G loss: 1.010714]\n",
      "[Epoch 16/200] [Batch 123/169] [D loss: 0.563030] [G loss: 1.021544]\n",
      "[Epoch 16/200] [Batch 124/169] [D loss: 0.651156] [G loss: 0.771125]\n",
      "[Epoch 16/200] [Batch 125/169] [D loss: 0.560231] [G loss: 0.926220]\n",
      "[Epoch 16/200] [Batch 126/169] [D loss: 0.538053] [G loss: 0.972834]\n",
      "[Epoch 16/200] [Batch 127/169] [D loss: 0.608104] [G loss: 0.916432]\n",
      "[Epoch 16/200] [Batch 128/169] [D loss: 0.614362] [G loss: 0.880658]\n",
      "[Epoch 16/200] [Batch 129/169] [D loss: 0.657556] [G loss: 0.885568]\n",
      "[Epoch 16/200] [Batch 130/169] [D loss: 0.550593] [G loss: 0.880140]\n",
      "[Epoch 16/200] [Batch 131/169] [D loss: 0.613501] [G loss: 0.999669]\n",
      "[Epoch 16/200] [Batch 132/169] [D loss: 0.572809] [G loss: 0.939204]\n",
      "[Epoch 16/200] [Batch 133/169] [D loss: 0.501694] [G loss: 0.967420]\n",
      "[Epoch 16/200] [Batch 134/169] [D loss: 0.551568] [G loss: 0.959898]\n",
      "[Epoch 16/200] [Batch 135/169] [D loss: 0.546070] [G loss: 0.898790]\n",
      "[Epoch 16/200] [Batch 136/169] [D loss: 0.630264] [G loss: 0.954637]\n",
      "[Epoch 16/200] [Batch 137/169] [D loss: 0.649145] [G loss: 0.899237]\n",
      "[Epoch 16/200] [Batch 138/169] [D loss: 0.672355] [G loss: 0.887839]\n",
      "[Epoch 16/200] [Batch 139/169] [D loss: 0.590095] [G loss: 1.013601]\n",
      "[Epoch 16/200] [Batch 140/169] [D loss: 0.681871] [G loss: 0.875159]\n",
      "[Epoch 16/200] [Batch 141/169] [D loss: 0.640460] [G loss: 0.882714]\n",
      "[Epoch 16/200] [Batch 142/169] [D loss: 0.586515] [G loss: 0.783714]\n",
      "[Epoch 16/200] [Batch 143/169] [D loss: 0.651541] [G loss: 0.912738]\n",
      "[Epoch 16/200] [Batch 144/169] [D loss: 0.658963] [G loss: 0.971990]\n",
      "[Epoch 16/200] [Batch 145/169] [D loss: 0.617107] [G loss: 1.027084]\n",
      "[Epoch 16/200] [Batch 146/169] [D loss: 0.550746] [G loss: 0.897376]\n",
      "[Epoch 16/200] [Batch 147/169] [D loss: 0.601547] [G loss: 0.900709]\n",
      "[Epoch 16/200] [Batch 148/169] [D loss: 0.593442] [G loss: 0.835005]\n",
      "[Epoch 16/200] [Batch 149/169] [D loss: 0.665428] [G loss: 0.840673]\n",
      "[Epoch 16/200] [Batch 150/169] [D loss: 0.664309] [G loss: 0.998208]\n",
      "[Epoch 16/200] [Batch 151/169] [D loss: 0.619022] [G loss: 1.142359]\n",
      "[Epoch 16/200] [Batch 152/169] [D loss: 0.668648] [G loss: 0.851632]\n",
      "[Epoch 16/200] [Batch 153/169] [D loss: 0.632846] [G loss: 0.966145]\n",
      "[Epoch 16/200] [Batch 154/169] [D loss: 0.600406] [G loss: 0.993406]\n",
      "[Epoch 16/200] [Batch 155/169] [D loss: 0.619104] [G loss: 0.931740]\n",
      "[Epoch 16/200] [Batch 156/169] [D loss: 0.694672] [G loss: 1.045645]\n",
      "[Epoch 16/200] [Batch 157/169] [D loss: 0.687263] [G loss: 0.878716]\n",
      "[Epoch 16/200] [Batch 158/169] [D loss: 0.611915] [G loss: 1.044454]\n",
      "[Epoch 16/200] [Batch 159/169] [D loss: 0.696179] [G loss: 1.120016]\n",
      "[Epoch 16/200] [Batch 160/169] [D loss: 0.616659] [G loss: 1.033493]\n",
      "[Epoch 16/200] [Batch 161/169] [D loss: 0.676153] [G loss: 0.948098]\n",
      "[Epoch 16/200] [Batch 162/169] [D loss: 0.537923] [G loss: 0.787988]\n",
      "[Epoch 16/200] [Batch 163/169] [D loss: 0.676200] [G loss: 0.803030]\n",
      "[Epoch 16/200] [Batch 164/169] [D loss: 0.558455] [G loss: 0.978508]\n",
      "[Epoch 16/200] [Batch 165/169] [D loss: 0.628639] [G loss: 0.938047]\n",
      "[Epoch 16/200] [Batch 166/169] [D loss: 0.644915] [G loss: 0.988377]\n",
      "[Epoch 16/200] [Batch 167/169] [D loss: 0.642297] [G loss: 0.906278]\n",
      "[Epoch 16/200] [Batch 168/169] [D loss: 0.685144] [G loss: 0.972285]\n",
      "[Epoch 17/200] [Batch 0/169] [D loss: 0.668622] [G loss: 0.969204]\n",
      "[Epoch 17/200] [Batch 1/169] [D loss: 0.594700] [G loss: 1.032293]\n",
      "[Epoch 17/200] [Batch 2/169] [D loss: 0.577844] [G loss: 0.876900]\n",
      "[Epoch 17/200] [Batch 3/169] [D loss: 0.630351] [G loss: 0.914075]\n",
      "[Epoch 17/200] [Batch 4/169] [D loss: 0.576452] [G loss: 0.877570]\n",
      "[Epoch 17/200] [Batch 5/169] [D loss: 0.579622] [G loss: 0.929774]\n",
      "[Epoch 17/200] [Batch 6/169] [D loss: 0.612422] [G loss: 0.861335]\n",
      "[Epoch 17/200] [Batch 7/169] [D loss: 0.506462] [G loss: 0.914505]\n",
      "[Epoch 17/200] [Batch 8/169] [D loss: 0.590359] [G loss: 0.953935]\n",
      "[Epoch 17/200] [Batch 9/169] [D loss: 0.579449] [G loss: 0.977942]\n",
      "[Epoch 17/200] [Batch 10/169] [D loss: 0.628121] [G loss: 0.917192]\n",
      "[Epoch 17/200] [Batch 11/169] [D loss: 0.617401] [G loss: 1.000451]\n",
      "[Epoch 17/200] [Batch 12/169] [D loss: 0.525245] [G loss: 0.941012]\n",
      "[Epoch 17/200] [Batch 13/169] [D loss: 0.559003] [G loss: 0.932349]\n",
      "[Epoch 17/200] [Batch 14/169] [D loss: 0.565875] [G loss: 1.025553]\n",
      "[Epoch 17/200] [Batch 15/169] [D loss: 0.687764] [G loss: 0.999817]\n",
      "[Epoch 17/200] [Batch 16/169] [D loss: 0.585691] [G loss: 1.064992]\n",
      "[Epoch 17/200] [Batch 17/169] [D loss: 0.572648] [G loss: 1.022205]\n",
      "[Epoch 17/200] [Batch 18/169] [D loss: 0.639607] [G loss: 0.901656]\n",
      "[Epoch 17/200] [Batch 19/169] [D loss: 0.629531] [G loss: 0.959368]\n",
      "[Epoch 17/200] [Batch 20/169] [D loss: 0.640802] [G loss: 1.002093]\n",
      "[Epoch 17/200] [Batch 21/169] [D loss: 0.585379] [G loss: 0.989517]\n",
      "[Epoch 17/200] [Batch 22/169] [D loss: 0.557103] [G loss: 0.835939]\n",
      "[Epoch 17/200] [Batch 23/169] [D loss: 0.674879] [G loss: 0.974247]\n",
      "[Epoch 17/200] [Batch 24/169] [D loss: 0.500392] [G loss: 0.931132]\n",
      "[Epoch 17/200] [Batch 25/169] [D loss: 0.552586] [G loss: 0.923922]\n",
      "[Epoch 17/200] [Batch 26/169] [D loss: 0.552023] [G loss: 0.968739]\n",
      "[Epoch 17/200] [Batch 27/169] [D loss: 0.535232] [G loss: 1.078505]\n",
      "[Epoch 17/200] [Batch 28/169] [D loss: 0.518278] [G loss: 1.032246]\n",
      "[Epoch 17/200] [Batch 29/169] [D loss: 0.507251] [G loss: 1.037161]\n",
      "[Epoch 17/200] [Batch 30/169] [D loss: 0.630890] [G loss: 0.878261]\n",
      "[Epoch 17/200] [Batch 31/169] [D loss: 0.521521] [G loss: 0.873124]\n",
      "[Epoch 17/200] [Batch 32/169] [D loss: 0.637406] [G loss: 0.972065]\n",
      "[Epoch 17/200] [Batch 33/169] [D loss: 0.661152] [G loss: 1.020705]\n",
      "[Epoch 17/200] [Batch 34/169] [D loss: 0.561328] [G loss: 0.896151]\n",
      "[Epoch 17/200] [Batch 35/169] [D loss: 0.683450] [G loss: 0.786776]\n",
      "[Epoch 17/200] [Batch 36/169] [D loss: 0.650891] [G loss: 0.898792]\n",
      "[Epoch 17/200] [Batch 37/169] [D loss: 0.640175] [G loss: 0.833745]\n",
      "[Epoch 17/200] [Batch 38/169] [D loss: 0.684710] [G loss: 0.893728]\n",
      "[Epoch 17/200] [Batch 39/169] [D loss: 0.711905] [G loss: 1.032153]\n",
      "[Epoch 17/200] [Batch 40/169] [D loss: 0.661047] [G loss: 0.961931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 41/169] [D loss: 0.593764] [G loss: 1.001930]\n",
      "[Epoch 17/200] [Batch 42/169] [D loss: 0.610156] [G loss: 0.937733]\n",
      "[Epoch 17/200] [Batch 43/169] [D loss: 0.577818] [G loss: 0.850717]\n",
      "[Epoch 17/200] [Batch 44/169] [D loss: 0.584636] [G loss: 0.791626]\n",
      "[Epoch 17/200] [Batch 45/169] [D loss: 0.550317] [G loss: 0.911182]\n",
      "[Epoch 17/200] [Batch 46/169] [D loss: 0.648255] [G loss: 0.897390]\n",
      "[Epoch 17/200] [Batch 47/169] [D loss: 0.663135] [G loss: 0.831074]\n",
      "[Epoch 17/200] [Batch 48/169] [D loss: 0.745214] [G loss: 0.782403]\n",
      "[Epoch 17/200] [Batch 49/169] [D loss: 0.647973] [G loss: 0.810870]\n",
      "[Epoch 17/200] [Batch 50/169] [D loss: 0.676190] [G loss: 0.798654]\n",
      "[Epoch 17/200] [Batch 51/169] [D loss: 0.650642] [G loss: 0.913082]\n",
      "[Epoch 17/200] [Batch 52/169] [D loss: 0.650669] [G loss: 1.058891]\n",
      "[Epoch 17/200] [Batch 53/169] [D loss: 0.587942] [G loss: 0.922577]\n",
      "[Epoch 17/200] [Batch 54/169] [D loss: 0.560773] [G loss: 0.977577]\n",
      "[Epoch 17/200] [Batch 55/169] [D loss: 0.585379] [G loss: 1.040441]\n",
      "[Epoch 17/200] [Batch 56/169] [D loss: 0.583833] [G loss: 1.195807]\n",
      "[Epoch 17/200] [Batch 57/169] [D loss: 0.579856] [G loss: 1.081260]\n",
      "[Epoch 17/200] [Batch 58/169] [D loss: 0.608962] [G loss: 0.861356]\n",
      "[Epoch 17/200] [Batch 59/169] [D loss: 0.604575] [G loss: 0.889894]\n",
      "[Epoch 17/200] [Batch 60/169] [D loss: 0.647591] [G loss: 0.859331]\n",
      "[Epoch 17/200] [Batch 61/169] [D loss: 0.553063] [G loss: 0.922993]\n",
      "[Epoch 17/200] [Batch 62/169] [D loss: 0.608347] [G loss: 0.995513]\n",
      "[Epoch 17/200] [Batch 63/169] [D loss: 0.620671] [G loss: 1.113709]\n",
      "[Epoch 17/200] [Batch 64/169] [D loss: 0.616842] [G loss: 0.980489]\n",
      "[Epoch 17/200] [Batch 65/169] [D loss: 0.595687] [G loss: 0.904534]\n",
      "[Epoch 17/200] [Batch 66/169] [D loss: 0.648063] [G loss: 1.005791]\n",
      "[Epoch 17/200] [Batch 67/169] [D loss: 0.617337] [G loss: 0.964011]\n",
      "[Epoch 17/200] [Batch 68/169] [D loss: 0.690053] [G loss: 0.866868]\n",
      "[Epoch 17/200] [Batch 69/169] [D loss: 0.709755] [G loss: 0.846128]\n",
      "[Epoch 17/200] [Batch 70/169] [D loss: 0.663581] [G loss: 1.044020]\n",
      "[Epoch 17/200] [Batch 71/169] [D loss: 0.648085] [G loss: 1.139927]\n",
      "[Epoch 17/200] [Batch 72/169] [D loss: 0.575034] [G loss: 1.132570]\n",
      "[Epoch 17/200] [Batch 73/169] [D loss: 0.597878] [G loss: 1.303989]\n",
      "[Epoch 17/200] [Batch 74/169] [D loss: 0.650158] [G loss: 1.182509]\n",
      "[Epoch 17/200] [Batch 75/169] [D loss: 0.635627] [G loss: 0.768143]\n",
      "[Epoch 17/200] [Batch 76/169] [D loss: 0.655197] [G loss: 0.767579]\n",
      "[Epoch 17/200] [Batch 77/169] [D loss: 0.548587] [G loss: 0.783850]\n",
      "[Epoch 17/200] [Batch 78/169] [D loss: 0.675775] [G loss: 0.880411]\n",
      "[Epoch 17/200] [Batch 79/169] [D loss: 0.612077] [G loss: 0.838366]\n",
      "[Epoch 17/200] [Batch 80/169] [D loss: 0.668615] [G loss: 0.919394]\n",
      "[Epoch 17/200] [Batch 81/169] [D loss: 0.632120] [G loss: 0.894624]\n",
      "[Epoch 17/200] [Batch 82/169] [D loss: 0.559340] [G loss: 0.912904]\n",
      "[Epoch 17/200] [Batch 83/169] [D loss: 0.568428] [G loss: 0.939728]\n",
      "[Epoch 17/200] [Batch 84/169] [D loss: 0.598114] [G loss: 0.983319]\n",
      "[Epoch 17/200] [Batch 85/169] [D loss: 0.543891] [G loss: 1.091437]\n",
      "[Epoch 17/200] [Batch 86/169] [D loss: 0.581077] [G loss: 0.939034]\n",
      "[Epoch 17/200] [Batch 87/169] [D loss: 0.602757] [G loss: 0.946626]\n",
      "[Epoch 17/200] [Batch 88/169] [D loss: 0.664114] [G loss: 0.754643]\n",
      "[Epoch 17/200] [Batch 89/169] [D loss: 0.583146] [G loss: 0.894742]\n",
      "[Epoch 17/200] [Batch 90/169] [D loss: 0.635463] [G loss: 0.869440]\n",
      "[Epoch 17/200] [Batch 91/169] [D loss: 0.675655] [G loss: 0.871769]\n",
      "[Epoch 17/200] [Batch 92/169] [D loss: 0.576059] [G loss: 0.853090]\n",
      "[Epoch 17/200] [Batch 93/169] [D loss: 0.638699] [G loss: 0.993588]\n",
      "[Epoch 17/200] [Batch 94/169] [D loss: 0.614836] [G loss: 1.118960]\n",
      "[Epoch 17/200] [Batch 95/169] [D loss: 0.663496] [G loss: 0.951301]\n",
      "[Epoch 17/200] [Batch 96/169] [D loss: 0.658392] [G loss: 0.875902]\n",
      "[Epoch 17/200] [Batch 97/169] [D loss: 0.652565] [G loss: 0.930811]\n",
      "[Epoch 17/200] [Batch 98/169] [D loss: 0.609967] [G loss: 0.838296]\n",
      "[Epoch 17/200] [Batch 99/169] [D loss: 0.667725] [G loss: 0.865037]\n",
      "[Epoch 17/200] [Batch 100/169] [D loss: 0.673154] [G loss: 1.017449]\n",
      "[Epoch 17/200] [Batch 101/169] [D loss: 0.667576] [G loss: 0.942105]\n",
      "[Epoch 17/200] [Batch 102/169] [D loss: 0.581366] [G loss: 1.040047]\n",
      "[Epoch 17/200] [Batch 103/169] [D loss: 0.614531] [G loss: 0.949059]\n",
      "[Epoch 17/200] [Batch 104/169] [D loss: 0.633124] [G loss: 0.786469]\n",
      "[Epoch 17/200] [Batch 105/169] [D loss: 0.591265] [G loss: 0.742568]\n",
      "[Epoch 17/200] [Batch 106/169] [D loss: 0.619474] [G loss: 0.980464]\n",
      "[Epoch 17/200] [Batch 107/169] [D loss: 0.568563] [G loss: 0.989117]\n",
      "[Epoch 17/200] [Batch 108/169] [D loss: 0.521247] [G loss: 1.145816]\n",
      "[Epoch 17/200] [Batch 109/169] [D loss: 0.564145] [G loss: 1.294476]\n",
      "[Epoch 17/200] [Batch 110/169] [D loss: 0.652094] [G loss: 0.972659]\n",
      "[Epoch 17/200] [Batch 111/169] [D loss: 0.499595] [G loss: 0.901542]\n",
      "[Epoch 17/200] [Batch 112/169] [D loss: 0.607010] [G loss: 0.938570]\n",
      "[Epoch 17/200] [Batch 113/169] [D loss: 0.547216] [G loss: 0.897397]\n",
      "[Epoch 17/200] [Batch 114/169] [D loss: 0.517148] [G loss: 0.931393]\n",
      "[Epoch 17/200] [Batch 115/169] [D loss: 0.525169] [G loss: 0.810334]\n",
      "[Epoch 17/200] [Batch 116/169] [D loss: 0.613515] [G loss: 0.832243]\n",
      "[Epoch 17/200] [Batch 117/169] [D loss: 0.598774] [G loss: 0.859302]\n",
      "[Epoch 17/200] [Batch 118/169] [D loss: 0.630862] [G loss: 1.007216]\n",
      "[Epoch 17/200] [Batch 119/169] [D loss: 0.667453] [G loss: 0.825045]\n",
      "[Epoch 17/200] [Batch 120/169] [D loss: 0.553070] [G loss: 0.983253]\n",
      "[Epoch 17/200] [Batch 121/169] [D loss: 0.661629] [G loss: 0.984409]\n",
      "[Epoch 17/200] [Batch 122/169] [D loss: 0.648600] [G loss: 0.959496]\n",
      "[Epoch 17/200] [Batch 123/169] [D loss: 0.609782] [G loss: 0.909283]\n",
      "[Epoch 17/200] [Batch 124/169] [D loss: 0.628376] [G loss: 0.837402]\n",
      "[Epoch 17/200] [Batch 125/169] [D loss: 0.867166] [G loss: 0.747908]\n",
      "[Epoch 17/200] [Batch 126/169] [D loss: 0.869367] [G loss: 0.793835]\n",
      "[Epoch 17/200] [Batch 127/169] [D loss: 1.020453] [G loss: 1.001557]\n",
      "[Epoch 17/200] [Batch 128/169] [D loss: 0.706242] [G loss: 1.313673]\n",
      "[Epoch 17/200] [Batch 129/169] [D loss: 0.607140] [G loss: 1.481660]\n",
      "[Epoch 17/200] [Batch 130/169] [D loss: 0.550938] [G loss: 1.126060]\n",
      "[Epoch 17/200] [Batch 131/169] [D loss: 0.534265] [G loss: 1.267370]\n",
      "[Epoch 17/200] [Batch 132/169] [D loss: 0.530598] [G loss: 0.976704]\n",
      "[Epoch 17/200] [Batch 133/169] [D loss: 0.583511] [G loss: 0.780831]\n",
      "[Epoch 17/200] [Batch 134/169] [D loss: 0.644933] [G loss: 1.112239]\n",
      "[Epoch 17/200] [Batch 135/169] [D loss: 0.587733] [G loss: 1.029550]\n",
      "[Epoch 17/200] [Batch 136/169] [D loss: 0.587593] [G loss: 1.041519]\n",
      "[Epoch 17/200] [Batch 137/169] [D loss: 0.640381] [G loss: 0.866462]\n",
      "[Epoch 17/200] [Batch 138/169] [D loss: 0.660110] [G loss: 0.906530]\n",
      "[Epoch 17/200] [Batch 139/169] [D loss: 0.665557] [G loss: 0.747333]\n",
      "[Epoch 17/200] [Batch 140/169] [D loss: 0.703631] [G loss: 0.781940]\n",
      "[Epoch 17/200] [Batch 141/169] [D loss: 0.696414] [G loss: 0.808883]\n",
      "[Epoch 17/200] [Batch 142/169] [D loss: 0.724255] [G loss: 0.963806]\n",
      "[Epoch 17/200] [Batch 143/169] [D loss: 0.691227] [G loss: 1.081541]\n",
      "[Epoch 17/200] [Batch 144/169] [D loss: 0.577342] [G loss: 1.194413]\n",
      "[Epoch 17/200] [Batch 145/169] [D loss: 0.576471] [G loss: 1.137773]\n",
      "[Epoch 17/200] [Batch 146/169] [D loss: 0.549459] [G loss: 1.077232]\n",
      "[Epoch 17/200] [Batch 147/169] [D loss: 0.606906] [G loss: 1.085310]\n",
      "[Epoch 17/200] [Batch 148/169] [D loss: 0.580325] [G loss: 1.032771]\n",
      "[Epoch 17/200] [Batch 149/169] [D loss: 0.614171] [G loss: 0.951702]\n",
      "[Epoch 17/200] [Batch 150/169] [D loss: 0.604451] [G loss: 0.950185]\n",
      "[Epoch 17/200] [Batch 151/169] [D loss: 0.643846] [G loss: 0.901830]\n",
      "[Epoch 17/200] [Batch 152/169] [D loss: 0.686744] [G loss: 0.912205]\n",
      "[Epoch 17/200] [Batch 153/169] [D loss: 0.621728] [G loss: 0.895818]\n",
      "[Epoch 17/200] [Batch 154/169] [D loss: 0.647751] [G loss: 0.838260]\n",
      "[Epoch 17/200] [Batch 155/169] [D loss: 0.574648] [G loss: 0.974885]\n",
      "[Epoch 17/200] [Batch 156/169] [D loss: 0.628316] [G loss: 0.919636]\n",
      "[Epoch 17/200] [Batch 157/169] [D loss: 0.597921] [G loss: 0.907809]\n",
      "[Epoch 17/200] [Batch 158/169] [D loss: 0.582417] [G loss: 0.982238]\n",
      "[Epoch 17/200] [Batch 159/169] [D loss: 0.638150] [G loss: 0.873204]\n",
      "[Epoch 17/200] [Batch 160/169] [D loss: 0.620019] [G loss: 0.790037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 161/169] [D loss: 0.647509] [G loss: 0.886408]\n",
      "[Epoch 17/200] [Batch 162/169] [D loss: 0.664262] [G loss: 0.903627]\n",
      "[Epoch 17/200] [Batch 163/169] [D loss: 0.624481] [G loss: 1.008884]\n",
      "[Epoch 17/200] [Batch 164/169] [D loss: 0.647835] [G loss: 1.012434]\n",
      "[Epoch 17/200] [Batch 165/169] [D loss: 0.607301] [G loss: 0.855097]\n",
      "[Epoch 17/200] [Batch 166/169] [D loss: 0.604520] [G loss: 1.056113]\n",
      "[Epoch 17/200] [Batch 167/169] [D loss: 0.614170] [G loss: 0.987646]\n",
      "[Epoch 17/200] [Batch 168/169] [D loss: 0.694908] [G loss: 0.919382]\n",
      "[Epoch 18/200] [Batch 0/169] [D loss: 0.649339] [G loss: 0.869538]\n",
      "[Epoch 18/200] [Batch 1/169] [D loss: 0.621392] [G loss: 0.754779]\n",
      "[Epoch 18/200] [Batch 2/169] [D loss: 0.606870] [G loss: 0.987282]\n",
      "[Epoch 18/200] [Batch 3/169] [D loss: 0.664824] [G loss: 0.952013]\n",
      "[Epoch 18/200] [Batch 4/169] [D loss: 0.704560] [G loss: 0.905306]\n",
      "[Epoch 18/200] [Batch 5/169] [D loss: 0.541070] [G loss: 1.015122]\n",
      "[Epoch 18/200] [Batch 6/169] [D loss: 0.601638] [G loss: 0.895215]\n",
      "[Epoch 18/200] [Batch 7/169] [D loss: 0.630138] [G loss: 0.966530]\n",
      "[Epoch 18/200] [Batch 8/169] [D loss: 0.572700] [G loss: 0.783961]\n",
      "[Epoch 18/200] [Batch 9/169] [D loss: 0.691135] [G loss: 0.861347]\n",
      "[Epoch 18/200] [Batch 10/169] [D loss: 0.536400] [G loss: 0.827955]\n",
      "[Epoch 18/200] [Batch 11/169] [D loss: 0.568570] [G loss: 0.978552]\n",
      "[Epoch 18/200] [Batch 12/169] [D loss: 0.619925] [G loss: 0.964786]\n",
      "[Epoch 18/200] [Batch 13/169] [D loss: 0.656192] [G loss: 0.936727]\n",
      "[Epoch 18/200] [Batch 14/169] [D loss: 0.667605] [G loss: 0.979161]\n",
      "[Epoch 18/200] [Batch 15/169] [D loss: 0.603216] [G loss: 1.094439]\n",
      "[Epoch 18/200] [Batch 16/169] [D loss: 0.698450] [G loss: 0.762715]\n",
      "[Epoch 18/200] [Batch 17/169] [D loss: 0.533184] [G loss: 0.806766]\n",
      "[Epoch 18/200] [Batch 18/169] [D loss: 0.552142] [G loss: 0.846845]\n",
      "[Epoch 18/200] [Batch 19/169] [D loss: 0.677403] [G loss: 1.146412]\n",
      "[Epoch 18/200] [Batch 20/169] [D loss: 0.650626] [G loss: 1.047461]\n",
      "[Epoch 18/200] [Batch 21/169] [D loss: 0.576014] [G loss: 0.932872]\n",
      "[Epoch 18/200] [Batch 22/169] [D loss: 0.634361] [G loss: 0.875180]\n",
      "[Epoch 18/200] [Batch 23/169] [D loss: 0.614393] [G loss: 0.965019]\n",
      "[Epoch 18/200] [Batch 24/169] [D loss: 0.629462] [G loss: 0.830160]\n",
      "[Epoch 18/200] [Batch 25/169] [D loss: 0.633403] [G loss: 0.803666]\n",
      "[Epoch 18/200] [Batch 26/169] [D loss: 0.551213] [G loss: 1.145739]\n",
      "[Epoch 18/200] [Batch 27/169] [D loss: 0.687074] [G loss: 0.946322]\n",
      "[Epoch 18/200] [Batch 28/169] [D loss: 0.631106] [G loss: 0.876915]\n",
      "[Epoch 18/200] [Batch 29/169] [D loss: 0.566315] [G loss: 0.813654]\n",
      "[Epoch 18/200] [Batch 30/169] [D loss: 0.672531] [G loss: 0.936449]\n",
      "[Epoch 18/200] [Batch 31/169] [D loss: 0.616381] [G loss: 0.877695]\n",
      "[Epoch 18/200] [Batch 32/169] [D loss: 0.607391] [G loss: 0.917337]\n",
      "[Epoch 18/200] [Batch 33/169] [D loss: 0.622218] [G loss: 0.920741]\n",
      "[Epoch 18/200] [Batch 34/169] [D loss: 0.606825] [G loss: 0.782379]\n",
      "[Epoch 18/200] [Batch 35/169] [D loss: 0.580309] [G loss: 0.946103]\n",
      "[Epoch 18/200] [Batch 36/169] [D loss: 0.695242] [G loss: 0.881056]\n",
      "[Epoch 18/200] [Batch 37/169] [D loss: 0.652539] [G loss: 0.926602]\n",
      "[Epoch 18/200] [Batch 38/169] [D loss: 0.610400] [G loss: 1.039893]\n",
      "[Epoch 18/200] [Batch 39/169] [D loss: 0.643589] [G loss: 0.901083]\n",
      "[Epoch 18/200] [Batch 40/169] [D loss: 0.627741] [G loss: 0.918686]\n",
      "[Epoch 18/200] [Batch 41/169] [D loss: 0.627239] [G loss: 0.887668]\n",
      "[Epoch 18/200] [Batch 42/169] [D loss: 0.691810] [G loss: 0.961617]\n",
      "[Epoch 18/200] [Batch 43/169] [D loss: 0.620142] [G loss: 0.750502]\n",
      "[Epoch 18/200] [Batch 44/169] [D loss: 0.624826] [G loss: 0.779159]\n",
      "[Epoch 18/200] [Batch 45/169] [D loss: 0.594938] [G loss: 0.734412]\n",
      "[Epoch 18/200] [Batch 46/169] [D loss: 0.539281] [G loss: 0.946362]\n",
      "[Epoch 18/200] [Batch 47/169] [D loss: 0.753181] [G loss: 0.947192]\n",
      "[Epoch 18/200] [Batch 48/169] [D loss: 0.609638] [G loss: 0.812387]\n",
      "[Epoch 18/200] [Batch 49/169] [D loss: 0.627556] [G loss: 0.840469]\n",
      "[Epoch 18/200] [Batch 50/169] [D loss: 0.577735] [G loss: 0.898040]\n",
      "[Epoch 18/200] [Batch 51/169] [D loss: 0.617005] [G loss: 1.245409]\n",
      "[Epoch 18/200] [Batch 52/169] [D loss: 0.630570] [G loss: 1.007114]\n",
      "[Epoch 18/200] [Batch 53/169] [D loss: 0.568432] [G loss: 0.971695]\n",
      "[Epoch 18/200] [Batch 54/169] [D loss: 0.649891] [G loss: 0.978776]\n",
      "[Epoch 18/200] [Batch 55/169] [D loss: 0.591179] [G loss: 0.869214]\n",
      "[Epoch 18/200] [Batch 56/169] [D loss: 0.600106] [G loss: 0.956629]\n",
      "[Epoch 18/200] [Batch 57/169] [D loss: 0.608303] [G loss: 0.965697]\n",
      "[Epoch 18/200] [Batch 58/169] [D loss: 0.650058] [G loss: 0.848087]\n",
      "[Epoch 18/200] [Batch 59/169] [D loss: 0.582893] [G loss: 1.023361]\n",
      "[Epoch 18/200] [Batch 60/169] [D loss: 0.576915] [G loss: 0.900840]\n",
      "[Epoch 18/200] [Batch 61/169] [D loss: 0.573031] [G loss: 0.891661]\n",
      "[Epoch 18/200] [Batch 62/169] [D loss: 0.597475] [G loss: 0.938722]\n",
      "[Epoch 18/200] [Batch 63/169] [D loss: 0.632848] [G loss: 0.953919]\n",
      "[Epoch 18/200] [Batch 64/169] [D loss: 0.670226] [G loss: 0.979037]\n",
      "[Epoch 18/200] [Batch 65/169] [D loss: 0.677012] [G loss: 0.838095]\n",
      "[Epoch 18/200] [Batch 66/169] [D loss: 0.630514] [G loss: 1.004512]\n",
      "[Epoch 18/200] [Batch 67/169] [D loss: 0.669644] [G loss: 0.900828]\n",
      "[Epoch 18/200] [Batch 68/169] [D loss: 0.583200] [G loss: 0.822785]\n",
      "[Epoch 18/200] [Batch 69/169] [D loss: 0.687232] [G loss: 0.913930]\n",
      "[Epoch 18/200] [Batch 70/169] [D loss: 0.598733] [G loss: 1.087855]\n",
      "[Epoch 18/200] [Batch 71/169] [D loss: 0.621523] [G loss: 0.963149]\n",
      "[Epoch 18/200] [Batch 72/169] [D loss: 0.562476] [G loss: 0.744214]\n",
      "[Epoch 18/200] [Batch 73/169] [D loss: 0.568032] [G loss: 1.119262]\n",
      "[Epoch 18/200] [Batch 74/169] [D loss: 0.634580] [G loss: 0.863531]\n",
      "[Epoch 18/200] [Batch 75/169] [D loss: 0.664121] [G loss: 0.918361]\n",
      "[Epoch 18/200] [Batch 76/169] [D loss: 0.544990] [G loss: 0.844966]\n",
      "[Epoch 18/200] [Batch 77/169] [D loss: 0.659660] [G loss: 0.897682]\n",
      "[Epoch 18/200] [Batch 78/169] [D loss: 0.610110] [G loss: 0.898526]\n",
      "[Epoch 18/200] [Batch 79/169] [D loss: 0.697153] [G loss: 0.906287]\n",
      "[Epoch 18/200] [Batch 80/169] [D loss: 0.636602] [G loss: 0.907203]\n",
      "[Epoch 18/200] [Batch 81/169] [D loss: 0.626295] [G loss: 0.959695]\n",
      "[Epoch 18/200] [Batch 82/169] [D loss: 0.621989] [G loss: 0.750859]\n",
      "[Epoch 18/200] [Batch 83/169] [D loss: 0.599916] [G loss: 0.721234]\n",
      "[Epoch 18/200] [Batch 84/169] [D loss: 0.610514] [G loss: 0.853790]\n",
      "[Epoch 18/200] [Batch 85/169] [D loss: 0.632332] [G loss: 0.805864]\n",
      "[Epoch 18/200] [Batch 86/169] [D loss: 0.642657] [G loss: 0.886685]\n",
      "[Epoch 18/200] [Batch 87/169] [D loss: 0.687759] [G loss: 1.019126]\n",
      "[Epoch 18/200] [Batch 88/169] [D loss: 0.568563] [G loss: 1.182946]\n",
      "[Epoch 18/200] [Batch 89/169] [D loss: 0.611264] [G loss: 0.837162]\n",
      "[Epoch 18/200] [Batch 90/169] [D loss: 0.607418] [G loss: 0.916448]\n",
      "[Epoch 18/200] [Batch 91/169] [D loss: 0.592684] [G loss: 1.047275]\n",
      "[Epoch 18/200] [Batch 92/169] [D loss: 0.634623] [G loss: 0.883016]\n",
      "[Epoch 18/200] [Batch 93/169] [D loss: 0.563028] [G loss: 0.945327]\n",
      "[Epoch 18/200] [Batch 94/169] [D loss: 0.566771] [G loss: 0.965544]\n",
      "[Epoch 18/200] [Batch 95/169] [D loss: 0.654819] [G loss: 1.051069]\n",
      "[Epoch 18/200] [Batch 96/169] [D loss: 0.637715] [G loss: 0.854720]\n",
      "[Epoch 18/200] [Batch 97/169] [D loss: 0.572201] [G loss: 0.930953]\n",
      "[Epoch 18/200] [Batch 98/169] [D loss: 0.711446] [G loss: 0.878345]\n",
      "[Epoch 18/200] [Batch 99/169] [D loss: 0.604724] [G loss: 0.887387]\n",
      "[Epoch 18/200] [Batch 100/169] [D loss: 0.616922] [G loss: 0.816919]\n",
      "[Epoch 18/200] [Batch 101/169] [D loss: 0.572232] [G loss: 0.801757]\n",
      "[Epoch 18/200] [Batch 102/169] [D loss: 0.638327] [G loss: 0.829531]\n",
      "[Epoch 18/200] [Batch 103/169] [D loss: 0.631097] [G loss: 0.961982]\n",
      "[Epoch 18/200] [Batch 104/169] [D loss: 0.648401] [G loss: 0.921077]\n",
      "[Epoch 18/200] [Batch 105/169] [D loss: 0.619053] [G loss: 0.951499]\n",
      "[Epoch 18/200] [Batch 106/169] [D loss: 0.659023] [G loss: 1.006270]\n",
      "[Epoch 18/200] [Batch 107/169] [D loss: 0.615640] [G loss: 0.868597]\n",
      "[Epoch 18/200] [Batch 108/169] [D loss: 0.654393] [G loss: 0.756233]\n",
      "[Epoch 18/200] [Batch 109/169] [D loss: 0.643732] [G loss: 0.899471]\n",
      "[Epoch 18/200] [Batch 110/169] [D loss: 0.670994] [G loss: 0.915981]\n",
      "[Epoch 18/200] [Batch 111/169] [D loss: 0.589881] [G loss: 0.907303]\n",
      "[Epoch 18/200] [Batch 112/169] [D loss: 0.585020] [G loss: 0.911524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 113/169] [D loss: 0.677748] [G loss: 0.854733]\n",
      "[Epoch 18/200] [Batch 114/169] [D loss: 0.587078] [G loss: 0.930628]\n",
      "[Epoch 18/200] [Batch 115/169] [D loss: 0.607578] [G loss: 0.900994]\n",
      "[Epoch 18/200] [Batch 116/169] [D loss: 0.579241] [G loss: 0.760522]\n",
      "[Epoch 18/200] [Batch 117/169] [D loss: 0.664859] [G loss: 0.864815]\n",
      "[Epoch 18/200] [Batch 118/169] [D loss: 0.768026] [G loss: 0.976598]\n",
      "[Epoch 18/200] [Batch 119/169] [D loss: 0.558227] [G loss: 0.977689]\n",
      "[Epoch 18/200] [Batch 120/169] [D loss: 0.627057] [G loss: 0.886807]\n",
      "[Epoch 18/200] [Batch 121/169] [D loss: 0.589175] [G loss: 0.776650]\n",
      "[Epoch 18/200] [Batch 122/169] [D loss: 0.638399] [G loss: 0.682860]\n",
      "[Epoch 18/200] [Batch 123/169] [D loss: 0.659869] [G loss: 0.793192]\n",
      "[Epoch 18/200] [Batch 124/169] [D loss: 0.597048] [G loss: 1.034590]\n",
      "[Epoch 18/200] [Batch 125/169] [D loss: 0.577486] [G loss: 1.008065]\n",
      "[Epoch 18/200] [Batch 126/169] [D loss: 0.642726] [G loss: 0.800647]\n",
      "[Epoch 18/200] [Batch 127/169] [D loss: 0.674974] [G loss: 0.833870]\n",
      "[Epoch 18/200] [Batch 128/169] [D loss: 0.658121] [G loss: 0.865417]\n",
      "[Epoch 18/200] [Batch 129/169] [D loss: 0.565374] [G loss: 0.924565]\n",
      "[Epoch 18/200] [Batch 130/169] [D loss: 0.598330] [G loss: 0.961466]\n",
      "[Epoch 18/200] [Batch 131/169] [D loss: 0.644404] [G loss: 0.839057]\n",
      "[Epoch 18/200] [Batch 132/169] [D loss: 0.603433] [G loss: 0.800789]\n",
      "[Epoch 18/200] [Batch 133/169] [D loss: 0.581043] [G loss: 0.901988]\n",
      "[Epoch 18/200] [Batch 134/169] [D loss: 0.606804] [G loss: 0.998726]\n",
      "[Epoch 18/200] [Batch 135/169] [D loss: 0.622162] [G loss: 0.955659]\n",
      "[Epoch 18/200] [Batch 136/169] [D loss: 0.647157] [G loss: 0.868871]\n",
      "[Epoch 18/200] [Batch 137/169] [D loss: 0.620453] [G loss: 0.841781]\n",
      "[Epoch 18/200] [Batch 138/169] [D loss: 0.661030] [G loss: 0.811655]\n",
      "[Epoch 18/200] [Batch 139/169] [D loss: 0.645442] [G loss: 0.895311]\n",
      "[Epoch 18/200] [Batch 140/169] [D loss: 0.624301] [G loss: 0.969184]\n",
      "[Epoch 18/200] [Batch 141/169] [D loss: 0.675470] [G loss: 0.945124]\n",
      "[Epoch 18/200] [Batch 142/169] [D loss: 0.609983] [G loss: 0.895332]\n",
      "[Epoch 18/200] [Batch 143/169] [D loss: 0.585919] [G loss: 0.811113]\n",
      "[Epoch 18/200] [Batch 144/169] [D loss: 0.542822] [G loss: 0.913635]\n",
      "[Epoch 18/200] [Batch 145/169] [D loss: 0.655914] [G loss: 0.844367]\n",
      "[Epoch 18/200] [Batch 146/169] [D loss: 0.642019] [G loss: 0.900213]\n",
      "[Epoch 18/200] [Batch 147/169] [D loss: 0.570843] [G loss: 0.837246]\n",
      "[Epoch 18/200] [Batch 148/169] [D loss: 0.602430] [G loss: 0.927718]\n",
      "[Epoch 18/200] [Batch 149/169] [D loss: 0.605336] [G loss: 0.869063]\n",
      "[Epoch 18/200] [Batch 150/169] [D loss: 0.673520] [G loss: 0.866904]\n",
      "[Epoch 18/200] [Batch 151/169] [D loss: 0.680884] [G loss: 0.937821]\n",
      "[Epoch 18/200] [Batch 152/169] [D loss: 0.719236] [G loss: 0.857418]\n",
      "[Epoch 18/200] [Batch 153/169] [D loss: 0.676394] [G loss: 0.855243]\n",
      "[Epoch 18/200] [Batch 154/169] [D loss: 0.637622] [G loss: 0.975774]\n",
      "[Epoch 18/200] [Batch 155/169] [D loss: 0.637007] [G loss: 0.843287]\n",
      "[Epoch 18/200] [Batch 156/169] [D loss: 0.624590] [G loss: 0.998848]\n",
      "[Epoch 18/200] [Batch 157/169] [D loss: 0.532075] [G loss: 0.971655]\n",
      "[Epoch 18/200] [Batch 158/169] [D loss: 0.589855] [G loss: 0.779555]\n",
      "[Epoch 18/200] [Batch 159/169] [D loss: 0.592497] [G loss: 0.817617]\n",
      "[Epoch 18/200] [Batch 160/169] [D loss: 0.540524] [G loss: 1.032258]\n",
      "[Epoch 18/200] [Batch 161/169] [D loss: 0.495374] [G loss: 0.985729]\n",
      "[Epoch 18/200] [Batch 162/169] [D loss: 0.635214] [G loss: 0.947260]\n",
      "[Epoch 18/200] [Batch 163/169] [D loss: 0.585403] [G loss: 1.029924]\n",
      "[Epoch 18/200] [Batch 164/169] [D loss: 0.650900] [G loss: 0.857562]\n",
      "[Epoch 18/200] [Batch 165/169] [D loss: 0.591341] [G loss: 0.919052]\n",
      "[Epoch 18/200] [Batch 166/169] [D loss: 0.649799] [G loss: 1.060513]\n",
      "[Epoch 18/200] [Batch 167/169] [D loss: 0.632049] [G loss: 1.186636]\n",
      "[Epoch 18/200] [Batch 168/169] [D loss: 0.517241] [G loss: 0.982015]\n",
      "[Epoch 19/200] [Batch 0/169] [D loss: 0.610222] [G loss: 0.827316]\n",
      "[Epoch 19/200] [Batch 1/169] [D loss: 0.613337] [G loss: 1.092030]\n",
      "[Epoch 19/200] [Batch 2/169] [D loss: 0.681715] [G loss: 1.045062]\n",
      "[Epoch 19/200] [Batch 3/169] [D loss: 0.613950] [G loss: 0.985567]\n",
      "[Epoch 19/200] [Batch 4/169] [D loss: 0.636511] [G loss: 1.013689]\n",
      "[Epoch 19/200] [Batch 5/169] [D loss: 0.732274] [G loss: 0.909000]\n",
      "[Epoch 19/200] [Batch 6/169] [D loss: 0.685012] [G loss: 1.027476]\n",
      "[Epoch 19/200] [Batch 7/169] [D loss: 0.708824] [G loss: 0.859131]\n",
      "[Epoch 19/200] [Batch 8/169] [D loss: 0.726611] [G loss: 0.941406]\n",
      "[Epoch 19/200] [Batch 9/169] [D loss: 0.659560] [G loss: 0.881698]\n",
      "[Epoch 19/200] [Batch 10/169] [D loss: 0.660791] [G loss: 0.926488]\n",
      "[Epoch 19/200] [Batch 11/169] [D loss: 0.577919] [G loss: 0.929513]\n",
      "[Epoch 19/200] [Batch 12/169] [D loss: 0.665057] [G loss: 0.910478]\n",
      "[Epoch 19/200] [Batch 13/169] [D loss: 0.672889] [G loss: 0.942648]\n",
      "[Epoch 19/200] [Batch 14/169] [D loss: 0.634515] [G loss: 0.797736]\n",
      "[Epoch 19/200] [Batch 15/169] [D loss: 0.652393] [G loss: 0.934646]\n",
      "[Epoch 19/200] [Batch 16/169] [D loss: 0.666391] [G loss: 0.867012]\n",
      "[Epoch 19/200] [Batch 17/169] [D loss: 0.646968] [G loss: 0.845114]\n",
      "[Epoch 19/200] [Batch 18/169] [D loss: 0.672317] [G loss: 0.907221]\n",
      "[Epoch 19/200] [Batch 19/169] [D loss: 0.726439] [G loss: 0.732506]\n",
      "[Epoch 19/200] [Batch 20/169] [D loss: 0.691409] [G loss: 0.733810]\n",
      "[Epoch 19/200] [Batch 21/169] [D loss: 0.637250] [G loss: 0.788266]\n",
      "[Epoch 19/200] [Batch 22/169] [D loss: 0.654117] [G loss: 0.942839]\n",
      "[Epoch 19/200] [Batch 23/169] [D loss: 0.638199] [G loss: 0.979647]\n",
      "[Epoch 19/200] [Batch 24/169] [D loss: 0.597612] [G loss: 0.844877]\n",
      "[Epoch 19/200] [Batch 25/169] [D loss: 0.585933] [G loss: 0.783261]\n",
      "[Epoch 19/200] [Batch 26/169] [D loss: 0.569972] [G loss: 0.848078]\n",
      "[Epoch 19/200] [Batch 27/169] [D loss: 0.586199] [G loss: 0.907272]\n",
      "[Epoch 19/200] [Batch 28/169] [D loss: 0.631291] [G loss: 0.985640]\n",
      "[Epoch 19/200] [Batch 29/169] [D loss: 0.570473] [G loss: 0.899936]\n",
      "[Epoch 19/200] [Batch 30/169] [D loss: 0.558420] [G loss: 0.937689]\n",
      "[Epoch 19/200] [Batch 31/169] [D loss: 0.593537] [G loss: 0.916107]\n",
      "[Epoch 19/200] [Batch 32/169] [D loss: 0.564656] [G loss: 0.883082]\n",
      "[Epoch 19/200] [Batch 33/169] [D loss: 0.647419] [G loss: 0.934543]\n",
      "[Epoch 19/200] [Batch 34/169] [D loss: 0.659585] [G loss: 1.030768]\n",
      "[Epoch 19/200] [Batch 35/169] [D loss: 0.622246] [G loss: 0.790858]\n",
      "[Epoch 19/200] [Batch 36/169] [D loss: 0.723697] [G loss: 0.728719]\n",
      "[Epoch 19/200] [Batch 37/169] [D loss: 0.686768] [G loss: 0.751074]\n",
      "[Epoch 19/200] [Batch 38/169] [D loss: 0.647800] [G loss: 0.873895]\n",
      "[Epoch 19/200] [Batch 39/169] [D loss: 0.722106] [G loss: 0.844240]\n",
      "[Epoch 19/200] [Batch 40/169] [D loss: 0.673993] [G loss: 1.179991]\n",
      "[Epoch 19/200] [Batch 41/169] [D loss: 0.609677] [G loss: 0.957393]\n",
      "[Epoch 19/200] [Batch 42/169] [D loss: 0.602801] [G loss: 0.782397]\n",
      "[Epoch 19/200] [Batch 43/169] [D loss: 0.608599] [G loss: 0.675834]\n",
      "[Epoch 19/200] [Batch 44/169] [D loss: 0.672135] [G loss: 0.757335]\n",
      "[Epoch 19/200] [Batch 45/169] [D loss: 0.605680] [G loss: 0.693889]\n",
      "[Epoch 19/200] [Batch 46/169] [D loss: 0.592969] [G loss: 0.879733]\n",
      "[Epoch 19/200] [Batch 47/169] [D loss: 0.613131] [G loss: 0.918713]\n",
      "[Epoch 19/200] [Batch 48/169] [D loss: 0.685989] [G loss: 0.812154]\n",
      "[Epoch 19/200] [Batch 49/169] [D loss: 0.617926] [G loss: 0.789900]\n",
      "[Epoch 19/200] [Batch 50/169] [D loss: 0.585569] [G loss: 0.877625]\n",
      "[Epoch 19/200] [Batch 51/169] [D loss: 0.656341] [G loss: 0.889430]\n",
      "[Epoch 19/200] [Batch 52/169] [D loss: 0.561205] [G loss: 0.821392]\n",
      "[Epoch 19/200] [Batch 53/169] [D loss: 0.696057] [G loss: 1.032068]\n",
      "[Epoch 19/200] [Batch 54/169] [D loss: 0.630833] [G loss: 0.908943]\n",
      "[Epoch 19/200] [Batch 55/169] [D loss: 0.625972] [G loss: 0.986957]\n",
      "[Epoch 19/200] [Batch 56/169] [D loss: 0.649976] [G loss: 0.977173]\n",
      "[Epoch 19/200] [Batch 57/169] [D loss: 0.643703] [G loss: 0.853373]\n",
      "[Epoch 19/200] [Batch 58/169] [D loss: 0.616587] [G loss: 0.794147]\n",
      "[Epoch 19/200] [Batch 59/169] [D loss: 0.613120] [G loss: 0.899839]\n",
      "[Epoch 19/200] [Batch 60/169] [D loss: 0.585397] [G loss: 1.042435]\n",
      "[Epoch 19/200] [Batch 61/169] [D loss: 0.599523] [G loss: 0.977124]\n",
      "[Epoch 19/200] [Batch 62/169] [D loss: 0.574352] [G loss: 0.976635]\n",
      "[Epoch 19/200] [Batch 63/169] [D loss: 0.630036] [G loss: 0.889635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 64/169] [D loss: 0.653195] [G loss: 0.871544]\n",
      "[Epoch 19/200] [Batch 65/169] [D loss: 0.593001] [G loss: 0.858922]\n",
      "[Epoch 19/200] [Batch 66/169] [D loss: 0.597192] [G loss: 0.979654]\n",
      "[Epoch 19/200] [Batch 67/169] [D loss: 0.622065] [G loss: 0.844052]\n",
      "[Epoch 19/200] [Batch 68/169] [D loss: 0.653740] [G loss: 0.903730]\n",
      "[Epoch 19/200] [Batch 69/169] [D loss: 0.607424] [G loss: 0.947982]\n",
      "[Epoch 19/200] [Batch 70/169] [D loss: 0.622393] [G loss: 0.877775]\n",
      "[Epoch 19/200] [Batch 71/169] [D loss: 0.676621] [G loss: 0.900136]\n",
      "[Epoch 19/200] [Batch 72/169] [D loss: 0.580030] [G loss: 0.848233]\n",
      "[Epoch 19/200] [Batch 73/169] [D loss: 0.599778] [G loss: 0.933880]\n",
      "[Epoch 19/200] [Batch 74/169] [D loss: 0.629687] [G loss: 0.882631]\n",
      "[Epoch 19/200] [Batch 75/169] [D loss: 0.612517] [G loss: 0.957603]\n",
      "[Epoch 19/200] [Batch 76/169] [D loss: 0.642745] [G loss: 0.942932]\n",
      "[Epoch 19/200] [Batch 77/169] [D loss: 0.608735] [G loss: 0.953297]\n",
      "[Epoch 19/200] [Batch 78/169] [D loss: 0.619875] [G loss: 0.834179]\n",
      "[Epoch 19/200] [Batch 79/169] [D loss: 0.648795] [G loss: 0.829381]\n",
      "[Epoch 19/200] [Batch 80/169] [D loss: 0.655307] [G loss: 0.897928]\n",
      "[Epoch 19/200] [Batch 81/169] [D loss: 0.555642] [G loss: 0.869930]\n",
      "[Epoch 19/200] [Batch 82/169] [D loss: 0.659073] [G loss: 0.995186]\n",
      "[Epoch 19/200] [Batch 83/169] [D loss: 0.649522] [G loss: 0.830177]\n",
      "[Epoch 19/200] [Batch 84/169] [D loss: 0.607433] [G loss: 1.005561]\n",
      "[Epoch 19/200] [Batch 85/169] [D loss: 0.604765] [G loss: 0.897102]\n",
      "[Epoch 19/200] [Batch 86/169] [D loss: 0.643992] [G loss: 0.804302]\n",
      "[Epoch 19/200] [Batch 87/169] [D loss: 0.561086] [G loss: 0.823668]\n",
      "[Epoch 19/200] [Batch 88/169] [D loss: 0.626156] [G loss: 0.949704]\n",
      "[Epoch 19/200] [Batch 89/169] [D loss: 0.611474] [G loss: 0.864174]\n",
      "[Epoch 19/200] [Batch 90/169] [D loss: 0.627495] [G loss: 0.806922]\n",
      "[Epoch 19/200] [Batch 91/169] [D loss: 0.624793] [G loss: 0.857054]\n",
      "[Epoch 19/200] [Batch 92/169] [D loss: 0.626642] [G loss: 0.825404]\n",
      "[Epoch 19/200] [Batch 93/169] [D loss: 0.616617] [G loss: 0.911218]\n",
      "[Epoch 19/200] [Batch 94/169] [D loss: 0.580908] [G loss: 0.880488]\n",
      "[Epoch 19/200] [Batch 95/169] [D loss: 0.655178] [G loss: 0.955824]\n",
      "[Epoch 19/200] [Batch 96/169] [D loss: 0.681671] [G loss: 0.897817]\n",
      "[Epoch 19/200] [Batch 97/169] [D loss: 0.629778] [G loss: 0.822200]\n",
      "[Epoch 19/200] [Batch 98/169] [D loss: 0.665842] [G loss: 0.841282]\n",
      "[Epoch 19/200] [Batch 99/169] [D loss: 0.608607] [G loss: 0.848255]\n",
      "[Epoch 19/200] [Batch 100/169] [D loss: 0.572322] [G loss: 0.864527]\n",
      "[Epoch 19/200] [Batch 101/169] [D loss: 0.617636] [G loss: 0.941004]\n",
      "[Epoch 19/200] [Batch 102/169] [D loss: 0.704933] [G loss: 1.001693]\n",
      "[Epoch 19/200] [Batch 103/169] [D loss: 0.600389] [G loss: 0.903926]\n",
      "[Epoch 19/200] [Batch 104/169] [D loss: 0.671487] [G loss: 0.864730]\n",
      "[Epoch 19/200] [Batch 105/169] [D loss: 0.617095] [G loss: 0.969786]\n",
      "[Epoch 19/200] [Batch 106/169] [D loss: 0.627884] [G loss: 0.847620]\n",
      "[Epoch 19/200] [Batch 107/169] [D loss: 0.642635] [G loss: 0.875338]\n",
      "[Epoch 19/200] [Batch 108/169] [D loss: 0.605694] [G loss: 0.679077]\n",
      "[Epoch 19/200] [Batch 109/169] [D loss: 0.576915] [G loss: 0.689322]\n",
      "[Epoch 19/200] [Batch 110/169] [D loss: 0.738913] [G loss: 0.827543]\n",
      "[Epoch 19/200] [Batch 111/169] [D loss: 0.590064] [G loss: 0.989039]\n",
      "[Epoch 19/200] [Batch 112/169] [D loss: 0.604896] [G loss: 0.872559]\n",
      "[Epoch 19/200] [Batch 113/169] [D loss: 0.623366] [G loss: 0.850024]\n",
      "[Epoch 19/200] [Batch 114/169] [D loss: 0.589382] [G loss: 0.784341]\n",
      "[Epoch 19/200] [Batch 115/169] [D loss: 0.564714] [G loss: 0.799930]\n",
      "[Epoch 19/200] [Batch 116/169] [D loss: 0.693480] [G loss: 0.845618]\n",
      "[Epoch 19/200] [Batch 117/169] [D loss: 0.625742] [G loss: 0.840977]\n",
      "[Epoch 19/200] [Batch 118/169] [D loss: 0.584898] [G loss: 0.849899]\n",
      "[Epoch 19/200] [Batch 119/169] [D loss: 0.576862] [G loss: 1.014478]\n",
      "[Epoch 19/200] [Batch 120/169] [D loss: 0.650091] [G loss: 0.811856]\n",
      "[Epoch 19/200] [Batch 121/169] [D loss: 0.569759] [G loss: 0.821971]\n",
      "[Epoch 19/200] [Batch 122/169] [D loss: 0.627547] [G loss: 0.722072]\n",
      "[Epoch 19/200] [Batch 123/169] [D loss: 0.641715] [G loss: 0.904918]\n",
      "[Epoch 19/200] [Batch 124/169] [D loss: 0.627131] [G loss: 0.966293]\n",
      "[Epoch 19/200] [Batch 125/169] [D loss: 0.601182] [G loss: 0.955148]\n",
      "[Epoch 19/200] [Batch 126/169] [D loss: 0.664813] [G loss: 0.919442]\n",
      "[Epoch 19/200] [Batch 127/169] [D loss: 0.667357] [G loss: 0.886031]\n",
      "[Epoch 19/200] [Batch 128/169] [D loss: 0.648787] [G loss: 0.834412]\n",
      "[Epoch 19/200] [Batch 129/169] [D loss: 0.576583] [G loss: 0.935292]\n",
      "[Epoch 19/200] [Batch 130/169] [D loss: 0.606768] [G loss: 0.854637]\n",
      "[Epoch 19/200] [Batch 131/169] [D loss: 0.594887] [G loss: 0.816799]\n",
      "[Epoch 19/200] [Batch 132/169] [D loss: 0.560089] [G loss: 0.982768]\n",
      "[Epoch 19/200] [Batch 133/169] [D loss: 0.595030] [G loss: 1.053202]\n",
      "[Epoch 19/200] [Batch 134/169] [D loss: 0.636700] [G loss: 1.034254]\n",
      "[Epoch 19/200] [Batch 135/169] [D loss: 0.607463] [G loss: 0.771238]\n",
      "[Epoch 19/200] [Batch 136/169] [D loss: 0.613519] [G loss: 0.901177]\n",
      "[Epoch 19/200] [Batch 137/169] [D loss: 0.638468] [G loss: 0.816052]\n",
      "[Epoch 19/200] [Batch 138/169] [D loss: 0.562663] [G loss: 0.705652]\n",
      "[Epoch 19/200] [Batch 139/169] [D loss: 0.616990] [G loss: 0.917984]\n",
      "[Epoch 19/200] [Batch 140/169] [D loss: 0.601867] [G loss: 1.052818]\n",
      "[Epoch 19/200] [Batch 141/169] [D loss: 0.574783] [G loss: 0.830453]\n",
      "[Epoch 19/200] [Batch 142/169] [D loss: 0.638496] [G loss: 1.052122]\n",
      "[Epoch 19/200] [Batch 143/169] [D loss: 0.635831] [G loss: 0.898228]\n",
      "[Epoch 19/200] [Batch 144/169] [D loss: 0.557226] [G loss: 0.783068]\n",
      "[Epoch 19/200] [Batch 145/169] [D loss: 0.558429] [G loss: 0.931791]\n",
      "[Epoch 19/200] [Batch 146/169] [D loss: 0.624025] [G loss: 0.948108]\n",
      "[Epoch 19/200] [Batch 147/169] [D loss: 0.660751] [G loss: 0.876216]\n",
      "[Epoch 19/200] [Batch 148/169] [D loss: 0.659408] [G loss: 0.878914]\n",
      "[Epoch 19/200] [Batch 149/169] [D loss: 0.612293] [G loss: 0.871789]\n",
      "[Epoch 19/200] [Batch 150/169] [D loss: 0.633274] [G loss: 0.818419]\n",
      "[Epoch 19/200] [Batch 151/169] [D loss: 0.649366] [G loss: 0.891087]\n",
      "[Epoch 19/200] [Batch 152/169] [D loss: 0.711345] [G loss: 0.785254]\n",
      "[Epoch 19/200] [Batch 153/169] [D loss: 0.571997] [G loss: 1.018057]\n",
      "[Epoch 19/200] [Batch 154/169] [D loss: 0.669365] [G loss: 0.986837]\n",
      "[Epoch 19/200] [Batch 155/169] [D loss: 0.539328] [G loss: 0.796048]\n",
      "[Epoch 19/200] [Batch 156/169] [D loss: 0.642433] [G loss: 0.677593]\n",
      "[Epoch 19/200] [Batch 157/169] [D loss: 0.655934] [G loss: 0.799852]\n",
      "[Epoch 19/200] [Batch 158/169] [D loss: 0.591068] [G loss: 0.915717]\n",
      "[Epoch 19/200] [Batch 159/169] [D loss: 0.615552] [G loss: 0.888157]\n",
      "[Epoch 19/200] [Batch 160/169] [D loss: 0.634258] [G loss: 0.871754]\n",
      "[Epoch 19/200] [Batch 161/169] [D loss: 0.599150] [G loss: 1.020926]\n",
      "[Epoch 19/200] [Batch 162/169] [D loss: 0.571754] [G loss: 0.936357]\n",
      "[Epoch 19/200] [Batch 163/169] [D loss: 0.586683] [G loss: 0.842107]\n",
      "[Epoch 19/200] [Batch 164/169] [D loss: 0.605313] [G loss: 1.010479]\n",
      "[Epoch 19/200] [Batch 165/169] [D loss: 0.600549] [G loss: 0.856025]\n",
      "[Epoch 19/200] [Batch 166/169] [D loss: 0.584773] [G loss: 0.898610]\n",
      "[Epoch 19/200] [Batch 167/169] [D loss: 0.589829] [G loss: 0.939748]\n",
      "[Epoch 19/200] [Batch 168/169] [D loss: 0.573374] [G loss: 0.978591]\n",
      "[Epoch 20/200] [Batch 0/169] [D loss: 0.659282] [G loss: 0.718684]\n",
      "[Epoch 20/200] [Batch 1/169] [D loss: 0.650356] [G loss: 0.551183]\n",
      "[Epoch 20/200] [Batch 2/169] [D loss: 0.714292] [G loss: 0.881856]\n",
      "[Epoch 20/200] [Batch 3/169] [D loss: 0.602140] [G loss: 1.219009]\n",
      "[Epoch 20/200] [Batch 4/169] [D loss: 0.570267] [G loss: 1.007785]\n",
      "[Epoch 20/200] [Batch 5/169] [D loss: 0.609175] [G loss: 1.046221]\n",
      "[Epoch 20/200] [Batch 6/169] [D loss: 0.642743] [G loss: 0.794412]\n",
      "[Epoch 20/200] [Batch 7/169] [D loss: 0.632183] [G loss: 0.844086]\n",
      "[Epoch 20/200] [Batch 8/169] [D loss: 0.582663] [G loss: 0.910799]\n",
      "[Epoch 20/200] [Batch 9/169] [D loss: 0.506354] [G loss: 0.958492]\n",
      "[Epoch 20/200] [Batch 10/169] [D loss: 0.559901] [G loss: 1.005501]\n",
      "[Epoch 20/200] [Batch 11/169] [D loss: 0.648617] [G loss: 0.877691]\n",
      "[Epoch 20/200] [Batch 12/169] [D loss: 0.532768] [G loss: 0.926330]\n",
      "[Epoch 20/200] [Batch 13/169] [D loss: 0.640955] [G loss: 0.956508]\n",
      "[Epoch 20/200] [Batch 14/169] [D loss: 0.645395] [G loss: 0.976315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 15/169] [D loss: 0.669773] [G loss: 0.891715]\n",
      "[Epoch 20/200] [Batch 16/169] [D loss: 0.613760] [G loss: 0.946681]\n",
      "[Epoch 20/200] [Batch 17/169] [D loss: 0.687044] [G loss: 0.942785]\n",
      "[Epoch 20/200] [Batch 18/169] [D loss: 0.621166] [G loss: 0.874158]\n",
      "[Epoch 20/200] [Batch 19/169] [D loss: 0.680837] [G loss: 0.965666]\n",
      "[Epoch 20/200] [Batch 20/169] [D loss: 0.668378] [G loss: 0.860322]\n",
      "[Epoch 20/200] [Batch 21/169] [D loss: 0.685725] [G loss: 0.879948]\n",
      "[Epoch 20/200] [Batch 22/169] [D loss: 0.703165] [G loss: 1.030895]\n",
      "[Epoch 20/200] [Batch 23/169] [D loss: 0.666961] [G loss: 1.139306]\n",
      "[Epoch 20/200] [Batch 24/169] [D loss: 0.683949] [G loss: 0.944733]\n",
      "[Epoch 20/200] [Batch 25/169] [D loss: 0.619657] [G loss: 0.872959]\n",
      "[Epoch 20/200] [Batch 26/169] [D loss: 0.639254] [G loss: 0.871268]\n",
      "[Epoch 20/200] [Batch 27/169] [D loss: 0.611029] [G loss: 0.774227]\n",
      "[Epoch 20/200] [Batch 28/169] [D loss: 0.712884] [G loss: 0.810821]\n",
      "[Epoch 20/200] [Batch 29/169] [D loss: 0.699940] [G loss: 1.053947]\n",
      "[Epoch 20/200] [Batch 30/169] [D loss: 0.566267] [G loss: 1.098040]\n",
      "[Epoch 20/200] [Batch 31/169] [D loss: 0.562820] [G loss: 0.913188]\n",
      "[Epoch 20/200] [Batch 32/169] [D loss: 0.641898] [G loss: 0.977809]\n",
      "[Epoch 20/200] [Batch 33/169] [D loss: 0.528372] [G loss: 0.813838]\n",
      "[Epoch 20/200] [Batch 34/169] [D loss: 0.639982] [G loss: 0.866916]\n",
      "[Epoch 20/200] [Batch 35/169] [D loss: 0.603717] [G loss: 0.978504]\n",
      "[Epoch 20/200] [Batch 36/169] [D loss: 0.612755] [G loss: 0.993011]\n",
      "[Epoch 20/200] [Batch 37/169] [D loss: 0.585760] [G loss: 0.914895]\n",
      "[Epoch 20/200] [Batch 38/169] [D loss: 0.584358] [G loss: 0.862656]\n",
      "[Epoch 20/200] [Batch 39/169] [D loss: 0.617916] [G loss: 0.833618]\n",
      "[Epoch 20/200] [Batch 40/169] [D loss: 0.533109] [G loss: 0.877703]\n",
      "[Epoch 20/200] [Batch 41/169] [D loss: 0.600323] [G loss: 0.994025]\n",
      "[Epoch 20/200] [Batch 42/169] [D loss: 0.586460] [G loss: 0.926215]\n",
      "[Epoch 20/200] [Batch 43/169] [D loss: 0.669080] [G loss: 1.187972]\n",
      "[Epoch 20/200] [Batch 44/169] [D loss: 0.576259] [G loss: 1.042045]\n",
      "[Epoch 20/200] [Batch 45/169] [D loss: 0.568233] [G loss: 0.886759]\n",
      "[Epoch 20/200] [Batch 46/169] [D loss: 0.531993] [G loss: 0.805772]\n",
      "[Epoch 20/200] [Batch 47/169] [D loss: 0.613562] [G loss: 0.736293]\n",
      "[Epoch 20/200] [Batch 48/169] [D loss: 0.582836] [G loss: 0.810478]\n",
      "[Epoch 20/200] [Batch 49/169] [D loss: 0.623541] [G loss: 0.958902]\n",
      "[Epoch 20/200] [Batch 50/169] [D loss: 0.662595] [G loss: 0.962422]\n",
      "[Epoch 20/200] [Batch 51/169] [D loss: 0.623500] [G loss: 0.934215]\n",
      "[Epoch 20/200] [Batch 52/169] [D loss: 0.601657] [G loss: 0.758059]\n",
      "[Epoch 20/200] [Batch 53/169] [D loss: 0.677648] [G loss: 0.751410]\n",
      "[Epoch 20/200] [Batch 54/169] [D loss: 0.646993] [G loss: 0.796618]\n",
      "[Epoch 20/200] [Batch 55/169] [D loss: 0.639947] [G loss: 0.857032]\n",
      "[Epoch 20/200] [Batch 56/169] [D loss: 0.600248] [G loss: 0.717709]\n",
      "[Epoch 20/200] [Batch 57/169] [D loss: 0.653992] [G loss: 0.785759]\n",
      "[Epoch 20/200] [Batch 58/169] [D loss: 0.616023] [G loss: 0.846073]\n",
      "[Epoch 20/200] [Batch 59/169] [D loss: 0.731078] [G loss: 0.901036]\n",
      "[Epoch 20/200] [Batch 60/169] [D loss: 0.658019] [G loss: 0.737625]\n",
      "[Epoch 20/200] [Batch 61/169] [D loss: 0.691581] [G loss: 0.901243]\n",
      "[Epoch 20/200] [Batch 62/169] [D loss: 0.561318] [G loss: 0.948619]\n",
      "[Epoch 20/200] [Batch 63/169] [D loss: 0.591367] [G loss: 0.797667]\n",
      "[Epoch 20/200] [Batch 64/169] [D loss: 0.678007] [G loss: 0.850171]\n",
      "[Epoch 20/200] [Batch 65/169] [D loss: 0.687337] [G loss: 0.858728]\n",
      "[Epoch 20/200] [Batch 66/169] [D loss: 0.693779] [G loss: 1.021741]\n",
      "[Epoch 20/200] [Batch 67/169] [D loss: 0.674175] [G loss: 1.110559]\n",
      "[Epoch 20/200] [Batch 68/169] [D loss: 0.651905] [G loss: 0.924252]\n",
      "[Epoch 20/200] [Batch 69/169] [D loss: 0.587713] [G loss: 0.878484]\n",
      "[Epoch 20/200] [Batch 70/169] [D loss: 0.639817] [G loss: 0.816750]\n",
      "[Epoch 20/200] [Batch 71/169] [D loss: 0.687410] [G loss: 0.821901]\n",
      "[Epoch 20/200] [Batch 72/169] [D loss: 0.639802] [G loss: 0.916777]\n",
      "[Epoch 20/200] [Batch 73/169] [D loss: 0.699014] [G loss: 0.871165]\n",
      "[Epoch 20/200] [Batch 74/169] [D loss: 0.686393] [G loss: 0.851653]\n",
      "[Epoch 20/200] [Batch 75/169] [D loss: 0.550301] [G loss: 0.896320]\n",
      "[Epoch 20/200] [Batch 76/169] [D loss: 0.624478] [G loss: 0.868721]\n",
      "[Epoch 20/200] [Batch 77/169] [D loss: 0.686485] [G loss: 0.825271]\n",
      "[Epoch 20/200] [Batch 78/169] [D loss: 0.646605] [G loss: 0.940128]\n",
      "[Epoch 20/200] [Batch 79/169] [D loss: 0.678663] [G loss: 0.887824]\n",
      "[Epoch 20/200] [Batch 80/169] [D loss: 0.606727] [G loss: 0.837830]\n",
      "[Epoch 20/200] [Batch 81/169] [D loss: 0.620902] [G loss: 1.024395]\n",
      "[Epoch 20/200] [Batch 82/169] [D loss: 0.580090] [G loss: 0.881962]\n",
      "[Epoch 20/200] [Batch 83/169] [D loss: 0.590644] [G loss: 0.819322]\n",
      "[Epoch 20/200] [Batch 84/169] [D loss: 0.627529] [G loss: 0.884032]\n",
      "[Epoch 20/200] [Batch 85/169] [D loss: 0.575570] [G loss: 0.935666]\n",
      "[Epoch 20/200] [Batch 86/169] [D loss: 0.619526] [G loss: 1.000744]\n",
      "[Epoch 20/200] [Batch 87/169] [D loss: 0.578924] [G loss: 0.919717]\n",
      "[Epoch 20/200] [Batch 88/169] [D loss: 0.628523] [G loss: 0.968810]\n",
      "[Epoch 20/200] [Batch 89/169] [D loss: 0.568678] [G loss: 0.862110]\n",
      "[Epoch 20/200] [Batch 90/169] [D loss: 0.594369] [G loss: 0.733988]\n",
      "[Epoch 20/200] [Batch 91/169] [D loss: 0.673685] [G loss: 0.758401]\n",
      "[Epoch 20/200] [Batch 92/169] [D loss: 0.633150] [G loss: 0.818694]\n",
      "[Epoch 20/200] [Batch 93/169] [D loss: 0.591889] [G loss: 1.017573]\n",
      "[Epoch 20/200] [Batch 94/169] [D loss: 0.641433] [G loss: 1.091578]\n",
      "[Epoch 20/200] [Batch 95/169] [D loss: 0.662296] [G loss: 0.984163]\n",
      "[Epoch 20/200] [Batch 96/169] [D loss: 0.626589] [G loss: 0.933192]\n",
      "[Epoch 20/200] [Batch 97/169] [D loss: 0.661071] [G loss: 0.993199]\n",
      "[Epoch 20/200] [Batch 98/169] [D loss: 0.625138] [G loss: 0.851266]\n",
      "[Epoch 20/200] [Batch 99/169] [D loss: 0.686584] [G loss: 0.842294]\n",
      "[Epoch 20/200] [Batch 100/169] [D loss: 0.653941] [G loss: 0.803614]\n",
      "[Epoch 20/200] [Batch 101/169] [D loss: 0.701614] [G loss: 0.870777]\n",
      "[Epoch 20/200] [Batch 102/169] [D loss: 0.716228] [G loss: 0.981393]\n",
      "[Epoch 20/200] [Batch 103/169] [D loss: 0.641855] [G loss: 0.876525]\n",
      "[Epoch 20/200] [Batch 104/169] [D loss: 0.631704] [G loss: 0.897683]\n",
      "[Epoch 20/200] [Batch 105/169] [D loss: 0.642578] [G loss: 0.987248]\n",
      "[Epoch 20/200] [Batch 106/169] [D loss: 0.638142] [G loss: 0.944793]\n",
      "[Epoch 20/200] [Batch 107/169] [D loss: 0.604591] [G loss: 0.959840]\n",
      "[Epoch 20/200] [Batch 108/169] [D loss: 0.584928] [G loss: 0.777666]\n",
      "[Epoch 20/200] [Batch 109/169] [D loss: 0.578094] [G loss: 0.849158]\n",
      "[Epoch 20/200] [Batch 110/169] [D loss: 0.569739] [G loss: 0.959547]\n",
      "[Epoch 20/200] [Batch 111/169] [D loss: 0.680749] [G loss: 0.931037]\n",
      "[Epoch 20/200] [Batch 112/169] [D loss: 0.569863] [G loss: 0.959104]\n",
      "[Epoch 20/200] [Batch 113/169] [D loss: 0.563178] [G loss: 0.960734]\n",
      "[Epoch 20/200] [Batch 114/169] [D loss: 0.640468] [G loss: 0.774233]\n",
      "[Epoch 20/200] [Batch 115/169] [D loss: 0.599935] [G loss: 0.712842]\n",
      "[Epoch 20/200] [Batch 116/169] [D loss: 0.703206] [G loss: 0.818337]\n",
      "[Epoch 20/200] [Batch 117/169] [D loss: 0.652153] [G loss: 1.033251]\n",
      "[Epoch 20/200] [Batch 118/169] [D loss: 0.640249] [G loss: 0.976565]\n",
      "[Epoch 20/200] [Batch 119/169] [D loss: 0.596711] [G loss: 0.777006]\n",
      "[Epoch 20/200] [Batch 120/169] [D loss: 0.679544] [G loss: 0.838274]\n",
      "[Epoch 20/200] [Batch 121/169] [D loss: 0.708961] [G loss: 0.752656]\n",
      "[Epoch 20/200] [Batch 122/169] [D loss: 0.650495] [G loss: 0.997349]\n",
      "[Epoch 20/200] [Batch 123/169] [D loss: 0.598018] [G loss: 0.800238]\n",
      "[Epoch 20/200] [Batch 124/169] [D loss: 0.647827] [G loss: 0.755076]\n",
      "[Epoch 20/200] [Batch 125/169] [D loss: 0.639693] [G loss: 0.839432]\n",
      "[Epoch 20/200] [Batch 126/169] [D loss: 0.670309] [G loss: 0.779832]\n",
      "[Epoch 20/200] [Batch 127/169] [D loss: 0.675815] [G loss: 0.880774]\n",
      "[Epoch 20/200] [Batch 128/169] [D loss: 0.547151] [G loss: 0.921408]\n",
      "[Epoch 20/200] [Batch 129/169] [D loss: 0.644777] [G loss: 0.883994]\n",
      "[Epoch 20/200] [Batch 130/169] [D loss: 0.594496] [G loss: 0.831400]\n",
      "[Epoch 20/200] [Batch 131/169] [D loss: 0.622851] [G loss: 0.979775]\n",
      "[Epoch 20/200] [Batch 132/169] [D loss: 0.634077] [G loss: 0.823580]\n",
      "[Epoch 20/200] [Batch 133/169] [D loss: 0.548066] [G loss: 0.990728]\n",
      "[Epoch 20/200] [Batch 134/169] [D loss: 0.643202] [G loss: 0.944603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 135/169] [D loss: 0.615220] [G loss: 0.926103]\n",
      "[Epoch 20/200] [Batch 136/169] [D loss: 0.735245] [G loss: 0.822039]\n",
      "[Epoch 20/200] [Batch 137/169] [D loss: 0.627302] [G loss: 0.881709]\n",
      "[Epoch 20/200] [Batch 138/169] [D loss: 0.602013] [G loss: 0.892190]\n",
      "[Epoch 20/200] [Batch 139/169] [D loss: 0.565463] [G loss: 1.012756]\n",
      "[Epoch 20/200] [Batch 140/169] [D loss: 0.611988] [G loss: 0.787462]\n",
      "[Epoch 20/200] [Batch 141/169] [D loss: 0.620560] [G loss: 0.989886]\n",
      "[Epoch 20/200] [Batch 142/169] [D loss: 0.626476] [G loss: 0.990077]\n",
      "[Epoch 20/200] [Batch 143/169] [D loss: 0.592290] [G loss: 1.001430]\n",
      "[Epoch 20/200] [Batch 144/169] [D loss: 0.622060] [G loss: 0.946106]\n",
      "[Epoch 20/200] [Batch 145/169] [D loss: 0.638999] [G loss: 0.880408]\n",
      "[Epoch 20/200] [Batch 146/169] [D loss: 0.603555] [G loss: 0.981259]\n",
      "[Epoch 20/200] [Batch 147/169] [D loss: 0.670393] [G loss: 0.898321]\n",
      "[Epoch 20/200] [Batch 148/169] [D loss: 0.718968] [G loss: 0.904170]\n",
      "[Epoch 20/200] [Batch 149/169] [D loss: 0.645037] [G loss: 1.070630]\n",
      "[Epoch 20/200] [Batch 150/169] [D loss: 0.662471] [G loss: 0.998801]\n",
      "[Epoch 20/200] [Batch 151/169] [D loss: 0.633843] [G loss: 1.038742]\n",
      "[Epoch 20/200] [Batch 152/169] [D loss: 0.564947] [G loss: 0.999843]\n",
      "[Epoch 20/200] [Batch 153/169] [D loss: 0.623671] [G loss: 0.849859]\n",
      "[Epoch 20/200] [Batch 154/169] [D loss: 0.580977] [G loss: 0.857557]\n",
      "[Epoch 20/200] [Batch 155/169] [D loss: 0.643917] [G loss: 0.903046]\n",
      "[Epoch 20/200] [Batch 156/169] [D loss: 0.583126] [G loss: 0.714337]\n",
      "[Epoch 20/200] [Batch 157/169] [D loss: 0.643402] [G loss: 0.868275]\n",
      "[Epoch 20/200] [Batch 158/169] [D loss: 0.709172] [G loss: 0.698153]\n",
      "[Epoch 20/200] [Batch 159/169] [D loss: 0.732458] [G loss: 0.665436]\n",
      "[Epoch 20/200] [Batch 160/169] [D loss: 0.672934] [G loss: 0.767283]\n",
      "[Epoch 20/200] [Batch 161/169] [D loss: 0.727043] [G loss: 0.809450]\n",
      "[Epoch 20/200] [Batch 162/169] [D loss: 0.571037] [G loss: 1.014510]\n",
      "[Epoch 20/200] [Batch 163/169] [D loss: 0.721047] [G loss: 0.986126]\n",
      "[Epoch 20/200] [Batch 164/169] [D loss: 0.582021] [G loss: 1.021431]\n",
      "[Epoch 20/200] [Batch 165/169] [D loss: 0.518399] [G loss: 0.942482]\n",
      "[Epoch 20/200] [Batch 166/169] [D loss: 0.574131] [G loss: 0.777355]\n",
      "[Epoch 20/200] [Batch 167/169] [D loss: 0.543823] [G loss: 0.706933]\n",
      "[Epoch 20/200] [Batch 168/169] [D loss: 0.601979] [G loss: 0.816012]\n",
      "[Epoch 21/200] [Batch 0/169] [D loss: 0.625851] [G loss: 0.908385]\n",
      "[Epoch 21/200] [Batch 1/169] [D loss: 0.704822] [G loss: 0.825354]\n",
      "[Epoch 21/200] [Batch 2/169] [D loss: 0.628273] [G loss: 1.004218]\n",
      "[Epoch 21/200] [Batch 3/169] [D loss: 0.638952] [G loss: 0.958308]\n",
      "[Epoch 21/200] [Batch 4/169] [D loss: 0.680737] [G loss: 0.846060]\n",
      "[Epoch 21/200] [Batch 5/169] [D loss: 0.580024] [G loss: 0.932538]\n",
      "[Epoch 21/200] [Batch 6/169] [D loss: 0.690845] [G loss: 0.996807]\n",
      "[Epoch 21/200] [Batch 7/169] [D loss: 0.628594] [G loss: 0.806267]\n",
      "[Epoch 21/200] [Batch 8/169] [D loss: 0.619341] [G loss: 0.880711]\n",
      "[Epoch 21/200] [Batch 9/169] [D loss: 0.652097] [G loss: 0.857346]\n",
      "[Epoch 21/200] [Batch 10/169] [D loss: 0.615322] [G loss: 0.991046]\n",
      "[Epoch 21/200] [Batch 11/169] [D loss: 0.570714] [G loss: 0.956249]\n",
      "[Epoch 21/200] [Batch 12/169] [D loss: 0.587366] [G loss: 0.918480]\n",
      "[Epoch 21/200] [Batch 13/169] [D loss: 0.589875] [G loss: 0.960807]\n",
      "[Epoch 21/200] [Batch 14/169] [D loss: 0.717821] [G loss: 0.920695]\n",
      "[Epoch 21/200] [Batch 15/169] [D loss: 0.595818] [G loss: 0.921575]\n",
      "[Epoch 21/200] [Batch 16/169] [D loss: 0.618236] [G loss: 0.888245]\n",
      "[Epoch 21/200] [Batch 17/169] [D loss: 0.544708] [G loss: 0.830287]\n",
      "[Epoch 21/200] [Batch 18/169] [D loss: 0.629703] [G loss: 0.905615]\n",
      "[Epoch 21/200] [Batch 19/169] [D loss: 0.641798] [G loss: 0.789636]\n",
      "[Epoch 21/200] [Batch 20/169] [D loss: 0.678667] [G loss: 0.753767]\n",
      "[Epoch 21/200] [Batch 21/169] [D loss: 0.656946] [G loss: 0.721313]\n",
      "[Epoch 21/200] [Batch 22/169] [D loss: 0.622264] [G loss: 0.798415]\n",
      "[Epoch 21/200] [Batch 23/169] [D loss: 0.597663] [G loss: 0.680676]\n",
      "[Epoch 21/200] [Batch 24/169] [D loss: 0.655955] [G loss: 0.797742]\n",
      "[Epoch 21/200] [Batch 25/169] [D loss: 0.714015] [G loss: 0.865223]\n",
      "[Epoch 21/200] [Batch 26/169] [D loss: 0.727406] [G loss: 0.952504]\n",
      "[Epoch 21/200] [Batch 27/169] [D loss: 0.654379] [G loss: 0.876311]\n",
      "[Epoch 21/200] [Batch 28/169] [D loss: 0.700468] [G loss: 0.774633]\n",
      "[Epoch 21/200] [Batch 29/169] [D loss: 0.671732] [G loss: 0.730992]\n",
      "[Epoch 21/200] [Batch 30/169] [D loss: 0.616857] [G loss: 0.943096]\n",
      "[Epoch 21/200] [Batch 31/169] [D loss: 0.643435] [G loss: 0.805704]\n",
      "[Epoch 21/200] [Batch 32/169] [D loss: 0.629696] [G loss: 0.837376]\n",
      "[Epoch 21/200] [Batch 33/169] [D loss: 0.677335] [G loss: 0.907778]\n",
      "[Epoch 21/200] [Batch 34/169] [D loss: 0.656147] [G loss: 0.911167]\n",
      "[Epoch 21/200] [Batch 35/169] [D loss: 0.566638] [G loss: 0.888041]\n",
      "[Epoch 21/200] [Batch 36/169] [D loss: 0.636489] [G loss: 0.655781]\n",
      "[Epoch 21/200] [Batch 37/169] [D loss: 0.715730] [G loss: 0.833214]\n",
      "[Epoch 21/200] [Batch 38/169] [D loss: 0.699971] [G loss: 0.844773]\n",
      "[Epoch 21/200] [Batch 39/169] [D loss: 0.628997] [G loss: 0.834545]\n",
      "[Epoch 21/200] [Batch 40/169] [D loss: 0.623599] [G loss: 0.850738]\n",
      "[Epoch 21/200] [Batch 41/169] [D loss: 0.629982] [G loss: 0.732954]\n",
      "[Epoch 21/200] [Batch 42/169] [D loss: 0.578618] [G loss: 0.956608]\n",
      "[Epoch 21/200] [Batch 43/169] [D loss: 0.700318] [G loss: 0.836994]\n",
      "[Epoch 21/200] [Batch 44/169] [D loss: 0.701071] [G loss: 0.830028]\n",
      "[Epoch 21/200] [Batch 45/169] [D loss: 0.656151] [G loss: 0.893322]\n",
      "[Epoch 21/200] [Batch 46/169] [D loss: 0.596907] [G loss: 0.811887]\n",
      "[Epoch 21/200] [Batch 47/169] [D loss: 0.700461] [G loss: 0.868243]\n",
      "[Epoch 21/200] [Batch 48/169] [D loss: 0.737870] [G loss: 0.838516]\n",
      "[Epoch 21/200] [Batch 49/169] [D loss: 0.590515] [G loss: 1.038238]\n",
      "[Epoch 21/200] [Batch 50/169] [D loss: 0.611707] [G loss: 1.023148]\n",
      "[Epoch 21/200] [Batch 51/169] [D loss: 0.634611] [G loss: 0.937089]\n",
      "[Epoch 21/200] [Batch 52/169] [D loss: 0.618281] [G loss: 1.016224]\n",
      "[Epoch 21/200] [Batch 53/169] [D loss: 0.633018] [G loss: 0.757538]\n",
      "[Epoch 21/200] [Batch 54/169] [D loss: 0.617375] [G loss: 0.844109]\n",
      "[Epoch 21/200] [Batch 55/169] [D loss: 0.629778] [G loss: 0.977989]\n",
      "[Epoch 21/200] [Batch 56/169] [D loss: 0.635310] [G loss: 0.986377]\n",
      "[Epoch 21/200] [Batch 57/169] [D loss: 0.660137] [G loss: 0.815069]\n",
      "[Epoch 21/200] [Batch 58/169] [D loss: 0.636785] [G loss: 0.854063]\n",
      "[Epoch 21/200] [Batch 59/169] [D loss: 0.657038] [G loss: 0.832075]\n",
      "[Epoch 21/200] [Batch 60/169] [D loss: 0.655040] [G loss: 0.887657]\n",
      "[Epoch 21/200] [Batch 61/169] [D loss: 0.604491] [G loss: 0.981231]\n",
      "[Epoch 21/200] [Batch 62/169] [D loss: 0.664992] [G loss: 0.953651]\n",
      "[Epoch 21/200] [Batch 63/169] [D loss: 0.612810] [G loss: 0.934077]\n",
      "[Epoch 21/200] [Batch 64/169] [D loss: 0.629874] [G loss: 0.797775]\n",
      "[Epoch 21/200] [Batch 65/169] [D loss: 0.563076] [G loss: 0.932806]\n",
      "[Epoch 21/200] [Batch 66/169] [D loss: 0.625281] [G loss: 0.918553]\n",
      "[Epoch 21/200] [Batch 67/169] [D loss: 0.630034] [G loss: 0.951937]\n",
      "[Epoch 21/200] [Batch 68/169] [D loss: 0.646537] [G loss: 0.974246]\n",
      "[Epoch 21/200] [Batch 69/169] [D loss: 0.606653] [G loss: 0.911156]\n",
      "[Epoch 21/200] [Batch 70/169] [D loss: 0.590430] [G loss: 0.812703]\n",
      "[Epoch 21/200] [Batch 71/169] [D loss: 0.625585] [G loss: 1.024799]\n",
      "[Epoch 21/200] [Batch 72/169] [D loss: 0.589610] [G loss: 0.941757]\n",
      "[Epoch 21/200] [Batch 73/169] [D loss: 0.620351] [G loss: 0.805463]\n",
      "[Epoch 21/200] [Batch 74/169] [D loss: 0.675113] [G loss: 0.846001]\n",
      "[Epoch 21/200] [Batch 75/169] [D loss: 0.636731] [G loss: 0.985693]\n",
      "[Epoch 21/200] [Batch 76/169] [D loss: 0.661678] [G loss: 0.857117]\n",
      "[Epoch 21/200] [Batch 77/169] [D loss: 0.615040] [G loss: 0.969406]\n",
      "[Epoch 21/200] [Batch 78/169] [D loss: 0.629362] [G loss: 0.833635]\n",
      "[Epoch 21/200] [Batch 79/169] [D loss: 0.542585] [G loss: 0.951242]\n",
      "[Epoch 21/200] [Batch 80/169] [D loss: 0.647600] [G loss: 0.858820]\n",
      "[Epoch 21/200] [Batch 81/169] [D loss: 0.722252] [G loss: 0.736885]\n",
      "[Epoch 21/200] [Batch 82/169] [D loss: 0.637981] [G loss: 0.852840]\n",
      "[Epoch 21/200] [Batch 83/169] [D loss: 0.605914] [G loss: 0.812313]\n",
      "[Epoch 21/200] [Batch 84/169] [D loss: 0.626405] [G loss: 0.946615]\n",
      "[Epoch 21/200] [Batch 85/169] [D loss: 0.578763] [G loss: 0.911843]\n",
      "[Epoch 21/200] [Batch 86/169] [D loss: 0.601457] [G loss: 0.940528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 87/169] [D loss: 0.655070] [G loss: 0.947471]\n",
      "[Epoch 21/200] [Batch 88/169] [D loss: 0.610797] [G loss: 0.972158]\n",
      "[Epoch 21/200] [Batch 89/169] [D loss: 0.596357] [G loss: 0.886848]\n",
      "[Epoch 21/200] [Batch 90/169] [D loss: 0.626216] [G loss: 0.865195]\n",
      "[Epoch 21/200] [Batch 91/169] [D loss: 0.691012] [G loss: 0.911677]\n",
      "[Epoch 21/200] [Batch 92/169] [D loss: 0.644688] [G loss: 0.850139]\n",
      "[Epoch 21/200] [Batch 93/169] [D loss: 0.666046] [G loss: 0.950624]\n",
      "[Epoch 21/200] [Batch 94/169] [D loss: 0.615076] [G loss: 0.971387]\n",
      "[Epoch 21/200] [Batch 95/169] [D loss: 0.699023] [G loss: 0.985424]\n",
      "[Epoch 21/200] [Batch 96/169] [D loss: 0.629767] [G loss: 0.768441]\n",
      "[Epoch 21/200] [Batch 97/169] [D loss: 0.638601] [G loss: 0.786056]\n",
      "[Epoch 21/200] [Batch 98/169] [D loss: 0.644164] [G loss: 0.922920]\n",
      "[Epoch 21/200] [Batch 99/169] [D loss: 0.599668] [G loss: 0.835704]\n",
      "[Epoch 21/200] [Batch 100/169] [D loss: 0.583534] [G loss: 0.868908]\n",
      "[Epoch 21/200] [Batch 101/169] [D loss: 0.647693] [G loss: 0.909517]\n",
      "[Epoch 21/200] [Batch 102/169] [D loss: 0.615227] [G loss: 0.867600]\n",
      "[Epoch 21/200] [Batch 103/169] [D loss: 0.579524] [G loss: 0.840768]\n",
      "[Epoch 21/200] [Batch 104/169] [D loss: 0.605276] [G loss: 0.680488]\n",
      "[Epoch 21/200] [Batch 105/169] [D loss: 0.652603] [G loss: 0.824780]\n",
      "[Epoch 21/200] [Batch 106/169] [D loss: 0.629055] [G loss: 0.768113]\n",
      "[Epoch 21/200] [Batch 107/169] [D loss: 0.528702] [G loss: 0.941465]\n",
      "[Epoch 21/200] [Batch 108/169] [D loss: 0.558184] [G loss: 0.915080]\n",
      "[Epoch 21/200] [Batch 109/169] [D loss: 0.635058] [G loss: 0.878147]\n",
      "[Epoch 21/200] [Batch 110/169] [D loss: 0.655704] [G loss: 0.874694]\n",
      "[Epoch 21/200] [Batch 111/169] [D loss: 0.605959] [G loss: 0.749530]\n",
      "[Epoch 21/200] [Batch 112/169] [D loss: 0.569450] [G loss: 0.757237]\n",
      "[Epoch 21/200] [Batch 113/169] [D loss: 0.634698] [G loss: 0.857082]\n",
      "[Epoch 21/200] [Batch 114/169] [D loss: 0.540405] [G loss: 0.978374]\n",
      "[Epoch 21/200] [Batch 115/169] [D loss: 0.588221] [G loss: 0.863738]\n",
      "[Epoch 21/200] [Batch 116/169] [D loss: 0.619644] [G loss: 0.805834]\n",
      "[Epoch 21/200] [Batch 117/169] [D loss: 0.642548] [G loss: 0.835164]\n",
      "[Epoch 21/200] [Batch 118/169] [D loss: 0.570155] [G loss: 0.888739]\n",
      "[Epoch 21/200] [Batch 119/169] [D loss: 0.622672] [G loss: 0.958095]\n",
      "[Epoch 21/200] [Batch 120/169] [D loss: 0.627862] [G loss: 0.828221]\n",
      "[Epoch 21/200] [Batch 121/169] [D loss: 0.642640] [G loss: 0.859769]\n",
      "[Epoch 21/200] [Batch 122/169] [D loss: 0.599721] [G loss: 0.849289]\n",
      "[Epoch 21/200] [Batch 123/169] [D loss: 0.590475] [G loss: 0.981904]\n",
      "[Epoch 21/200] [Batch 124/169] [D loss: 0.705029] [G loss: 1.068591]\n",
      "[Epoch 21/200] [Batch 125/169] [D loss: 0.666896] [G loss: 0.824655]\n",
      "[Epoch 21/200] [Batch 126/169] [D loss: 0.645599] [G loss: 0.807719]\n",
      "[Epoch 21/200] [Batch 127/169] [D loss: 0.575563] [G loss: 0.882719]\n",
      "[Epoch 21/200] [Batch 128/169] [D loss: 0.615543] [G loss: 0.743562]\n",
      "[Epoch 21/200] [Batch 129/169] [D loss: 0.693674] [G loss: 0.765209]\n",
      "[Epoch 21/200] [Batch 130/169] [D loss: 0.648157] [G loss: 0.685505]\n",
      "[Epoch 21/200] [Batch 131/169] [D loss: 0.652036] [G loss: 0.848302]\n",
      "[Epoch 21/200] [Batch 132/169] [D loss: 0.630636] [G loss: 0.923750]\n",
      "[Epoch 21/200] [Batch 133/169] [D loss: 0.628897] [G loss: 0.934365]\n",
      "[Epoch 21/200] [Batch 134/169] [D loss: 0.645932] [G loss: 0.955852]\n",
      "[Epoch 21/200] [Batch 135/169] [D loss: 0.671482] [G loss: 0.999443]\n",
      "[Epoch 21/200] [Batch 136/169] [D loss: 0.621902] [G loss: 0.862749]\n",
      "[Epoch 21/200] [Batch 137/169] [D loss: 0.546186] [G loss: 0.840404]\n",
      "[Epoch 21/200] [Batch 138/169] [D loss: 0.615552] [G loss: 0.828107]\n",
      "[Epoch 21/200] [Batch 139/169] [D loss: 0.601600] [G loss: 0.915627]\n",
      "[Epoch 21/200] [Batch 140/169] [D loss: 0.582806] [G loss: 0.862604]\n",
      "[Epoch 21/200] [Batch 141/169] [D loss: 0.574575] [G loss: 0.813241]\n",
      "[Epoch 21/200] [Batch 142/169] [D loss: 0.579173] [G loss: 0.888253]\n",
      "[Epoch 21/200] [Batch 143/169] [D loss: 0.577752] [G loss: 0.815468]\n",
      "[Epoch 21/200] [Batch 144/169] [D loss: 0.651866] [G loss: 0.860882]\n",
      "[Epoch 21/200] [Batch 145/169] [D loss: 0.672207] [G loss: 0.855771]\n",
      "[Epoch 21/200] [Batch 146/169] [D loss: 0.660214] [G loss: 0.869111]\n",
      "[Epoch 21/200] [Batch 147/169] [D loss: 0.616082] [G loss: 0.977349]\n",
      "[Epoch 21/200] [Batch 148/169] [D loss: 0.709024] [G loss: 0.969521]\n",
      "[Epoch 21/200] [Batch 149/169] [D loss: 0.634317] [G loss: 0.927962]\n",
      "[Epoch 21/200] [Batch 150/169] [D loss: 0.625570] [G loss: 0.925519]\n",
      "[Epoch 21/200] [Batch 151/169] [D loss: 0.609653] [G loss: 0.856784]\n",
      "[Epoch 21/200] [Batch 152/169] [D loss: 0.582301] [G loss: 0.897340]\n",
      "[Epoch 21/200] [Batch 153/169] [D loss: 0.608364] [G loss: 0.907038]\n",
      "[Epoch 21/200] [Batch 154/169] [D loss: 0.656858] [G loss: 0.825853]\n",
      "[Epoch 21/200] [Batch 155/169] [D loss: 0.726927] [G loss: 0.872201]\n",
      "[Epoch 21/200] [Batch 156/169] [D loss: 0.627196] [G loss: 0.707047]\n",
      "[Epoch 21/200] [Batch 157/169] [D loss: 0.548903] [G loss: 0.813432]\n",
      "[Epoch 21/200] [Batch 158/169] [D loss: 0.729110] [G loss: 0.831564]\n",
      "[Epoch 21/200] [Batch 159/169] [D loss: 0.665919] [G loss: 0.734080]\n",
      "[Epoch 21/200] [Batch 160/169] [D loss: 0.765490] [G loss: 0.755514]\n",
      "[Epoch 21/200] [Batch 161/169] [D loss: 0.800237] [G loss: 0.766539]\n",
      "[Epoch 21/200] [Batch 162/169] [D loss: 0.774073] [G loss: 0.790361]\n",
      "[Epoch 21/200] [Batch 163/169] [D loss: 0.719113] [G loss: 0.768302]\n",
      "[Epoch 21/200] [Batch 164/169] [D loss: 0.703658] [G loss: 1.010609]\n",
      "[Epoch 21/200] [Batch 165/169] [D loss: 0.567240] [G loss: 1.135170]\n",
      "[Epoch 21/200] [Batch 166/169] [D loss: 0.638666] [G loss: 0.877610]\n",
      "[Epoch 21/200] [Batch 167/169] [D loss: 0.607826] [G loss: 0.864271]\n",
      "[Epoch 21/200] [Batch 168/169] [D loss: 0.589794] [G loss: 0.852802]\n",
      "[Epoch 22/200] [Batch 0/169] [D loss: 0.617446] [G loss: 0.722788]\n",
      "[Epoch 22/200] [Batch 1/169] [D loss: 0.715044] [G loss: 0.610714]\n",
      "[Epoch 22/200] [Batch 2/169] [D loss: 0.601789] [G loss: 0.796066]\n",
      "[Epoch 22/200] [Batch 3/169] [D loss: 0.591689] [G loss: 0.819047]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6291456 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-7223897611e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0msavepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'image_cov'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-acd13e2ff54d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# 创建ground truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6291456 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "### 加载状态字典\n",
    "load2 = torch.load('net_state_dict.pth')\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "\n",
    "\n",
    "generator.load_state_dict(load2['generator'])\n",
    "generator.apply(init_cov)              ### 初始化模型，保留卷积层\n",
    "discriminator.load_state_dict(load2['discriminator'])\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "optimizer_G.load_state_dict(load2['optimizer_G'])\n",
    "optimizer_D.load_state_dict(load2['optimizer_D'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "savepath = 'image_cov'\n",
    "\n",
    "train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc3dc2",
   "metadata": {},
   "source": [
    "### G保留卷积，D同样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d70e0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/169] [D loss: 0.706744] [G loss: 0.659710]\n",
      "[Epoch 0/200] [Batch 1/169] [D loss: 0.703107] [G loss: 0.659453]\n",
      "[Epoch 0/200] [Batch 2/169] [D loss: 0.706694] [G loss: 0.669835]\n",
      "[Epoch 0/200] [Batch 3/169] [D loss: 0.697640] [G loss: 0.695723]\n",
      "[Epoch 0/200] [Batch 4/169] [D loss: 0.686661] [G loss: 0.730310]\n",
      "[Epoch 0/200] [Batch 5/169] [D loss: 0.675556] [G loss: 0.773826]\n",
      "[Epoch 0/200] [Batch 6/169] [D loss: 0.662284] [G loss: 0.795079]\n",
      "[Epoch 0/200] [Batch 7/169] [D loss: 0.657457] [G loss: 0.816485]\n",
      "[Epoch 0/200] [Batch 8/169] [D loss: 0.656678] [G loss: 0.816324]\n",
      "[Epoch 0/200] [Batch 9/169] [D loss: 0.683151] [G loss: 0.774808]\n",
      "[Epoch 0/200] [Batch 10/169] [D loss: 0.705304] [G loss: 0.719674]\n",
      "[Epoch 0/200] [Batch 11/169] [D loss: 0.708868] [G loss: 0.706347]\n",
      "[Epoch 0/200] [Batch 12/169] [D loss: 0.697540] [G loss: 0.706158]\n",
      "[Epoch 0/200] [Batch 13/169] [D loss: 0.694833] [G loss: 0.720033]\n",
      "[Epoch 0/200] [Batch 14/169] [D loss: 0.692508] [G loss: 0.727006]\n",
      "[Epoch 0/200] [Batch 15/169] [D loss: 0.688533] [G loss: 0.719591]\n",
      "[Epoch 0/200] [Batch 16/169] [D loss: 0.677490] [G loss: 0.705279]\n",
      "[Epoch 0/200] [Batch 17/169] [D loss: 0.677803] [G loss: 0.697985]\n",
      "[Epoch 0/200] [Batch 18/169] [D loss: 0.673489] [G loss: 0.698659]\n",
      "[Epoch 0/200] [Batch 19/169] [D loss: 0.664796] [G loss: 0.686084]\n",
      "[Epoch 0/200] [Batch 20/169] [D loss: 0.673676] [G loss: 0.677581]\n",
      "[Epoch 0/200] [Batch 21/169] [D loss: 0.676392] [G loss: 0.659111]\n",
      "[Epoch 0/200] [Batch 22/169] [D loss: 0.681171] [G loss: 0.644167]\n",
      "[Epoch 0/200] [Batch 23/169] [D loss: 0.668614] [G loss: 0.683235]\n",
      "[Epoch 0/200] [Batch 24/169] [D loss: 0.637230] [G loss: 0.746972]\n",
      "[Epoch 0/200] [Batch 25/169] [D loss: 0.611759] [G loss: 0.788397]\n",
      "[Epoch 0/200] [Batch 26/169] [D loss: 0.589291] [G loss: 0.869998]\n",
      "[Epoch 0/200] [Batch 27/169] [D loss: 0.566005] [G loss: 0.929076]\n",
      "[Epoch 0/200] [Batch 28/169] [D loss: 0.540073] [G loss: 0.976760]\n",
      "[Epoch 0/200] [Batch 29/169] [D loss: 0.563773] [G loss: 0.921141]\n",
      "[Epoch 0/200] [Batch 30/169] [D loss: 0.648970] [G loss: 0.708345]\n",
      "[Epoch 0/200] [Batch 31/169] [D loss: 0.789690] [G loss: 0.472891]\n",
      "[Epoch 0/200] [Batch 32/169] [D loss: 0.877300] [G loss: 0.388501]\n",
      "[Epoch 0/200] [Batch 33/169] [D loss: 0.844686] [G loss: 0.452728]\n",
      "[Epoch 0/200] [Batch 34/169] [D loss: 0.745662] [G loss: 0.542042]\n",
      "[Epoch 0/200] [Batch 35/169] [D loss: 0.669824] [G loss: 0.678754]\n",
      "[Epoch 0/200] [Batch 36/169] [D loss: 0.638601] [G loss: 0.778081]\n",
      "[Epoch 0/200] [Batch 37/169] [D loss: 0.622381] [G loss: 0.816113]\n",
      "[Epoch 0/200] [Batch 38/169] [D loss: 0.629364] [G loss: 0.804739]\n",
      "[Epoch 0/200] [Batch 39/169] [D loss: 0.632607] [G loss: 0.811627]\n",
      "[Epoch 0/200] [Batch 40/169] [D loss: 0.644319] [G loss: 0.803074]\n",
      "[Epoch 0/200] [Batch 41/169] [D loss: 0.656491] [G loss: 0.787958]\n",
      "[Epoch 0/200] [Batch 42/169] [D loss: 0.673833] [G loss: 0.771159]\n",
      "[Epoch 0/200] [Batch 43/169] [D loss: 0.671178] [G loss: 0.751135]\n",
      "[Epoch 0/200] [Batch 44/169] [D loss: 0.677169] [G loss: 0.744263]\n",
      "[Epoch 0/200] [Batch 45/169] [D loss: 0.669393] [G loss: 0.755702]\n",
      "[Epoch 0/200] [Batch 46/169] [D loss: 0.675296] [G loss: 0.772072]\n",
      "[Epoch 0/200] [Batch 47/169] [D loss: 0.665512] [G loss: 0.779052]\n",
      "[Epoch 0/200] [Batch 48/169] [D loss: 0.654070] [G loss: 0.807475]\n",
      "[Epoch 0/200] [Batch 49/169] [D loss: 0.657848] [G loss: 0.820297]\n",
      "[Epoch 0/200] [Batch 50/169] [D loss: 0.660722] [G loss: 0.809332]\n",
      "[Epoch 0/200] [Batch 51/169] [D loss: 0.661224] [G loss: 0.780016]\n",
      "[Epoch 0/200] [Batch 52/169] [D loss: 0.668033] [G loss: 0.784950]\n",
      "[Epoch 0/200] [Batch 53/169] [D loss: 0.672202] [G loss: 0.787318]\n",
      "[Epoch 0/200] [Batch 54/169] [D loss: 0.658746] [G loss: 0.772072]\n",
      "[Epoch 0/200] [Batch 55/169] [D loss: 0.665910] [G loss: 0.772043]\n",
      "[Epoch 0/200] [Batch 56/169] [D loss: 0.651042] [G loss: 0.801034]\n",
      "[Epoch 0/200] [Batch 57/169] [D loss: 0.654405] [G loss: 0.773961]\n",
      "[Epoch 0/200] [Batch 58/169] [D loss: 0.682790] [G loss: 0.751745]\n",
      "[Epoch 0/200] [Batch 59/169] [D loss: 0.700956] [G loss: 0.698035]\n",
      "[Epoch 0/200] [Batch 60/169] [D loss: 0.728943] [G loss: 0.633307]\n",
      "[Epoch 0/200] [Batch 61/169] [D loss: 0.737841] [G loss: 0.632996]\n",
      "[Epoch 0/200] [Batch 62/169] [D loss: 0.733928] [G loss: 0.612452]\n",
      "[Epoch 0/200] [Batch 63/169] [D loss: 0.727247] [G loss: 0.632052]\n",
      "[Epoch 0/200] [Batch 64/169] [D loss: 0.729335] [G loss: 0.637358]\n",
      "[Epoch 0/200] [Batch 65/169] [D loss: 0.710545] [G loss: 0.663989]\n",
      "[Epoch 0/200] [Batch 66/169] [D loss: 0.702745] [G loss: 0.671989]\n",
      "[Epoch 0/200] [Batch 67/169] [D loss: 0.690636] [G loss: 0.704005]\n",
      "[Epoch 0/200] [Batch 68/169] [D loss: 0.683165] [G loss: 0.685253]\n",
      "[Epoch 0/200] [Batch 69/169] [D loss: 0.674839] [G loss: 0.693194]\n",
      "[Epoch 0/200] [Batch 70/169] [D loss: 0.671232] [G loss: 0.685721]\n",
      "[Epoch 0/200] [Batch 71/169] [D loss: 0.670477] [G loss: 0.717570]\n",
      "[Epoch 0/200] [Batch 72/169] [D loss: 0.673645] [G loss: 0.693630]\n",
      "[Epoch 0/200] [Batch 73/169] [D loss: 0.669041] [G loss: 0.690552]\n",
      "[Epoch 0/200] [Batch 74/169] [D loss: 0.661836] [G loss: 0.693120]\n",
      "[Epoch 0/200] [Batch 75/169] [D loss: 0.679058] [G loss: 0.697162]\n",
      "[Epoch 0/200] [Batch 76/169] [D loss: 0.676041] [G loss: 0.701522]\n",
      "[Epoch 0/200] [Batch 77/169] [D loss: 0.659761] [G loss: 0.705813]\n",
      "[Epoch 0/200] [Batch 78/169] [D loss: 0.649967] [G loss: 0.711076]\n",
      "[Epoch 0/200] [Batch 79/169] [D loss: 0.650356] [G loss: 0.739392]\n",
      "[Epoch 0/200] [Batch 80/169] [D loss: 0.632177] [G loss: 0.760939]\n",
      "[Epoch 0/200] [Batch 81/169] [D loss: 0.638649] [G loss: 0.758080]\n",
      "[Epoch 0/200] [Batch 82/169] [D loss: 0.656972] [G loss: 0.742215]\n",
      "[Epoch 0/200] [Batch 83/169] [D loss: 0.640339] [G loss: 0.747060]\n",
      "[Epoch 0/200] [Batch 84/169] [D loss: 0.672171] [G loss: 0.726022]\n",
      "[Epoch 0/200] [Batch 85/169] [D loss: 0.685346] [G loss: 0.707748]\n",
      "[Epoch 0/200] [Batch 86/169] [D loss: 0.709207] [G loss: 0.669451]\n",
      "[Epoch 0/200] [Batch 87/169] [D loss: 0.716461] [G loss: 0.657232]\n",
      "[Epoch 0/200] [Batch 88/169] [D loss: 0.741363] [G loss: 0.611478]\n",
      "[Epoch 0/200] [Batch 89/169] [D loss: 0.708253] [G loss: 0.667187]\n",
      "[Epoch 0/200] [Batch 90/169] [D loss: 0.672749] [G loss: 0.708905]\n",
      "[Epoch 0/200] [Batch 91/169] [D loss: 0.618515] [G loss: 0.809501]\n",
      "[Epoch 0/200] [Batch 92/169] [D loss: 0.609857] [G loss: 0.796399]\n",
      "[Epoch 0/200] [Batch 93/169] [D loss: 0.628077] [G loss: 0.712591]\n",
      "[Epoch 0/200] [Batch 94/169] [D loss: 0.728593] [G loss: 0.552073]\n",
      "[Epoch 0/200] [Batch 95/169] [D loss: 0.758610] [G loss: 0.521287]\n",
      "[Epoch 0/200] [Batch 96/169] [D loss: 0.761684] [G loss: 0.557550]\n",
      "[Epoch 0/200] [Batch 97/169] [D loss: 0.736270] [G loss: 0.640726]\n",
      "[Epoch 0/200] [Batch 98/169] [D loss: 0.731077] [G loss: 0.649364]\n",
      "[Epoch 0/200] [Batch 99/169] [D loss: 0.728406] [G loss: 0.679293]\n",
      "[Epoch 0/200] [Batch 100/169] [D loss: 0.725779] [G loss: 0.684825]\n",
      "[Epoch 0/200] [Batch 101/169] [D loss: 0.714924] [G loss: 0.705996]\n",
      "[Epoch 0/200] [Batch 102/169] [D loss: 0.704465] [G loss: 0.714066]\n",
      "[Epoch 0/200] [Batch 103/169] [D loss: 0.700211] [G loss: 0.727645]\n",
      "[Epoch 0/200] [Batch 104/169] [D loss: 0.697186] [G loss: 0.729809]\n",
      "[Epoch 0/200] [Batch 105/169] [D loss: 0.689363] [G loss: 0.750626]\n",
      "[Epoch 0/200] [Batch 106/169] [D loss: 0.695239] [G loss: 0.718923]\n",
      "[Epoch 0/200] [Batch 107/169] [D loss: 0.690314] [G loss: 0.713019]\n",
      "[Epoch 0/200] [Batch 108/169] [D loss: 0.689072] [G loss: 0.688334]\n",
      "[Epoch 0/200] [Batch 109/169] [D loss: 0.691960] [G loss: 0.690106]\n",
      "[Epoch 0/200] [Batch 110/169] [D loss: 0.682555] [G loss: 0.680774]\n",
      "[Epoch 0/200] [Batch 111/169] [D loss: 0.690140] [G loss: 0.675372]\n",
      "[Epoch 0/200] [Batch 112/169] [D loss: 0.697853] [G loss: 0.682197]\n",
      "[Epoch 0/200] [Batch 113/169] [D loss: 0.694625] [G loss: 0.656915]\n",
      "[Epoch 0/200] [Batch 114/169] [D loss: 0.691854] [G loss: 0.670246]\n",
      "[Epoch 0/200] [Batch 115/169] [D loss: 0.689479] [G loss: 0.658820]\n",
      "[Epoch 0/200] [Batch 116/169] [D loss: 0.702707] [G loss: 0.647058]\n",
      "[Epoch 0/200] [Batch 117/169] [D loss: 0.704360] [G loss: 0.668067]\n",
      "[Epoch 0/200] [Batch 118/169] [D loss: 0.701029] [G loss: 0.675898]\n",
      "[Epoch 0/200] [Batch 119/169] [D loss: 0.702496] [G loss: 0.669580]\n",
      "[Epoch 0/200] [Batch 120/169] [D loss: 0.686813] [G loss: 0.691190]\n",
      "[Epoch 0/200] [Batch 121/169] [D loss: 0.686177] [G loss: 0.698778]\n",
      "[Epoch 0/200] [Batch 122/169] [D loss: 0.678865] [G loss: 0.711723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 123/169] [D loss: 0.678994] [G loss: 0.716090]\n",
      "[Epoch 0/200] [Batch 124/169] [D loss: 0.665372] [G loss: 0.724456]\n",
      "[Epoch 0/200] [Batch 125/169] [D loss: 0.658498] [G loss: 0.735632]\n",
      "[Epoch 0/200] [Batch 126/169] [D loss: 0.654507] [G loss: 0.727231]\n",
      "[Epoch 0/200] [Batch 127/169] [D loss: 0.660293] [G loss: 0.727102]\n",
      "[Epoch 0/200] [Batch 128/169] [D loss: 0.651572] [G loss: 0.731427]\n",
      "[Epoch 0/200] [Batch 129/169] [D loss: 0.644395] [G loss: 0.738096]\n",
      "[Epoch 0/200] [Batch 130/169] [D loss: 0.648315] [G loss: 0.729369]\n",
      "[Epoch 0/200] [Batch 131/169] [D loss: 0.637744] [G loss: 0.734709]\n",
      "[Epoch 0/200] [Batch 132/169] [D loss: 0.634546] [G loss: 0.731067]\n",
      "[Epoch 0/200] [Batch 133/169] [D loss: 0.634173] [G loss: 0.741003]\n",
      "[Epoch 0/200] [Batch 134/169] [D loss: 0.620879] [G loss: 0.732057]\n",
      "[Epoch 0/200] [Batch 135/169] [D loss: 0.619055] [G loss: 0.732477]\n",
      "[Epoch 0/200] [Batch 136/169] [D loss: 0.625288] [G loss: 0.738744]\n",
      "[Epoch 0/200] [Batch 137/169] [D loss: 0.609287] [G loss: 0.730090]\n",
      "[Epoch 0/200] [Batch 138/169] [D loss: 0.609088] [G loss: 0.733966]\n",
      "[Epoch 0/200] [Batch 139/169] [D loss: 0.596565] [G loss: 0.731893]\n",
      "[Epoch 0/200] [Batch 140/169] [D loss: 0.596417] [G loss: 0.733582]\n",
      "[Epoch 0/200] [Batch 141/169] [D loss: 0.582852] [G loss: 0.728233]\n",
      "[Epoch 0/200] [Batch 142/169] [D loss: 0.593455] [G loss: 0.723539]\n",
      "[Epoch 0/200] [Batch 143/169] [D loss: 0.611609] [G loss: 0.686278]\n",
      "[Epoch 0/200] [Batch 144/169] [D loss: 0.644514] [G loss: 0.641793]\n",
      "[Epoch 0/200] [Batch 145/169] [D loss: 0.667739] [G loss: 0.587107]\n",
      "[Epoch 0/200] [Batch 146/169] [D loss: 0.695646] [G loss: 0.551311]\n",
      "[Epoch 0/200] [Batch 147/169] [D loss: 0.709085] [G loss: 0.555930]\n",
      "[Epoch 0/200] [Batch 148/169] [D loss: 0.711127] [G loss: 0.541616]\n",
      "[Epoch 0/200] [Batch 149/169] [D loss: 0.736870] [G loss: 0.535297]\n",
      "[Epoch 0/200] [Batch 150/169] [D loss: 0.748454] [G loss: 0.546105]\n",
      "[Epoch 0/200] [Batch 151/169] [D loss: 0.731659] [G loss: 0.580396]\n",
      "[Epoch 0/200] [Batch 152/169] [D loss: 0.712068] [G loss: 0.645802]\n",
      "[Epoch 0/200] [Batch 153/169] [D loss: 0.658590] [G loss: 0.717381]\n",
      "[Epoch 0/200] [Batch 154/169] [D loss: 0.651484] [G loss: 0.807153]\n",
      "[Epoch 0/200] [Batch 155/169] [D loss: 0.647864] [G loss: 0.831387]\n",
      "[Epoch 0/200] [Batch 156/169] [D loss: 0.656614] [G loss: 0.809170]\n",
      "[Epoch 0/200] [Batch 157/169] [D loss: 0.711728] [G loss: 0.718573]\n",
      "[Epoch 0/200] [Batch 158/169] [D loss: 0.746492] [G loss: 0.645106]\n",
      "[Epoch 0/200] [Batch 159/169] [D loss: 0.742215] [G loss: 0.627377]\n",
      "[Epoch 0/200] [Batch 160/169] [D loss: 0.724742] [G loss: 0.665651]\n",
      "[Epoch 0/200] [Batch 161/169] [D loss: 0.710331] [G loss: 0.703591]\n",
      "[Epoch 0/200] [Batch 162/169] [D loss: 0.685833] [G loss: 0.721980]\n",
      "[Epoch 0/200] [Batch 163/169] [D loss: 0.673707] [G loss: 0.724376]\n",
      "[Epoch 0/200] [Batch 164/169] [D loss: 0.673672] [G loss: 0.725938]\n",
      "[Epoch 0/200] [Batch 165/169] [D loss: 0.658497] [G loss: 0.724348]\n",
      "[Epoch 0/200] [Batch 166/169] [D loss: 0.643673] [G loss: 0.744290]\n",
      "[Epoch 0/200] [Batch 167/169] [D loss: 0.627162] [G loss: 0.750441]\n",
      "[Epoch 0/200] [Batch 168/169] [D loss: 0.634312] [G loss: 0.741288]\n",
      "[Epoch 1/200] [Batch 0/169] [D loss: 0.616141] [G loss: 0.751886]\n",
      "[Epoch 1/200] [Batch 1/169] [D loss: 0.623938] [G loss: 0.726837]\n",
      "[Epoch 1/200] [Batch 2/169] [D loss: 0.655231] [G loss: 0.695736]\n",
      "[Epoch 1/200] [Batch 3/169] [D loss: 0.670354] [G loss: 0.664625]\n",
      "[Epoch 1/200] [Batch 4/169] [D loss: 0.680347] [G loss: 0.659650]\n",
      "[Epoch 1/200] [Batch 5/169] [D loss: 0.676759] [G loss: 0.685999]\n",
      "[Epoch 1/200] [Batch 6/169] [D loss: 0.676873] [G loss: 0.680952]\n",
      "[Epoch 1/200] [Batch 7/169] [D loss: 0.672477] [G loss: 0.695720]\n",
      "[Epoch 1/200] [Batch 8/169] [D loss: 0.685337] [G loss: 0.706814]\n",
      "[Epoch 1/200] [Batch 9/169] [D loss: 0.714588] [G loss: 0.666202]\n",
      "[Epoch 1/200] [Batch 10/169] [D loss: 0.723641] [G loss: 0.662005]\n",
      "[Epoch 1/200] [Batch 11/169] [D loss: 0.740038] [G loss: 0.674629]\n",
      "[Epoch 1/200] [Batch 12/169] [D loss: 0.744547] [G loss: 0.642730]\n",
      "[Epoch 1/200] [Batch 13/169] [D loss: 0.749340] [G loss: 0.647219]\n",
      "[Epoch 1/200] [Batch 14/169] [D loss: 0.741777] [G loss: 0.698061]\n",
      "[Epoch 1/200] [Batch 15/169] [D loss: 0.728969] [G loss: 0.711783]\n",
      "[Epoch 1/200] [Batch 16/169] [D loss: 0.715935] [G loss: 0.721725]\n",
      "[Epoch 1/200] [Batch 17/169] [D loss: 0.714855] [G loss: 0.768993]\n",
      "[Epoch 1/200] [Batch 18/169] [D loss: 0.692066] [G loss: 0.810197]\n",
      "[Epoch 1/200] [Batch 19/169] [D loss: 0.690901] [G loss: 0.811799]\n",
      "[Epoch 1/200] [Batch 20/169] [D loss: 0.696223] [G loss: 0.826854]\n",
      "[Epoch 1/200] [Batch 21/169] [D loss: 0.691691] [G loss: 0.826647]\n",
      "[Epoch 1/200] [Batch 22/169] [D loss: 0.696982] [G loss: 0.791158]\n",
      "[Epoch 1/200] [Batch 23/169] [D loss: 0.695023] [G loss: 0.796757]\n",
      "[Epoch 1/200] [Batch 24/169] [D loss: 0.698334] [G loss: 0.762729]\n",
      "[Epoch 1/200] [Batch 25/169] [D loss: 0.698044] [G loss: 0.758386]\n",
      "[Epoch 1/200] [Batch 26/169] [D loss: 0.692916] [G loss: 0.790746]\n",
      "[Epoch 1/200] [Batch 27/169] [D loss: 0.674633] [G loss: 0.792921]\n",
      "[Epoch 1/200] [Batch 28/169] [D loss: 0.631210] [G loss: 0.943124]\n",
      "[Epoch 1/200] [Batch 29/169] [D loss: 0.597722] [G loss: 0.997472]\n",
      "[Epoch 1/200] [Batch 30/169] [D loss: 0.569318] [G loss: 0.987733]\n",
      "[Epoch 1/200] [Batch 31/169] [D loss: 0.572427] [G loss: 0.927422]\n",
      "[Epoch 1/200] [Batch 32/169] [D loss: 0.698353] [G loss: 0.642022]\n",
      "[Epoch 1/200] [Batch 33/169] [D loss: 0.747852] [G loss: 0.633102]\n",
      "[Epoch 1/200] [Batch 34/169] [D loss: 0.729958] [G loss: 0.762584]\n",
      "[Epoch 1/200] [Batch 35/169] [D loss: 0.730490] [G loss: 0.976699]\n",
      "[Epoch 1/200] [Batch 36/169] [D loss: 0.674139] [G loss: 1.196165]\n",
      "[Epoch 1/200] [Batch 37/169] [D loss: 0.639294] [G loss: 1.212610]\n",
      "[Epoch 1/200] [Batch 38/169] [D loss: 0.674439] [G loss: 1.067228]\n",
      "[Epoch 1/200] [Batch 39/169] [D loss: 0.656344] [G loss: 0.884753]\n",
      "[Epoch 1/200] [Batch 40/169] [D loss: 0.738929] [G loss: 0.665661]\n",
      "[Epoch 1/200] [Batch 41/169] [D loss: 0.781314] [G loss: 0.607415]\n",
      "[Epoch 1/200] [Batch 42/169] [D loss: 0.783801] [G loss: 0.608993]\n",
      "[Epoch 1/200] [Batch 43/169] [D loss: 0.831635] [G loss: 0.548380]\n",
      "[Epoch 1/200] [Batch 44/169] [D loss: 0.828350] [G loss: 0.552692]\n",
      "[Epoch 1/200] [Batch 45/169] [D loss: 0.806348] [G loss: 0.587455]\n",
      "[Epoch 1/200] [Batch 46/169] [D loss: 0.743360] [G loss: 0.639806]\n",
      "[Epoch 1/200] [Batch 47/169] [D loss: 0.701463] [G loss: 0.682100]\n",
      "[Epoch 1/200] [Batch 48/169] [D loss: 0.668007] [G loss: 0.719400]\n",
      "[Epoch 1/200] [Batch 49/169] [D loss: 0.677992] [G loss: 0.715007]\n",
      "[Epoch 1/200] [Batch 50/169] [D loss: 0.641045] [G loss: 0.758229]\n",
      "[Epoch 1/200] [Batch 51/169] [D loss: 0.643287] [G loss: 0.762336]\n",
      "[Epoch 1/200] [Batch 52/169] [D loss: 0.625089] [G loss: 0.775154]\n",
      "[Epoch 1/200] [Batch 53/169] [D loss: 0.615738] [G loss: 0.790263]\n",
      "[Epoch 1/200] [Batch 54/169] [D loss: 0.601889] [G loss: 0.772322]\n",
      "[Epoch 1/200] [Batch 55/169] [D loss: 0.606242] [G loss: 0.757880]\n",
      "[Epoch 1/200] [Batch 56/169] [D loss: 0.584398] [G loss: 0.742015]\n",
      "[Epoch 1/200] [Batch 57/169] [D loss: 0.596512] [G loss: 0.712321]\n",
      "[Epoch 1/200] [Batch 58/169] [D loss: 0.624014] [G loss: 0.668852]\n",
      "[Epoch 1/200] [Batch 59/169] [D loss: 0.652829] [G loss: 0.597019]\n",
      "[Epoch 1/200] [Batch 60/169] [D loss: 0.637864] [G loss: 0.580885]\n",
      "[Epoch 1/200] [Batch 61/169] [D loss: 0.620371] [G loss: 0.589036]\n",
      "[Epoch 1/200] [Batch 62/169] [D loss: 0.607371] [G loss: 0.683613]\n",
      "[Epoch 1/200] [Batch 63/169] [D loss: 0.570522] [G loss: 0.752763]\n",
      "[Epoch 1/200] [Batch 64/169] [D loss: 0.567900] [G loss: 0.844546]\n",
      "[Epoch 1/200] [Batch 65/169] [D loss: 0.548371] [G loss: 0.865052]\n",
      "[Epoch 1/200] [Batch 66/169] [D loss: 0.564734] [G loss: 0.857208]\n",
      "[Epoch 1/200] [Batch 67/169] [D loss: 0.606763] [G loss: 0.824151]\n",
      "[Epoch 1/200] [Batch 68/169] [D loss: 0.641258] [G loss: 0.863336]\n",
      "[Epoch 1/200] [Batch 69/169] [D loss: 0.667117] [G loss: 0.762032]\n",
      "[Epoch 1/200] [Batch 70/169] [D loss: 0.759570] [G loss: 0.600257]\n",
      "[Epoch 1/200] [Batch 71/169] [D loss: 0.930490] [G loss: 0.423493]\n",
      "[Epoch 1/200] [Batch 72/169] [D loss: 0.960536] [G loss: 0.411225]\n",
      "[Epoch 1/200] [Batch 73/169] [D loss: 0.941235] [G loss: 0.474214]\n",
      "[Epoch 1/200] [Batch 74/169] [D loss: 0.839272] [G loss: 0.574328]\n",
      "[Epoch 1/200] [Batch 75/169] [D loss: 0.736755] [G loss: 0.742766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 76/169] [D loss: 0.673004] [G loss: 0.856007]\n",
      "[Epoch 1/200] [Batch 77/169] [D loss: 0.655492] [G loss: 0.869196]\n",
      "[Epoch 1/200] [Batch 78/169] [D loss: 0.648015] [G loss: 0.874380]\n",
      "[Epoch 1/200] [Batch 79/169] [D loss: 0.648123] [G loss: 0.879005]\n",
      "[Epoch 1/200] [Batch 80/169] [D loss: 0.649476] [G loss: 0.856799]\n",
      "[Epoch 1/200] [Batch 81/169] [D loss: 0.645017] [G loss: 0.835137]\n",
      "[Epoch 1/200] [Batch 82/169] [D loss: 0.643040] [G loss: 0.812838]\n",
      "[Epoch 1/200] [Batch 83/169] [D loss: 0.644529] [G loss: 0.788351]\n",
      "[Epoch 1/200] [Batch 84/169] [D loss: 0.645880] [G loss: 0.774351]\n",
      "[Epoch 1/200] [Batch 85/169] [D loss: 0.652454] [G loss: 0.741788]\n",
      "[Epoch 1/200] [Batch 86/169] [D loss: 0.677211] [G loss: 0.747531]\n",
      "[Epoch 1/200] [Batch 87/169] [D loss: 0.661615] [G loss: 0.739434]\n",
      "[Epoch 1/200] [Batch 88/169] [D loss: 0.668949] [G loss: 0.748623]\n",
      "[Epoch 1/200] [Batch 89/169] [D loss: 0.665399] [G loss: 0.737249]\n",
      "[Epoch 1/200] [Batch 90/169] [D loss: 0.668320] [G loss: 0.751968]\n",
      "[Epoch 1/200] [Batch 91/169] [D loss: 0.671885] [G loss: 0.736077]\n",
      "[Epoch 1/200] [Batch 92/169] [D loss: 0.683885] [G loss: 0.751038]\n",
      "[Epoch 1/200] [Batch 93/169] [D loss: 0.661559] [G loss: 0.727806]\n",
      "[Epoch 1/200] [Batch 94/169] [D loss: 0.680564] [G loss: 0.704687]\n",
      "[Epoch 1/200] [Batch 95/169] [D loss: 0.695152] [G loss: 0.712534]\n",
      "[Epoch 1/200] [Batch 96/169] [D loss: 0.690693] [G loss: 0.711536]\n",
      "[Epoch 1/200] [Batch 97/169] [D loss: 0.684138] [G loss: 0.718895]\n",
      "[Epoch 1/200] [Batch 98/169] [D loss: 0.706443] [G loss: 0.710631]\n",
      "[Epoch 1/200] [Batch 99/169] [D loss: 0.678779] [G loss: 0.712361]\n",
      "[Epoch 1/200] [Batch 100/169] [D loss: 0.686963] [G loss: 0.712682]\n",
      "[Epoch 1/200] [Batch 101/169] [D loss: 0.682729] [G loss: 0.732982]\n",
      "[Epoch 1/200] [Batch 102/169] [D loss: 0.674673] [G loss: 0.749841]\n",
      "[Epoch 1/200] [Batch 103/169] [D loss: 0.685049] [G loss: 0.738042]\n",
      "[Epoch 1/200] [Batch 104/169] [D loss: 0.689593] [G loss: 0.749141]\n",
      "[Epoch 1/200] [Batch 105/169] [D loss: 0.679504] [G loss: 0.739689]\n",
      "[Epoch 1/200] [Batch 106/169] [D loss: 0.700215] [G loss: 0.728379]\n",
      "[Epoch 1/200] [Batch 107/169] [D loss: 0.679728] [G loss: 0.740155]\n",
      "[Epoch 1/200] [Batch 108/169] [D loss: 0.688409] [G loss: 0.751198]\n",
      "[Epoch 1/200] [Batch 109/169] [D loss: 0.690423] [G loss: 0.713173]\n",
      "[Epoch 1/200] [Batch 110/169] [D loss: 0.710222] [G loss: 0.733668]\n",
      "[Epoch 1/200] [Batch 111/169] [D loss: 0.705308] [G loss: 0.690065]\n",
      "[Epoch 1/200] [Batch 112/169] [D loss: 0.718573] [G loss: 0.689671]\n",
      "[Epoch 1/200] [Batch 113/169] [D loss: 0.717533] [G loss: 0.671628]\n",
      "[Epoch 1/200] [Batch 114/169] [D loss: 0.708975] [G loss: 0.687116]\n",
      "[Epoch 1/200] [Batch 115/169] [D loss: 0.701692] [G loss: 0.667597]\n",
      "[Epoch 1/200] [Batch 116/169] [D loss: 0.708813] [G loss: 0.683588]\n",
      "[Epoch 1/200] [Batch 117/169] [D loss: 0.706318] [G loss: 0.678496]\n",
      "[Epoch 1/200] [Batch 118/169] [D loss: 0.685688] [G loss: 0.676974]\n",
      "[Epoch 1/200] [Batch 119/169] [D loss: 0.677872] [G loss: 0.692112]\n",
      "[Epoch 1/200] [Batch 120/169] [D loss: 0.690442] [G loss: 0.679307]\n",
      "[Epoch 1/200] [Batch 121/169] [D loss: 0.675650] [G loss: 0.685329]\n",
      "[Epoch 1/200] [Batch 122/169] [D loss: 0.679239] [G loss: 0.684244]\n",
      "[Epoch 1/200] [Batch 123/169] [D loss: 0.677850] [G loss: 0.691410]\n",
      "[Epoch 1/200] [Batch 124/169] [D loss: 0.676202] [G loss: 0.689576]\n",
      "[Epoch 1/200] [Batch 125/169] [D loss: 0.675532] [G loss: 0.691284]\n",
      "[Epoch 1/200] [Batch 126/169] [D loss: 0.670624] [G loss: 0.697086]\n",
      "[Epoch 1/200] [Batch 127/169] [D loss: 0.670365] [G loss: 0.707996]\n",
      "[Epoch 1/200] [Batch 128/169] [D loss: 0.683383] [G loss: 0.709959]\n",
      "[Epoch 1/200] [Batch 129/169] [D loss: 0.655233] [G loss: 0.736725]\n",
      "[Epoch 1/200] [Batch 130/169] [D loss: 0.656129] [G loss: 0.719417]\n",
      "[Epoch 1/200] [Batch 131/169] [D loss: 0.655502] [G loss: 0.728748]\n",
      "[Epoch 1/200] [Batch 132/169] [D loss: 0.646321] [G loss: 0.735869]\n",
      "[Epoch 1/200] [Batch 133/169] [D loss: 0.653340] [G loss: 0.727268]\n",
      "[Epoch 1/200] [Batch 134/169] [D loss: 0.657046] [G loss: 0.730818]\n",
      "[Epoch 1/200] [Batch 135/169] [D loss: 0.665632] [G loss: 0.701868]\n",
      "[Epoch 1/200] [Batch 136/169] [D loss: 0.659690] [G loss: 0.723482]\n",
      "[Epoch 1/200] [Batch 137/169] [D loss: 0.660795] [G loss: 0.707434]\n",
      "[Epoch 1/200] [Batch 138/169] [D loss: 0.647809] [G loss: 0.725461]\n",
      "[Epoch 1/200] [Batch 139/169] [D loss: 0.637852] [G loss: 0.723303]\n",
      "[Epoch 1/200] [Batch 140/169] [D loss: 0.631663] [G loss: 0.732879]\n",
      "[Epoch 1/200] [Batch 141/169] [D loss: 0.619939] [G loss: 0.737586]\n",
      "[Epoch 1/200] [Batch 142/169] [D loss: 0.613880] [G loss: 0.738310]\n",
      "[Epoch 1/200] [Batch 143/169] [D loss: 0.604961] [G loss: 0.759344]\n",
      "[Epoch 1/200] [Batch 144/169] [D loss: 0.583956] [G loss: 0.763262]\n",
      "[Epoch 1/200] [Batch 145/169] [D loss: 0.582089] [G loss: 0.749686]\n",
      "[Epoch 1/200] [Batch 146/169] [D loss: 0.617163] [G loss: 0.724061]\n",
      "[Epoch 1/200] [Batch 147/169] [D loss: 0.624244] [G loss: 0.675858]\n",
      "[Epoch 1/200] [Batch 148/169] [D loss: 0.641344] [G loss: 0.659157]\n",
      "[Epoch 1/200] [Batch 149/169] [D loss: 0.701023] [G loss: 0.592845]\n",
      "[Epoch 1/200] [Batch 150/169] [D loss: 0.749410] [G loss: 0.529676]\n",
      "[Epoch 1/200] [Batch 151/169] [D loss: 0.782616] [G loss: 0.464034]\n",
      "[Epoch 1/200] [Batch 152/169] [D loss: 0.774741] [G loss: 0.491079]\n",
      "[Epoch 1/200] [Batch 153/169] [D loss: 0.722286] [G loss: 0.570515]\n",
      "[Epoch 1/200] [Batch 154/169] [D loss: 0.677600] [G loss: 0.759867]\n",
      "[Epoch 1/200] [Batch 155/169] [D loss: 0.637586] [G loss: 0.878983]\n",
      "[Epoch 1/200] [Batch 156/169] [D loss: 0.599289] [G loss: 1.021735]\n",
      "[Epoch 1/200] [Batch 157/169] [D loss: 0.599433] [G loss: 1.016632]\n",
      "[Epoch 1/200] [Batch 158/169] [D loss: 0.594709] [G loss: 0.984759]\n",
      "[Epoch 1/200] [Batch 159/169] [D loss: 0.646274] [G loss: 0.831096]\n",
      "[Epoch 1/200] [Batch 160/169] [D loss: 0.686771] [G loss: 0.716205]\n",
      "[Epoch 1/200] [Batch 161/169] [D loss: 0.719939] [G loss: 0.668818]\n",
      "[Epoch 1/200] [Batch 162/169] [D loss: 0.691478] [G loss: 0.644676]\n",
      "[Epoch 1/200] [Batch 163/169] [D loss: 0.697177] [G loss: 0.655444]\n",
      "[Epoch 1/200] [Batch 164/169] [D loss: 0.707834] [G loss: 0.644340]\n",
      "[Epoch 1/200] [Batch 165/169] [D loss: 0.681862] [G loss: 0.609376]\n",
      "[Epoch 1/200] [Batch 166/169] [D loss: 0.720032] [G loss: 0.591040]\n",
      "[Epoch 1/200] [Batch 167/169] [D loss: 0.730417] [G loss: 0.564629]\n",
      "[Epoch 1/200] [Batch 168/169] [D loss: 0.696092] [G loss: 0.593295]\n",
      "[Epoch 2/200] [Batch 0/169] [D loss: 0.716807] [G loss: 0.578277]\n",
      "[Epoch 2/200] [Batch 1/169] [D loss: 0.711670] [G loss: 0.614514]\n",
      "[Epoch 2/200] [Batch 2/169] [D loss: 0.685438] [G loss: 0.677125]\n",
      "[Epoch 2/200] [Batch 3/169] [D loss: 0.675495] [G loss: 0.729497]\n",
      "[Epoch 2/200] [Batch 4/169] [D loss: 0.667307] [G loss: 0.774465]\n",
      "[Epoch 2/200] [Batch 5/169] [D loss: 0.647725] [G loss: 0.800648]\n",
      "[Epoch 2/200] [Batch 6/169] [D loss: 0.649272] [G loss: 0.820595]\n",
      "[Epoch 2/200] [Batch 7/169] [D loss: 0.637461] [G loss: 0.852469]\n",
      "[Epoch 2/200] [Batch 8/169] [D loss: 0.631658] [G loss: 0.844347]\n",
      "[Epoch 2/200] [Batch 9/169] [D loss: 0.618317] [G loss: 0.868251]\n",
      "[Epoch 2/200] [Batch 10/169] [D loss: 0.620066] [G loss: 0.870081]\n",
      "[Epoch 2/200] [Batch 11/169] [D loss: 0.645090] [G loss: 0.866179]\n",
      "[Epoch 2/200] [Batch 12/169] [D loss: 0.630392] [G loss: 0.823632]\n",
      "[Epoch 2/200] [Batch 13/169] [D loss: 0.633451] [G loss: 0.767733]\n",
      "[Epoch 2/200] [Batch 14/169] [D loss: 0.663949] [G loss: 0.743661]\n",
      "[Epoch 2/200] [Batch 15/169] [D loss: 0.669028] [G loss: 0.698560]\n",
      "[Epoch 2/200] [Batch 16/169] [D loss: 0.677823] [G loss: 0.681541]\n",
      "[Epoch 2/200] [Batch 17/169] [D loss: 0.691622] [G loss: 0.656518]\n",
      "[Epoch 2/200] [Batch 18/169] [D loss: 0.665936] [G loss: 0.649394]\n",
      "[Epoch 2/200] [Batch 19/169] [D loss: 0.666316] [G loss: 0.631649]\n",
      "[Epoch 2/200] [Batch 20/169] [D loss: 0.661363] [G loss: 0.613731]\n",
      "[Epoch 2/200] [Batch 21/169] [D loss: 0.659859] [G loss: 0.625260]\n",
      "[Epoch 2/200] [Batch 22/169] [D loss: 0.656933] [G loss: 0.615196]\n",
      "[Epoch 2/200] [Batch 23/169] [D loss: 0.656540] [G loss: 0.599399]\n",
      "[Epoch 2/200] [Batch 24/169] [D loss: 0.658611] [G loss: 0.616797]\n",
      "[Epoch 2/200] [Batch 25/169] [D loss: 0.649697] [G loss: 0.622559]\n",
      "[Epoch 2/200] [Batch 26/169] [D loss: 0.672816] [G loss: 0.639396]\n",
      "[Epoch 2/200] [Batch 27/169] [D loss: 0.663117] [G loss: 0.626127]\n",
      "[Epoch 2/200] [Batch 28/169] [D loss: 0.661183] [G loss: 0.617274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 29/169] [D loss: 0.695791] [G loss: 0.631353]\n",
      "[Epoch 2/200] [Batch 30/169] [D loss: 0.679967] [G loss: 0.648125]\n",
      "[Epoch 2/200] [Batch 31/169] [D loss: 0.664077] [G loss: 0.692651]\n",
      "[Epoch 2/200] [Batch 32/169] [D loss: 0.644766] [G loss: 0.713724]\n",
      "[Epoch 2/200] [Batch 33/169] [D loss: 0.645715] [G loss: 0.711834]\n",
      "[Epoch 2/200] [Batch 34/169] [D loss: 0.676829] [G loss: 0.710670]\n",
      "[Epoch 2/200] [Batch 35/169] [D loss: 0.700303] [G loss: 0.694945]\n",
      "[Epoch 2/200] [Batch 36/169] [D loss: 0.718477] [G loss: 0.667976]\n",
      "[Epoch 2/200] [Batch 37/169] [D loss: 0.695469] [G loss: 0.645943]\n",
      "[Epoch 2/200] [Batch 38/169] [D loss: 0.720423] [G loss: 0.663052]\n",
      "[Epoch 2/200] [Batch 39/169] [D loss: 0.727147] [G loss: 0.693246]\n",
      "[Epoch 2/200] [Batch 40/169] [D loss: 0.710074] [G loss: 0.697698]\n",
      "[Epoch 2/200] [Batch 41/169] [D loss: 0.712716] [G loss: 0.689533]\n",
      "[Epoch 2/200] [Batch 42/169] [D loss: 0.712885] [G loss: 0.686605]\n",
      "[Epoch 2/200] [Batch 43/169] [D loss: 0.726571] [G loss: 0.708771]\n",
      "[Epoch 2/200] [Batch 44/169] [D loss: 0.728177] [G loss: 0.705623]\n",
      "[Epoch 2/200] [Batch 45/169] [D loss: 0.731261] [G loss: 0.690394]\n",
      "[Epoch 2/200] [Batch 46/169] [D loss: 0.712734] [G loss: 0.684538]\n",
      "[Epoch 2/200] [Batch 47/169] [D loss: 0.696231] [G loss: 0.742738]\n",
      "[Epoch 2/200] [Batch 48/169] [D loss: 0.681643] [G loss: 0.761208]\n",
      "[Epoch 2/200] [Batch 49/169] [D loss: 0.666528] [G loss: 0.779521]\n",
      "[Epoch 2/200] [Batch 50/169] [D loss: 0.641247] [G loss: 0.810308]\n",
      "[Epoch 2/200] [Batch 51/169] [D loss: 0.625979] [G loss: 0.799200]\n",
      "[Epoch 2/200] [Batch 52/169] [D loss: 0.613567] [G loss: 0.828211]\n",
      "[Epoch 2/200] [Batch 53/169] [D loss: 0.598718] [G loss: 0.858839]\n",
      "[Epoch 2/200] [Batch 54/169] [D loss: 0.603895] [G loss: 0.842293]\n",
      "[Epoch 2/200] [Batch 55/169] [D loss: 0.608686] [G loss: 0.834759]\n",
      "[Epoch 2/200] [Batch 56/169] [D loss: 0.619443] [G loss: 0.784653]\n",
      "[Epoch 2/200] [Batch 57/169] [D loss: 0.629723] [G loss: 0.729860]\n",
      "[Epoch 2/200] [Batch 58/169] [D loss: 0.678759] [G loss: 0.666422]\n",
      "[Epoch 2/200] [Batch 59/169] [D loss: 0.719224] [G loss: 0.634275]\n",
      "[Epoch 2/200] [Batch 60/169] [D loss: 0.724219] [G loss: 0.578403]\n",
      "[Epoch 2/200] [Batch 61/169] [D loss: 0.729468] [G loss: 0.570299]\n",
      "[Epoch 2/200] [Batch 62/169] [D loss: 0.743548] [G loss: 0.650109]\n",
      "[Epoch 2/200] [Batch 63/169] [D loss: 0.692641] [G loss: 0.721595]\n",
      "[Epoch 2/200] [Batch 64/169] [D loss: 0.696222] [G loss: 0.800344]\n",
      "[Epoch 2/200] [Batch 65/169] [D loss: 0.672245] [G loss: 0.853202]\n",
      "[Epoch 2/200] [Batch 66/169] [D loss: 0.651930] [G loss: 0.927288]\n",
      "[Epoch 2/200] [Batch 67/169] [D loss: 0.639743] [G loss: 0.929897]\n",
      "[Epoch 2/200] [Batch 68/169] [D loss: 0.643388] [G loss: 0.919162]\n",
      "[Epoch 2/200] [Batch 69/169] [D loss: 0.659850] [G loss: 0.914138]\n",
      "[Epoch 2/200] [Batch 70/169] [D loss: 0.672623] [G loss: 0.834573]\n",
      "[Epoch 2/200] [Batch 71/169] [D loss: 0.704770] [G loss: 0.731172]\n",
      "[Epoch 2/200] [Batch 72/169] [D loss: 0.714962] [G loss: 0.697323]\n",
      "[Epoch 2/200] [Batch 73/169] [D loss: 0.727355] [G loss: 0.680586]\n",
      "[Epoch 2/200] [Batch 74/169] [D loss: 0.698563] [G loss: 0.685987]\n",
      "[Epoch 2/200] [Batch 75/169] [D loss: 0.697711] [G loss: 0.693555]\n",
      "[Epoch 2/200] [Batch 76/169] [D loss: 0.675730] [G loss: 0.714899]\n",
      "[Epoch 2/200] [Batch 77/169] [D loss: 0.663925] [G loss: 0.707237]\n",
      "[Epoch 2/200] [Batch 78/169] [D loss: 0.655785] [G loss: 0.731301]\n",
      "[Epoch 2/200] [Batch 79/169] [D loss: 0.640577] [G loss: 0.728226]\n",
      "[Epoch 2/200] [Batch 80/169] [D loss: 0.639898] [G loss: 0.781219]\n",
      "[Epoch 2/200] [Batch 81/169] [D loss: 0.646468] [G loss: 0.731021]\n",
      "[Epoch 2/200] [Batch 82/169] [D loss: 0.631428] [G loss: 0.726500]\n",
      "[Epoch 2/200] [Batch 83/169] [D loss: 0.625879] [G loss: 0.708185]\n",
      "[Epoch 2/200] [Batch 84/169] [D loss: 0.637418] [G loss: 0.734969]\n",
      "[Epoch 2/200] [Batch 85/169] [D loss: 0.658339] [G loss: 0.738065]\n",
      "[Epoch 2/200] [Batch 86/169] [D loss: 0.664724] [G loss: 0.708937]\n",
      "[Epoch 2/200] [Batch 87/169] [D loss: 0.661620] [G loss: 0.689559]\n",
      "[Epoch 2/200] [Batch 88/169] [D loss: 0.670087] [G loss: 0.698015]\n",
      "[Epoch 2/200] [Batch 89/169] [D loss: 0.667645] [G loss: 0.674115]\n",
      "[Epoch 2/200] [Batch 90/169] [D loss: 0.676498] [G loss: 0.671425]\n",
      "[Epoch 2/200] [Batch 91/169] [D loss: 0.676564] [G loss: 0.665702]\n",
      "[Epoch 2/200] [Batch 92/169] [D loss: 0.669917] [G loss: 0.680704]\n",
      "[Epoch 2/200] [Batch 93/169] [D loss: 0.664305] [G loss: 0.685402]\n",
      "[Epoch 2/200] [Batch 94/169] [D loss: 0.662455] [G loss: 0.704993]\n",
      "[Epoch 2/200] [Batch 95/169] [D loss: 0.670989] [G loss: 0.687271]\n",
      "[Epoch 2/200] [Batch 96/169] [D loss: 0.682042] [G loss: 0.687190]\n",
      "[Epoch 2/200] [Batch 97/169] [D loss: 0.698403] [G loss: 0.706122]\n",
      "[Epoch 2/200] [Batch 98/169] [D loss: 0.675195] [G loss: 0.684830]\n",
      "[Epoch 2/200] [Batch 99/169] [D loss: 0.680955] [G loss: 0.675776]\n",
      "[Epoch 2/200] [Batch 100/169] [D loss: 0.686272] [G loss: 0.661387]\n",
      "[Epoch 2/200] [Batch 101/169] [D loss: 0.701499] [G loss: 0.660801]\n",
      "[Epoch 2/200] [Batch 102/169] [D loss: 0.685480] [G loss: 0.646481]\n",
      "[Epoch 2/200] [Batch 103/169] [D loss: 0.712763] [G loss: 0.641300]\n",
      "[Epoch 2/200] [Batch 104/169] [D loss: 0.709289] [G loss: 0.665195]\n",
      "[Epoch 2/200] [Batch 105/169] [D loss: 0.684756] [G loss: 0.673357]\n",
      "[Epoch 2/200] [Batch 106/169] [D loss: 0.683470] [G loss: 0.675365]\n",
      "[Epoch 2/200] [Batch 107/169] [D loss: 0.677123] [G loss: 0.725749]\n",
      "[Epoch 2/200] [Batch 108/169] [D loss: 0.684714] [G loss: 0.721881]\n",
      "[Epoch 2/200] [Batch 109/169] [D loss: 0.679326] [G loss: 0.738007]\n",
      "[Epoch 2/200] [Batch 110/169] [D loss: 0.665541] [G loss: 0.751874]\n",
      "[Epoch 2/200] [Batch 111/169] [D loss: 0.653304] [G loss: 0.757306]\n",
      "[Epoch 2/200] [Batch 112/169] [D loss: 0.655085] [G loss: 0.757046]\n",
      "[Epoch 2/200] [Batch 113/169] [D loss: 0.660253] [G loss: 0.762242]\n",
      "[Epoch 2/200] [Batch 114/169] [D loss: 0.653275] [G loss: 0.774663]\n",
      "[Epoch 2/200] [Batch 115/169] [D loss: 0.648668] [G loss: 0.767804]\n",
      "[Epoch 2/200] [Batch 116/169] [D loss: 0.639093] [G loss: 0.758966]\n",
      "[Epoch 2/200] [Batch 117/169] [D loss: 0.632785] [G loss: 0.747318]\n",
      "[Epoch 2/200] [Batch 118/169] [D loss: 0.635493] [G loss: 0.744011]\n",
      "[Epoch 2/200] [Batch 119/169] [D loss: 0.634190] [G loss: 0.736040]\n",
      "[Epoch 2/200] [Batch 120/169] [D loss: 0.615682] [G loss: 0.763151]\n",
      "[Epoch 2/200] [Batch 121/169] [D loss: 0.630090] [G loss: 0.743684]\n",
      "[Epoch 2/200] [Batch 122/169] [D loss: 0.630318] [G loss: 0.720277]\n",
      "[Epoch 2/200] [Batch 123/169] [D loss: 0.627730] [G loss: 0.724847]\n",
      "[Epoch 2/200] [Batch 124/169] [D loss: 0.621561] [G loss: 0.731599]\n",
      "[Epoch 2/200] [Batch 125/169] [D loss: 0.633783] [G loss: 0.719463]\n",
      "[Epoch 2/200] [Batch 126/169] [D loss: 0.621961] [G loss: 0.712311]\n",
      "[Epoch 2/200] [Batch 127/169] [D loss: 0.635866] [G loss: 0.703425]\n",
      "[Epoch 2/200] [Batch 128/169] [D loss: 0.639249] [G loss: 0.723427]\n",
      "[Epoch 2/200] [Batch 129/169] [D loss: 0.620695] [G loss: 0.728785]\n",
      "[Epoch 2/200] [Batch 130/169] [D loss: 0.630073] [G loss: 0.719322]\n",
      "[Epoch 2/200] [Batch 131/169] [D loss: 0.638544] [G loss: 0.707329]\n",
      "[Epoch 2/200] [Batch 132/169] [D loss: 0.637934] [G loss: 0.710031]\n",
      "[Epoch 2/200] [Batch 133/169] [D loss: 0.640334] [G loss: 0.706337]\n",
      "[Epoch 2/200] [Batch 134/169] [D loss: 0.648772] [G loss: 0.704038]\n",
      "[Epoch 2/200] [Batch 135/169] [D loss: 0.653937] [G loss: 0.669640]\n",
      "[Epoch 2/200] [Batch 136/169] [D loss: 0.642338] [G loss: 0.679045]\n",
      "[Epoch 2/200] [Batch 137/169] [D loss: 0.657483] [G loss: 0.687545]\n",
      "[Epoch 2/200] [Batch 138/169] [D loss: 0.655066] [G loss: 0.707345]\n",
      "[Epoch 2/200] [Batch 139/169] [D loss: 0.663188] [G loss: 0.736548]\n",
      "[Epoch 2/200] [Batch 140/169] [D loss: 0.681187] [G loss: 0.732121]\n",
      "[Epoch 2/200] [Batch 141/169] [D loss: 0.679897] [G loss: 0.719863]\n",
      "[Epoch 2/200] [Batch 142/169] [D loss: 0.663731] [G loss: 0.713856]\n",
      "[Epoch 2/200] [Batch 143/169] [D loss: 0.673472] [G loss: 0.716055]\n",
      "[Epoch 2/200] [Batch 144/169] [D loss: 0.675169] [G loss: 0.721456]\n",
      "[Epoch 2/200] [Batch 145/169] [D loss: 0.664191] [G loss: 0.724114]\n",
      "[Epoch 2/200] [Batch 146/169] [D loss: 0.660637] [G loss: 0.739279]\n",
      "[Epoch 2/200] [Batch 147/169] [D loss: 0.660333] [G loss: 0.752831]\n",
      "[Epoch 2/200] [Batch 148/169] [D loss: 0.661386] [G loss: 0.734939]\n",
      "[Epoch 2/200] [Batch 149/169] [D loss: 0.657924] [G loss: 0.735608]\n",
      "[Epoch 2/200] [Batch 150/169] [D loss: 0.623846] [G loss: 0.765496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 151/169] [D loss: 0.638843] [G loss: 0.776833]\n",
      "[Epoch 2/200] [Batch 152/169] [D loss: 0.648115] [G loss: 0.770872]\n",
      "[Epoch 2/200] [Batch 153/169] [D loss: 0.620093] [G loss: 0.814364]\n",
      "[Epoch 2/200] [Batch 154/169] [D loss: 0.615903] [G loss: 0.816069]\n",
      "[Epoch 2/200] [Batch 155/169] [D loss: 0.623133] [G loss: 0.782708]\n",
      "[Epoch 2/200] [Batch 156/169] [D loss: 0.620656] [G loss: 0.803623]\n",
      "[Epoch 2/200] [Batch 157/169] [D loss: 0.628035] [G loss: 0.762124]\n",
      "[Epoch 2/200] [Batch 158/169] [D loss: 0.620246] [G loss: 0.789953]\n",
      "[Epoch 2/200] [Batch 159/169] [D loss: 0.634392] [G loss: 0.779338]\n",
      "[Epoch 2/200] [Batch 160/169] [D loss: 0.615358] [G loss: 0.819748]\n",
      "[Epoch 2/200] [Batch 161/169] [D loss: 0.648854] [G loss: 0.811964]\n",
      "[Epoch 2/200] [Batch 162/169] [D loss: 0.632306] [G loss: 0.816515]\n",
      "[Epoch 2/200] [Batch 163/169] [D loss: 0.626700] [G loss: 0.806213]\n",
      "[Epoch 2/200] [Batch 164/169] [D loss: 0.637459] [G loss: 0.811596]\n",
      "[Epoch 2/200] [Batch 165/169] [D loss: 0.650158] [G loss: 0.763612]\n",
      "[Epoch 2/200] [Batch 166/169] [D loss: 0.629664] [G loss: 0.765917]\n",
      "[Epoch 2/200] [Batch 167/169] [D loss: 0.640760] [G loss: 0.727309]\n",
      "[Epoch 2/200] [Batch 168/169] [D loss: 0.602653] [G loss: 0.698646]\n",
      "[Epoch 3/200] [Batch 0/169] [D loss: 0.678243] [G loss: 0.655720]\n",
      "[Epoch 3/200] [Batch 1/169] [D loss: 0.665409] [G loss: 0.632790]\n",
      "[Epoch 3/200] [Batch 2/169] [D loss: 0.727923] [G loss: 0.542478]\n",
      "[Epoch 3/200] [Batch 3/169] [D loss: 0.741907] [G loss: 0.537064]\n",
      "[Epoch 3/200] [Batch 4/169] [D loss: 0.725828] [G loss: 0.557189]\n",
      "[Epoch 3/200] [Batch 5/169] [D loss: 0.722393] [G loss: 0.591458]\n",
      "[Epoch 3/200] [Batch 6/169] [D loss: 0.713943] [G loss: 0.639713]\n",
      "[Epoch 3/200] [Batch 7/169] [D loss: 0.722486] [G loss: 0.663692]\n",
      "[Epoch 3/200] [Batch 8/169] [D loss: 0.726096] [G loss: 0.706268]\n",
      "[Epoch 3/200] [Batch 9/169] [D loss: 0.729117] [G loss: 0.749924]\n",
      "[Epoch 3/200] [Batch 10/169] [D loss: 0.721731] [G loss: 0.757011]\n",
      "[Epoch 3/200] [Batch 11/169] [D loss: 0.709875] [G loss: 0.769097]\n",
      "[Epoch 3/200] [Batch 12/169] [D loss: 0.712956] [G loss: 0.754623]\n",
      "[Epoch 3/200] [Batch 13/169] [D loss: 0.693082] [G loss: 0.829639]\n",
      "[Epoch 3/200] [Batch 14/169] [D loss: 0.651821] [G loss: 0.814844]\n",
      "[Epoch 3/200] [Batch 15/169] [D loss: 0.635274] [G loss: 0.805369]\n",
      "[Epoch 3/200] [Batch 16/169] [D loss: 0.636358] [G loss: 0.808359]\n",
      "[Epoch 3/200] [Batch 17/169] [D loss: 0.625052] [G loss: 0.809241]\n",
      "[Epoch 3/200] [Batch 18/169] [D loss: 0.611590] [G loss: 0.775517]\n",
      "[Epoch 3/200] [Batch 19/169] [D loss: 0.627490] [G loss: 0.778473]\n",
      "[Epoch 3/200] [Batch 20/169] [D loss: 0.601091] [G loss: 0.758135]\n",
      "[Epoch 3/200] [Batch 21/169] [D loss: 0.614273] [G loss: 0.789750]\n",
      "[Epoch 3/200] [Batch 22/169] [D loss: 0.582543] [G loss: 0.773582]\n",
      "[Epoch 3/200] [Batch 23/169] [D loss: 0.582149] [G loss: 0.812679]\n",
      "[Epoch 3/200] [Batch 24/169] [D loss: 0.583380] [G loss: 0.850941]\n",
      "[Epoch 3/200] [Batch 25/169] [D loss: 0.573667] [G loss: 0.797472]\n",
      "[Epoch 3/200] [Batch 26/169] [D loss: 0.597816] [G loss: 0.816586]\n",
      "[Epoch 3/200] [Batch 27/169] [D loss: 0.633686] [G loss: 0.716342]\n",
      "[Epoch 3/200] [Batch 28/169] [D loss: 0.658721] [G loss: 0.681663]\n",
      "[Epoch 3/200] [Batch 29/169] [D loss: 0.692811] [G loss: 0.636377]\n",
      "[Epoch 3/200] [Batch 30/169] [D loss: 0.671140] [G loss: 0.694927]\n",
      "[Epoch 3/200] [Batch 31/169] [D loss: 0.657160] [G loss: 0.743786]\n",
      "[Epoch 3/200] [Batch 32/169] [D loss: 0.644319] [G loss: 0.826505]\n",
      "[Epoch 3/200] [Batch 33/169] [D loss: 0.612063] [G loss: 0.895571]\n",
      "[Epoch 3/200] [Batch 34/169] [D loss: 0.607464] [G loss: 0.878766]\n",
      "[Epoch 3/200] [Batch 35/169] [D loss: 0.623596] [G loss: 0.850232]\n",
      "[Epoch 3/200] [Batch 36/169] [D loss: 0.639778] [G loss: 0.847580]\n",
      "[Epoch 3/200] [Batch 37/169] [D loss: 0.632655] [G loss: 0.747101]\n",
      "[Epoch 3/200] [Batch 38/169] [D loss: 0.681947] [G loss: 0.720326]\n",
      "[Epoch 3/200] [Batch 39/169] [D loss: 0.709309] [G loss: 0.690212]\n",
      "[Epoch 3/200] [Batch 40/169] [D loss: 0.686197] [G loss: 0.702830]\n",
      "[Epoch 3/200] [Batch 41/169] [D loss: 0.685002] [G loss: 0.703265]\n",
      "[Epoch 3/200] [Batch 42/169] [D loss: 0.662271] [G loss: 0.714392]\n",
      "[Epoch 3/200] [Batch 43/169] [D loss: 0.650953] [G loss: 0.718786]\n",
      "[Epoch 3/200] [Batch 44/169] [D loss: 0.634735] [G loss: 0.747725]\n",
      "[Epoch 3/200] [Batch 45/169] [D loss: 0.633289] [G loss: 0.787934]\n",
      "[Epoch 3/200] [Batch 46/169] [D loss: 0.606232] [G loss: 0.801355]\n",
      "[Epoch 3/200] [Batch 47/169] [D loss: 0.617271] [G loss: 0.853871]\n",
      "[Epoch 3/200] [Batch 48/169] [D loss: 0.576926] [G loss: 0.859025]\n",
      "[Epoch 3/200] [Batch 49/169] [D loss: 0.578350] [G loss: 0.906958]\n",
      "[Epoch 3/200] [Batch 50/169] [D loss: 0.584696] [G loss: 0.877962]\n",
      "[Epoch 3/200] [Batch 51/169] [D loss: 0.555351] [G loss: 0.897298]\n",
      "[Epoch 3/200] [Batch 52/169] [D loss: 0.568170] [G loss: 0.865786]\n",
      "[Epoch 3/200] [Batch 53/169] [D loss: 0.596012] [G loss: 0.825547]\n",
      "[Epoch 3/200] [Batch 54/169] [D loss: 0.600192] [G loss: 0.824391]\n",
      "[Epoch 3/200] [Batch 55/169] [D loss: 0.602193] [G loss: 0.817290]\n",
      "[Epoch 3/200] [Batch 56/169] [D loss: 0.652557] [G loss: 0.753021]\n",
      "[Epoch 3/200] [Batch 57/169] [D loss: 0.660589] [G loss: 0.731280]\n",
      "[Epoch 3/200] [Batch 58/169] [D loss: 0.684017] [G loss: 0.752256]\n",
      "[Epoch 3/200] [Batch 59/169] [D loss: 0.670843] [G loss: 0.757386]\n",
      "[Epoch 3/200] [Batch 60/169] [D loss: 0.646425] [G loss: 0.798001]\n",
      "[Epoch 3/200] [Batch 61/169] [D loss: 0.659264] [G loss: 0.780203]\n",
      "[Epoch 3/200] [Batch 62/169] [D loss: 0.662238] [G loss: 0.755473]\n",
      "[Epoch 3/200] [Batch 63/169] [D loss: 0.694669] [G loss: 0.688616]\n",
      "[Epoch 3/200] [Batch 64/169] [D loss: 0.692901] [G loss: 0.664068]\n",
      "[Epoch 3/200] [Batch 65/169] [D loss: 0.736101] [G loss: 0.623651]\n",
      "[Epoch 3/200] [Batch 66/169] [D loss: 0.719818] [G loss: 0.624248]\n",
      "[Epoch 3/200] [Batch 67/169] [D loss: 0.706283] [G loss: 0.626229]\n",
      "[Epoch 3/200] [Batch 68/169] [D loss: 0.706269] [G loss: 0.635853]\n",
      "[Epoch 3/200] [Batch 69/169] [D loss: 0.692238] [G loss: 0.705760]\n",
      "[Epoch 3/200] [Batch 70/169] [D loss: 0.710935] [G loss: 0.749426]\n",
      "[Epoch 3/200] [Batch 71/169] [D loss: 0.679130] [G loss: 0.770820]\n",
      "[Epoch 3/200] [Batch 72/169] [D loss: 0.682948] [G loss: 0.776262]\n",
      "[Epoch 3/200] [Batch 73/169] [D loss: 0.677833] [G loss: 0.802721]\n",
      "[Epoch 3/200] [Batch 74/169] [D loss: 0.637801] [G loss: 0.842720]\n",
      "[Epoch 3/200] [Batch 75/169] [D loss: 0.634136] [G loss: 0.891687]\n",
      "[Epoch 3/200] [Batch 76/169] [D loss: 0.611784] [G loss: 0.890966]\n",
      "[Epoch 3/200] [Batch 77/169] [D loss: 0.613573] [G loss: 0.844308]\n",
      "[Epoch 3/200] [Batch 78/169] [D loss: 0.618778] [G loss: 0.867804]\n",
      "[Epoch 3/200] [Batch 79/169] [D loss: 0.627658] [G loss: 0.868204]\n",
      "[Epoch 3/200] [Batch 80/169] [D loss: 0.601134] [G loss: 0.826452]\n",
      "[Epoch 3/200] [Batch 81/169] [D loss: 0.615357] [G loss: 0.809938]\n",
      "[Epoch 3/200] [Batch 82/169] [D loss: 0.625044] [G loss: 0.804379]\n",
      "[Epoch 3/200] [Batch 83/169] [D loss: 0.632445] [G loss: 0.829722]\n",
      "[Epoch 3/200] [Batch 84/169] [D loss: 0.645023] [G loss: 0.776070]\n",
      "[Epoch 3/200] [Batch 85/169] [D loss: 0.642454] [G loss: 0.780050]\n",
      "[Epoch 3/200] [Batch 86/169] [D loss: 0.631486] [G loss: 0.779714]\n",
      "[Epoch 3/200] [Batch 87/169] [D loss: 0.621347] [G loss: 0.754502]\n",
      "[Epoch 3/200] [Batch 88/169] [D loss: 0.681280] [G loss: 0.759144]\n",
      "[Epoch 3/200] [Batch 89/169] [D loss: 0.669807] [G loss: 0.711397]\n",
      "[Epoch 3/200] [Batch 90/169] [D loss: 0.674194] [G loss: 0.694716]\n",
      "[Epoch 3/200] [Batch 91/169] [D loss: 0.696376] [G loss: 0.697676]\n",
      "[Epoch 3/200] [Batch 92/169] [D loss: 0.716394] [G loss: 0.643943]\n",
      "[Epoch 3/200] [Batch 93/169] [D loss: 0.715117] [G loss: 0.653882]\n",
      "[Epoch 3/200] [Batch 94/169] [D loss: 0.707896] [G loss: 0.654252]\n",
      "[Epoch 3/200] [Batch 95/169] [D loss: 0.702869] [G loss: 0.671212]\n",
      "[Epoch 3/200] [Batch 96/169] [D loss: 0.692665] [G loss: 0.696871]\n",
      "[Epoch 3/200] [Batch 97/169] [D loss: 0.663398] [G loss: 0.700933]\n",
      "[Epoch 3/200] [Batch 98/169] [D loss: 0.664665] [G loss: 0.731136]\n",
      "[Epoch 3/200] [Batch 99/169] [D loss: 0.655308] [G loss: 0.798992]\n",
      "[Epoch 3/200] [Batch 100/169] [D loss: 0.632846] [G loss: 0.805190]\n",
      "[Epoch 3/200] [Batch 101/169] [D loss: 0.622913] [G loss: 0.834157]\n",
      "[Epoch 3/200] [Batch 102/169] [D loss: 0.616279] [G loss: 0.839265]\n",
      "[Epoch 3/200] [Batch 103/169] [D loss: 0.598424] [G loss: 0.862713]\n",
      "[Epoch 3/200] [Batch 104/169] [D loss: 0.587309] [G loss: 0.810480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 105/169] [D loss: 0.593385] [G loss: 0.842368]\n",
      "[Epoch 3/200] [Batch 106/169] [D loss: 0.597301] [G loss: 0.830692]\n",
      "[Epoch 3/200] [Batch 107/169] [D loss: 0.602764] [G loss: 0.866139]\n",
      "[Epoch 3/200] [Batch 108/169] [D loss: 0.638883] [G loss: 0.792070]\n",
      "[Epoch 3/200] [Batch 109/169] [D loss: 0.585761] [G loss: 0.781719]\n",
      "[Epoch 3/200] [Batch 110/169] [D loss: 0.631636] [G loss: 0.762095]\n",
      "[Epoch 3/200] [Batch 111/169] [D loss: 0.637106] [G loss: 0.710082]\n",
      "[Epoch 3/200] [Batch 112/169] [D loss: 0.649158] [G loss: 0.712528]\n",
      "[Epoch 3/200] [Batch 113/169] [D loss: 0.648797] [G loss: 0.702063]\n",
      "[Epoch 3/200] [Batch 114/169] [D loss: 0.651893] [G loss: 0.710242]\n",
      "[Epoch 3/200] [Batch 115/169] [D loss: 0.640515] [G loss: 0.723756]\n",
      "[Epoch 3/200] [Batch 116/169] [D loss: 0.683078] [G loss: 0.761296]\n",
      "[Epoch 3/200] [Batch 117/169] [D loss: 0.669349] [G loss: 0.737340]\n",
      "[Epoch 3/200] [Batch 118/169] [D loss: 0.647286] [G loss: 0.716056]\n",
      "[Epoch 3/200] [Batch 119/169] [D loss: 0.670218] [G loss: 0.690919]\n",
      "[Epoch 3/200] [Batch 120/169] [D loss: 0.676696] [G loss: 0.689538]\n",
      "[Epoch 3/200] [Batch 121/169] [D loss: 0.687455] [G loss: 0.665902]\n",
      "[Epoch 3/200] [Batch 122/169] [D loss: 0.713475] [G loss: 0.652257]\n",
      "[Epoch 3/200] [Batch 123/169] [D loss: 0.677420] [G loss: 0.708077]\n",
      "[Epoch 3/200] [Batch 124/169] [D loss: 0.659994] [G loss: 0.696574]\n",
      "[Epoch 3/200] [Batch 125/169] [D loss: 0.651167] [G loss: 0.756234]\n",
      "[Epoch 3/200] [Batch 126/169] [D loss: 0.630766] [G loss: 0.772725]\n",
      "[Epoch 3/200] [Batch 127/169] [D loss: 0.633782] [G loss: 0.810363]\n",
      "[Epoch 3/200] [Batch 128/169] [D loss: 0.593785] [G loss: 0.799483]\n",
      "[Epoch 3/200] [Batch 129/169] [D loss: 0.616856] [G loss: 0.814363]\n",
      "[Epoch 3/200] [Batch 130/169] [D loss: 0.588825] [G loss: 0.789997]\n",
      "[Epoch 3/200] [Batch 131/169] [D loss: 0.609312] [G loss: 0.768584]\n",
      "[Epoch 3/200] [Batch 132/169] [D loss: 0.605914] [G loss: 0.777274]\n",
      "[Epoch 3/200] [Batch 133/169] [D loss: 0.613716] [G loss: 0.723322]\n",
      "[Epoch 3/200] [Batch 134/169] [D loss: 0.614466] [G loss: 0.770487]\n",
      "[Epoch 3/200] [Batch 135/169] [D loss: 0.607764] [G loss: 0.722391]\n",
      "[Epoch 3/200] [Batch 136/169] [D loss: 0.579277] [G loss: 0.747939]\n",
      "[Epoch 3/200] [Batch 137/169] [D loss: 0.578143] [G loss: 0.785114]\n",
      "[Epoch 3/200] [Batch 138/169] [D loss: 0.597772] [G loss: 0.845184]\n",
      "[Epoch 3/200] [Batch 139/169] [D loss: 0.571987] [G loss: 0.820136]\n",
      "[Epoch 3/200] [Batch 140/169] [D loss: 0.598521] [G loss: 0.682599]\n",
      "[Epoch 3/200] [Batch 141/169] [D loss: 0.648611] [G loss: 0.632019]\n",
      "[Epoch 3/200] [Batch 142/169] [D loss: 0.698701] [G loss: 0.600893]\n",
      "[Epoch 3/200] [Batch 143/169] [D loss: 0.681151] [G loss: 0.644739]\n",
      "[Epoch 3/200] [Batch 144/169] [D loss: 0.628567] [G loss: 0.774423]\n",
      "[Epoch 3/200] [Batch 145/169] [D loss: 0.632755] [G loss: 0.796766]\n",
      "[Epoch 3/200] [Batch 146/169] [D loss: 0.657185] [G loss: 0.776932]\n",
      "[Epoch 3/200] [Batch 147/169] [D loss: 0.669742] [G loss: 0.780562]\n",
      "[Epoch 3/200] [Batch 148/169] [D loss: 0.688366] [G loss: 0.745263]\n",
      "[Epoch 3/200] [Batch 149/169] [D loss: 0.689043] [G loss: 0.716927]\n",
      "[Epoch 3/200] [Batch 150/169] [D loss: 0.698074] [G loss: 0.710204]\n",
      "[Epoch 3/200] [Batch 151/169] [D loss: 0.708118] [G loss: 0.712949]\n",
      "[Epoch 3/200] [Batch 152/169] [D loss: 0.706058] [G loss: 0.693835]\n",
      "[Epoch 3/200] [Batch 153/169] [D loss: 0.697771] [G loss: 0.703220]\n",
      "[Epoch 3/200] [Batch 154/169] [D loss: 0.692998] [G loss: 0.710494]\n",
      "[Epoch 3/200] [Batch 155/169] [D loss: 0.666174] [G loss: 0.740148]\n",
      "[Epoch 3/200] [Batch 156/169] [D loss: 0.679017] [G loss: 0.805846]\n",
      "[Epoch 3/200] [Batch 157/169] [D loss: 0.641802] [G loss: 0.791317]\n",
      "[Epoch 3/200] [Batch 158/169] [D loss: 0.620406] [G loss: 0.847434]\n",
      "[Epoch 3/200] [Batch 159/169] [D loss: 0.633793] [G loss: 0.859333]\n",
      "[Epoch 3/200] [Batch 160/169] [D loss: 0.610171] [G loss: 0.904017]\n",
      "[Epoch 3/200] [Batch 161/169] [D loss: 0.588201] [G loss: 0.907723]\n",
      "[Epoch 3/200] [Batch 162/169] [D loss: 0.600182] [G loss: 0.875244]\n",
      "[Epoch 3/200] [Batch 163/169] [D loss: 0.594953] [G loss: 0.855113]\n",
      "[Epoch 3/200] [Batch 164/169] [D loss: 0.593396] [G loss: 0.872703]\n",
      "[Epoch 3/200] [Batch 165/169] [D loss: 0.618446] [G loss: 0.826837]\n",
      "[Epoch 3/200] [Batch 166/169] [D loss: 0.618919] [G loss: 0.816268]\n",
      "[Epoch 3/200] [Batch 167/169] [D loss: 0.627635] [G loss: 0.810058]\n",
      "[Epoch 3/200] [Batch 168/169] [D loss: 0.673367] [G loss: 0.719403]\n",
      "[Epoch 4/200] [Batch 0/169] [D loss: 0.667970] [G loss: 0.791549]\n",
      "[Epoch 4/200] [Batch 1/169] [D loss: 0.660339] [G loss: 0.848395]\n",
      "[Epoch 4/200] [Batch 2/169] [D loss: 0.636887] [G loss: 0.876462]\n",
      "[Epoch 4/200] [Batch 3/169] [D loss: 0.642038] [G loss: 0.848594]\n",
      "[Epoch 4/200] [Batch 4/169] [D loss: 0.623405] [G loss: 0.849308]\n",
      "[Epoch 4/200] [Batch 5/169] [D loss: 0.660866] [G loss: 0.855945]\n",
      "[Epoch 4/200] [Batch 6/169] [D loss: 0.632763] [G loss: 0.829472]\n",
      "[Epoch 4/200] [Batch 7/169] [D loss: 0.647009] [G loss: 0.814072]\n",
      "[Epoch 4/200] [Batch 8/169] [D loss: 0.665360] [G loss: 0.770517]\n",
      "[Epoch 4/200] [Batch 9/169] [D loss: 0.679568] [G loss: 0.755186]\n",
      "[Epoch 4/200] [Batch 10/169] [D loss: 0.682251] [G loss: 0.775785]\n",
      "[Epoch 4/200] [Batch 11/169] [D loss: 0.712088] [G loss: 0.739759]\n",
      "[Epoch 4/200] [Batch 12/169] [D loss: 0.686036] [G loss: 0.772880]\n",
      "[Epoch 4/200] [Batch 13/169] [D loss: 0.668374] [G loss: 0.773691]\n",
      "[Epoch 4/200] [Batch 14/169] [D loss: 0.673869] [G loss: 0.801617]\n",
      "[Epoch 4/200] [Batch 15/169] [D loss: 0.659375] [G loss: 0.762541]\n",
      "[Epoch 4/200] [Batch 16/169] [D loss: 0.665819] [G loss: 0.813789]\n",
      "[Epoch 4/200] [Batch 17/169] [D loss: 0.652328] [G loss: 0.791741]\n",
      "[Epoch 4/200] [Batch 18/169] [D loss: 0.637674] [G loss: 0.797380]\n",
      "[Epoch 4/200] [Batch 19/169] [D loss: 0.612811] [G loss: 0.840138]\n",
      "[Epoch 4/200] [Batch 20/169] [D loss: 0.591605] [G loss: 0.851767]\n",
      "[Epoch 4/200] [Batch 21/169] [D loss: 0.579601] [G loss: 0.830831]\n",
      "[Epoch 4/200] [Batch 22/169] [D loss: 0.609289] [G loss: 0.803234]\n",
      "[Epoch 4/200] [Batch 23/169] [D loss: 0.599486] [G loss: 0.822978]\n",
      "[Epoch 4/200] [Batch 24/169] [D loss: 0.595802] [G loss: 0.836720]\n",
      "[Epoch 4/200] [Batch 25/169] [D loss: 0.580745] [G loss: 0.808753]\n",
      "[Epoch 4/200] [Batch 26/169] [D loss: 0.633805] [G loss: 0.844321]\n",
      "[Epoch 4/200] [Batch 27/169] [D loss: 0.639555] [G loss: 0.811882]\n",
      "[Epoch 4/200] [Batch 28/169] [D loss: 0.585793] [G loss: 0.866838]\n",
      "[Epoch 4/200] [Batch 29/169] [D loss: 0.633223] [G loss: 0.848098]\n",
      "[Epoch 4/200] [Batch 30/169] [D loss: 0.607254] [G loss: 0.906020]\n",
      "[Epoch 4/200] [Batch 31/169] [D loss: 0.632752] [G loss: 0.868720]\n",
      "[Epoch 4/200] [Batch 32/169] [D loss: 0.579402] [G loss: 0.897514]\n",
      "[Epoch 4/200] [Batch 33/169] [D loss: 0.614211] [G loss: 0.868788]\n",
      "[Epoch 4/200] [Batch 34/169] [D loss: 0.611870] [G loss: 0.822514]\n",
      "[Epoch 4/200] [Batch 35/169] [D loss: 0.601730] [G loss: 0.813588]\n",
      "[Epoch 4/200] [Batch 36/169] [D loss: 0.621193] [G loss: 0.748758]\n",
      "[Epoch 4/200] [Batch 37/169] [D loss: 0.633934] [G loss: 0.752782]\n",
      "[Epoch 4/200] [Batch 38/169] [D loss: 0.637087] [G loss: 0.722085]\n",
      "[Epoch 4/200] [Batch 39/169] [D loss: 0.650176] [G loss: 0.667225]\n",
      "[Epoch 4/200] [Batch 40/169] [D loss: 0.659828] [G loss: 0.691095]\n",
      "[Epoch 4/200] [Batch 41/169] [D loss: 0.663749] [G loss: 0.691362]\n",
      "[Epoch 4/200] [Batch 42/169] [D loss: 0.678524] [G loss: 0.711614]\n",
      "[Epoch 4/200] [Batch 43/169] [D loss: 0.646384] [G loss: 0.654169]\n",
      "[Epoch 4/200] [Batch 44/169] [D loss: 0.670234] [G loss: 0.663451]\n",
      "[Epoch 4/200] [Batch 45/169] [D loss: 0.665172] [G loss: 0.643827]\n",
      "[Epoch 4/200] [Batch 46/169] [D loss: 0.673918] [G loss: 0.709656]\n",
      "[Epoch 4/200] [Batch 47/169] [D loss: 0.648717] [G loss: 0.687808]\n",
      "[Epoch 4/200] [Batch 48/169] [D loss: 0.642669] [G loss: 0.740778]\n",
      "[Epoch 4/200] [Batch 49/169] [D loss: 0.649341] [G loss: 0.776837]\n",
      "[Epoch 4/200] [Batch 50/169] [D loss: 0.672287] [G loss: 0.750123]\n",
      "[Epoch 4/200] [Batch 51/169] [D loss: 0.608446] [G loss: 0.731972]\n",
      "[Epoch 4/200] [Batch 52/169] [D loss: 0.629281] [G loss: 0.815154]\n",
      "[Epoch 4/200] [Batch 53/169] [D loss: 0.640681] [G loss: 0.867342]\n",
      "[Epoch 4/200] [Batch 54/169] [D loss: 0.653192] [G loss: 0.847721]\n",
      "[Epoch 4/200] [Batch 55/169] [D loss: 0.615335] [G loss: 0.878938]\n",
      "[Epoch 4/200] [Batch 56/169] [D loss: 0.635102] [G loss: 0.884789]\n",
      "[Epoch 4/200] [Batch 57/169] [D loss: 0.673390] [G loss: 0.817954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 58/169] [D loss: 0.655685] [G loss: 0.775841]\n",
      "[Epoch 4/200] [Batch 59/169] [D loss: 0.636831] [G loss: 0.758633]\n",
      "[Epoch 4/200] [Batch 60/169] [D loss: 0.661224] [G loss: 0.770412]\n",
      "[Epoch 4/200] [Batch 61/169] [D loss: 0.659882] [G loss: 0.741447]\n",
      "[Epoch 4/200] [Batch 62/169] [D loss: 0.656006] [G loss: 0.762901]\n",
      "[Epoch 4/200] [Batch 63/169] [D loss: 0.670444] [G loss: 0.730008]\n",
      "[Epoch 4/200] [Batch 64/169] [D loss: 0.631571] [G loss: 0.793148]\n",
      "[Epoch 4/200] [Batch 65/169] [D loss: 0.652557] [G loss: 0.741781]\n",
      "[Epoch 4/200] [Batch 66/169] [D loss: 0.626192] [G loss: 0.782827]\n",
      "[Epoch 4/200] [Batch 67/169] [D loss: 0.634559] [G loss: 0.824477]\n",
      "[Epoch 4/200] [Batch 68/169] [D loss: 0.627312] [G loss: 0.793877]\n",
      "[Epoch 4/200] [Batch 69/169] [D loss: 0.631853] [G loss: 0.819372]\n",
      "[Epoch 4/200] [Batch 70/169] [D loss: 0.633209] [G loss: 0.852706]\n",
      "[Epoch 4/200] [Batch 71/169] [D loss: 0.617790] [G loss: 0.835598]\n",
      "[Epoch 4/200] [Batch 72/169] [D loss: 0.631831] [G loss: 0.846471]\n",
      "[Epoch 4/200] [Batch 73/169] [D loss: 0.640898] [G loss: 0.826850]\n",
      "[Epoch 4/200] [Batch 74/169] [D loss: 0.609571] [G loss: 0.906846]\n",
      "[Epoch 4/200] [Batch 75/169] [D loss: 0.607318] [G loss: 0.835332]\n",
      "[Epoch 4/200] [Batch 76/169] [D loss: 0.609415] [G loss: 0.849785]\n",
      "[Epoch 4/200] [Batch 77/169] [D loss: 0.619285] [G loss: 0.881418]\n",
      "[Epoch 4/200] [Batch 78/169] [D loss: 0.601408] [G loss: 0.854299]\n",
      "[Epoch 4/200] [Batch 79/169] [D loss: 0.597506] [G loss: 0.819710]\n",
      "[Epoch 4/200] [Batch 80/169] [D loss: 0.614308] [G loss: 0.774856]\n",
      "[Epoch 4/200] [Batch 81/169] [D loss: 0.598433] [G loss: 0.798762]\n",
      "[Epoch 4/200] [Batch 82/169] [D loss: 0.620019] [G loss: 0.804883]\n",
      "[Epoch 4/200] [Batch 83/169] [D loss: 0.589156] [G loss: 0.792867]\n",
      "[Epoch 4/200] [Batch 84/169] [D loss: 0.619945] [G loss: 0.725547]\n",
      "[Epoch 4/200] [Batch 85/169] [D loss: 0.612878] [G loss: 0.751042]\n",
      "[Epoch 4/200] [Batch 86/169] [D loss: 0.622556] [G loss: 0.736012]\n",
      "[Epoch 4/200] [Batch 87/169] [D loss: 0.618950] [G loss: 0.734509]\n",
      "[Epoch 4/200] [Batch 88/169] [D loss: 0.635482] [G loss: 0.755682]\n",
      "[Epoch 4/200] [Batch 89/169] [D loss: 0.625812] [G loss: 0.742938]\n",
      "[Epoch 4/200] [Batch 90/169] [D loss: 0.621458] [G loss: 0.778123]\n",
      "[Epoch 4/200] [Batch 91/169] [D loss: 0.625124] [G loss: 0.768690]\n",
      "[Epoch 4/200] [Batch 92/169] [D loss: 0.630949] [G loss: 0.737779]\n",
      "[Epoch 4/200] [Batch 93/169] [D loss: 0.603163] [G loss: 0.809497]\n",
      "[Epoch 4/200] [Batch 94/169] [D loss: 0.630418] [G loss: 0.798173]\n",
      "[Epoch 4/200] [Batch 95/169] [D loss: 0.601693] [G loss: 0.802701]\n",
      "[Epoch 4/200] [Batch 96/169] [D loss: 0.576449] [G loss: 0.836935]\n",
      "[Epoch 4/200] [Batch 97/169] [D loss: 0.574148] [G loss: 0.856142]\n",
      "[Epoch 4/200] [Batch 98/169] [D loss: 0.591991] [G loss: 0.824313]\n",
      "[Epoch 4/200] [Batch 99/169] [D loss: 0.587195] [G loss: 0.870224]\n",
      "[Epoch 4/200] [Batch 100/169] [D loss: 0.602960] [G loss: 0.890094]\n",
      "[Epoch 4/200] [Batch 101/169] [D loss: 0.596912] [G loss: 0.852726]\n",
      "[Epoch 4/200] [Batch 102/169] [D loss: 0.590949] [G loss: 0.822106]\n",
      "[Epoch 4/200] [Batch 103/169] [D loss: 0.627366] [G loss: 0.787892]\n",
      "[Epoch 4/200] [Batch 104/169] [D loss: 0.645599] [G loss: 0.746858]\n",
      "[Epoch 4/200] [Batch 105/169] [D loss: 0.646249] [G loss: 0.776058]\n",
      "[Epoch 4/200] [Batch 106/169] [D loss: 0.645572] [G loss: 0.731914]\n",
      "[Epoch 4/200] [Batch 107/169] [D loss: 0.701902] [G loss: 0.744754]\n",
      "[Epoch 4/200] [Batch 108/169] [D loss: 0.688311] [G loss: 0.666601]\n",
      "[Epoch 4/200] [Batch 109/169] [D loss: 0.677151] [G loss: 0.670297]\n",
      "[Epoch 4/200] [Batch 110/169] [D loss: 0.706207] [G loss: 0.715312]\n",
      "[Epoch 4/200] [Batch 111/169] [D loss: 0.694857] [G loss: 0.729520]\n",
      "[Epoch 4/200] [Batch 112/169] [D loss: 0.656479] [G loss: 0.795460]\n",
      "[Epoch 4/200] [Batch 113/169] [D loss: 0.678574] [G loss: 0.766342]\n",
      "[Epoch 4/200] [Batch 114/169] [D loss: 0.670624] [G loss: 0.827572]\n",
      "[Epoch 4/200] [Batch 115/169] [D loss: 0.619654] [G loss: 0.828288]\n",
      "[Epoch 4/200] [Batch 116/169] [D loss: 0.615059] [G loss: 0.843856]\n",
      "[Epoch 4/200] [Batch 117/169] [D loss: 0.608311] [G loss: 0.843054]\n",
      "[Epoch 4/200] [Batch 118/169] [D loss: 0.640911] [G loss: 0.799931]\n",
      "[Epoch 4/200] [Batch 119/169] [D loss: 0.674550] [G loss: 0.769106]\n",
      "[Epoch 4/200] [Batch 120/169] [D loss: 0.655505] [G loss: 0.697318]\n",
      "[Epoch 4/200] [Batch 121/169] [D loss: 0.634436] [G loss: 0.749479]\n",
      "[Epoch 4/200] [Batch 122/169] [D loss: 0.637026] [G loss: 0.726037]\n",
      "[Epoch 4/200] [Batch 123/169] [D loss: 0.631845] [G loss: 0.711473]\n",
      "[Epoch 4/200] [Batch 124/169] [D loss: 0.656568] [G loss: 0.685879]\n",
      "[Epoch 4/200] [Batch 125/169] [D loss: 0.655861] [G loss: 0.699016]\n",
      "[Epoch 4/200] [Batch 126/169] [D loss: 0.664476] [G loss: 0.700885]\n",
      "[Epoch 4/200] [Batch 127/169] [D loss: 0.673151] [G loss: 0.746011]\n",
      "[Epoch 4/200] [Batch 128/169] [D loss: 0.674403] [G loss: 0.749731]\n",
      "[Epoch 4/200] [Batch 129/169] [D loss: 0.677628] [G loss: 0.723106]\n",
      "[Epoch 4/200] [Batch 130/169] [D loss: 0.671626] [G loss: 0.747854]\n",
      "[Epoch 4/200] [Batch 131/169] [D loss: 0.652694] [G loss: 0.789082]\n",
      "[Epoch 4/200] [Batch 132/169] [D loss: 0.621736] [G loss: 0.792083]\n",
      "[Epoch 4/200] [Batch 133/169] [D loss: 0.641239] [G loss: 0.797557]\n",
      "[Epoch 4/200] [Batch 134/169] [D loss: 0.675725] [G loss: 0.808676]\n",
      "[Epoch 4/200] [Batch 135/169] [D loss: 0.680743] [G loss: 0.783186]\n",
      "[Epoch 4/200] [Batch 136/169] [D loss: 0.651722] [G loss: 0.745039]\n",
      "[Epoch 4/200] [Batch 137/169] [D loss: 0.656847] [G loss: 0.849153]\n",
      "[Epoch 4/200] [Batch 138/169] [D loss: 0.645850] [G loss: 0.850088]\n",
      "[Epoch 4/200] [Batch 139/169] [D loss: 0.625835] [G loss: 0.907319]\n",
      "[Epoch 4/200] [Batch 140/169] [D loss: 0.605775] [G loss: 0.880799]\n",
      "[Epoch 4/200] [Batch 141/169] [D loss: 0.605864] [G loss: 0.898125]\n",
      "[Epoch 4/200] [Batch 142/169] [D loss: 0.623082] [G loss: 0.879939]\n",
      "[Epoch 4/200] [Batch 143/169] [D loss: 0.600364] [G loss: 0.835710]\n",
      "[Epoch 4/200] [Batch 144/169] [D loss: 0.623691] [G loss: 0.789003]\n",
      "[Epoch 4/200] [Batch 145/169] [D loss: 0.642028] [G loss: 0.799641]\n",
      "[Epoch 4/200] [Batch 146/169] [D loss: 0.637654] [G loss: 0.739773]\n",
      "[Epoch 4/200] [Batch 147/169] [D loss: 0.621713] [G loss: 0.770070]\n",
      "[Epoch 4/200] [Batch 148/169] [D loss: 0.642650] [G loss: 0.712532]\n",
      "[Epoch 4/200] [Batch 149/169] [D loss: 0.662951] [G loss: 0.755697]\n",
      "[Epoch 4/200] [Batch 150/169] [D loss: 0.634616] [G loss: 0.760755]\n",
      "[Epoch 4/200] [Batch 151/169] [D loss: 0.624661] [G loss: 0.781913]\n",
      "[Epoch 4/200] [Batch 152/169] [D loss: 0.618633] [G loss: 0.787021]\n",
      "[Epoch 4/200] [Batch 153/169] [D loss: 0.621614] [G loss: 0.778946]\n",
      "[Epoch 4/200] [Batch 154/169] [D loss: 0.625320] [G loss: 0.766135]\n",
      "[Epoch 4/200] [Batch 155/169] [D loss: 0.627642] [G loss: 0.775827]\n",
      "[Epoch 4/200] [Batch 156/169] [D loss: 0.631425] [G loss: 0.754405]\n",
      "[Epoch 4/200] [Batch 157/169] [D loss: 0.631038] [G loss: 0.759785]\n",
      "[Epoch 4/200] [Batch 158/169] [D loss: 0.634269] [G loss: 0.778904]\n",
      "[Epoch 4/200] [Batch 159/169] [D loss: 0.648070] [G loss: 0.820806]\n",
      "[Epoch 4/200] [Batch 160/169] [D loss: 0.649225] [G loss: 0.802882]\n",
      "[Epoch 4/200] [Batch 161/169] [D loss: 0.674094] [G loss: 0.801924]\n",
      "[Epoch 4/200] [Batch 162/169] [D loss: 0.645487] [G loss: 0.841411]\n",
      "[Epoch 4/200] [Batch 163/169] [D loss: 0.603388] [G loss: 0.951522]\n",
      "[Epoch 4/200] [Batch 164/169] [D loss: 0.606723] [G loss: 0.975666]\n",
      "[Epoch 4/200] [Batch 165/169] [D loss: 0.600786] [G loss: 0.935925]\n",
      "[Epoch 4/200] [Batch 166/169] [D loss: 0.610979] [G loss: 0.779191]\n",
      "[Epoch 4/200] [Batch 167/169] [D loss: 0.710282] [G loss: 0.654765]\n",
      "[Epoch 4/200] [Batch 168/169] [D loss: 0.723744] [G loss: 0.622900]\n",
      "[Epoch 5/200] [Batch 0/169] [D loss: 0.749925] [G loss: 0.657987]\n",
      "[Epoch 5/200] [Batch 1/169] [D loss: 0.733397] [G loss: 0.699445]\n",
      "[Epoch 5/200] [Batch 2/169] [D loss: 0.713882] [G loss: 0.795646]\n",
      "[Epoch 5/200] [Batch 3/169] [D loss: 0.675765] [G loss: 0.897936]\n",
      "[Epoch 5/200] [Batch 4/169] [D loss: 0.675685] [G loss: 0.889751]\n",
      "[Epoch 5/200] [Batch 5/169] [D loss: 0.635935] [G loss: 0.925735]\n",
      "[Epoch 5/200] [Batch 6/169] [D loss: 0.622469] [G loss: 0.925918]\n",
      "[Epoch 5/200] [Batch 7/169] [D loss: 0.654700] [G loss: 0.863329]\n",
      "[Epoch 5/200] [Batch 8/169] [D loss: 0.628918] [G loss: 0.711161]\n",
      "[Epoch 5/200] [Batch 9/169] [D loss: 0.638196] [G loss: 0.701910]\n",
      "[Epoch 5/200] [Batch 10/169] [D loss: 0.613445] [G loss: 0.702991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 11/169] [D loss: 0.655286] [G loss: 0.736035]\n",
      "[Epoch 5/200] [Batch 12/169] [D loss: 0.636611] [G loss: 0.793384]\n",
      "[Epoch 5/200] [Batch 13/169] [D loss: 0.656544] [G loss: 0.836149]\n",
      "[Epoch 5/200] [Batch 14/169] [D loss: 0.641268] [G loss: 0.854187]\n",
      "[Epoch 5/200] [Batch 15/169] [D loss: 0.619646] [G loss: 0.922177]\n",
      "[Epoch 5/200] [Batch 16/169] [D loss: 0.615407] [G loss: 0.869686]\n",
      "[Epoch 5/200] [Batch 17/169] [D loss: 0.625631] [G loss: 0.821308]\n",
      "[Epoch 5/200] [Batch 18/169] [D loss: 0.647607] [G loss: 0.847617]\n",
      "[Epoch 5/200] [Batch 19/169] [D loss: 0.663635] [G loss: 0.821513]\n",
      "[Epoch 5/200] [Batch 20/169] [D loss: 0.632540] [G loss: 0.843163]\n",
      "[Epoch 5/200] [Batch 21/169] [D loss: 0.676299] [G loss: 0.900555]\n",
      "[Epoch 5/200] [Batch 22/169] [D loss: 0.644747] [G loss: 0.872000]\n",
      "[Epoch 5/200] [Batch 23/169] [D loss: 0.667071] [G loss: 0.858055]\n",
      "[Epoch 5/200] [Batch 24/169] [D loss: 0.658692] [G loss: 0.916586]\n",
      "[Epoch 5/200] [Batch 25/169] [D loss: 0.663755] [G loss: 0.894692]\n",
      "[Epoch 5/200] [Batch 26/169] [D loss: 0.628762] [G loss: 0.865571]\n",
      "[Epoch 5/200] [Batch 27/169] [D loss: 0.663223] [G loss: 0.902690]\n",
      "[Epoch 5/200] [Batch 28/169] [D loss: 0.627258] [G loss: 0.853477]\n",
      "[Epoch 5/200] [Batch 29/169] [D loss: 0.616734] [G loss: 0.918635]\n",
      "[Epoch 5/200] [Batch 30/169] [D loss: 0.607237] [G loss: 0.873541]\n",
      "[Epoch 5/200] [Batch 31/169] [D loss: 0.612435] [G loss: 0.963927]\n",
      "[Epoch 5/200] [Batch 32/169] [D loss: 0.569385] [G loss: 0.860656]\n",
      "[Epoch 5/200] [Batch 33/169] [D loss: 0.604508] [G loss: 0.891805]\n",
      "[Epoch 5/200] [Batch 34/169] [D loss: 0.627567] [G loss: 0.851335]\n",
      "[Epoch 5/200] [Batch 35/169] [D loss: 0.576410] [G loss: 0.795999]\n",
      "[Epoch 5/200] [Batch 36/169] [D loss: 0.612169] [G loss: 0.801819]\n",
      "[Epoch 5/200] [Batch 37/169] [D loss: 0.624857] [G loss: 0.823833]\n",
      "[Epoch 5/200] [Batch 38/169] [D loss: 0.627803] [G loss: 0.791461]\n",
      "[Epoch 5/200] [Batch 39/169] [D loss: 0.637972] [G loss: 0.738059]\n",
      "[Epoch 5/200] [Batch 40/169] [D loss: 0.617079] [G loss: 0.779639]\n",
      "[Epoch 5/200] [Batch 41/169] [D loss: 0.634383] [G loss: 0.807386]\n",
      "[Epoch 5/200] [Batch 42/169] [D loss: 0.647634] [G loss: 0.767140]\n",
      "[Epoch 5/200] [Batch 43/169] [D loss: 0.709404] [G loss: 0.683340]\n",
      "[Epoch 5/200] [Batch 44/169] [D loss: 0.658225] [G loss: 0.681204]\n",
      "[Epoch 5/200] [Batch 45/169] [D loss: 0.697515] [G loss: 0.680977]\n",
      "[Epoch 5/200] [Batch 46/169] [D loss: 0.685328] [G loss: 0.686087]\n",
      "[Epoch 5/200] [Batch 47/169] [D loss: 0.743006] [G loss: 0.697702]\n",
      "[Epoch 5/200] [Batch 48/169] [D loss: 0.680136] [G loss: 0.641632]\n",
      "[Epoch 5/200] [Batch 49/169] [D loss: 0.707090] [G loss: 0.722338]\n",
      "[Epoch 5/200] [Batch 50/169] [D loss: 0.683239] [G loss: 0.683572]\n",
      "[Epoch 5/200] [Batch 51/169] [D loss: 0.657792] [G loss: 0.699097]\n",
      "[Epoch 5/200] [Batch 52/169] [D loss: 0.649893] [G loss: 0.704803]\n",
      "[Epoch 5/200] [Batch 53/169] [D loss: 0.658114] [G loss: 0.715254]\n",
      "[Epoch 5/200] [Batch 54/169] [D loss: 0.662534] [G loss: 0.682486]\n",
      "[Epoch 5/200] [Batch 55/169] [D loss: 0.654680] [G loss: 0.683797]\n",
      "[Epoch 5/200] [Batch 56/169] [D loss: 0.657008] [G loss: 0.685239]\n",
      "[Epoch 5/200] [Batch 57/169] [D loss: 0.661295] [G loss: 0.704586]\n",
      "[Epoch 5/200] [Batch 58/169] [D loss: 0.653307] [G loss: 0.671417]\n",
      "[Epoch 5/200] [Batch 59/169] [D loss: 0.678988] [G loss: 0.672977]\n",
      "[Epoch 5/200] [Batch 60/169] [D loss: 0.637426] [G loss: 0.715363]\n",
      "[Epoch 5/200] [Batch 61/169] [D loss: 0.644562] [G loss: 0.678838]\n",
      "[Epoch 5/200] [Batch 62/169] [D loss: 0.654735] [G loss: 0.697387]\n",
      "[Epoch 5/200] [Batch 63/169] [D loss: 0.666259] [G loss: 0.700877]\n",
      "[Epoch 5/200] [Batch 64/169] [D loss: 0.674652] [G loss: 0.717245]\n",
      "[Epoch 5/200] [Batch 65/169] [D loss: 0.663800] [G loss: 0.704264]\n",
      "[Epoch 5/200] [Batch 66/169] [D loss: 0.677477] [G loss: 0.692111]\n",
      "[Epoch 5/200] [Batch 67/169] [D loss: 0.638212] [G loss: 0.720120]\n",
      "[Epoch 5/200] [Batch 68/169] [D loss: 0.667780] [G loss: 0.746833]\n",
      "[Epoch 5/200] [Batch 69/169] [D loss: 0.667527] [G loss: 0.676839]\n",
      "[Epoch 5/200] [Batch 70/169] [D loss: 0.703073] [G loss: 0.706847]\n",
      "[Epoch 5/200] [Batch 71/169] [D loss: 0.677166] [G loss: 0.726803]\n",
      "[Epoch 5/200] [Batch 72/169] [D loss: 0.681185] [G loss: 0.780708]\n",
      "[Epoch 5/200] [Batch 73/169] [D loss: 0.708978] [G loss: 0.744540]\n",
      "[Epoch 5/200] [Batch 74/169] [D loss: 0.687728] [G loss: 0.751730]\n",
      "[Epoch 5/200] [Batch 75/169] [D loss: 0.690265] [G loss: 0.793192]\n",
      "[Epoch 5/200] [Batch 76/169] [D loss: 0.695457] [G loss: 0.823813]\n",
      "[Epoch 5/200] [Batch 77/169] [D loss: 0.664457] [G loss: 0.844948]\n",
      "[Epoch 5/200] [Batch 78/169] [D loss: 0.662498] [G loss: 0.825094]\n",
      "[Epoch 5/200] [Batch 79/169] [D loss: 0.668633] [G loss: 0.879516]\n",
      "[Epoch 5/200] [Batch 80/169] [D loss: 0.660687] [G loss: 0.882402]\n",
      "[Epoch 5/200] [Batch 81/169] [D loss: 0.661055] [G loss: 0.845100]\n",
      "[Epoch 5/200] [Batch 82/169] [D loss: 0.627599] [G loss: 0.885046]\n",
      "[Epoch 5/200] [Batch 83/169] [D loss: 0.613667] [G loss: 0.910264]\n",
      "[Epoch 5/200] [Batch 84/169] [D loss: 0.652291] [G loss: 0.905614]\n",
      "[Epoch 5/200] [Batch 85/169] [D loss: 0.634007] [G loss: 0.898430]\n",
      "[Epoch 5/200] [Batch 86/169] [D loss: 0.635199] [G loss: 0.941920]\n",
      "[Epoch 5/200] [Batch 87/169] [D loss: 0.663525] [G loss: 0.858944]\n",
      "[Epoch 5/200] [Batch 88/169] [D loss: 0.633636] [G loss: 0.805939]\n",
      "[Epoch 5/200] [Batch 89/169] [D loss: 0.645259] [G loss: 0.847806]\n",
      "[Epoch 5/200] [Batch 90/169] [D loss: 0.657224] [G loss: 0.782060]\n",
      "[Epoch 5/200] [Batch 91/169] [D loss: 0.646285] [G loss: 0.743276]\n",
      "[Epoch 5/200] [Batch 92/169] [D loss: 0.654330] [G loss: 0.803079]\n",
      "[Epoch 5/200] [Batch 93/169] [D loss: 0.687895] [G loss: 0.790255]\n",
      "[Epoch 5/200] [Batch 94/169] [D loss: 0.654374] [G loss: 0.752307]\n",
      "[Epoch 5/200] [Batch 95/169] [D loss: 0.656938] [G loss: 0.796023]\n",
      "[Epoch 5/200] [Batch 96/169] [D loss: 0.640041] [G loss: 0.777360]\n",
      "[Epoch 5/200] [Batch 97/169] [D loss: 0.656101] [G loss: 0.761341]\n",
      "[Epoch 5/200] [Batch 98/169] [D loss: 0.627317] [G loss: 0.725516]\n",
      "[Epoch 5/200] [Batch 99/169] [D loss: 0.640872] [G loss: 0.778096]\n",
      "[Epoch 5/200] [Batch 100/169] [D loss: 0.667922] [G loss: 0.741729]\n",
      "[Epoch 5/200] [Batch 101/169] [D loss: 0.622770] [G loss: 0.766360]\n",
      "[Epoch 5/200] [Batch 102/169] [D loss: 0.636867] [G loss: 0.765200]\n",
      "[Epoch 5/200] [Batch 103/169] [D loss: 0.649847] [G loss: 0.752375]\n",
      "[Epoch 5/200] [Batch 104/169] [D loss: 0.653711] [G loss: 0.754122]\n",
      "[Epoch 5/200] [Batch 105/169] [D loss: 0.641784] [G loss: 0.793156]\n",
      "[Epoch 5/200] [Batch 106/169] [D loss: 0.671241] [G loss: 0.775696]\n",
      "[Epoch 5/200] [Batch 107/169] [D loss: 0.637952] [G loss: 0.783995]\n",
      "[Epoch 5/200] [Batch 108/169] [D loss: 0.628467] [G loss: 0.789977]\n",
      "[Epoch 5/200] [Batch 109/169] [D loss: 0.672133] [G loss: 0.735051]\n",
      "[Epoch 5/200] [Batch 110/169] [D loss: 0.673795] [G loss: 0.733053]\n",
      "[Epoch 5/200] [Batch 111/169] [D loss: 0.662773] [G loss: 0.758480]\n",
      "[Epoch 5/200] [Batch 112/169] [D loss: 0.641270] [G loss: 0.763211]\n",
      "[Epoch 5/200] [Batch 113/169] [D loss: 0.639321] [G loss: 0.754462]\n",
      "[Epoch 5/200] [Batch 114/169] [D loss: 0.645454] [G loss: 0.740195]\n",
      "[Epoch 5/200] [Batch 115/169] [D loss: 0.632026] [G loss: 0.742262]\n",
      "[Epoch 5/200] [Batch 116/169] [D loss: 0.645576] [G loss: 0.740016]\n",
      "[Epoch 5/200] [Batch 117/169] [D loss: 0.645196] [G loss: 0.717475]\n",
      "[Epoch 5/200] [Batch 118/169] [D loss: 0.656638] [G loss: 0.720111]\n",
      "[Epoch 5/200] [Batch 119/169] [D loss: 0.648965] [G loss: 0.759178]\n",
      "[Epoch 5/200] [Batch 120/169] [D loss: 0.643812] [G loss: 0.718540]\n",
      "[Epoch 5/200] [Batch 121/169] [D loss: 0.619204] [G loss: 0.754983]\n",
      "[Epoch 5/200] [Batch 122/169] [D loss: 0.643428] [G loss: 0.720475]\n",
      "[Epoch 5/200] [Batch 123/169] [D loss: 0.656901] [G loss: 0.718978]\n",
      "[Epoch 5/200] [Batch 124/169] [D loss: 0.618666] [G loss: 0.742010]\n",
      "[Epoch 5/200] [Batch 125/169] [D loss: 0.643533] [G loss: 0.757139]\n",
      "[Epoch 5/200] [Batch 126/169] [D loss: 0.620190] [G loss: 0.771525]\n",
      "[Epoch 5/200] [Batch 127/169] [D loss: 0.641515] [G loss: 0.774131]\n",
      "[Epoch 5/200] [Batch 128/169] [D loss: 0.632848] [G loss: 0.791347]\n",
      "[Epoch 5/200] [Batch 129/169] [D loss: 0.616259] [G loss: 0.835560]\n",
      "[Epoch 5/200] [Batch 130/169] [D loss: 0.634077] [G loss: 0.791694]\n",
      "[Epoch 5/200] [Batch 131/169] [D loss: 0.611450] [G loss: 0.802156]\n",
      "[Epoch 5/200] [Batch 132/169] [D loss: 0.641502] [G loss: 0.761935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 133/169] [D loss: 0.612245] [G loss: 0.794986]\n",
      "[Epoch 5/200] [Batch 134/169] [D loss: 0.631843] [G loss: 0.752871]\n",
      "[Epoch 5/200] [Batch 135/169] [D loss: 0.657699] [G loss: 0.758814]\n",
      "[Epoch 5/200] [Batch 136/169] [D loss: 0.624873] [G loss: 0.795502]\n",
      "[Epoch 5/200] [Batch 137/169] [D loss: 0.632072] [G loss: 0.746931]\n",
      "[Epoch 5/200] [Batch 138/169] [D loss: 0.675227] [G loss: 0.768559]\n",
      "[Epoch 5/200] [Batch 139/169] [D loss: 0.670431] [G loss: 0.724792]\n",
      "[Epoch 5/200] [Batch 140/169] [D loss: 0.688181] [G loss: 0.739296]\n",
      "[Epoch 5/200] [Batch 141/169] [D loss: 0.647177] [G loss: 0.715987]\n",
      "[Epoch 5/200] [Batch 142/169] [D loss: 0.668974] [G loss: 0.714971]\n",
      "[Epoch 5/200] [Batch 143/169] [D loss: 0.695974] [G loss: 0.708941]\n",
      "[Epoch 5/200] [Batch 144/169] [D loss: 0.698225] [G loss: 0.723537]\n",
      "[Epoch 5/200] [Batch 145/169] [D loss: 0.687589] [G loss: 0.720933]\n",
      "[Epoch 5/200] [Batch 146/169] [D loss: 0.701587] [G loss: 0.759092]\n",
      "[Epoch 5/200] [Batch 147/169] [D loss: 0.686089] [G loss: 0.740885]\n",
      "[Epoch 5/200] [Batch 148/169] [D loss: 0.704008] [G loss: 0.764207]\n",
      "[Epoch 5/200] [Batch 149/169] [D loss: 0.706631] [G loss: 0.747430]\n",
      "[Epoch 5/200] [Batch 150/169] [D loss: 0.672588] [G loss: 0.751222]\n",
      "[Epoch 5/200] [Batch 151/169] [D loss: 0.659927] [G loss: 0.768159]\n",
      "[Epoch 5/200] [Batch 152/169] [D loss: 0.657783] [G loss: 0.786881]\n",
      "[Epoch 5/200] [Batch 153/169] [D loss: 0.674379] [G loss: 0.744257]\n",
      "[Epoch 5/200] [Batch 154/169] [D loss: 0.641753] [G loss: 0.744311]\n",
      "[Epoch 5/200] [Batch 155/169] [D loss: 0.672611] [G loss: 0.755118]\n",
      "[Epoch 5/200] [Batch 156/169] [D loss: 0.639390] [G loss: 0.805564]\n",
      "[Epoch 5/200] [Batch 157/169] [D loss: 0.629452] [G loss: 0.837293]\n",
      "[Epoch 5/200] [Batch 158/169] [D loss: 0.622220] [G loss: 0.814429]\n",
      "[Epoch 5/200] [Batch 159/169] [D loss: 0.623497] [G loss: 0.792978]\n",
      "[Epoch 5/200] [Batch 160/169] [D loss: 0.621891] [G loss: 0.829672]\n",
      "[Epoch 5/200] [Batch 161/169] [D loss: 0.610216] [G loss: 0.800280]\n",
      "[Epoch 5/200] [Batch 162/169] [D loss: 0.618370] [G loss: 0.823524]\n",
      "[Epoch 5/200] [Batch 163/169] [D loss: 0.623803] [G loss: 0.847611]\n",
      "[Epoch 5/200] [Batch 164/169] [D loss: 0.613272] [G loss: 0.833301]\n",
      "[Epoch 5/200] [Batch 165/169] [D loss: 0.628937] [G loss: 0.860754]\n",
      "[Epoch 5/200] [Batch 166/169] [D loss: 0.603630] [G loss: 0.833661]\n",
      "[Epoch 5/200] [Batch 167/169] [D loss: 0.630712] [G loss: 0.823031]\n",
      "[Epoch 5/200] [Batch 168/169] [D loss: 0.626366] [G loss: 0.803948]\n",
      "[Epoch 6/200] [Batch 0/169] [D loss: 0.617085] [G loss: 0.913196]\n",
      "[Epoch 6/200] [Batch 1/169] [D loss: 0.619750] [G loss: 0.841666]\n",
      "[Epoch 6/200] [Batch 2/169] [D loss: 0.633720] [G loss: 0.821254]\n",
      "[Epoch 6/200] [Batch 3/169] [D loss: 0.633219] [G loss: 0.804314]\n",
      "[Epoch 6/200] [Batch 4/169] [D loss: 0.617003] [G loss: 0.819238]\n",
      "[Epoch 6/200] [Batch 5/169] [D loss: 0.629386] [G loss: 0.753707]\n",
      "[Epoch 6/200] [Batch 6/169] [D loss: 0.654973] [G loss: 0.767296]\n",
      "[Epoch 6/200] [Batch 7/169] [D loss: 0.639874] [G loss: 0.761223]\n",
      "[Epoch 6/200] [Batch 8/169] [D loss: 0.630810] [G loss: 0.801115]\n",
      "[Epoch 6/200] [Batch 9/169] [D loss: 0.633630] [G loss: 0.790048]\n",
      "[Epoch 6/200] [Batch 10/169] [D loss: 0.626877] [G loss: 0.790391]\n",
      "[Epoch 6/200] [Batch 11/169] [D loss: 0.619859] [G loss: 0.786243]\n",
      "[Epoch 6/200] [Batch 12/169] [D loss: 0.614582] [G loss: 0.774690]\n",
      "[Epoch 6/200] [Batch 13/169] [D loss: 0.634248] [G loss: 0.752142]\n",
      "[Epoch 6/200] [Batch 14/169] [D loss: 0.640395] [G loss: 0.722257]\n",
      "[Epoch 6/200] [Batch 15/169] [D loss: 0.673259] [G loss: 0.710719]\n",
      "[Epoch 6/200] [Batch 16/169] [D loss: 0.656431] [G loss: 0.672566]\n",
      "[Epoch 6/200] [Batch 17/169] [D loss: 0.648940] [G loss: 0.723412]\n",
      "[Epoch 6/200] [Batch 18/169] [D loss: 0.671461] [G loss: 0.718942]\n",
      "[Epoch 6/200] [Batch 19/169] [D loss: 0.631727] [G loss: 0.806204]\n",
      "[Epoch 6/200] [Batch 20/169] [D loss: 0.593336] [G loss: 0.827260]\n",
      "[Epoch 6/200] [Batch 21/169] [D loss: 0.553882] [G loss: 0.830702]\n",
      "[Epoch 6/200] [Batch 22/169] [D loss: 0.531542] [G loss: 0.797520]\n",
      "[Epoch 6/200] [Batch 23/169] [D loss: 0.540867] [G loss: 0.801092]\n",
      "[Epoch 6/200] [Batch 24/169] [D loss: 0.575548] [G loss: 0.792104]\n",
      "[Epoch 6/200] [Batch 25/169] [D loss: 0.598403] [G loss: 0.707195]\n",
      "[Epoch 6/200] [Batch 26/169] [D loss: 0.610865] [G loss: 0.703019]\n",
      "[Epoch 6/200] [Batch 27/169] [D loss: 0.609475] [G loss: 0.712822]\n",
      "[Epoch 6/200] [Batch 28/169] [D loss: 0.620952] [G loss: 0.721812]\n",
      "[Epoch 6/200] [Batch 29/169] [D loss: 0.628023] [G loss: 0.708753]\n",
      "[Epoch 6/200] [Batch 30/169] [D loss: 0.651194] [G loss: 0.713104]\n",
      "[Epoch 6/200] [Batch 31/169] [D loss: 0.653165] [G loss: 0.741341]\n",
      "[Epoch 6/200] [Batch 32/169] [D loss: 0.669743] [G loss: 0.776799]\n",
      "[Epoch 6/200] [Batch 33/169] [D loss: 0.645371] [G loss: 0.805654]\n",
      "[Epoch 6/200] [Batch 34/169] [D loss: 0.656148] [G loss: 0.820025]\n",
      "[Epoch 6/200] [Batch 35/169] [D loss: 0.638467] [G loss: 0.868432]\n",
      "[Epoch 6/200] [Batch 36/169] [D loss: 0.628856] [G loss: 0.877303]\n",
      "[Epoch 6/200] [Batch 37/169] [D loss: 0.645565] [G loss: 0.845498]\n",
      "[Epoch 6/200] [Batch 38/169] [D loss: 0.637774] [G loss: 0.878758]\n",
      "[Epoch 6/200] [Batch 39/169] [D loss: 0.651745] [G loss: 0.849713]\n",
      "[Epoch 6/200] [Batch 40/169] [D loss: 0.632831] [G loss: 0.784381]\n",
      "[Epoch 6/200] [Batch 41/169] [D loss: 0.662351] [G loss: 0.802587]\n",
      "[Epoch 6/200] [Batch 42/169] [D loss: 0.665442] [G loss: 0.771573]\n",
      "[Epoch 6/200] [Batch 43/169] [D loss: 0.671845] [G loss: 0.797708]\n",
      "[Epoch 6/200] [Batch 44/169] [D loss: 0.668851] [G loss: 0.802007]\n",
      "[Epoch 6/200] [Batch 45/169] [D loss: 0.677438] [G loss: 0.778822]\n",
      "[Epoch 6/200] [Batch 46/169] [D loss: 0.646938] [G loss: 0.800294]\n",
      "[Epoch 6/200] [Batch 47/169] [D loss: 0.681248] [G loss: 0.793805]\n",
      "[Epoch 6/200] [Batch 48/169] [D loss: 0.653115] [G loss: 0.799698]\n",
      "[Epoch 6/200] [Batch 49/169] [D loss: 0.658696] [G loss: 0.876885]\n",
      "[Epoch 6/200] [Batch 50/169] [D loss: 0.665674] [G loss: 0.830581]\n",
      "[Epoch 6/200] [Batch 51/169] [D loss: 0.666546] [G loss: 0.851884]\n",
      "[Epoch 6/200] [Batch 52/169] [D loss: 0.667987] [G loss: 0.914040]\n",
      "[Epoch 6/200] [Batch 53/169] [D loss: 0.691044] [G loss: 0.840157]\n",
      "[Epoch 6/200] [Batch 54/169] [D loss: 0.665285] [G loss: 0.831968]\n",
      "[Epoch 6/200] [Batch 55/169] [D loss: 0.676132] [G loss: 0.783638]\n",
      "[Epoch 6/200] [Batch 56/169] [D loss: 0.647226] [G loss: 0.783276]\n",
      "[Epoch 6/200] [Batch 57/169] [D loss: 0.658248] [G loss: 0.793596]\n",
      "[Epoch 6/200] [Batch 58/169] [D loss: 0.661693] [G loss: 0.780569]\n",
      "[Epoch 6/200] [Batch 59/169] [D loss: 0.667270] [G loss: 0.787640]\n",
      "[Epoch 6/200] [Batch 60/169] [D loss: 0.663641] [G loss: 0.776833]\n",
      "[Epoch 6/200] [Batch 61/169] [D loss: 0.675536] [G loss: 0.838348]\n",
      "[Epoch 6/200] [Batch 62/169] [D loss: 0.642210] [G loss: 0.817152]\n",
      "[Epoch 6/200] [Batch 63/169] [D loss: 0.680068] [G loss: 0.776967]\n",
      "[Epoch 6/200] [Batch 64/169] [D loss: 0.673414] [G loss: 0.778836]\n",
      "[Epoch 6/200] [Batch 65/169] [D loss: 0.669446] [G loss: 0.773667]\n",
      "[Epoch 6/200] [Batch 66/169] [D loss: 0.658317] [G loss: 0.761303]\n",
      "[Epoch 6/200] [Batch 67/169] [D loss: 0.672508] [G loss: 0.724878]\n",
      "[Epoch 6/200] [Batch 68/169] [D loss: 0.659431] [G loss: 0.756041]\n",
      "[Epoch 6/200] [Batch 69/169] [D loss: 0.663297] [G loss: 0.703296]\n",
      "[Epoch 6/200] [Batch 70/169] [D loss: 0.636226] [G loss: 0.751505]\n",
      "[Epoch 6/200] [Batch 71/169] [D loss: 0.679906] [G loss: 0.734979]\n",
      "[Epoch 6/200] [Batch 72/169] [D loss: 0.675489] [G loss: 0.723880]\n",
      "[Epoch 6/200] [Batch 73/169] [D loss: 0.688472] [G loss: 0.706225]\n",
      "[Epoch 6/200] [Batch 74/169] [D loss: 0.666859] [G loss: 0.712033]\n",
      "[Epoch 6/200] [Batch 75/169] [D loss: 0.666883] [G loss: 0.744884]\n",
      "[Epoch 6/200] [Batch 76/169] [D loss: 0.616914] [G loss: 0.686647]\n",
      "[Epoch 6/200] [Batch 77/169] [D loss: 0.658702] [G loss: 0.753293]\n",
      "[Epoch 6/200] [Batch 78/169] [D loss: 0.614063] [G loss: 0.790084]\n",
      "[Epoch 6/200] [Batch 79/169] [D loss: 0.616839] [G loss: 0.849591]\n",
      "[Epoch 6/200] [Batch 80/169] [D loss: 0.626146] [G loss: 0.763993]\n",
      "[Epoch 6/200] [Batch 81/169] [D loss: 0.625944] [G loss: 0.756931]\n",
      "[Epoch 6/200] [Batch 82/169] [D loss: 0.634565] [G loss: 0.729457]\n",
      "[Epoch 6/200] [Batch 83/169] [D loss: 0.636096] [G loss: 0.709732]\n",
      "[Epoch 6/200] [Batch 84/169] [D loss: 0.623302] [G loss: 0.707738]\n",
      "[Epoch 6/200] [Batch 85/169] [D loss: 0.632940] [G loss: 0.716238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 86/169] [D loss: 0.606426] [G loss: 0.713382]\n",
      "[Epoch 6/200] [Batch 87/169] [D loss: 0.621131] [G loss: 0.707749]\n",
      "[Epoch 6/200] [Batch 88/169] [D loss: 0.610752] [G loss: 0.724859]\n",
      "[Epoch 6/200] [Batch 89/169] [D loss: 0.615310] [G loss: 0.725674]\n",
      "[Epoch 6/200] [Batch 90/169] [D loss: 0.584806] [G loss: 0.729724]\n",
      "[Epoch 6/200] [Batch 91/169] [D loss: 0.609145] [G loss: 0.772632]\n",
      "[Epoch 6/200] [Batch 92/169] [D loss: 0.590099] [G loss: 0.758240]\n",
      "[Epoch 6/200] [Batch 93/169] [D loss: 0.628841] [G loss: 0.764913]\n",
      "[Epoch 6/200] [Batch 94/169] [D loss: 0.603902] [G loss: 0.759936]\n",
      "[Epoch 6/200] [Batch 95/169] [D loss: 0.626560] [G loss: 0.760883]\n",
      "[Epoch 6/200] [Batch 96/169] [D loss: 0.624295] [G loss: 0.757015]\n",
      "[Epoch 6/200] [Batch 97/169] [D loss: 0.648013] [G loss: 0.779804]\n",
      "[Epoch 6/200] [Batch 98/169] [D loss: 0.624177] [G loss: 0.771431]\n",
      "[Epoch 6/200] [Batch 99/169] [D loss: 0.639794] [G loss: 0.759268]\n",
      "[Epoch 6/200] [Batch 100/169] [D loss: 0.634613] [G loss: 0.776992]\n",
      "[Epoch 6/200] [Batch 101/169] [D loss: 0.640705] [G loss: 0.775029]\n",
      "[Epoch 6/200] [Batch 102/169] [D loss: 0.651561] [G loss: 0.811869]\n",
      "[Epoch 6/200] [Batch 103/169] [D loss: 0.627388] [G loss: 0.821706]\n",
      "[Epoch 6/200] [Batch 104/169] [D loss: 0.609431] [G loss: 0.765089]\n",
      "[Epoch 6/200] [Batch 105/169] [D loss: 0.612396] [G loss: 0.772623]\n",
      "[Epoch 6/200] [Batch 106/169] [D loss: 0.622195] [G loss: 0.784973]\n",
      "[Epoch 6/200] [Batch 107/169] [D loss: 0.616683] [G loss: 0.727377]\n",
      "[Epoch 6/200] [Batch 108/169] [D loss: 0.650184] [G loss: 0.798319]\n",
      "[Epoch 6/200] [Batch 109/169] [D loss: 0.626916] [G loss: 0.820603]\n",
      "[Epoch 6/200] [Batch 110/169] [D loss: 0.619749] [G loss: 0.736340]\n",
      "[Epoch 6/200] [Batch 111/169] [D loss: 0.642441] [G loss: 0.782522]\n",
      "[Epoch 6/200] [Batch 112/169] [D loss: 0.625152] [G loss: 0.762812]\n",
      "[Epoch 6/200] [Batch 113/169] [D loss: 0.647396] [G loss: 0.815111]\n",
      "[Epoch 6/200] [Batch 114/169] [D loss: 0.665765] [G loss: 0.816580]\n",
      "[Epoch 6/200] [Batch 115/169] [D loss: 0.664321] [G loss: 0.832351]\n",
      "[Epoch 6/200] [Batch 116/169] [D loss: 0.654578] [G loss: 0.832608]\n",
      "[Epoch 6/200] [Batch 117/169] [D loss: 0.657456] [G loss: 0.840501]\n",
      "[Epoch 6/200] [Batch 118/169] [D loss: 0.688277] [G loss: 0.819207]\n",
      "[Epoch 6/200] [Batch 119/169] [D loss: 0.674961] [G loss: 0.811838]\n",
      "[Epoch 6/200] [Batch 120/169] [D loss: 0.652226] [G loss: 0.856629]\n",
      "[Epoch 6/200] [Batch 121/169] [D loss: 0.678938] [G loss: 0.870130]\n",
      "[Epoch 6/200] [Batch 122/169] [D loss: 0.651352] [G loss: 0.864947]\n",
      "[Epoch 6/200] [Batch 123/169] [D loss: 0.648751] [G loss: 0.831972]\n",
      "[Epoch 6/200] [Batch 124/169] [D loss: 0.655883] [G loss: 0.881564]\n",
      "[Epoch 6/200] [Batch 125/169] [D loss: 0.638366] [G loss: 0.878259]\n",
      "[Epoch 6/200] [Batch 126/169] [D loss: 0.649888] [G loss: 0.854090]\n",
      "[Epoch 6/200] [Batch 127/169] [D loss: 0.633299] [G loss: 0.854161]\n",
      "[Epoch 6/200] [Batch 128/169] [D loss: 0.682501] [G loss: 0.762455]\n",
      "[Epoch 6/200] [Batch 129/169] [D loss: 0.668641] [G loss: 0.770073]\n",
      "[Epoch 6/200] [Batch 130/169] [D loss: 0.629366] [G loss: 0.814284]\n",
      "[Epoch 6/200] [Batch 131/169] [D loss: 0.649929] [G loss: 0.787794]\n",
      "[Epoch 6/200] [Batch 132/169] [D loss: 0.664612] [G loss: 0.757672]\n",
      "[Epoch 6/200] [Batch 133/169] [D loss: 0.672038] [G loss: 0.770589]\n",
      "[Epoch 6/200] [Batch 134/169] [D loss: 0.656454] [G loss: 0.775387]\n",
      "[Epoch 6/200] [Batch 135/169] [D loss: 0.686500] [G loss: 0.731465]\n",
      "[Epoch 6/200] [Batch 136/169] [D loss: 0.669155] [G loss: 0.724421]\n",
      "[Epoch 6/200] [Batch 137/169] [D loss: 0.683369] [G loss: 0.722524]\n",
      "[Epoch 6/200] [Batch 138/169] [D loss: 0.665111] [G loss: 0.758436]\n",
      "[Epoch 6/200] [Batch 139/169] [D loss: 0.641167] [G loss: 0.763856]\n",
      "[Epoch 6/200] [Batch 140/169] [D loss: 0.650510] [G loss: 0.752200]\n",
      "[Epoch 6/200] [Batch 141/169] [D loss: 0.655723] [G loss: 0.740985]\n",
      "[Epoch 6/200] [Batch 142/169] [D loss: 0.610913] [G loss: 0.766647]\n",
      "[Epoch 6/200] [Batch 143/169] [D loss: 0.622847] [G loss: 0.762437]\n",
      "[Epoch 6/200] [Batch 144/169] [D loss: 0.646594] [G loss: 0.759631]\n",
      "[Epoch 6/200] [Batch 145/169] [D loss: 0.638518] [G loss: 0.759111]\n",
      "[Epoch 6/200] [Batch 146/169] [D loss: 0.646541] [G loss: 0.792580]\n",
      "[Epoch 6/200] [Batch 147/169] [D loss: 0.655780] [G loss: 0.814233]\n",
      "[Epoch 6/200] [Batch 148/169] [D loss: 0.610625] [G loss: 0.763885]\n",
      "[Epoch 6/200] [Batch 149/169] [D loss: 0.673075] [G loss: 0.838967]\n",
      "[Epoch 6/200] [Batch 150/169] [D loss: 0.644716] [G loss: 0.798190]\n",
      "[Epoch 6/200] [Batch 151/169] [D loss: 0.654501] [G loss: 0.769790]\n",
      "[Epoch 6/200] [Batch 152/169] [D loss: 0.628369] [G loss: 0.784798]\n",
      "[Epoch 6/200] [Batch 153/169] [D loss: 0.650653] [G loss: 0.806264]\n",
      "[Epoch 6/200] [Batch 154/169] [D loss: 0.643340] [G loss: 0.801212]\n",
      "[Epoch 6/200] [Batch 155/169] [D loss: 0.604858] [G loss: 0.740484]\n",
      "[Epoch 6/200] [Batch 156/169] [D loss: 0.644119] [G loss: 0.766891]\n",
      "[Epoch 6/200] [Batch 157/169] [D loss: 0.642442] [G loss: 0.735637]\n",
      "[Epoch 6/200] [Batch 158/169] [D loss: 0.639842] [G loss: 0.761165]\n",
      "[Epoch 6/200] [Batch 159/169] [D loss: 0.647068] [G loss: 0.724815]\n",
      "[Epoch 6/200] [Batch 160/169] [D loss: 0.648488] [G loss: 0.760610]\n",
      "[Epoch 6/200] [Batch 161/169] [D loss: 0.626573] [G loss: 0.782781]\n",
      "[Epoch 6/200] [Batch 162/169] [D loss: 0.637593] [G loss: 0.767669]\n",
      "[Epoch 6/200] [Batch 163/169] [D loss: 0.616265] [G loss: 0.744661]\n",
      "[Epoch 6/200] [Batch 164/169] [D loss: 0.627110] [G loss: 0.717251]\n",
      "[Epoch 6/200] [Batch 165/169] [D loss: 0.641050] [G loss: 0.768322]\n",
      "[Epoch 6/200] [Batch 166/169] [D loss: 0.647040] [G loss: 0.759994]\n",
      "[Epoch 6/200] [Batch 167/169] [D loss: 0.643482] [G loss: 0.779324]\n",
      "[Epoch 6/200] [Batch 168/169] [D loss: 0.625262] [G loss: 0.760599]\n",
      "[Epoch 7/200] [Batch 0/169] [D loss: 0.656661] [G loss: 0.829481]\n",
      "[Epoch 7/200] [Batch 1/169] [D loss: 0.654149] [G loss: 0.787654]\n",
      "[Epoch 7/200] [Batch 2/169] [D loss: 0.643031] [G loss: 0.842507]\n",
      "[Epoch 7/200] [Batch 3/169] [D loss: 0.672188] [G loss: 0.819367]\n",
      "[Epoch 7/200] [Batch 4/169] [D loss: 0.645430] [G loss: 0.773800]\n",
      "[Epoch 7/200] [Batch 5/169] [D loss: 0.630509] [G loss: 0.748882]\n",
      "[Epoch 7/200] [Batch 6/169] [D loss: 0.620206] [G loss: 0.816235]\n",
      "[Epoch 7/200] [Batch 7/169] [D loss: 0.643027] [G loss: 0.801612]\n",
      "[Epoch 7/200] [Batch 8/169] [D loss: 0.606010] [G loss: 0.838712]\n",
      "[Epoch 7/200] [Batch 9/169] [D loss: 0.614490] [G loss: 0.761744]\n",
      "[Epoch 7/200] [Batch 10/169] [D loss: 0.605861] [G loss: 0.799113]\n",
      "[Epoch 7/200] [Batch 11/169] [D loss: 0.594373] [G loss: 0.843177]\n",
      "[Epoch 7/200] [Batch 12/169] [D loss: 0.615204] [G loss: 0.815315]\n",
      "[Epoch 7/200] [Batch 13/169] [D loss: 0.619580] [G loss: 0.756545]\n",
      "[Epoch 7/200] [Batch 14/169] [D loss: 0.623327] [G loss: 0.756090]\n",
      "[Epoch 7/200] [Batch 15/169] [D loss: 0.665022] [G loss: 0.803385]\n",
      "[Epoch 7/200] [Batch 16/169] [D loss: 0.651342] [G loss: 0.748665]\n",
      "[Epoch 7/200] [Batch 17/169] [D loss: 0.639815] [G loss: 0.881656]\n",
      "[Epoch 7/200] [Batch 18/169] [D loss: 0.640088] [G loss: 0.774310]\n",
      "[Epoch 7/200] [Batch 19/169] [D loss: 0.668721] [G loss: 0.821335]\n",
      "[Epoch 7/200] [Batch 20/169] [D loss: 0.668426] [G loss: 0.766839]\n",
      "[Epoch 7/200] [Batch 21/169] [D loss: 0.658976] [G loss: 0.789631]\n",
      "[Epoch 7/200] [Batch 22/169] [D loss: 0.665977] [G loss: 0.788263]\n",
      "[Epoch 7/200] [Batch 23/169] [D loss: 0.666779] [G loss: 0.781575]\n",
      "[Epoch 7/200] [Batch 24/169] [D loss: 0.686929] [G loss: 0.769060]\n",
      "[Epoch 7/200] [Batch 25/169] [D loss: 0.645581] [G loss: 0.739850]\n",
      "[Epoch 7/200] [Batch 26/169] [D loss: 0.670868] [G loss: 0.776520]\n",
      "[Epoch 7/200] [Batch 27/169] [D loss: 0.654967] [G loss: 0.758454]\n",
      "[Epoch 7/200] [Batch 28/169] [D loss: 0.659553] [G loss: 0.770077]\n",
      "[Epoch 7/200] [Batch 29/169] [D loss: 0.659030] [G loss: 0.775563]\n",
      "[Epoch 7/200] [Batch 30/169] [D loss: 0.691103] [G loss: 0.701600]\n",
      "[Epoch 7/200] [Batch 31/169] [D loss: 0.665970] [G loss: 0.714655]\n",
      "[Epoch 7/200] [Batch 32/169] [D loss: 0.643644] [G loss: 0.756357]\n",
      "[Epoch 7/200] [Batch 33/169] [D loss: 0.693036] [G loss: 0.775323]\n",
      "[Epoch 7/200] [Batch 34/169] [D loss: 0.670249] [G loss: 0.778428]\n",
      "[Epoch 7/200] [Batch 35/169] [D loss: 0.637176] [G loss: 0.828054]\n",
      "[Epoch 7/200] [Batch 36/169] [D loss: 0.646612] [G loss: 0.807720]\n",
      "[Epoch 7/200] [Batch 37/169] [D loss: 0.676396] [G loss: 0.818215]\n",
      "[Epoch 7/200] [Batch 38/169] [D loss: 0.675824] [G loss: 0.800519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 39/169] [D loss: 0.648416] [G loss: 0.817615]\n",
      "[Epoch 7/200] [Batch 40/169] [D loss: 0.646277] [G loss: 0.771030]\n",
      "[Epoch 7/200] [Batch 41/169] [D loss: 0.637254] [G loss: 0.843464]\n",
      "[Epoch 7/200] [Batch 42/169] [D loss: 0.670436] [G loss: 0.817108]\n",
      "[Epoch 7/200] [Batch 43/169] [D loss: 0.647607] [G loss: 0.862770]\n",
      "[Epoch 7/200] [Batch 44/169] [D loss: 0.628509] [G loss: 0.851966]\n",
      "[Epoch 7/200] [Batch 45/169] [D loss: 0.644398] [G loss: 0.798742]\n",
      "[Epoch 7/200] [Batch 46/169] [D loss: 0.656184] [G loss: 0.836346]\n",
      "[Epoch 7/200] [Batch 47/169] [D loss: 0.645896] [G loss: 0.839611]\n",
      "[Epoch 7/200] [Batch 48/169] [D loss: 0.649175] [G loss: 0.771812]\n",
      "[Epoch 7/200] [Batch 49/169] [D loss: 0.640316] [G loss: 0.712297]\n",
      "[Epoch 7/200] [Batch 50/169] [D loss: 0.649702] [G loss: 0.763715]\n",
      "[Epoch 7/200] [Batch 51/169] [D loss: 0.638935] [G loss: 0.781462]\n",
      "[Epoch 7/200] [Batch 52/169] [D loss: 0.634714] [G loss: 0.771876]\n",
      "[Epoch 7/200] [Batch 53/169] [D loss: 0.635668] [G loss: 0.768051]\n",
      "[Epoch 7/200] [Batch 54/169] [D loss: 0.649516] [G loss: 0.791970]\n",
      "[Epoch 7/200] [Batch 55/169] [D loss: 0.665843] [G loss: 0.757096]\n",
      "[Epoch 7/200] [Batch 56/169] [D loss: 0.670815] [G loss: 0.719921]\n",
      "[Epoch 7/200] [Batch 57/169] [D loss: 0.675375] [G loss: 0.782412]\n",
      "[Epoch 7/200] [Batch 58/169] [D loss: 0.639375] [G loss: 0.815073]\n",
      "[Epoch 7/200] [Batch 59/169] [D loss: 0.633516] [G loss: 0.824994]\n",
      "[Epoch 7/200] [Batch 60/169] [D loss: 0.604541] [G loss: 0.848503]\n",
      "[Epoch 7/200] [Batch 61/169] [D loss: 0.610783] [G loss: 0.800985]\n",
      "[Epoch 7/200] [Batch 62/169] [D loss: 0.606099] [G loss: 0.808976]\n",
      "[Epoch 7/200] [Batch 63/169] [D loss: 0.609330] [G loss: 0.819376]\n",
      "[Epoch 7/200] [Batch 64/169] [D loss: 0.606526] [G loss: 0.811568]\n",
      "[Epoch 7/200] [Batch 65/169] [D loss: 0.617353] [G loss: 0.755485]\n",
      "[Epoch 7/200] [Batch 66/169] [D loss: 0.633813] [G loss: 0.768806]\n",
      "[Epoch 7/200] [Batch 67/169] [D loss: 0.630008] [G loss: 0.787382]\n",
      "[Epoch 7/200] [Batch 68/169] [D loss: 0.639080] [G loss: 0.769689]\n",
      "[Epoch 7/200] [Batch 69/169] [D loss: 0.641571] [G loss: 0.790322]\n",
      "[Epoch 7/200] [Batch 70/169] [D loss: 0.639132] [G loss: 0.754815]\n",
      "[Epoch 7/200] [Batch 71/169] [D loss: 0.641839] [G loss: 0.746518]\n",
      "[Epoch 7/200] [Batch 72/169] [D loss: 0.654068] [G loss: 0.722061]\n",
      "[Epoch 7/200] [Batch 73/169] [D loss: 0.669224] [G loss: 0.740765]\n",
      "[Epoch 7/200] [Batch 74/169] [D loss: 0.637648] [G loss: 0.747561]\n",
      "[Epoch 7/200] [Batch 75/169] [D loss: 0.642894] [G loss: 0.833823]\n",
      "[Epoch 7/200] [Batch 76/169] [D loss: 0.590067] [G loss: 0.875299]\n",
      "[Epoch 7/200] [Batch 77/169] [D loss: 0.587909] [G loss: 0.879766]\n",
      "[Epoch 7/200] [Batch 78/169] [D loss: 0.597152] [G loss: 0.895727]\n",
      "[Epoch 7/200] [Batch 79/169] [D loss: 0.594329] [G loss: 0.846652]\n",
      "[Epoch 7/200] [Batch 80/169] [D loss: 0.606342] [G loss: 0.795581]\n",
      "[Epoch 7/200] [Batch 81/169] [D loss: 0.610651] [G loss: 0.742855]\n",
      "[Epoch 7/200] [Batch 82/169] [D loss: 0.643077] [G loss: 0.696462]\n",
      "[Epoch 7/200] [Batch 83/169] [D loss: 0.680367] [G loss: 0.665980]\n",
      "[Epoch 7/200] [Batch 84/169] [D loss: 0.686015] [G loss: 0.648378]\n",
      "[Epoch 7/200] [Batch 85/169] [D loss: 0.675879] [G loss: 0.693962]\n",
      "[Epoch 7/200] [Batch 86/169] [D loss: 0.693542] [G loss: 0.775004]\n",
      "[Epoch 7/200] [Batch 87/169] [D loss: 0.705440] [G loss: 0.826107]\n",
      "[Epoch 7/200] [Batch 88/169] [D loss: 0.657977] [G loss: 0.854488]\n",
      "[Epoch 7/200] [Batch 89/169] [D loss: 0.689512] [G loss: 0.837594]\n",
      "[Epoch 7/200] [Batch 90/169] [D loss: 0.638424] [G loss: 0.949418]\n",
      "[Epoch 7/200] [Batch 91/169] [D loss: 0.657894] [G loss: 0.861130]\n",
      "[Epoch 7/200] [Batch 92/169] [D loss: 0.660836] [G loss: 0.829052]\n",
      "[Epoch 7/200] [Batch 93/169] [D loss: 0.667950] [G loss: 0.751270]\n",
      "[Epoch 7/200] [Batch 94/169] [D loss: 0.645221] [G loss: 0.718042]\n",
      "[Epoch 7/200] [Batch 95/169] [D loss: 0.670398] [G loss: 0.777035]\n",
      "[Epoch 7/200] [Batch 96/169] [D loss: 0.647637] [G loss: 0.737749]\n",
      "[Epoch 7/200] [Batch 97/169] [D loss: 0.669192] [G loss: 0.701434]\n",
      "[Epoch 7/200] [Batch 98/169] [D loss: 0.678567] [G loss: 0.729101]\n",
      "[Epoch 7/200] [Batch 99/169] [D loss: 0.658418] [G loss: 0.741640]\n",
      "[Epoch 7/200] [Batch 100/169] [D loss: 0.669266] [G loss: 0.805778]\n",
      "[Epoch 7/200] [Batch 101/169] [D loss: 0.681681] [G loss: 0.790201]\n",
      "[Epoch 7/200] [Batch 102/169] [D loss: 0.677027] [G loss: 0.769714]\n",
      "[Epoch 7/200] [Batch 103/169] [D loss: 0.651438] [G loss: 0.744687]\n",
      "[Epoch 7/200] [Batch 104/169] [D loss: 0.664538] [G loss: 0.766029]\n",
      "[Epoch 7/200] [Batch 105/169] [D loss: 0.655711] [G loss: 0.748660]\n",
      "[Epoch 7/200] [Batch 106/169] [D loss: 0.600218] [G loss: 0.769545]\n",
      "[Epoch 7/200] [Batch 107/169] [D loss: 0.608074] [G loss: 0.782773]\n",
      "[Epoch 7/200] [Batch 108/169] [D loss: 0.616859] [G loss: 0.781937]\n",
      "[Epoch 7/200] [Batch 109/169] [D loss: 0.661660] [G loss: 0.788828]\n",
      "[Epoch 7/200] [Batch 110/169] [D loss: 0.624803] [G loss: 0.788411]\n",
      "[Epoch 7/200] [Batch 111/169] [D loss: 0.639435] [G loss: 0.807752]\n",
      "[Epoch 7/200] [Batch 112/169] [D loss: 0.637312] [G loss: 0.790179]\n",
      "[Epoch 7/200] [Batch 113/169] [D loss: 0.634133] [G loss: 0.767082]\n",
      "[Epoch 7/200] [Batch 114/169] [D loss: 0.634493] [G loss: 0.820671]\n",
      "[Epoch 7/200] [Batch 115/169] [D loss: 0.620436] [G loss: 0.780837]\n",
      "[Epoch 7/200] [Batch 116/169] [D loss: 0.620469] [G loss: 0.795681]\n",
      "[Epoch 7/200] [Batch 117/169] [D loss: 0.646931] [G loss: 0.787179]\n",
      "[Epoch 7/200] [Batch 118/169] [D loss: 0.665967] [G loss: 0.748018]\n",
      "[Epoch 7/200] [Batch 119/169] [D loss: 0.657010] [G loss: 0.744035]\n",
      "[Epoch 7/200] [Batch 120/169] [D loss: 0.655932] [G loss: 0.752994]\n",
      "[Epoch 7/200] [Batch 121/169] [D loss: 0.669422] [G loss: 0.832688]\n",
      "[Epoch 7/200] [Batch 122/169] [D loss: 0.623408] [G loss: 0.803857]\n",
      "[Epoch 7/200] [Batch 123/169] [D loss: 0.653986] [G loss: 0.784672]\n",
      "[Epoch 7/200] [Batch 124/169] [D loss: 0.623420] [G loss: 0.792794]\n",
      "[Epoch 7/200] [Batch 125/169] [D loss: 0.634777] [G loss: 0.752701]\n",
      "[Epoch 7/200] [Batch 126/169] [D loss: 0.675655] [G loss: 0.779679]\n",
      "[Epoch 7/200] [Batch 127/169] [D loss: 0.657141] [G loss: 0.802400]\n",
      "[Epoch 7/200] [Batch 128/169] [D loss: 0.647010] [G loss: 0.785724]\n",
      "[Epoch 7/200] [Batch 129/169] [D loss: 0.661107] [G loss: 0.789092]\n",
      "[Epoch 7/200] [Batch 130/169] [D loss: 0.692844] [G loss: 0.798695]\n",
      "[Epoch 7/200] [Batch 131/169] [D loss: 0.648467] [G loss: 0.758817]\n",
      "[Epoch 7/200] [Batch 132/169] [D loss: 0.654898] [G loss: 0.818738]\n",
      "[Epoch 7/200] [Batch 133/169] [D loss: 0.656455] [G loss: 0.788102]\n",
      "[Epoch 7/200] [Batch 134/169] [D loss: 0.648516] [G loss: 0.799794]\n",
      "[Epoch 7/200] [Batch 135/169] [D loss: 0.645340] [G loss: 0.793497]\n",
      "[Epoch 7/200] [Batch 136/169] [D loss: 0.647074] [G loss: 0.790227]\n",
      "[Epoch 7/200] [Batch 137/169] [D loss: 0.667943] [G loss: 0.800646]\n",
      "[Epoch 7/200] [Batch 138/169] [D loss: 0.621453] [G loss: 0.853408]\n",
      "[Epoch 7/200] [Batch 139/169] [D loss: 0.658921] [G loss: 0.784594]\n",
      "[Epoch 7/200] [Batch 140/169] [D loss: 0.647985] [G loss: 0.825063]\n",
      "[Epoch 7/200] [Batch 141/169] [D loss: 0.657629] [G loss: 0.819757]\n",
      "[Epoch 7/200] [Batch 142/169] [D loss: 0.647079] [G loss: 0.807012]\n",
      "[Epoch 7/200] [Batch 143/169] [D loss: 0.633852] [G loss: 0.827726]\n",
      "[Epoch 7/200] [Batch 144/169] [D loss: 0.639209] [G loss: 0.797922]\n",
      "[Epoch 7/200] [Batch 145/169] [D loss: 0.623503] [G loss: 0.851656]\n",
      "[Epoch 7/200] [Batch 146/169] [D loss: 0.643585] [G loss: 0.900220]\n",
      "[Epoch 7/200] [Batch 147/169] [D loss: 0.622711] [G loss: 0.865017]\n",
      "[Epoch 7/200] [Batch 148/169] [D loss: 0.628672] [G loss: 0.812954]\n",
      "[Epoch 7/200] [Batch 149/169] [D loss: 0.647398] [G loss: 0.876510]\n",
      "[Epoch 7/200] [Batch 150/169] [D loss: 0.619832] [G loss: 0.795905]\n",
      "[Epoch 7/200] [Batch 151/169] [D loss: 0.648429] [G loss: 0.745389]\n",
      "[Epoch 7/200] [Batch 152/169] [D loss: 0.684602] [G loss: 0.695367]\n",
      "[Epoch 7/200] [Batch 153/169] [D loss: 0.729500] [G loss: 0.695481]\n",
      "[Epoch 7/200] [Batch 154/169] [D loss: 0.745981] [G loss: 0.636033]\n",
      "[Epoch 7/200] [Batch 155/169] [D loss: 0.728152] [G loss: 0.703576]\n",
      "[Epoch 7/200] [Batch 156/169] [D loss: 0.707429] [G loss: 0.875398]\n",
      "[Epoch 7/200] [Batch 157/169] [D loss: 0.599056] [G loss: 1.020269]\n",
      "[Epoch 7/200] [Batch 158/169] [D loss: 0.639085] [G loss: 0.958399]\n",
      "[Epoch 7/200] [Batch 159/169] [D loss: 0.632461] [G loss: 0.883114]\n",
      "[Epoch 7/200] [Batch 160/169] [D loss: 0.689456] [G loss: 0.760575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 161/169] [D loss: 0.686860] [G loss: 0.649903]\n",
      "[Epoch 7/200] [Batch 162/169] [D loss: 0.623362] [G loss: 0.687740]\n",
      "[Epoch 7/200] [Batch 163/169] [D loss: 0.691149] [G loss: 0.703295]\n",
      "[Epoch 7/200] [Batch 164/169] [D loss: 0.671309] [G loss: 0.678672]\n",
      "[Epoch 7/200] [Batch 165/169] [D loss: 0.661327] [G loss: 0.708928]\n",
      "[Epoch 7/200] [Batch 166/169] [D loss: 0.656653] [G loss: 0.765192]\n",
      "[Epoch 7/200] [Batch 167/169] [D loss: 0.673934] [G loss: 0.774707]\n",
      "[Epoch 7/200] [Batch 168/169] [D loss: 0.609969] [G loss: 0.825053]\n",
      "[Epoch 8/200] [Batch 0/169] [D loss: 0.601428] [G loss: 0.763775]\n",
      "[Epoch 8/200] [Batch 1/169] [D loss: 0.618550] [G loss: 0.818682]\n",
      "[Epoch 8/200] [Batch 2/169] [D loss: 0.630033] [G loss: 0.697331]\n",
      "[Epoch 8/200] [Batch 3/169] [D loss: 0.630743] [G loss: 0.802555]\n",
      "[Epoch 8/200] [Batch 4/169] [D loss: 0.646946] [G loss: 0.755805]\n",
      "[Epoch 8/200] [Batch 5/169] [D loss: 0.655941] [G loss: 0.774769]\n",
      "[Epoch 8/200] [Batch 6/169] [D loss: 0.680227] [G loss: 0.759742]\n",
      "[Epoch 8/200] [Batch 7/169] [D loss: 0.663404] [G loss: 0.751493]\n",
      "[Epoch 8/200] [Batch 8/169] [D loss: 0.678534] [G loss: 0.771403]\n",
      "[Epoch 8/200] [Batch 9/169] [D loss: 0.620039] [G loss: 0.847950]\n",
      "[Epoch 8/200] [Batch 10/169] [D loss: 0.662701] [G loss: 0.792070]\n",
      "[Epoch 8/200] [Batch 11/169] [D loss: 0.626412] [G loss: 0.765083]\n",
      "[Epoch 8/200] [Batch 12/169] [D loss: 0.651517] [G loss: 0.722323]\n",
      "[Epoch 8/200] [Batch 13/169] [D loss: 0.660807] [G loss: 0.843613]\n",
      "[Epoch 8/200] [Batch 14/169] [D loss: 0.662959] [G loss: 0.778642]\n",
      "[Epoch 8/200] [Batch 15/169] [D loss: 0.660144] [G loss: 0.801288]\n",
      "[Epoch 8/200] [Batch 16/169] [D loss: 0.650271] [G loss: 0.768367]\n",
      "[Epoch 8/200] [Batch 17/169] [D loss: 0.629586] [G loss: 0.730383]\n",
      "[Epoch 8/200] [Batch 18/169] [D loss: 0.642493] [G loss: 0.770852]\n",
      "[Epoch 8/200] [Batch 19/169] [D loss: 0.629107] [G loss: 0.767398]\n",
      "[Epoch 8/200] [Batch 20/169] [D loss: 0.674156] [G loss: 0.766967]\n",
      "[Epoch 8/200] [Batch 21/169] [D loss: 0.693296] [G loss: 0.752617]\n",
      "[Epoch 8/200] [Batch 22/169] [D loss: 0.668457] [G loss: 0.819745]\n",
      "[Epoch 8/200] [Batch 23/169] [D loss: 0.683685] [G loss: 0.784869]\n",
      "[Epoch 8/200] [Batch 24/169] [D loss: 0.640367] [G loss: 0.849688]\n",
      "[Epoch 8/200] [Batch 25/169] [D loss: 0.660098] [G loss: 0.743712]\n",
      "[Epoch 8/200] [Batch 26/169] [D loss: 0.622040] [G loss: 0.757583]\n",
      "[Epoch 8/200] [Batch 27/169] [D loss: 0.638049] [G loss: 0.757118]\n",
      "[Epoch 8/200] [Batch 28/169] [D loss: 0.650741] [G loss: 0.723849]\n",
      "[Epoch 8/200] [Batch 29/169] [D loss: 0.620648] [G loss: 0.881931]\n",
      "[Epoch 8/200] [Batch 30/169] [D loss: 0.644547] [G loss: 0.834545]\n",
      "[Epoch 8/200] [Batch 31/169] [D loss: 0.664907] [G loss: 0.829334]\n",
      "[Epoch 8/200] [Batch 32/169] [D loss: 0.650403] [G loss: 0.739871]\n",
      "[Epoch 8/200] [Batch 33/169] [D loss: 0.632342] [G loss: 0.759929]\n",
      "[Epoch 8/200] [Batch 34/169] [D loss: 0.631534] [G loss: 0.772705]\n",
      "[Epoch 8/200] [Batch 35/169] [D loss: 0.654020] [G loss: 0.717771]\n",
      "[Epoch 8/200] [Batch 36/169] [D loss: 0.617518] [G loss: 0.848397]\n",
      "[Epoch 8/200] [Batch 37/169] [D loss: 0.648041] [G loss: 0.788792]\n",
      "[Epoch 8/200] [Batch 38/169] [D loss: 0.639614] [G loss: 0.783400]\n",
      "[Epoch 8/200] [Batch 39/169] [D loss: 0.679571] [G loss: 0.730873]\n",
      "[Epoch 8/200] [Batch 40/169] [D loss: 0.655477] [G loss: 0.734258]\n",
      "[Epoch 8/200] [Batch 41/169] [D loss: 0.678065] [G loss: 0.771791]\n",
      "[Epoch 8/200] [Batch 42/169] [D loss: 0.677047] [G loss: 0.722862]\n",
      "[Epoch 8/200] [Batch 43/169] [D loss: 0.655946] [G loss: 0.796476]\n",
      "[Epoch 8/200] [Batch 44/169] [D loss: 0.645624] [G loss: 0.799319]\n",
      "[Epoch 8/200] [Batch 45/169] [D loss: 0.630935] [G loss: 0.797833]\n",
      "[Epoch 8/200] [Batch 46/169] [D loss: 0.658097] [G loss: 0.848045]\n",
      "[Epoch 8/200] [Batch 47/169] [D loss: 0.661502] [G loss: 0.770559]\n",
      "[Epoch 8/200] [Batch 48/169] [D loss: 0.656763] [G loss: 0.755583]\n",
      "[Epoch 8/200] [Batch 49/169] [D loss: 0.670093] [G loss: 0.734371]\n",
      "[Epoch 8/200] [Batch 50/169] [D loss: 0.661147] [G loss: 0.747137]\n",
      "[Epoch 8/200] [Batch 51/169] [D loss: 0.657541] [G loss: 0.747274]\n",
      "[Epoch 8/200] [Batch 52/169] [D loss: 0.652661] [G loss: 0.774443]\n",
      "[Epoch 8/200] [Batch 53/169] [D loss: 0.660715] [G loss: 0.735278]\n",
      "[Epoch 8/200] [Batch 54/169] [D loss: 0.647882] [G loss: 0.708304]\n",
      "[Epoch 8/200] [Batch 55/169] [D loss: 0.646217] [G loss: 0.776349]\n",
      "[Epoch 8/200] [Batch 56/169] [D loss: 0.644926] [G loss: 0.785295]\n",
      "[Epoch 8/200] [Batch 57/169] [D loss: 0.658143] [G loss: 0.761764]\n",
      "[Epoch 8/200] [Batch 58/169] [D loss: 0.644564] [G loss: 0.724955]\n",
      "[Epoch 8/200] [Batch 59/169] [D loss: 0.648596] [G loss: 0.735578]\n",
      "[Epoch 8/200] [Batch 60/169] [D loss: 0.684890] [G loss: 0.758162]\n",
      "[Epoch 8/200] [Batch 61/169] [D loss: 0.639182] [G loss: 0.774754]\n",
      "[Epoch 8/200] [Batch 62/169] [D loss: 0.646040] [G loss: 0.746956]\n",
      "[Epoch 8/200] [Batch 63/169] [D loss: 0.659610] [G loss: 0.749303]\n",
      "[Epoch 8/200] [Batch 64/169] [D loss: 0.663969] [G loss: 0.749590]\n",
      "[Epoch 8/200] [Batch 65/169] [D loss: 0.662929] [G loss: 0.776753]\n",
      "[Epoch 8/200] [Batch 66/169] [D loss: 0.657720] [G loss: 0.773246]\n",
      "[Epoch 8/200] [Batch 67/169] [D loss: 0.654704] [G loss: 0.748478]\n",
      "[Epoch 8/200] [Batch 68/169] [D loss: 0.657166] [G loss: 0.690203]\n",
      "[Epoch 8/200] [Batch 69/169] [D loss: 0.680347] [G loss: 0.735367]\n",
      "[Epoch 8/200] [Batch 70/169] [D loss: 0.659195] [G loss: 0.733787]\n",
      "[Epoch 8/200] [Batch 71/169] [D loss: 0.666319] [G loss: 0.734860]\n",
      "[Epoch 8/200] [Batch 72/169] [D loss: 0.655218] [G loss: 0.753158]\n",
      "[Epoch 8/200] [Batch 73/169] [D loss: 0.659070] [G loss: 0.716643]\n",
      "[Epoch 8/200] [Batch 74/169] [D loss: 0.672120] [G loss: 0.707595]\n",
      "[Epoch 8/200] [Batch 75/169] [D loss: 0.652001] [G loss: 0.728004]\n",
      "[Epoch 8/200] [Batch 76/169] [D loss: 0.674587] [G loss: 0.729046]\n",
      "[Epoch 8/200] [Batch 77/169] [D loss: 0.670173] [G loss: 0.733218]\n",
      "[Epoch 8/200] [Batch 78/169] [D loss: 0.664741] [G loss: 0.746991]\n",
      "[Epoch 8/200] [Batch 79/169] [D loss: 0.642615] [G loss: 0.746398]\n",
      "[Epoch 8/200] [Batch 80/169] [D loss: 0.647899] [G loss: 0.817069]\n",
      "[Epoch 8/200] [Batch 81/169] [D loss: 0.684002] [G loss: 0.842968]\n",
      "[Epoch 8/200] [Batch 82/169] [D loss: 0.654684] [G loss: 0.839219]\n",
      "[Epoch 8/200] [Batch 83/169] [D loss: 0.645761] [G loss: 0.816603]\n",
      "[Epoch 8/200] [Batch 84/169] [D loss: 0.664471] [G loss: 0.794666]\n",
      "[Epoch 8/200] [Batch 85/169] [D loss: 0.650379] [G loss: 0.798465]\n",
      "[Epoch 8/200] [Batch 86/169] [D loss: 0.638601] [G loss: 0.797754]\n",
      "[Epoch 8/200] [Batch 87/169] [D loss: 0.614394] [G loss: 0.846210]\n",
      "[Epoch 8/200] [Batch 88/169] [D loss: 0.648127] [G loss: 0.786738]\n",
      "[Epoch 8/200] [Batch 89/169] [D loss: 0.653627] [G loss: 0.782127]\n",
      "[Epoch 8/200] [Batch 90/169] [D loss: 0.653923] [G loss: 0.759931]\n",
      "[Epoch 8/200] [Batch 91/169] [D loss: 0.642593] [G loss: 0.743036]\n",
      "[Epoch 8/200] [Batch 92/169] [D loss: 0.670087] [G loss: 0.790006]\n",
      "[Epoch 8/200] [Batch 93/169] [D loss: 0.644250] [G loss: 0.812040]\n",
      "[Epoch 8/200] [Batch 94/169] [D loss: 0.649485] [G loss: 0.787265]\n",
      "[Epoch 8/200] [Batch 95/169] [D loss: 0.643354] [G loss: 0.763409]\n",
      "[Epoch 8/200] [Batch 96/169] [D loss: 0.593208] [G loss: 0.845490]\n",
      "[Epoch 8/200] [Batch 97/169] [D loss: 0.673123] [G loss: 0.819994]\n",
      "[Epoch 8/200] [Batch 98/169] [D loss: 0.657584] [G loss: 0.784069]\n",
      "[Epoch 8/200] [Batch 99/169] [D loss: 0.670990] [G loss: 0.770763]\n",
      "[Epoch 8/200] [Batch 100/169] [D loss: 0.664121] [G loss: 0.756107]\n",
      "[Epoch 8/200] [Batch 101/169] [D loss: 0.678696] [G loss: 0.782764]\n",
      "[Epoch 8/200] [Batch 102/169] [D loss: 0.665078] [G loss: 0.839033]\n",
      "[Epoch 8/200] [Batch 103/169] [D loss: 0.646383] [G loss: 0.801912]\n",
      "[Epoch 8/200] [Batch 104/169] [D loss: 0.632123] [G loss: 0.746441]\n",
      "[Epoch 8/200] [Batch 105/169] [D loss: 0.646805] [G loss: 0.779326]\n",
      "[Epoch 8/200] [Batch 106/169] [D loss: 0.661878] [G loss: 0.746689]\n",
      "[Epoch 8/200] [Batch 107/169] [D loss: 0.638572] [G loss: 0.779100]\n",
      "[Epoch 8/200] [Batch 108/169] [D loss: 0.662076] [G loss: 0.717384]\n",
      "[Epoch 8/200] [Batch 109/169] [D loss: 0.649937] [G loss: 0.707614]\n",
      "[Epoch 8/200] [Batch 110/169] [D loss: 0.661202] [G loss: 0.695038]\n",
      "[Epoch 8/200] [Batch 111/169] [D loss: 0.664870] [G loss: 0.785584]\n",
      "[Epoch 8/200] [Batch 112/169] [D loss: 0.690168] [G loss: 0.760489]\n",
      "[Epoch 8/200] [Batch 113/169] [D loss: 0.669359] [G loss: 0.806650]\n",
      "[Epoch 8/200] [Batch 114/169] [D loss: 0.664202] [G loss: 0.815568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 115/169] [D loss: 0.657991] [G loss: 0.806143]\n",
      "[Epoch 8/200] [Batch 116/169] [D loss: 0.640764] [G loss: 0.782882]\n",
      "[Epoch 8/200] [Batch 117/169] [D loss: 0.649077] [G loss: 0.749699]\n",
      "[Epoch 8/200] [Batch 118/169] [D loss: 0.627618] [G loss: 0.758005]\n",
      "[Epoch 8/200] [Batch 119/169] [D loss: 0.702499] [G loss: 0.739161]\n",
      "[Epoch 8/200] [Batch 120/169] [D loss: 0.680964] [G loss: 0.765328]\n",
      "[Epoch 8/200] [Batch 121/169] [D loss: 0.657928] [G loss: 0.756566]\n",
      "[Epoch 8/200] [Batch 122/169] [D loss: 0.614467] [G loss: 0.779795]\n",
      "[Epoch 8/200] [Batch 123/169] [D loss: 0.658256] [G loss: 0.839070]\n",
      "[Epoch 8/200] [Batch 124/169] [D loss: 0.664405] [G loss: 0.825567]\n",
      "[Epoch 8/200] [Batch 125/169] [D loss: 0.641680] [G loss: 0.758296]\n",
      "[Epoch 8/200] [Batch 126/169] [D loss: 0.641507] [G loss: 0.805139]\n",
      "[Epoch 8/200] [Batch 127/169] [D loss: 0.614271] [G loss: 0.823114]\n",
      "[Epoch 8/200] [Batch 128/169] [D loss: 0.628899] [G loss: 0.834779]\n",
      "[Epoch 8/200] [Batch 129/169] [D loss: 0.647206] [G loss: 0.781546]\n",
      "[Epoch 8/200] [Batch 130/169] [D loss: 0.669838] [G loss: 0.820996]\n",
      "[Epoch 8/200] [Batch 131/169] [D loss: 0.661397] [G loss: 0.785410]\n",
      "[Epoch 8/200] [Batch 132/169] [D loss: 0.622848] [G loss: 0.782799]\n",
      "[Epoch 8/200] [Batch 133/169] [D loss: 0.614515] [G loss: 0.798984]\n",
      "[Epoch 8/200] [Batch 134/169] [D loss: 0.669936] [G loss: 0.747809]\n",
      "[Epoch 8/200] [Batch 135/169] [D loss: 0.634366] [G loss: 0.827792]\n",
      "[Epoch 8/200] [Batch 136/169] [D loss: 0.669940] [G loss: 0.757833]\n",
      "[Epoch 8/200] [Batch 137/169] [D loss: 0.653621] [G loss: 0.775426]\n",
      "[Epoch 8/200] [Batch 138/169] [D loss: 0.662414] [G loss: 0.775364]\n",
      "[Epoch 8/200] [Batch 139/169] [D loss: 0.683604] [G loss: 0.830771]\n",
      "[Epoch 8/200] [Batch 140/169] [D loss: 0.645772] [G loss: 0.784324]\n",
      "[Epoch 8/200] [Batch 141/169] [D loss: 0.647075] [G loss: 0.752580]\n",
      "[Epoch 8/200] [Batch 142/169] [D loss: 0.610349] [G loss: 0.794106]\n",
      "[Epoch 8/200] [Batch 143/169] [D loss: 0.650902] [G loss: 0.779187]\n",
      "[Epoch 8/200] [Batch 144/169] [D loss: 0.671228] [G loss: 0.799151]\n",
      "[Epoch 8/200] [Batch 145/169] [D loss: 0.665406] [G loss: 0.814163]\n",
      "[Epoch 8/200] [Batch 146/169] [D loss: 0.635277] [G loss: 0.769686]\n",
      "[Epoch 8/200] [Batch 147/169] [D loss: 0.621759] [G loss: 0.735299]\n",
      "[Epoch 8/200] [Batch 148/169] [D loss: 0.683311] [G loss: 0.722812]\n",
      "[Epoch 8/200] [Batch 149/169] [D loss: 0.653602] [G loss: 0.722361]\n",
      "[Epoch 8/200] [Batch 150/169] [D loss: 0.669830] [G loss: 0.703024]\n",
      "[Epoch 8/200] [Batch 151/169] [D loss: 0.671969] [G loss: 0.707424]\n",
      "[Epoch 8/200] [Batch 152/169] [D loss: 0.653789] [G loss: 0.734420]\n",
      "[Epoch 8/200] [Batch 153/169] [D loss: 0.647946] [G loss: 0.797063]\n",
      "[Epoch 8/200] [Batch 154/169] [D loss: 0.639168] [G loss: 0.784855]\n",
      "[Epoch 8/200] [Batch 155/169] [D loss: 0.620587] [G loss: 0.800497]\n",
      "[Epoch 8/200] [Batch 156/169] [D loss: 0.632518] [G loss: 0.829133]\n",
      "[Epoch 8/200] [Batch 157/169] [D loss: 0.632765] [G loss: 0.856544]\n",
      "[Epoch 8/200] [Batch 158/169] [D loss: 0.583940] [G loss: 0.774126]\n",
      "[Epoch 8/200] [Batch 159/169] [D loss: 0.624955] [G loss: 0.777765]\n",
      "[Epoch 8/200] [Batch 160/169] [D loss: 0.642010] [G loss: 0.720918]\n",
      "[Epoch 8/200] [Batch 161/169] [D loss: 0.645849] [G loss: 0.757312]\n",
      "[Epoch 8/200] [Batch 162/169] [D loss: 0.658594] [G loss: 0.720962]\n",
      "[Epoch 8/200] [Batch 163/169] [D loss: 0.668427] [G loss: 0.684162]\n",
      "[Epoch 8/200] [Batch 164/169] [D loss: 0.639303] [G loss: 0.785042]\n",
      "[Epoch 8/200] [Batch 165/169] [D loss: 0.647683] [G loss: 0.740346]\n",
      "[Epoch 8/200] [Batch 166/169] [D loss: 0.654412] [G loss: 0.778311]\n",
      "[Epoch 8/200] [Batch 167/169] [D loss: 0.668787] [G loss: 0.757560]\n",
      "[Epoch 8/200] [Batch 168/169] [D loss: 0.668392] [G loss: 0.856113]\n",
      "[Epoch 9/200] [Batch 0/169] [D loss: 0.705121] [G loss: 0.785274]\n",
      "[Epoch 9/200] [Batch 1/169] [D loss: 0.718111] [G loss: 0.725557]\n",
      "[Epoch 9/200] [Batch 2/169] [D loss: 0.701504] [G loss: 0.760662]\n",
      "[Epoch 9/200] [Batch 3/169] [D loss: 0.663782] [G loss: 0.755883]\n",
      "[Epoch 9/200] [Batch 4/169] [D loss: 0.656558] [G loss: 0.760472]\n",
      "[Epoch 9/200] [Batch 5/169] [D loss: 0.662503] [G loss: 0.796131]\n",
      "[Epoch 9/200] [Batch 6/169] [D loss: 0.648336] [G loss: 0.767832]\n",
      "[Epoch 9/200] [Batch 7/169] [D loss: 0.671930] [G loss: 0.759597]\n",
      "[Epoch 9/200] [Batch 8/169] [D loss: 0.643617] [G loss: 0.859059]\n",
      "[Epoch 9/200] [Batch 9/169] [D loss: 0.622319] [G loss: 0.851245]\n",
      "[Epoch 9/200] [Batch 10/169] [D loss: 0.647523] [G loss: 0.821956]\n",
      "[Epoch 9/200] [Batch 11/169] [D loss: 0.672685] [G loss: 0.790725]\n",
      "[Epoch 9/200] [Batch 12/169] [D loss: 0.670847] [G loss: 0.826989]\n",
      "[Epoch 9/200] [Batch 13/169] [D loss: 0.669794] [G loss: 0.759959]\n",
      "[Epoch 9/200] [Batch 14/169] [D loss: 0.693913] [G loss: 0.761073]\n",
      "[Epoch 9/200] [Batch 15/169] [D loss: 0.693684] [G loss: 0.778176]\n",
      "[Epoch 9/200] [Batch 16/169] [D loss: 0.671929] [G loss: 0.776984]\n",
      "[Epoch 9/200] [Batch 17/169] [D loss: 0.646318] [G loss: 0.783393]\n",
      "[Epoch 9/200] [Batch 18/169] [D loss: 0.673669] [G loss: 0.718796]\n",
      "[Epoch 9/200] [Batch 19/169] [D loss: 0.693578] [G loss: 0.698511]\n",
      "[Epoch 9/200] [Batch 20/169] [D loss: 0.657121] [G loss: 0.738513]\n",
      "[Epoch 9/200] [Batch 21/169] [D loss: 0.639848] [G loss: 0.783022]\n",
      "[Epoch 9/200] [Batch 22/169] [D loss: 0.624102] [G loss: 0.841545]\n",
      "[Epoch 9/200] [Batch 23/169] [D loss: 0.631407] [G loss: 0.830626]\n",
      "[Epoch 9/200] [Batch 24/169] [D loss: 0.626868] [G loss: 0.815444]\n",
      "[Epoch 9/200] [Batch 25/169] [D loss: 0.665135] [G loss: 0.771788]\n",
      "[Epoch 9/200] [Batch 26/169] [D loss: 0.630104] [G loss: 0.824803]\n",
      "[Epoch 9/200] [Batch 27/169] [D loss: 0.623287] [G loss: 0.756092]\n",
      "[Epoch 9/200] [Batch 28/169] [D loss: 0.601357] [G loss: 0.778558]\n",
      "[Epoch 9/200] [Batch 29/169] [D loss: 0.643318] [G loss: 0.743753]\n",
      "[Epoch 9/200] [Batch 30/169] [D loss: 0.633967] [G loss: 0.764614]\n",
      "[Epoch 9/200] [Batch 31/169] [D loss: 0.627936] [G loss: 0.773661]\n",
      "[Epoch 9/200] [Batch 32/169] [D loss: 0.639804] [G loss: 0.757593]\n",
      "[Epoch 9/200] [Batch 33/169] [D loss: 0.641164] [G loss: 0.751431]\n",
      "[Epoch 9/200] [Batch 34/169] [D loss: 0.661111] [G loss: 0.748828]\n",
      "[Epoch 9/200] [Batch 35/169] [D loss: 0.711311] [G loss: 0.754666]\n",
      "[Epoch 9/200] [Batch 36/169] [D loss: 0.695792] [G loss: 0.750323]\n",
      "[Epoch 9/200] [Batch 37/169] [D loss: 0.668931] [G loss: 0.719108]\n",
      "[Epoch 9/200] [Batch 38/169] [D loss: 0.668240] [G loss: 0.801579]\n",
      "[Epoch 9/200] [Batch 39/169] [D loss: 0.661835] [G loss: 0.794139]\n",
      "[Epoch 9/200] [Batch 40/169] [D loss: 0.678237] [G loss: 0.804745]\n",
      "[Epoch 9/200] [Batch 41/169] [D loss: 0.660224] [G loss: 0.819229]\n",
      "[Epoch 9/200] [Batch 42/169] [D loss: 0.643803] [G loss: 0.771107]\n",
      "[Epoch 9/200] [Batch 43/169] [D loss: 0.685394] [G loss: 0.803117]\n",
      "[Epoch 9/200] [Batch 44/169] [D loss: 0.675156] [G loss: 0.796997]\n",
      "[Epoch 9/200] [Batch 45/169] [D loss: 0.672261] [G loss: 0.743152]\n",
      "[Epoch 9/200] [Batch 46/169] [D loss: 0.664779] [G loss: 0.777308]\n",
      "[Epoch 9/200] [Batch 47/169] [D loss: 0.645729] [G loss: 0.771793]\n",
      "[Epoch 9/200] [Batch 48/169] [D loss: 0.621741] [G loss: 0.739928]\n",
      "[Epoch 9/200] [Batch 49/169] [D loss: 0.632218] [G loss: 0.743640]\n",
      "[Epoch 9/200] [Batch 50/169] [D loss: 0.662085] [G loss: 0.696468]\n",
      "[Epoch 9/200] [Batch 51/169] [D loss: 0.635278] [G loss: 0.744126]\n",
      "[Epoch 9/200] [Batch 52/169] [D loss: 0.640159] [G loss: 0.701596]\n",
      "[Epoch 9/200] [Batch 53/169] [D loss: 0.661686] [G loss: 0.771942]\n",
      "[Epoch 9/200] [Batch 54/169] [D loss: 0.618211] [G loss: 0.797461]\n",
      "[Epoch 9/200] [Batch 55/169] [D loss: 0.665920] [G loss: 0.792200]\n",
      "[Epoch 9/200] [Batch 56/169] [D loss: 0.661795] [G loss: 0.738722]\n",
      "[Epoch 9/200] [Batch 57/169] [D loss: 0.628957] [G loss: 0.750567]\n",
      "[Epoch 9/200] [Batch 58/169] [D loss: 0.642377] [G loss: 0.716947]\n",
      "[Epoch 9/200] [Batch 59/169] [D loss: 0.650170] [G loss: 0.750643]\n",
      "[Epoch 9/200] [Batch 60/169] [D loss: 0.638389] [G loss: 0.794211]\n",
      "[Epoch 9/200] [Batch 61/169] [D loss: 0.658528] [G loss: 0.767486]\n",
      "[Epoch 9/200] [Batch 62/169] [D loss: 0.635659] [G loss: 0.867669]\n",
      "[Epoch 9/200] [Batch 63/169] [D loss: 0.638719] [G loss: 0.841888]\n",
      "[Epoch 9/200] [Batch 64/169] [D loss: 0.655929] [G loss: 0.808966]\n",
      "[Epoch 9/200] [Batch 65/169] [D loss: 0.656486] [G loss: 0.768525]\n",
      "[Epoch 9/200] [Batch 66/169] [D loss: 0.642275] [G loss: 0.812576]\n",
      "[Epoch 9/200] [Batch 67/169] [D loss: 0.628470] [G loss: 0.802193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 68/169] [D loss: 0.632479] [G loss: 0.843175]\n",
      "[Epoch 9/200] [Batch 69/169] [D loss: 0.636511] [G loss: 0.816272]\n",
      "[Epoch 9/200] [Batch 70/169] [D loss: 0.616903] [G loss: 0.791139]\n",
      "[Epoch 9/200] [Batch 71/169] [D loss: 0.681088] [G loss: 0.784489]\n",
      "[Epoch 9/200] [Batch 72/169] [D loss: 0.647355] [G loss: 0.770502]\n",
      "[Epoch 9/200] [Batch 73/169] [D loss: 0.669817] [G loss: 0.754249]\n",
      "[Epoch 9/200] [Batch 74/169] [D loss: 0.709759] [G loss: 0.768369]\n",
      "[Epoch 9/200] [Batch 75/169] [D loss: 0.682325] [G loss: 0.721835]\n",
      "[Epoch 9/200] [Batch 76/169] [D loss: 0.640329] [G loss: 0.727060]\n",
      "[Epoch 9/200] [Batch 77/169] [D loss: 0.672390] [G loss: 0.756357]\n",
      "[Epoch 9/200] [Batch 78/169] [D loss: 0.663801] [G loss: 0.766199]\n",
      "[Epoch 9/200] [Batch 79/169] [D loss: 0.668997] [G loss: 0.794335]\n",
      "[Epoch 9/200] [Batch 80/169] [D loss: 0.657532] [G loss: 0.841319]\n",
      "[Epoch 9/200] [Batch 81/169] [D loss: 0.649736] [G loss: 0.820599]\n",
      "[Epoch 9/200] [Batch 82/169] [D loss: 0.626793] [G loss: 0.869989]\n",
      "[Epoch 9/200] [Batch 83/169] [D loss: 0.618814] [G loss: 0.800746]\n",
      "[Epoch 9/200] [Batch 84/169] [D loss: 0.630637] [G loss: 0.791629]\n",
      "[Epoch 9/200] [Batch 85/169] [D loss: 0.598166] [G loss: 0.854715]\n",
      "[Epoch 9/200] [Batch 86/169] [D loss: 0.620139] [G loss: 0.819128]\n",
      "[Epoch 9/200] [Batch 87/169] [D loss: 0.617286] [G loss: 0.777271]\n",
      "[Epoch 9/200] [Batch 88/169] [D loss: 0.614233] [G loss: 0.780029]\n",
      "[Epoch 9/200] [Batch 89/169] [D loss: 0.646967] [G loss: 0.729930]\n",
      "[Epoch 9/200] [Batch 90/169] [D loss: 0.666240] [G loss: 0.745113]\n",
      "[Epoch 9/200] [Batch 91/169] [D loss: 0.640432] [G loss: 0.731024]\n",
      "[Epoch 9/200] [Batch 92/169] [D loss: 0.663694] [G loss: 0.671139]\n",
      "[Epoch 9/200] [Batch 93/169] [D loss: 0.705660] [G loss: 0.586719]\n",
      "[Epoch 9/200] [Batch 94/169] [D loss: 0.766380] [G loss: 0.676991]\n",
      "[Epoch 9/200] [Batch 95/169] [D loss: 0.665150] [G loss: 0.655712]\n",
      "[Epoch 9/200] [Batch 96/169] [D loss: 0.712007] [G loss: 0.701421]\n",
      "[Epoch 9/200] [Batch 97/169] [D loss: 0.658421] [G loss: 0.902388]\n",
      "[Epoch 9/200] [Batch 98/169] [D loss: 0.633791] [G loss: 1.011714]\n",
      "[Epoch 9/200] [Batch 99/169] [D loss: 0.557843] [G loss: 1.150337]\n",
      "[Epoch 9/200] [Batch 100/169] [D loss: 0.524513] [G loss: 0.954652]\n",
      "[Epoch 9/200] [Batch 101/169] [D loss: 0.601479] [G loss: 0.776220]\n",
      "[Epoch 9/200] [Batch 102/169] [D loss: 0.655302] [G loss: 0.639840]\n",
      "[Epoch 9/200] [Batch 103/169] [D loss: 0.647757] [G loss: 0.647003]\n",
      "[Epoch 9/200] [Batch 104/169] [D loss: 0.651444] [G loss: 0.617676]\n",
      "[Epoch 9/200] [Batch 105/169] [D loss: 0.666199] [G loss: 0.686535]\n",
      "[Epoch 9/200] [Batch 106/169] [D loss: 0.693840] [G loss: 0.644114]\n",
      "[Epoch 9/200] [Batch 107/169] [D loss: 0.694237] [G loss: 0.748400]\n",
      "[Epoch 9/200] [Batch 108/169] [D loss: 0.667531] [G loss: 0.813630]\n",
      "[Epoch 9/200] [Batch 109/169] [D loss: 0.651980] [G loss: 0.753093]\n",
      "[Epoch 9/200] [Batch 110/169] [D loss: 0.690825] [G loss: 0.773023]\n",
      "[Epoch 9/200] [Batch 111/169] [D loss: 0.639385] [G loss: 0.794821]\n",
      "[Epoch 9/200] [Batch 112/169] [D loss: 0.643831] [G loss: 0.769833]\n",
      "[Epoch 9/200] [Batch 113/169] [D loss: 0.636565] [G loss: 0.812664]\n",
      "[Epoch 9/200] [Batch 114/169] [D loss: 0.632989] [G loss: 0.872897]\n",
      "[Epoch 9/200] [Batch 115/169] [D loss: 0.640858] [G loss: 0.787337]\n",
      "[Epoch 9/200] [Batch 116/169] [D loss: 0.587939] [G loss: 0.876251]\n",
      "[Epoch 9/200] [Batch 117/169] [D loss: 0.641164] [G loss: 0.782392]\n",
      "[Epoch 9/200] [Batch 118/169] [D loss: 0.632678] [G loss: 0.900790]\n",
      "[Epoch 9/200] [Batch 119/169] [D loss: 0.643010] [G loss: 0.796353]\n",
      "[Epoch 9/200] [Batch 120/169] [D loss: 0.626418] [G loss: 0.828603]\n",
      "[Epoch 9/200] [Batch 121/169] [D loss: 0.631660] [G loss: 0.820064]\n",
      "[Epoch 9/200] [Batch 122/169] [D loss: 0.654663] [G loss: 0.819257]\n",
      "[Epoch 9/200] [Batch 123/169] [D loss: 0.669983] [G loss: 0.844156]\n",
      "[Epoch 9/200] [Batch 124/169] [D loss: 0.645184] [G loss: 0.825170]\n",
      "[Epoch 9/200] [Batch 125/169] [D loss: 0.619180] [G loss: 0.837200]\n",
      "[Epoch 9/200] [Batch 126/169] [D loss: 0.645226] [G loss: 0.768028]\n",
      "[Epoch 9/200] [Batch 127/169] [D loss: 0.671948] [G loss: 0.763886]\n",
      "[Epoch 9/200] [Batch 128/169] [D loss: 0.627036] [G loss: 0.748570]\n",
      "[Epoch 9/200] [Batch 129/169] [D loss: 0.661403] [G loss: 0.703901]\n",
      "[Epoch 9/200] [Batch 130/169] [D loss: 0.637811] [G loss: 0.760883]\n",
      "[Epoch 9/200] [Batch 131/169] [D loss: 0.644275] [G loss: 0.722685]\n",
      "[Epoch 9/200] [Batch 132/169] [D loss: 0.655873] [G loss: 0.751414]\n",
      "[Epoch 9/200] [Batch 133/169] [D loss: 0.673770] [G loss: 0.719752]\n",
      "[Epoch 9/200] [Batch 134/169] [D loss: 0.693134] [G loss: 0.711858]\n",
      "[Epoch 9/200] [Batch 135/169] [D loss: 0.643244] [G loss: 0.718711]\n",
      "[Epoch 9/200] [Batch 136/169] [D loss: 0.666180] [G loss: 0.696743]\n",
      "[Epoch 9/200] [Batch 137/169] [D loss: 0.702374] [G loss: 0.749313]\n",
      "[Epoch 9/200] [Batch 138/169] [D loss: 0.646842] [G loss: 0.763426]\n",
      "[Epoch 9/200] [Batch 139/169] [D loss: 0.683423] [G loss: 0.783454]\n",
      "[Epoch 9/200] [Batch 140/169] [D loss: 0.683303] [G loss: 0.718750]\n",
      "[Epoch 9/200] [Batch 141/169] [D loss: 0.644646] [G loss: 0.764923]\n",
      "[Epoch 9/200] [Batch 142/169] [D loss: 0.697227] [G loss: 0.684306]\n",
      "[Epoch 9/200] [Batch 143/169] [D loss: 0.666921] [G loss: 0.733982]\n",
      "[Epoch 9/200] [Batch 144/169] [D loss: 0.632744] [G loss: 0.743618]\n",
      "[Epoch 9/200] [Batch 145/169] [D loss: 0.662957] [G loss: 0.753076]\n",
      "[Epoch 9/200] [Batch 146/169] [D loss: 0.613674] [G loss: 0.778283]\n",
      "[Epoch 9/200] [Batch 147/169] [D loss: 0.657053] [G loss: 0.793181]\n",
      "[Epoch 9/200] [Batch 148/169] [D loss: 0.660383] [G loss: 0.775752]\n",
      "[Epoch 9/200] [Batch 149/169] [D loss: 0.655749] [G loss: 0.797488]\n",
      "[Epoch 9/200] [Batch 150/169] [D loss: 0.670444] [G loss: 0.705649]\n",
      "[Epoch 9/200] [Batch 151/169] [D loss: 0.690226] [G loss: 0.783955]\n",
      "[Epoch 9/200] [Batch 152/169] [D loss: 0.653180] [G loss: 0.691587]\n",
      "[Epoch 9/200] [Batch 153/169] [D loss: 0.647834] [G loss: 0.759531]\n",
      "[Epoch 9/200] [Batch 154/169] [D loss: 0.656123] [G loss: 0.779642]\n",
      "[Epoch 9/200] [Batch 155/169] [D loss: 0.616461] [G loss: 0.701687]\n",
      "[Epoch 9/200] [Batch 156/169] [D loss: 0.643282] [G loss: 0.739316]\n",
      "[Epoch 9/200] [Batch 157/169] [D loss: 0.639363] [G loss: 0.789960]\n",
      "[Epoch 9/200] [Batch 158/169] [D loss: 0.650396] [G loss: 0.745903]\n",
      "[Epoch 9/200] [Batch 159/169] [D loss: 0.639000] [G loss: 0.776079]\n",
      "[Epoch 9/200] [Batch 160/169] [D loss: 0.627686] [G loss: 0.769138]\n",
      "[Epoch 9/200] [Batch 161/169] [D loss: 0.649643] [G loss: 0.792324]\n",
      "[Epoch 9/200] [Batch 162/169] [D loss: 0.645346] [G loss: 0.770418]\n",
      "[Epoch 9/200] [Batch 163/169] [D loss: 0.640424] [G loss: 0.774687]\n",
      "[Epoch 9/200] [Batch 164/169] [D loss: 0.646849] [G loss: 0.818304]\n",
      "[Epoch 9/200] [Batch 165/169] [D loss: 0.690496] [G loss: 0.790879]\n",
      "[Epoch 9/200] [Batch 166/169] [D loss: 0.671898] [G loss: 0.740554]\n",
      "[Epoch 9/200] [Batch 167/169] [D loss: 0.661769] [G loss: 0.771839]\n",
      "[Epoch 9/200] [Batch 168/169] [D loss: 0.700906] [G loss: 0.747455]\n",
      "[Epoch 10/200] [Batch 0/169] [D loss: 0.672847] [G loss: 0.763556]\n",
      "[Epoch 10/200] [Batch 1/169] [D loss: 0.662482] [G loss: 0.771004]\n",
      "[Epoch 10/200] [Batch 2/169] [D loss: 0.650983] [G loss: 0.760587]\n",
      "[Epoch 10/200] [Batch 3/169] [D loss: 0.650533] [G loss: 0.805318]\n",
      "[Epoch 10/200] [Batch 4/169] [D loss: 0.673709] [G loss: 0.711287]\n",
      "[Epoch 10/200] [Batch 5/169] [D loss: 0.665727] [G loss: 0.817099]\n",
      "[Epoch 10/200] [Batch 6/169] [D loss: 0.640881] [G loss: 0.789182]\n",
      "[Epoch 10/200] [Batch 7/169] [D loss: 0.660322] [G loss: 0.855326]\n",
      "[Epoch 10/200] [Batch 8/169] [D loss: 0.675934] [G loss: 0.779226]\n",
      "[Epoch 10/200] [Batch 9/169] [D loss: 0.632664] [G loss: 0.758390]\n",
      "[Epoch 10/200] [Batch 10/169] [D loss: 0.660707] [G loss: 0.812908]\n",
      "[Epoch 10/200] [Batch 11/169] [D loss: 0.712789] [G loss: 0.736571]\n",
      "[Epoch 10/200] [Batch 12/169] [D loss: 0.659080] [G loss: 0.752721]\n",
      "[Epoch 10/200] [Batch 13/169] [D loss: 0.660599] [G loss: 0.700191]\n",
      "[Epoch 10/200] [Batch 14/169] [D loss: 0.688261] [G loss: 0.694581]\n",
      "[Epoch 10/200] [Batch 15/169] [D loss: 0.671692] [G loss: 0.717031]\n",
      "[Epoch 10/200] [Batch 16/169] [D loss: 0.722127] [G loss: 0.742561]\n",
      "[Epoch 10/200] [Batch 17/169] [D loss: 0.692915] [G loss: 0.876243]\n",
      "[Epoch 10/200] [Batch 18/169] [D loss: 0.630475] [G loss: 0.891508]\n",
      "[Epoch 10/200] [Batch 19/169] [D loss: 0.658328] [G loss: 0.875497]\n",
      "[Epoch 10/200] [Batch 20/169] [D loss: 0.684894] [G loss: 0.857696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 21/169] [D loss: 0.650110] [G loss: 0.761378]\n",
      "[Epoch 10/200] [Batch 22/169] [D loss: 0.662632] [G loss: 0.785760]\n",
      "[Epoch 10/200] [Batch 23/169] [D loss: 0.665291] [G loss: 0.753804]\n",
      "[Epoch 10/200] [Batch 24/169] [D loss: 0.650778] [G loss: 0.733608]\n",
      "[Epoch 10/200] [Batch 25/169] [D loss: 0.621722] [G loss: 0.727078]\n",
      "[Epoch 10/200] [Batch 26/169] [D loss: 0.661007] [G loss: 0.749210]\n",
      "[Epoch 10/200] [Batch 27/169] [D loss: 0.644830] [G loss: 0.696252]\n",
      "[Epoch 10/200] [Batch 28/169] [D loss: 0.680258] [G loss: 0.677718]\n",
      "[Epoch 10/200] [Batch 29/169] [D loss: 0.650414] [G loss: 0.718722]\n",
      "[Epoch 10/200] [Batch 30/169] [D loss: 0.669900] [G loss: 0.739917]\n",
      "[Epoch 10/200] [Batch 31/169] [D loss: 0.639859] [G loss: 0.776463]\n",
      "[Epoch 10/200] [Batch 32/169] [D loss: 0.648585] [G loss: 0.815711]\n",
      "[Epoch 10/200] [Batch 33/169] [D loss: 0.666134] [G loss: 0.832348]\n",
      "[Epoch 10/200] [Batch 34/169] [D loss: 0.643441] [G loss: 0.788287]\n",
      "[Epoch 10/200] [Batch 35/169] [D loss: 0.670532] [G loss: 0.772854]\n",
      "[Epoch 10/200] [Batch 36/169] [D loss: 0.657783] [G loss: 0.793476]\n",
      "[Epoch 10/200] [Batch 37/169] [D loss: 0.648726] [G loss: 0.796452]\n",
      "[Epoch 10/200] [Batch 38/169] [D loss: 0.644466] [G loss: 0.788126]\n",
      "[Epoch 10/200] [Batch 39/169] [D loss: 0.620941] [G loss: 0.802096]\n",
      "[Epoch 10/200] [Batch 40/169] [D loss: 0.667851] [G loss: 0.771134]\n",
      "[Epoch 10/200] [Batch 41/169] [D loss: 0.630285] [G loss: 0.746150]\n",
      "[Epoch 10/200] [Batch 42/169] [D loss: 0.644912] [G loss: 0.777468]\n",
      "[Epoch 10/200] [Batch 43/169] [D loss: 0.629507] [G loss: 0.813956]\n",
      "[Epoch 10/200] [Batch 44/169] [D loss: 0.657438] [G loss: 0.769052]\n",
      "[Epoch 10/200] [Batch 45/169] [D loss: 0.673200] [G loss: 0.747589]\n",
      "[Epoch 10/200] [Batch 46/169] [D loss: 0.652998] [G loss: 0.707849]\n",
      "[Epoch 10/200] [Batch 47/169] [D loss: 0.692676] [G loss: 0.737300]\n",
      "[Epoch 10/200] [Batch 48/169] [D loss: 0.691976] [G loss: 0.732036]\n",
      "[Epoch 10/200] [Batch 49/169] [D loss: 0.703987] [G loss: 0.667013]\n",
      "[Epoch 10/200] [Batch 50/169] [D loss: 0.699873] [G loss: 0.786121]\n",
      "[Epoch 10/200] [Batch 51/169] [D loss: 0.664397] [G loss: 0.805778]\n",
      "[Epoch 10/200] [Batch 52/169] [D loss: 0.686960] [G loss: 0.821338]\n",
      "[Epoch 10/200] [Batch 53/169] [D loss: 0.656400] [G loss: 0.791857]\n",
      "[Epoch 10/200] [Batch 54/169] [D loss: 0.642666] [G loss: 0.760234]\n",
      "[Epoch 10/200] [Batch 55/169] [D loss: 0.630101] [G loss: 0.793470]\n",
      "[Epoch 10/200] [Batch 56/169] [D loss: 0.624846] [G loss: 0.813054]\n",
      "[Epoch 10/200] [Batch 57/169] [D loss: 0.637634] [G loss: 0.773807]\n",
      "[Epoch 10/200] [Batch 58/169] [D loss: 0.631383] [G loss: 0.772455]\n",
      "[Epoch 10/200] [Batch 59/169] [D loss: 0.647829] [G loss: 0.800121]\n",
      "[Epoch 10/200] [Batch 60/169] [D loss: 0.615458] [G loss: 0.781446]\n",
      "[Epoch 10/200] [Batch 61/169] [D loss: 0.633451] [G loss: 0.789681]\n",
      "[Epoch 10/200] [Batch 62/169] [D loss: 0.632553] [G loss: 0.836747]\n",
      "[Epoch 10/200] [Batch 63/169] [D loss: 0.624904] [G loss: 0.827680]\n",
      "[Epoch 10/200] [Batch 64/169] [D loss: 0.661421] [G loss: 0.784417]\n",
      "[Epoch 10/200] [Batch 65/169] [D loss: 0.634788] [G loss: 0.782930]\n",
      "[Epoch 10/200] [Batch 66/169] [D loss: 0.642669] [G loss: 0.802719]\n",
      "[Epoch 10/200] [Batch 67/169] [D loss: 0.654338] [G loss: 0.778203]\n",
      "[Epoch 10/200] [Batch 68/169] [D loss: 0.668723] [G loss: 0.734879]\n",
      "[Epoch 10/200] [Batch 69/169] [D loss: 0.695734] [G loss: 0.751711]\n",
      "[Epoch 10/200] [Batch 70/169] [D loss: 0.702482] [G loss: 0.715891]\n",
      "[Epoch 10/200] [Batch 71/169] [D loss: 0.709685] [G loss: 0.743395]\n",
      "[Epoch 10/200] [Batch 72/169] [D loss: 0.679075] [G loss: 0.882928]\n",
      "[Epoch 10/200] [Batch 73/169] [D loss: 0.651352] [G loss: 0.890614]\n",
      "[Epoch 10/200] [Batch 74/169] [D loss: 0.593845] [G loss: 0.882042]\n",
      "[Epoch 10/200] [Batch 75/169] [D loss: 0.617382] [G loss: 0.825240]\n",
      "[Epoch 10/200] [Batch 76/169] [D loss: 0.629479] [G loss: 0.822293]\n",
      "[Epoch 10/200] [Batch 77/169] [D loss: 0.656072] [G loss: 0.671077]\n",
      "[Epoch 10/200] [Batch 78/169] [D loss: 0.696382] [G loss: 0.690945]\n",
      "[Epoch 10/200] [Batch 79/169] [D loss: 0.715411] [G loss: 0.717571]\n",
      "[Epoch 10/200] [Batch 80/169] [D loss: 0.704591] [G loss: 0.773594]\n",
      "[Epoch 10/200] [Batch 81/169] [D loss: 0.684545] [G loss: 0.741485]\n",
      "[Epoch 10/200] [Batch 82/169] [D loss: 0.679312] [G loss: 0.751131]\n",
      "[Epoch 10/200] [Batch 83/169] [D loss: 0.721375] [G loss: 0.780615]\n",
      "[Epoch 10/200] [Batch 84/169] [D loss: 0.695084] [G loss: 0.756738]\n",
      "[Epoch 10/200] [Batch 85/169] [D loss: 0.659655] [G loss: 0.747733]\n",
      "[Epoch 10/200] [Batch 86/169] [D loss: 0.646320] [G loss: 0.676036]\n",
      "[Epoch 10/200] [Batch 87/169] [D loss: 0.648084] [G loss: 0.736193]\n",
      "[Epoch 10/200] [Batch 88/169] [D loss: 0.635939] [G loss: 0.779598]\n",
      "[Epoch 10/200] [Batch 89/169] [D loss: 0.620165] [G loss: 0.802546]\n",
      "[Epoch 10/200] [Batch 90/169] [D loss: 0.633023] [G loss: 0.817270]\n",
      "[Epoch 10/200] [Batch 91/169] [D loss: 0.622709] [G loss: 0.786331]\n",
      "[Epoch 10/200] [Batch 92/169] [D loss: 0.654779] [G loss: 0.778593]\n",
      "[Epoch 10/200] [Batch 93/169] [D loss: 0.621731] [G loss: 0.835190]\n",
      "[Epoch 10/200] [Batch 94/169] [D loss: 0.623403] [G loss: 0.754532]\n",
      "[Epoch 10/200] [Batch 95/169] [D loss: 0.645597] [G loss: 0.801955]\n",
      "[Epoch 10/200] [Batch 96/169] [D loss: 0.692478] [G loss: 0.760351]\n",
      "[Epoch 10/200] [Batch 97/169] [D loss: 0.684553] [G loss: 0.688396]\n",
      "[Epoch 10/200] [Batch 98/169] [D loss: 0.701645] [G loss: 0.718094]\n",
      "[Epoch 10/200] [Batch 99/169] [D loss: 0.684056] [G loss: 0.755533]\n",
      "[Epoch 10/200] [Batch 100/169] [D loss: 0.689502] [G loss: 0.811862]\n",
      "[Epoch 10/200] [Batch 101/169] [D loss: 0.674718] [G loss: 0.844723]\n",
      "[Epoch 10/200] [Batch 102/169] [D loss: 0.686624] [G loss: 0.857555]\n",
      "[Epoch 10/200] [Batch 103/169] [D loss: 0.649486] [G loss: 0.807893]\n",
      "[Epoch 10/200] [Batch 104/169] [D loss: 0.661414] [G loss: 0.782739]\n",
      "[Epoch 10/200] [Batch 105/169] [D loss: 0.645373] [G loss: 0.839175]\n",
      "[Epoch 10/200] [Batch 106/169] [D loss: 0.612325] [G loss: 0.792064]\n",
      "[Epoch 10/200] [Batch 107/169] [D loss: 0.632945] [G loss: 0.731579]\n",
      "[Epoch 10/200] [Batch 108/169] [D loss: 0.678167] [G loss: 0.723842]\n",
      "[Epoch 10/200] [Batch 109/169] [D loss: 0.672604] [G loss: 0.710870]\n",
      "[Epoch 10/200] [Batch 110/169] [D loss: 0.680305] [G loss: 0.722408]\n",
      "[Epoch 10/200] [Batch 111/169] [D loss: 0.676512] [G loss: 0.729482]\n",
      "[Epoch 10/200] [Batch 112/169] [D loss: 0.673672] [G loss: 0.725749]\n",
      "[Epoch 10/200] [Batch 113/169] [D loss: 0.657996] [G loss: 0.747366]\n",
      "[Epoch 10/200] [Batch 114/169] [D loss: 0.668234] [G loss: 0.780309]\n",
      "[Epoch 10/200] [Batch 115/169] [D loss: 0.655534] [G loss: 0.705042]\n",
      "[Epoch 10/200] [Batch 116/169] [D loss: 0.660786] [G loss: 0.721937]\n",
      "[Epoch 10/200] [Batch 117/169] [D loss: 0.685766] [G loss: 0.725101]\n",
      "[Epoch 10/200] [Batch 118/169] [D loss: 0.691156] [G loss: 0.745900]\n",
      "[Epoch 10/200] [Batch 119/169] [D loss: 0.664903] [G loss: 0.771524]\n",
      "[Epoch 10/200] [Batch 120/169] [D loss: 0.666784] [G loss: 0.715324]\n",
      "[Epoch 10/200] [Batch 121/169] [D loss: 0.655441] [G loss: 0.831076]\n",
      "[Epoch 10/200] [Batch 122/169] [D loss: 0.652365] [G loss: 0.789135]\n",
      "[Epoch 10/200] [Batch 123/169] [D loss: 0.656727] [G loss: 0.781258]\n",
      "[Epoch 10/200] [Batch 124/169] [D loss: 0.637208] [G loss: 0.737213]\n",
      "[Epoch 10/200] [Batch 125/169] [D loss: 0.662882] [G loss: 0.794496]\n",
      "[Epoch 10/200] [Batch 126/169] [D loss: 0.653216] [G loss: 0.791071]\n",
      "[Epoch 10/200] [Batch 127/169] [D loss: 0.633487] [G loss: 0.771139]\n",
      "[Epoch 10/200] [Batch 128/169] [D loss: 0.680589] [G loss: 0.721516]\n",
      "[Epoch 10/200] [Batch 129/169] [D loss: 0.658525] [G loss: 0.828980]\n",
      "[Epoch 10/200] [Batch 130/169] [D loss: 0.653987] [G loss: 0.834695]\n",
      "[Epoch 10/200] [Batch 131/169] [D loss: 0.629318] [G loss: 0.801192]\n",
      "[Epoch 10/200] [Batch 132/169] [D loss: 0.678823] [G loss: 0.792159]\n",
      "[Epoch 10/200] [Batch 133/169] [D loss: 0.635920] [G loss: 0.843338]\n",
      "[Epoch 10/200] [Batch 134/169] [D loss: 0.680578] [G loss: 0.743030]\n",
      "[Epoch 10/200] [Batch 135/169] [D loss: 0.658298] [G loss: 0.811792]\n",
      "[Epoch 10/200] [Batch 136/169] [D loss: 0.652479] [G loss: 0.805525]\n",
      "[Epoch 10/200] [Batch 137/169] [D loss: 0.665752] [G loss: 0.792488]\n",
      "[Epoch 10/200] [Batch 138/169] [D loss: 0.651649] [G loss: 0.760537]\n",
      "[Epoch 10/200] [Batch 139/169] [D loss: 0.652700] [G loss: 0.786126]\n",
      "[Epoch 10/200] [Batch 140/169] [D loss: 0.625101] [G loss: 0.822688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 141/169] [D loss: 0.660954] [G loss: 0.763708]\n",
      "[Epoch 10/200] [Batch 142/169] [D loss: 0.659109] [G loss: 0.764199]\n",
      "[Epoch 10/200] [Batch 143/169] [D loss: 0.623944] [G loss: 0.850847]\n",
      "[Epoch 10/200] [Batch 144/169] [D loss: 0.657224] [G loss: 0.793751]\n",
      "[Epoch 10/200] [Batch 145/169] [D loss: 0.661824] [G loss: 0.779063]\n",
      "[Epoch 10/200] [Batch 146/169] [D loss: 0.660489] [G loss: 0.761831]\n",
      "[Epoch 10/200] [Batch 147/169] [D loss: 0.661002] [G loss: 0.711165]\n",
      "[Epoch 10/200] [Batch 148/169] [D loss: 0.696342] [G loss: 0.709934]\n",
      "[Epoch 10/200] [Batch 149/169] [D loss: 0.651344] [G loss: 0.755969]\n",
      "[Epoch 10/200] [Batch 150/169] [D loss: 0.661899] [G loss: 0.700381]\n",
      "[Epoch 10/200] [Batch 151/169] [D loss: 0.652318] [G loss: 0.724002]\n",
      "[Epoch 10/200] [Batch 152/169] [D loss: 0.666759] [G loss: 0.780864]\n",
      "[Epoch 10/200] [Batch 153/169] [D loss: 0.660221] [G loss: 0.823929]\n",
      "[Epoch 10/200] [Batch 154/169] [D loss: 0.629234] [G loss: 0.772312]\n",
      "[Epoch 10/200] [Batch 155/169] [D loss: 0.645253] [G loss: 0.756224]\n",
      "[Epoch 10/200] [Batch 156/169] [D loss: 0.643302] [G loss: 0.746875]\n",
      "[Epoch 10/200] [Batch 157/169] [D loss: 0.613275] [G loss: 0.800771]\n",
      "[Epoch 10/200] [Batch 158/169] [D loss: 0.663322] [G loss: 0.778696]\n",
      "[Epoch 10/200] [Batch 159/169] [D loss: 0.684764] [G loss: 0.789413]\n",
      "[Epoch 10/200] [Batch 160/169] [D loss: 0.645875] [G loss: 0.790659]\n",
      "[Epoch 10/200] [Batch 161/169] [D loss: 0.619885] [G loss: 0.751202]\n",
      "[Epoch 10/200] [Batch 162/169] [D loss: 0.661973] [G loss: 0.778754]\n",
      "[Epoch 10/200] [Batch 163/169] [D loss: 0.655035] [G loss: 0.787816]\n",
      "[Epoch 10/200] [Batch 164/169] [D loss: 0.661036] [G loss: 0.794500]\n",
      "[Epoch 10/200] [Batch 165/169] [D loss: 0.643588] [G loss: 0.760676]\n",
      "[Epoch 10/200] [Batch 166/169] [D loss: 0.660520] [G loss: 0.804670]\n",
      "[Epoch 10/200] [Batch 167/169] [D loss: 0.624168] [G loss: 0.792535]\n",
      "[Epoch 10/200] [Batch 168/169] [D loss: 0.621151] [G loss: 0.858228]\n",
      "[Epoch 11/200] [Batch 0/169] [D loss: 0.639900] [G loss: 0.803127]\n",
      "[Epoch 11/200] [Batch 1/169] [D loss: 0.629924] [G loss: 0.781452]\n",
      "[Epoch 11/200] [Batch 2/169] [D loss: 0.684737] [G loss: 0.822381]\n",
      "[Epoch 11/200] [Batch 3/169] [D loss: 0.679742] [G loss: 0.743271]\n",
      "[Epoch 11/200] [Batch 4/169] [D loss: 0.675801] [G loss: 0.761306]\n",
      "[Epoch 11/200] [Batch 5/169] [D loss: 0.677758] [G loss: 0.865831]\n",
      "[Epoch 11/200] [Batch 6/169] [D loss: 0.681356] [G loss: 0.881611]\n",
      "[Epoch 11/200] [Batch 7/169] [D loss: 0.640869] [G loss: 0.897052]\n",
      "[Epoch 11/200] [Batch 8/169] [D loss: 0.639009] [G loss: 0.884401]\n",
      "[Epoch 11/200] [Batch 9/169] [D loss: 0.658774] [G loss: 0.821877]\n",
      "[Epoch 11/200] [Batch 10/169] [D loss: 0.691131] [G loss: 0.796063]\n",
      "[Epoch 11/200] [Batch 11/169] [D loss: 0.638782] [G loss: 0.779223]\n",
      "[Epoch 11/200] [Batch 12/169] [D loss: 0.648055] [G loss: 0.709807]\n",
      "[Epoch 11/200] [Batch 13/169] [D loss: 0.634177] [G loss: 0.723641]\n",
      "[Epoch 11/200] [Batch 14/169] [D loss: 0.639406] [G loss: 0.740956]\n",
      "[Epoch 11/200] [Batch 15/169] [D loss: 0.649058] [G loss: 0.736184]\n",
      "[Epoch 11/200] [Batch 16/169] [D loss: 0.628298] [G loss: 0.699550]\n",
      "[Epoch 11/200] [Batch 17/169] [D loss: 0.616186] [G loss: 0.792285]\n",
      "[Epoch 11/200] [Batch 18/169] [D loss: 0.653746] [G loss: 0.829874]\n",
      "[Epoch 11/200] [Batch 19/169] [D loss: 0.615006] [G loss: 0.817221]\n",
      "[Epoch 11/200] [Batch 20/169] [D loss: 0.633097] [G loss: 0.714588]\n",
      "[Epoch 11/200] [Batch 21/169] [D loss: 0.680630] [G loss: 0.737350]\n",
      "[Epoch 11/200] [Batch 22/169] [D loss: 0.624033] [G loss: 0.711757]\n",
      "[Epoch 11/200] [Batch 23/169] [D loss: 0.673825] [G loss: 0.781010]\n",
      "[Epoch 11/200] [Batch 24/169] [D loss: 0.671288] [G loss: 0.748363]\n",
      "[Epoch 11/200] [Batch 25/169] [D loss: 0.641760] [G loss: 0.729637]\n",
      "[Epoch 11/200] [Batch 26/169] [D loss: 0.622540] [G loss: 0.713463]\n",
      "[Epoch 11/200] [Batch 27/169] [D loss: 0.646999] [G loss: 0.700318]\n",
      "[Epoch 11/200] [Batch 28/169] [D loss: 0.657848] [G loss: 0.733622]\n",
      "[Epoch 11/200] [Batch 29/169] [D loss: 0.649792] [G loss: 0.766681]\n",
      "[Epoch 11/200] [Batch 30/169] [D loss: 0.670419] [G loss: 0.768587]\n",
      "[Epoch 11/200] [Batch 31/169] [D loss: 0.665940] [G loss: 0.765234]\n",
      "[Epoch 11/200] [Batch 32/169] [D loss: 0.643295] [G loss: 0.753059]\n",
      "[Epoch 11/200] [Batch 33/169] [D loss: 0.642089] [G loss: 0.795604]\n",
      "[Epoch 11/200] [Batch 34/169] [D loss: 0.662539] [G loss: 0.748558]\n",
      "[Epoch 11/200] [Batch 35/169] [D loss: 0.690106] [G loss: 0.739824]\n",
      "[Epoch 11/200] [Batch 36/169] [D loss: 0.664055] [G loss: 0.756155]\n",
      "[Epoch 11/200] [Batch 37/169] [D loss: 0.674601] [G loss: 0.732182]\n",
      "[Epoch 11/200] [Batch 38/169] [D loss: 0.662110] [G loss: 0.792133]\n",
      "[Epoch 11/200] [Batch 39/169] [D loss: 0.665617] [G loss: 0.791117]\n",
      "[Epoch 11/200] [Batch 40/169] [D loss: 0.668370] [G loss: 0.781500]\n",
      "[Epoch 11/200] [Batch 41/169] [D loss: 0.629967] [G loss: 0.731042]\n",
      "[Epoch 11/200] [Batch 42/169] [D loss: 0.644504] [G loss: 0.730250]\n",
      "[Epoch 11/200] [Batch 43/169] [D loss: 0.643739] [G loss: 0.729384]\n",
      "[Epoch 11/200] [Batch 44/169] [D loss: 0.595628] [G loss: 0.737034]\n",
      "[Epoch 11/200] [Batch 45/169] [D loss: 0.666811] [G loss: 0.780526]\n",
      "[Epoch 11/200] [Batch 46/169] [D loss: 0.691830] [G loss: 0.747156]\n",
      "[Epoch 11/200] [Batch 47/169] [D loss: 0.659485] [G loss: 0.766761]\n",
      "[Epoch 11/200] [Batch 48/169] [D loss: 0.685172] [G loss: 0.733966]\n",
      "[Epoch 11/200] [Batch 49/169] [D loss: 0.635924] [G loss: 0.696145]\n",
      "[Epoch 11/200] [Batch 50/169] [D loss: 0.691423] [G loss: 0.769526]\n",
      "[Epoch 11/200] [Batch 51/169] [D loss: 0.708587] [G loss: 0.767884]\n",
      "[Epoch 11/200] [Batch 52/169] [D loss: 0.680298] [G loss: 0.771791]\n",
      "[Epoch 11/200] [Batch 53/169] [D loss: 0.678700] [G loss: 0.808382]\n",
      "[Epoch 11/200] [Batch 54/169] [D loss: 0.670816] [G loss: 0.808118]\n",
      "[Epoch 11/200] [Batch 55/169] [D loss: 0.650334] [G loss: 0.783897]\n",
      "[Epoch 11/200] [Batch 56/169] [D loss: 0.632687] [G loss: 0.803461]\n",
      "[Epoch 11/200] [Batch 57/169] [D loss: 0.658248] [G loss: 0.787107]\n",
      "[Epoch 11/200] [Batch 58/169] [D loss: 0.609235] [G loss: 0.848939]\n",
      "[Epoch 11/200] [Batch 59/169] [D loss: 0.643610] [G loss: 0.792156]\n",
      "[Epoch 11/200] [Batch 60/169] [D loss: 0.638790] [G loss: 0.799085]\n",
      "[Epoch 11/200] [Batch 61/169] [D loss: 0.626567] [G loss: 0.752193]\n",
      "[Epoch 11/200] [Batch 62/169] [D loss: 0.632440] [G loss: 0.764191]\n",
      "[Epoch 11/200] [Batch 63/169] [D loss: 0.627448] [G loss: 0.826931]\n",
      "[Epoch 11/200] [Batch 64/169] [D loss: 0.605549] [G loss: 0.825167]\n",
      "[Epoch 11/200] [Batch 65/169] [D loss: 0.616979] [G loss: 0.817237]\n",
      "[Epoch 11/200] [Batch 66/169] [D loss: 0.605081] [G loss: 0.768218]\n",
      "[Epoch 11/200] [Batch 67/169] [D loss: 0.598792] [G loss: 0.720326]\n",
      "[Epoch 11/200] [Batch 68/169] [D loss: 0.652891] [G loss: 0.764107]\n",
      "[Epoch 11/200] [Batch 69/169] [D loss: 0.658455] [G loss: 0.757211]\n",
      "[Epoch 11/200] [Batch 70/169] [D loss: 0.635096] [G loss: 0.770737]\n",
      "[Epoch 11/200] [Batch 71/169] [D loss: 0.689821] [G loss: 0.814226]\n",
      "[Epoch 11/200] [Batch 72/169] [D loss: 0.667778] [G loss: 0.815435]\n",
      "[Epoch 11/200] [Batch 73/169] [D loss: 0.675508] [G loss: 0.840703]\n",
      "[Epoch 11/200] [Batch 74/169] [D loss: 0.674983] [G loss: 0.833444]\n",
      "[Epoch 11/200] [Batch 75/169] [D loss: 0.649909] [G loss: 0.844676]\n",
      "[Epoch 11/200] [Batch 76/169] [D loss: 0.669065] [G loss: 0.828586]\n",
      "[Epoch 11/200] [Batch 77/169] [D loss: 0.678518] [G loss: 0.824523]\n",
      "[Epoch 11/200] [Batch 78/169] [D loss: 0.687986] [G loss: 0.838722]\n",
      "[Epoch 11/200] [Batch 79/169] [D loss: 0.674602] [G loss: 0.818319]\n",
      "[Epoch 11/200] [Batch 80/169] [D loss: 0.648747] [G loss: 0.726479]\n",
      "[Epoch 11/200] [Batch 81/169] [D loss: 0.680258] [G loss: 0.747084]\n",
      "[Epoch 11/200] [Batch 82/169] [D loss: 0.695301] [G loss: 0.778516]\n",
      "[Epoch 11/200] [Batch 83/169] [D loss: 0.680461] [G loss: 0.801193]\n",
      "[Epoch 11/200] [Batch 84/169] [D loss: 0.683458] [G loss: 0.780740]\n",
      "[Epoch 11/200] [Batch 85/169] [D loss: 0.670730] [G loss: 0.789281]\n",
      "[Epoch 11/200] [Batch 86/169] [D loss: 0.687222] [G loss: 0.730903]\n",
      "[Epoch 11/200] [Batch 87/169] [D loss: 0.689449] [G loss: 0.737577]\n",
      "[Epoch 11/200] [Batch 88/169] [D loss: 0.679674] [G loss: 0.704362]\n",
      "[Epoch 11/200] [Batch 89/169] [D loss: 0.700071] [G loss: 0.723857]\n",
      "[Epoch 11/200] [Batch 90/169] [D loss: 0.684088] [G loss: 0.665573]\n",
      "[Epoch 11/200] [Batch 91/169] [D loss: 0.667764] [G loss: 0.692372]\n",
      "[Epoch 11/200] [Batch 92/169] [D loss: 0.696592] [G loss: 0.700685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 93/169] [D loss: 0.633930] [G loss: 0.744945]\n",
      "[Epoch 11/200] [Batch 94/169] [D loss: 0.678335] [G loss: 0.700272]\n",
      "[Epoch 11/200] [Batch 95/169] [D loss: 0.675618] [G loss: 0.735376]\n",
      "[Epoch 11/200] [Batch 96/169] [D loss: 0.633981] [G loss: 0.740869]\n",
      "[Epoch 11/200] [Batch 97/169] [D loss: 0.649670] [G loss: 0.777147]\n",
      "[Epoch 11/200] [Batch 98/169] [D loss: 0.609234] [G loss: 0.792956]\n",
      "[Epoch 11/200] [Batch 99/169] [D loss: 0.650934] [G loss: 0.835065]\n",
      "[Epoch 11/200] [Batch 100/169] [D loss: 0.610499] [G loss: 0.755746]\n",
      "[Epoch 11/200] [Batch 101/169] [D loss: 0.610014] [G loss: 0.822848]\n",
      "[Epoch 11/200] [Batch 102/169] [D loss: 0.613273] [G loss: 0.784838]\n",
      "[Epoch 11/200] [Batch 103/169] [D loss: 0.620109] [G loss: 0.798637]\n",
      "[Epoch 11/200] [Batch 104/169] [D loss: 0.632736] [G loss: 0.813524]\n",
      "[Epoch 11/200] [Batch 105/169] [D loss: 0.603145] [G loss: 0.850010]\n",
      "[Epoch 11/200] [Batch 106/169] [D loss: 0.611711] [G loss: 0.802853]\n",
      "[Epoch 11/200] [Batch 107/169] [D loss: 0.658042] [G loss: 0.824752]\n",
      "[Epoch 11/200] [Batch 108/169] [D loss: 0.617290] [G loss: 0.798420]\n",
      "[Epoch 11/200] [Batch 109/169] [D loss: 0.650354] [G loss: 0.785662]\n",
      "[Epoch 11/200] [Batch 110/169] [D loss: 0.659445] [G loss: 0.797103]\n",
      "[Epoch 11/200] [Batch 111/169] [D loss: 0.692368] [G loss: 0.720753]\n",
      "[Epoch 11/200] [Batch 112/169] [D loss: 0.688791] [G loss: 0.672212]\n",
      "[Epoch 11/200] [Batch 113/169] [D loss: 0.627695] [G loss: 0.876336]\n",
      "[Epoch 11/200] [Batch 114/169] [D loss: 0.617191] [G loss: 0.979261]\n",
      "[Epoch 11/200] [Batch 115/169] [D loss: 0.627357] [G loss: 0.946242]\n",
      "[Epoch 11/200] [Batch 116/169] [D loss: 0.643080] [G loss: 0.807889]\n",
      "[Epoch 11/200] [Batch 117/169] [D loss: 0.639901] [G loss: 0.801260]\n",
      "[Epoch 11/200] [Batch 118/169] [D loss: 0.638494] [G loss: 0.828368]\n",
      "[Epoch 11/200] [Batch 119/169] [D loss: 0.681570] [G loss: 0.717679]\n",
      "[Epoch 11/200] [Batch 120/169] [D loss: 0.722373] [G loss: 0.689538]\n",
      "[Epoch 11/200] [Batch 121/169] [D loss: 0.739621] [G loss: 0.700922]\n",
      "[Epoch 11/200] [Batch 122/169] [D loss: 0.700755] [G loss: 0.781438]\n",
      "[Epoch 11/200] [Batch 123/169] [D loss: 0.694942] [G loss: 0.733868]\n",
      "[Epoch 11/200] [Batch 124/169] [D loss: 0.692445] [G loss: 0.752539]\n",
      "[Epoch 11/200] [Batch 125/169] [D loss: 0.717484] [G loss: 0.790804]\n",
      "[Epoch 11/200] [Batch 126/169] [D loss: 0.697509] [G loss: 0.733671]\n",
      "[Epoch 11/200] [Batch 127/169] [D loss: 0.719717] [G loss: 0.721291]\n",
      "[Epoch 11/200] [Batch 128/169] [D loss: 0.714207] [G loss: 0.677665]\n",
      "[Epoch 11/200] [Batch 129/169] [D loss: 0.674061] [G loss: 0.813185]\n",
      "[Epoch 11/200] [Batch 130/169] [D loss: 0.692247] [G loss: 0.779600]\n",
      "[Epoch 11/200] [Batch 131/169] [D loss: 0.689098] [G loss: 0.794271]\n",
      "[Epoch 11/200] [Batch 132/169] [D loss: 0.694582] [G loss: 0.817959]\n",
      "[Epoch 11/200] [Batch 133/169] [D loss: 0.656068] [G loss: 0.806267]\n",
      "[Epoch 11/200] [Batch 134/169] [D loss: 0.665310] [G loss: 0.822176]\n",
      "[Epoch 11/200] [Batch 135/169] [D loss: 0.641565] [G loss: 0.757639]\n",
      "[Epoch 11/200] [Batch 136/169] [D loss: 0.648136] [G loss: 0.771586]\n",
      "[Epoch 11/200] [Batch 137/169] [D loss: 0.629099] [G loss: 0.781599]\n",
      "[Epoch 11/200] [Batch 138/169] [D loss: 0.623522] [G loss: 0.760091]\n",
      "[Epoch 11/200] [Batch 139/169] [D loss: 0.646171] [G loss: 0.809757]\n",
      "[Epoch 11/200] [Batch 140/169] [D loss: 0.621082] [G loss: 0.810290]\n",
      "[Epoch 11/200] [Batch 141/169] [D loss: 0.652777] [G loss: 0.760636]\n",
      "[Epoch 11/200] [Batch 142/169] [D loss: 0.630184] [G loss: 0.720324]\n",
      "[Epoch 11/200] [Batch 143/169] [D loss: 0.644314] [G loss: 0.705016]\n",
      "[Epoch 11/200] [Batch 144/169] [D loss: 0.670415] [G loss: 0.720445]\n",
      "[Epoch 11/200] [Batch 145/169] [D loss: 0.640828] [G loss: 0.747515]\n",
      "[Epoch 11/200] [Batch 146/169] [D loss: 0.667371] [G loss: 0.755665]\n",
      "[Epoch 11/200] [Batch 147/169] [D loss: 0.651814] [G loss: 0.703989]\n",
      "[Epoch 11/200] [Batch 148/169] [D loss: 0.630759] [G loss: 0.669325]\n",
      "[Epoch 11/200] [Batch 149/169] [D loss: 0.639492] [G loss: 0.738995]\n",
      "[Epoch 11/200] [Batch 150/169] [D loss: 0.634216] [G loss: 0.802732]\n",
      "[Epoch 11/200] [Batch 151/169] [D loss: 0.650987] [G loss: 0.815374]\n",
      "[Epoch 11/200] [Batch 152/169] [D loss: 0.657641] [G loss: 0.879314]\n",
      "[Epoch 11/200] [Batch 153/169] [D loss: 0.657814] [G loss: 0.899665]\n",
      "[Epoch 11/200] [Batch 154/169] [D loss: 0.627554] [G loss: 0.865190]\n",
      "[Epoch 11/200] [Batch 155/169] [D loss: 0.649309] [G loss: 0.806559]\n",
      "[Epoch 11/200] [Batch 156/169] [D loss: 0.627064] [G loss: 0.819576]\n",
      "[Epoch 11/200] [Batch 157/169] [D loss: 0.615946] [G loss: 0.874863]\n",
      "[Epoch 11/200] [Batch 158/169] [D loss: 0.648711] [G loss: 0.888154]\n",
      "[Epoch 11/200] [Batch 159/169] [D loss: 0.632363] [G loss: 0.810933]\n",
      "[Epoch 11/200] [Batch 160/169] [D loss: 0.638970] [G loss: 0.810904]\n",
      "[Epoch 11/200] [Batch 161/169] [D loss: 0.640266] [G loss: 0.784755]\n",
      "[Epoch 11/200] [Batch 162/169] [D loss: 0.616363] [G loss: 0.842345]\n",
      "[Epoch 11/200] [Batch 163/169] [D loss: 0.642476] [G loss: 0.890696]\n",
      "[Epoch 11/200] [Batch 164/169] [D loss: 0.663254] [G loss: 0.878597]\n",
      "[Epoch 11/200] [Batch 165/169] [D loss: 0.635863] [G loss: 0.824652]\n",
      "[Epoch 11/200] [Batch 166/169] [D loss: 0.641970] [G loss: 0.878759]\n",
      "[Epoch 11/200] [Batch 167/169] [D loss: 0.605639] [G loss: 0.778375]\n",
      "[Epoch 11/200] [Batch 168/169] [D loss: 0.645753] [G loss: 0.802363]\n",
      "[Epoch 12/200] [Batch 0/169] [D loss: 0.675346] [G loss: 0.727793]\n",
      "[Epoch 12/200] [Batch 1/169] [D loss: 0.696602] [G loss: 0.656914]\n",
      "[Epoch 12/200] [Batch 2/169] [D loss: 0.667972] [G loss: 0.739439]\n",
      "[Epoch 12/200] [Batch 3/169] [D loss: 0.666651] [G loss: 0.706075]\n",
      "[Epoch 12/200] [Batch 4/169] [D loss: 0.631416] [G loss: 0.698376]\n",
      "[Epoch 12/200] [Batch 5/169] [D loss: 0.659084] [G loss: 0.714472]\n",
      "[Epoch 12/200] [Batch 6/169] [D loss: 0.619118] [G loss: 0.802696]\n",
      "[Epoch 12/200] [Batch 7/169] [D loss: 0.669253] [G loss: 0.740762]\n",
      "[Epoch 12/200] [Batch 8/169] [D loss: 0.678892] [G loss: 0.728143]\n",
      "[Epoch 12/200] [Batch 9/169] [D loss: 0.656007] [G loss: 0.758148]\n",
      "[Epoch 12/200] [Batch 10/169] [D loss: 0.651478] [G loss: 0.757624]\n",
      "[Epoch 12/200] [Batch 11/169] [D loss: 0.676898] [G loss: 0.741590]\n",
      "[Epoch 12/200] [Batch 12/169] [D loss: 0.635856] [G loss: 0.763174]\n",
      "[Epoch 12/200] [Batch 13/169] [D loss: 0.611493] [G loss: 0.752329]\n",
      "[Epoch 12/200] [Batch 14/169] [D loss: 0.625293] [G loss: 0.767192]\n",
      "[Epoch 12/200] [Batch 15/169] [D loss: 0.579954] [G loss: 0.825073]\n",
      "[Epoch 12/200] [Batch 16/169] [D loss: 0.577357] [G loss: 0.853119]\n",
      "[Epoch 12/200] [Batch 17/169] [D loss: 0.614990] [G loss: 0.802141]\n",
      "[Epoch 12/200] [Batch 18/169] [D loss: 0.604717] [G loss: 0.740587]\n",
      "[Epoch 12/200] [Batch 19/169] [D loss: 0.574025] [G loss: 0.805535]\n",
      "[Epoch 12/200] [Batch 20/169] [D loss: 0.627805] [G loss: 0.763695]\n",
      "[Epoch 12/200] [Batch 21/169] [D loss: 0.627414] [G loss: 0.825590]\n",
      "[Epoch 12/200] [Batch 22/169] [D loss: 0.678615] [G loss: 0.917867]\n",
      "[Epoch 12/200] [Batch 23/169] [D loss: 0.604609] [G loss: 0.892128]\n",
      "[Epoch 12/200] [Batch 24/169] [D loss: 0.628928] [G loss: 0.889422]\n",
      "[Epoch 12/200] [Batch 25/169] [D loss: 0.621952] [G loss: 0.884689]\n",
      "[Epoch 12/200] [Batch 26/169] [D loss: 0.638307] [G loss: 0.788728]\n",
      "[Epoch 12/200] [Batch 27/169] [D loss: 0.610725] [G loss: 0.879624]\n",
      "[Epoch 12/200] [Batch 28/169] [D loss: 0.591213] [G loss: 0.878582]\n",
      "[Epoch 12/200] [Batch 29/169] [D loss: 0.593682] [G loss: 0.804267]\n",
      "[Epoch 12/200] [Batch 30/169] [D loss: 0.614087] [G loss: 0.783888]\n",
      "[Epoch 12/200] [Batch 31/169] [D loss: 0.628192] [G loss: 0.802399]\n",
      "[Epoch 12/200] [Batch 32/169] [D loss: 0.628751] [G loss: 0.842389]\n",
      "[Epoch 12/200] [Batch 33/169] [D loss: 0.624167] [G loss: 0.815525]\n",
      "[Epoch 12/200] [Batch 34/169] [D loss: 0.635145] [G loss: 0.816669]\n",
      "[Epoch 12/200] [Batch 35/169] [D loss: 0.641359] [G loss: 0.853944]\n",
      "[Epoch 12/200] [Batch 36/169] [D loss: 0.616393] [G loss: 0.886935]\n",
      "[Epoch 12/200] [Batch 37/169] [D loss: 0.635368] [G loss: 0.837750]\n",
      "[Epoch 12/200] [Batch 38/169] [D loss: 0.600596] [G loss: 0.811569]\n",
      "[Epoch 12/200] [Batch 39/169] [D loss: 0.635465] [G loss: 0.916101]\n",
      "[Epoch 12/200] [Batch 40/169] [D loss: 0.617969] [G loss: 0.860148]\n",
      "[Epoch 12/200] [Batch 41/169] [D loss: 0.615760] [G loss: 0.879036]\n",
      "[Epoch 12/200] [Batch 42/169] [D loss: 0.597406] [G loss: 0.839787]\n",
      "[Epoch 12/200] [Batch 43/169] [D loss: 0.632599] [G loss: 0.877686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 44/169] [D loss: 0.685139] [G loss: 0.746641]\n",
      "[Epoch 12/200] [Batch 45/169] [D loss: 0.728444] [G loss: 0.626741]\n",
      "[Epoch 12/200] [Batch 46/169] [D loss: 0.733491] [G loss: 0.692384]\n",
      "[Epoch 12/200] [Batch 47/169] [D loss: 0.770324] [G loss: 0.754318]\n",
      "[Epoch 12/200] [Batch 48/169] [D loss: 0.703845] [G loss: 0.765170]\n",
      "[Epoch 12/200] [Batch 49/169] [D loss: 0.714699] [G loss: 1.000768]\n",
      "[Epoch 12/200] [Batch 50/169] [D loss: 0.657758] [G loss: 1.089854]\n",
      "[Epoch 12/200] [Batch 51/169] [D loss: 0.664895] [G loss: 0.895593]\n",
      "[Epoch 12/200] [Batch 52/169] [D loss: 0.735105] [G loss: 0.710405]\n",
      "[Epoch 12/200] [Batch 53/169] [D loss: 0.684474] [G loss: 0.722354]\n",
      "[Epoch 12/200] [Batch 54/169] [D loss: 0.672419] [G loss: 0.734583]\n",
      "[Epoch 12/200] [Batch 55/169] [D loss: 0.667509] [G loss: 0.799104]\n",
      "[Epoch 12/200] [Batch 56/169] [D loss: 0.638790] [G loss: 0.740970]\n",
      "[Epoch 12/200] [Batch 57/169] [D loss: 0.632538] [G loss: 0.737466]\n",
      "[Epoch 12/200] [Batch 58/169] [D loss: 0.644256] [G loss: 0.677299]\n",
      "[Epoch 12/200] [Batch 59/169] [D loss: 0.643349] [G loss: 0.728780]\n",
      "[Epoch 12/200] [Batch 60/169] [D loss: 0.654681] [G loss: 0.683157]\n",
      "[Epoch 12/200] [Batch 61/169] [D loss: 0.655788] [G loss: 0.788620]\n",
      "[Epoch 12/200] [Batch 62/169] [D loss: 0.651243] [G loss: 0.710832]\n",
      "[Epoch 12/200] [Batch 63/169] [D loss: 0.690120] [G loss: 0.691753]\n",
      "[Epoch 12/200] [Batch 64/169] [D loss: 0.669971] [G loss: 0.746855]\n",
      "[Epoch 12/200] [Batch 65/169] [D loss: 0.726030] [G loss: 0.766181]\n",
      "[Epoch 12/200] [Batch 66/169] [D loss: 0.688833] [G loss: 0.737292]\n",
      "[Epoch 12/200] [Batch 67/169] [D loss: 0.643697] [G loss: 0.712426]\n",
      "[Epoch 12/200] [Batch 68/169] [D loss: 0.679472] [G loss: 0.725943]\n",
      "[Epoch 12/200] [Batch 69/169] [D loss: 0.700169] [G loss: 0.755462]\n",
      "[Epoch 12/200] [Batch 70/169] [D loss: 0.690977] [G loss: 0.729500]\n",
      "[Epoch 12/200] [Batch 71/169] [D loss: 0.664055] [G loss: 0.758944]\n",
      "[Epoch 12/200] [Batch 72/169] [D loss: 0.652561] [G loss: 0.771449]\n",
      "[Epoch 12/200] [Batch 73/169] [D loss: 0.685444] [G loss: 0.746679]\n",
      "[Epoch 12/200] [Batch 74/169] [D loss: 0.671591] [G loss: 0.776055]\n",
      "[Epoch 12/200] [Batch 75/169] [D loss: 0.650408] [G loss: 0.821493]\n",
      "[Epoch 12/200] [Batch 76/169] [D loss: 0.693683] [G loss: 0.726387]\n",
      "[Epoch 12/200] [Batch 77/169] [D loss: 0.648614] [G loss: 0.782434]\n",
      "[Epoch 12/200] [Batch 78/169] [D loss: 0.690655] [G loss: 0.727154]\n",
      "[Epoch 12/200] [Batch 79/169] [D loss: 0.669699] [G loss: 0.740956]\n",
      "[Epoch 12/200] [Batch 80/169] [D loss: 0.658159] [G loss: 0.703724]\n",
      "[Epoch 12/200] [Batch 81/169] [D loss: 0.658332] [G loss: 0.689098]\n",
      "[Epoch 12/200] [Batch 82/169] [D loss: 0.674084] [G loss: 0.759362]\n",
      "[Epoch 12/200] [Batch 83/169] [D loss: 0.680870] [G loss: 0.805406]\n",
      "[Epoch 12/200] [Batch 84/169] [D loss: 0.663376] [G loss: 0.749814]\n",
      "[Epoch 12/200] [Batch 85/169] [D loss: 0.705207] [G loss: 0.715992]\n",
      "[Epoch 12/200] [Batch 86/169] [D loss: 0.660386] [G loss: 0.748771]\n",
      "[Epoch 12/200] [Batch 87/169] [D loss: 0.700335] [G loss: 0.703127]\n",
      "[Epoch 12/200] [Batch 88/169] [D loss: 0.645437] [G loss: 0.762084]\n",
      "[Epoch 12/200] [Batch 89/169] [D loss: 0.670756] [G loss: 0.786879]\n",
      "[Epoch 12/200] [Batch 90/169] [D loss: 0.659308] [G loss: 0.747559]\n",
      "[Epoch 12/200] [Batch 91/169] [D loss: 0.661513] [G loss: 0.747444]\n",
      "[Epoch 12/200] [Batch 92/169] [D loss: 0.666210] [G loss: 0.801584]\n",
      "[Epoch 12/200] [Batch 93/169] [D loss: 0.684910] [G loss: 0.791139]\n",
      "[Epoch 12/200] [Batch 94/169] [D loss: 0.648431] [G loss: 0.766306]\n",
      "[Epoch 12/200] [Batch 95/169] [D loss: 0.653966] [G loss: 0.758870]\n",
      "[Epoch 12/200] [Batch 96/169] [D loss: 0.648924] [G loss: 0.702324]\n",
      "[Epoch 12/200] [Batch 97/169] [D loss: 0.659696] [G loss: 0.748645]\n",
      "[Epoch 12/200] [Batch 98/169] [D loss: 0.639497] [G loss: 0.704247]\n",
      "[Epoch 12/200] [Batch 99/169] [D loss: 0.623297] [G loss: 0.753283]\n",
      "[Epoch 12/200] [Batch 100/169] [D loss: 0.630010] [G loss: 0.798518]\n",
      "[Epoch 12/200] [Batch 101/169] [D loss: 0.685110] [G loss: 0.698372]\n",
      "[Epoch 12/200] [Batch 102/169] [D loss: 0.669145] [G loss: 0.731695]\n",
      "[Epoch 12/200] [Batch 103/169] [D loss: 0.663464] [G loss: 0.758740]\n",
      "[Epoch 12/200] [Batch 104/169] [D loss: 0.694190] [G loss: 0.796762]\n",
      "[Epoch 12/200] [Batch 105/169] [D loss: 0.668549] [G loss: 0.848046]\n",
      "[Epoch 12/200] [Batch 106/169] [D loss: 0.645149] [G loss: 0.841408]\n",
      "[Epoch 12/200] [Batch 107/169] [D loss: 0.721335] [G loss: 0.806012]\n",
      "[Epoch 12/200] [Batch 108/169] [D loss: 0.679071] [G loss: 0.806986]\n",
      "[Epoch 12/200] [Batch 109/169] [D loss: 0.660008] [G loss: 0.785306]\n",
      "[Epoch 12/200] [Batch 110/169] [D loss: 0.687842] [G loss: 0.772313]\n",
      "[Epoch 12/200] [Batch 111/169] [D loss: 0.697028] [G loss: 0.810230]\n",
      "[Epoch 12/200] [Batch 112/169] [D loss: 0.681387] [G loss: 0.806120]\n",
      "[Epoch 12/200] [Batch 113/169] [D loss: 0.628635] [G loss: 0.804027]\n",
      "[Epoch 12/200] [Batch 114/169] [D loss: 0.660479] [G loss: 0.742785]\n",
      "[Epoch 12/200] [Batch 115/169] [D loss: 0.619302] [G loss: 0.780201]\n",
      "[Epoch 12/200] [Batch 116/169] [D loss: 0.628420] [G loss: 0.788730]\n",
      "[Epoch 12/200] [Batch 117/169] [D loss: 0.669546] [G loss: 0.849385]\n",
      "[Epoch 12/200] [Batch 118/169] [D loss: 0.654813] [G loss: 0.824972]\n",
      "[Epoch 12/200] [Batch 119/169] [D loss: 0.662606] [G loss: 0.756211]\n",
      "[Epoch 12/200] [Batch 120/169] [D loss: 0.617610] [G loss: 0.834827]\n",
      "[Epoch 12/200] [Batch 121/169] [D loss: 0.613422] [G loss: 0.810246]\n",
      "[Epoch 12/200] [Batch 122/169] [D loss: 0.637178] [G loss: 0.868256]\n",
      "[Epoch 12/200] [Batch 123/169] [D loss: 0.640432] [G loss: 0.854076]\n",
      "[Epoch 12/200] [Batch 124/169] [D loss: 0.625982] [G loss: 0.774256]\n",
      "[Epoch 12/200] [Batch 125/169] [D loss: 0.645307] [G loss: 0.837712]\n",
      "[Epoch 12/200] [Batch 126/169] [D loss: 0.626600] [G loss: 0.786859]\n",
      "[Epoch 12/200] [Batch 127/169] [D loss: 0.618311] [G loss: 0.788349]\n",
      "[Epoch 12/200] [Batch 128/169] [D loss: 0.648502] [G loss: 0.778787]\n",
      "[Epoch 12/200] [Batch 129/169] [D loss: 0.638144] [G loss: 0.729296]\n",
      "[Epoch 12/200] [Batch 130/169] [D loss: 0.634359] [G loss: 0.770553]\n",
      "[Epoch 12/200] [Batch 131/169] [D loss: 0.679103] [G loss: 0.780710]\n",
      "[Epoch 12/200] [Batch 132/169] [D loss: 0.644446] [G loss: 0.811480]\n",
      "[Epoch 12/200] [Batch 133/169] [D loss: 0.663893] [G loss: 0.737640]\n",
      "[Epoch 12/200] [Batch 134/169] [D loss: 0.680563] [G loss: 0.700638]\n",
      "[Epoch 12/200] [Batch 135/169] [D loss: 0.668846] [G loss: 0.711307]\n",
      "[Epoch 12/200] [Batch 136/169] [D loss: 0.611623] [G loss: 0.741679]\n",
      "[Epoch 12/200] [Batch 137/169] [D loss: 0.675637] [G loss: 0.745452]\n",
      "[Epoch 12/200] [Batch 138/169] [D loss: 0.637346] [G loss: 0.820278]\n",
      "[Epoch 12/200] [Batch 139/169] [D loss: 0.646986] [G loss: 0.777372]\n",
      "[Epoch 12/200] [Batch 140/169] [D loss: 0.657168] [G loss: 0.710708]\n",
      "[Epoch 12/200] [Batch 141/169] [D loss: 0.629596] [G loss: 0.770311]\n",
      "[Epoch 12/200] [Batch 142/169] [D loss: 0.644962] [G loss: 0.860252]\n",
      "[Epoch 12/200] [Batch 143/169] [D loss: 0.622667] [G loss: 0.773924]\n",
      "[Epoch 12/200] [Batch 144/169] [D loss: 0.647359] [G loss: 0.765976]\n",
      "[Epoch 12/200] [Batch 145/169] [D loss: 0.651808] [G loss: 0.731266]\n",
      "[Epoch 12/200] [Batch 146/169] [D loss: 0.643476] [G loss: 0.749464]\n",
      "[Epoch 12/200] [Batch 147/169] [D loss: 0.688297] [G loss: 0.722034]\n",
      "[Epoch 12/200] [Batch 148/169] [D loss: 0.640065] [G loss: 0.753360]\n",
      "[Epoch 12/200] [Batch 149/169] [D loss: 0.643275] [G loss: 0.749598]\n",
      "[Epoch 12/200] [Batch 150/169] [D loss: 0.669728] [G loss: 0.780285]\n",
      "[Epoch 12/200] [Batch 151/169] [D loss: 0.667797] [G loss: 0.832285]\n",
      "[Epoch 12/200] [Batch 152/169] [D loss: 0.695504] [G loss: 0.813819]\n",
      "[Epoch 12/200] [Batch 153/169] [D loss: 0.677424] [G loss: 0.827701]\n",
      "[Epoch 12/200] [Batch 154/169] [D loss: 0.645140] [G loss: 0.759032]\n",
      "[Epoch 12/200] [Batch 155/169] [D loss: 0.662720] [G loss: 0.694857]\n",
      "[Epoch 12/200] [Batch 156/169] [D loss: 0.671620] [G loss: 0.766410]\n",
      "[Epoch 12/200] [Batch 157/169] [D loss: 0.649584] [G loss: 0.730223]\n",
      "[Epoch 12/200] [Batch 158/169] [D loss: 0.639391] [G loss: 0.707781]\n",
      "[Epoch 12/200] [Batch 159/169] [D loss: 0.678167] [G loss: 0.740642]\n",
      "[Epoch 12/200] [Batch 160/169] [D loss: 0.646034] [G loss: 0.749334]\n",
      "[Epoch 12/200] [Batch 161/169] [D loss: 0.680177] [G loss: 0.816064]\n",
      "[Epoch 12/200] [Batch 162/169] [D loss: 0.682357] [G loss: 0.791199]\n",
      "[Epoch 12/200] [Batch 163/169] [D loss: 0.584257] [G loss: 0.806159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 164/169] [D loss: 0.669119] [G loss: 0.790615]\n",
      "[Epoch 12/200] [Batch 165/169] [D loss: 0.671381] [G loss: 0.766409]\n",
      "[Epoch 12/200] [Batch 166/169] [D loss: 0.713258] [G loss: 0.778976]\n",
      "[Epoch 12/200] [Batch 167/169] [D loss: 0.626964] [G loss: 0.792532]\n",
      "[Epoch 12/200] [Batch 168/169] [D loss: 0.694782] [G loss: 0.803121]\n",
      "[Epoch 13/200] [Batch 0/169] [D loss: 0.651251] [G loss: 0.816565]\n",
      "[Epoch 13/200] [Batch 1/169] [D loss: 0.662309] [G loss: 0.790179]\n",
      "[Epoch 13/200] [Batch 2/169] [D loss: 0.640990] [G loss: 0.791807]\n",
      "[Epoch 13/200] [Batch 3/169] [D loss: 0.653419] [G loss: 0.803753]\n",
      "[Epoch 13/200] [Batch 4/169] [D loss: 0.665616] [G loss: 0.805215]\n",
      "[Epoch 13/200] [Batch 5/169] [D loss: 0.631131] [G loss: 0.823933]\n",
      "[Epoch 13/200] [Batch 6/169] [D loss: 0.652086] [G loss: 0.807364]\n",
      "[Epoch 13/200] [Batch 7/169] [D loss: 0.635298] [G loss: 0.765179]\n",
      "[Epoch 13/200] [Batch 8/169] [D loss: 0.682013] [G loss: 0.777464]\n",
      "[Epoch 13/200] [Batch 9/169] [D loss: 0.636881] [G loss: 0.813501]\n",
      "[Epoch 13/200] [Batch 10/169] [D loss: 0.649284] [G loss: 0.732355]\n",
      "[Epoch 13/200] [Batch 11/169] [D loss: 0.654934] [G loss: 0.745129]\n",
      "[Epoch 13/200] [Batch 12/169] [D loss: 0.637964] [G loss: 0.739178]\n",
      "[Epoch 13/200] [Batch 13/169] [D loss: 0.668047] [G loss: 0.749955]\n",
      "[Epoch 13/200] [Batch 14/169] [D loss: 0.632608] [G loss: 0.754921]\n",
      "[Epoch 13/200] [Batch 15/169] [D loss: 0.671446] [G loss: 0.779502]\n",
      "[Epoch 13/200] [Batch 16/169] [D loss: 0.675286] [G loss: 0.718445]\n",
      "[Epoch 13/200] [Batch 17/169] [D loss: 0.660036] [G loss: 0.789942]\n",
      "[Epoch 13/200] [Batch 18/169] [D loss: 0.651079] [G loss: 0.793360]\n",
      "[Epoch 13/200] [Batch 19/169] [D loss: 0.645037] [G loss: 0.749775]\n",
      "[Epoch 13/200] [Batch 20/169] [D loss: 0.652691] [G loss: 0.785243]\n",
      "[Epoch 13/200] [Batch 21/169] [D loss: 0.697592] [G loss: 0.831520]\n",
      "[Epoch 13/200] [Batch 22/169] [D loss: 0.659649] [G loss: 0.763523]\n",
      "[Epoch 13/200] [Batch 23/169] [D loss: 0.638886] [G loss: 0.820527]\n",
      "[Epoch 13/200] [Batch 24/169] [D loss: 0.637202] [G loss: 0.794686]\n",
      "[Epoch 13/200] [Batch 25/169] [D loss: 0.638383] [G loss: 0.795194]\n",
      "[Epoch 13/200] [Batch 26/169] [D loss: 0.647054] [G loss: 0.795214]\n",
      "[Epoch 13/200] [Batch 27/169] [D loss: 0.610600] [G loss: 0.850430]\n",
      "[Epoch 13/200] [Batch 28/169] [D loss: 0.636602] [G loss: 0.795353]\n",
      "[Epoch 13/200] [Batch 29/169] [D loss: 0.633727] [G loss: 0.766263]\n",
      "[Epoch 13/200] [Batch 30/169] [D loss: 0.659814] [G loss: 0.836791]\n",
      "[Epoch 13/200] [Batch 31/169] [D loss: 0.676676] [G loss: 0.788216]\n",
      "[Epoch 13/200] [Batch 32/169] [D loss: 0.644533] [G loss: 0.802482]\n",
      "[Epoch 13/200] [Batch 33/169] [D loss: 0.655310] [G loss: 0.832098]\n",
      "[Epoch 13/200] [Batch 34/169] [D loss: 0.710640] [G loss: 0.755645]\n",
      "[Epoch 13/200] [Batch 35/169] [D loss: 0.666367] [G loss: 0.722768]\n",
      "[Epoch 13/200] [Batch 36/169] [D loss: 0.640210] [G loss: 0.750792]\n",
      "[Epoch 13/200] [Batch 37/169] [D loss: 0.681641] [G loss: 0.723983]\n",
      "[Epoch 13/200] [Batch 38/169] [D loss: 0.678313] [G loss: 0.701048]\n",
      "[Epoch 13/200] [Batch 39/169] [D loss: 0.691432] [G loss: 0.706149]\n",
      "[Epoch 13/200] [Batch 40/169] [D loss: 0.660457] [G loss: 0.691767]\n",
      "[Epoch 13/200] [Batch 41/169] [D loss: 0.635089] [G loss: 0.743946]\n",
      "[Epoch 13/200] [Batch 42/169] [D loss: 0.673546] [G loss: 0.695938]\n",
      "[Epoch 13/200] [Batch 43/169] [D loss: 0.676135] [G loss: 0.723799]\n",
      "[Epoch 13/200] [Batch 44/169] [D loss: 0.651593] [G loss: 0.753718]\n",
      "[Epoch 13/200] [Batch 45/169] [D loss: 0.647140] [G loss: 0.704807]\n",
      "[Epoch 13/200] [Batch 46/169] [D loss: 0.630353] [G loss: 0.692486]\n",
      "[Epoch 13/200] [Batch 47/169] [D loss: 0.629377] [G loss: 0.712920]\n",
      "[Epoch 13/200] [Batch 48/169] [D loss: 0.636020] [G loss: 0.753980]\n",
      "[Epoch 13/200] [Batch 49/169] [D loss: 0.647353] [G loss: 0.743796]\n",
      "[Epoch 13/200] [Batch 50/169] [D loss: 0.639770] [G loss: 0.755320]\n",
      "[Epoch 13/200] [Batch 51/169] [D loss: 0.637393] [G loss: 0.739087]\n",
      "[Epoch 13/200] [Batch 52/169] [D loss: 0.667580] [G loss: 0.760377]\n",
      "[Epoch 13/200] [Batch 53/169] [D loss: 0.649782] [G loss: 0.787414]\n",
      "[Epoch 13/200] [Batch 54/169] [D loss: 0.681314] [G loss: 0.755940]\n",
      "[Epoch 13/200] [Batch 55/169] [D loss: 0.629450] [G loss: 0.738428]\n",
      "[Epoch 13/200] [Batch 56/169] [D loss: 0.680607] [G loss: 0.808260]\n",
      "[Epoch 13/200] [Batch 57/169] [D loss: 0.661854] [G loss: 0.778924]\n",
      "[Epoch 13/200] [Batch 58/169] [D loss: 0.685980] [G loss: 0.756173]\n",
      "[Epoch 13/200] [Batch 59/169] [D loss: 0.654259] [G loss: 0.781047]\n",
      "[Epoch 13/200] [Batch 60/169] [D loss: 0.627787] [G loss: 0.802300]\n",
      "[Epoch 13/200] [Batch 61/169] [D loss: 0.639980] [G loss: 0.796145]\n",
      "[Epoch 13/200] [Batch 62/169] [D loss: 0.667440] [G loss: 0.862732]\n",
      "[Epoch 13/200] [Batch 63/169] [D loss: 0.649070] [G loss: 0.838044]\n",
      "[Epoch 13/200] [Batch 64/169] [D loss: 0.637068] [G loss: 0.828070]\n",
      "[Epoch 13/200] [Batch 65/169] [D loss: 0.623445] [G loss: 0.783034]\n",
      "[Epoch 13/200] [Batch 66/169] [D loss: 0.634244] [G loss: 0.782400]\n",
      "[Epoch 13/200] [Batch 67/169] [D loss: 0.622343] [G loss: 0.757096]\n",
      "[Epoch 13/200] [Batch 68/169] [D loss: 0.647067] [G loss: 0.799076]\n",
      "[Epoch 13/200] [Batch 69/169] [D loss: 0.646094] [G loss: 0.786673]\n",
      "[Epoch 13/200] [Batch 70/169] [D loss: 0.674076] [G loss: 0.753852]\n",
      "[Epoch 13/200] [Batch 71/169] [D loss: 0.657425] [G loss: 0.724090]\n",
      "[Epoch 13/200] [Batch 72/169] [D loss: 0.656320] [G loss: 0.770379]\n",
      "[Epoch 13/200] [Batch 73/169] [D loss: 0.640462] [G loss: 0.768939]\n",
      "[Epoch 13/200] [Batch 74/169] [D loss: 0.649684] [G loss: 0.779675]\n",
      "[Epoch 13/200] [Batch 75/169] [D loss: 0.669956] [G loss: 0.779917]\n",
      "[Epoch 13/200] [Batch 76/169] [D loss: 0.715027] [G loss: 0.792338]\n",
      "[Epoch 13/200] [Batch 77/169] [D loss: 0.675024] [G loss: 0.793908]\n",
      "[Epoch 13/200] [Batch 78/169] [D loss: 0.695399] [G loss: 0.756561]\n",
      "[Epoch 13/200] [Batch 79/169] [D loss: 0.662302] [G loss: 0.795598]\n",
      "[Epoch 13/200] [Batch 80/169] [D loss: 0.659895] [G loss: 0.838515]\n",
      "[Epoch 13/200] [Batch 81/169] [D loss: 0.666314] [G loss: 0.788377]\n",
      "[Epoch 13/200] [Batch 82/169] [D loss: 0.691396] [G loss: 0.810943]\n",
      "[Epoch 13/200] [Batch 83/169] [D loss: 0.650672] [G loss: 0.781863]\n",
      "[Epoch 13/200] [Batch 84/169] [D loss: 0.654554] [G loss: 0.788866]\n",
      "[Epoch 13/200] [Batch 85/169] [D loss: 0.670779] [G loss: 0.810356]\n",
      "[Epoch 13/200] [Batch 86/169] [D loss: 0.634916] [G loss: 0.768310]\n",
      "[Epoch 13/200] [Batch 87/169] [D loss: 0.656423] [G loss: 0.792238]\n",
      "[Epoch 13/200] [Batch 88/169] [D loss: 0.620404] [G loss: 0.777168]\n",
      "[Epoch 13/200] [Batch 89/169] [D loss: 0.653811] [G loss: 0.753389]\n",
      "[Epoch 13/200] [Batch 90/169] [D loss: 0.653849] [G loss: 0.764868]\n",
      "[Epoch 13/200] [Batch 91/169] [D loss: 0.658216] [G loss: 0.744809]\n",
      "[Epoch 13/200] [Batch 92/169] [D loss: 0.677520] [G loss: 0.745879]\n",
      "[Epoch 13/200] [Batch 93/169] [D loss: 0.665507] [G loss: 0.730936]\n",
      "[Epoch 13/200] [Batch 94/169] [D loss: 0.686951] [G loss: 0.740772]\n",
      "[Epoch 13/200] [Batch 95/169] [D loss: 0.652514] [G loss: 0.840840]\n",
      "[Epoch 13/200] [Batch 96/169] [D loss: 0.670842] [G loss: 0.818518]\n",
      "[Epoch 13/200] [Batch 97/169] [D loss: 0.608990] [G loss: 0.905035]\n",
      "[Epoch 13/200] [Batch 98/169] [D loss: 0.603082] [G loss: 0.878928]\n",
      "[Epoch 13/200] [Batch 99/169] [D loss: 0.658697] [G loss: 0.813659]\n",
      "[Epoch 13/200] [Batch 100/169] [D loss: 0.638984] [G loss: 0.871835]\n",
      "[Epoch 13/200] [Batch 101/169] [D loss: 0.619452] [G loss: 0.831779]\n",
      "[Epoch 13/200] [Batch 102/169] [D loss: 0.627112] [G loss: 0.837078]\n",
      "[Epoch 13/200] [Batch 103/169] [D loss: 0.644384] [G loss: 0.798621]\n",
      "[Epoch 13/200] [Batch 104/169] [D loss: 0.646882] [G loss: 0.775529]\n",
      "[Epoch 13/200] [Batch 105/169] [D loss: 0.619001] [G loss: 0.774215]\n",
      "[Epoch 13/200] [Batch 106/169] [D loss: 0.642732] [G loss: 0.741563]\n",
      "[Epoch 13/200] [Batch 107/169] [D loss: 0.635481] [G loss: 0.749019]\n",
      "[Epoch 13/200] [Batch 108/169] [D loss: 0.658024] [G loss: 0.679907]\n",
      "[Epoch 13/200] [Batch 109/169] [D loss: 0.682640] [G loss: 0.724073]\n",
      "[Epoch 13/200] [Batch 110/169] [D loss: 0.716880] [G loss: 0.685785]\n",
      "[Epoch 13/200] [Batch 111/169] [D loss: 0.689414] [G loss: 0.692128]\n",
      "[Epoch 13/200] [Batch 112/169] [D loss: 0.695008] [G loss: 0.731228]\n",
      "[Epoch 13/200] [Batch 113/169] [D loss: 0.691832] [G loss: 0.765326]\n",
      "[Epoch 13/200] [Batch 114/169] [D loss: 0.613276] [G loss: 0.827252]\n",
      "[Epoch 13/200] [Batch 115/169] [D loss: 0.570258] [G loss: 0.800204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 116/169] [D loss: 0.647610] [G loss: 0.820274]\n",
      "[Epoch 13/200] [Batch 117/169] [D loss: 0.661927] [G loss: 0.790231]\n",
      "[Epoch 13/200] [Batch 118/169] [D loss: 0.661430] [G loss: 0.818417]\n",
      "[Epoch 13/200] [Batch 119/169] [D loss: 0.678962] [G loss: 0.780765]\n",
      "[Epoch 13/200] [Batch 120/169] [D loss: 0.652706] [G loss: 0.725122]\n",
      "[Epoch 13/200] [Batch 121/169] [D loss: 0.624137] [G loss: 0.702701]\n",
      "[Epoch 13/200] [Batch 122/169] [D loss: 0.673118] [G loss: 0.679051]\n",
      "[Epoch 13/200] [Batch 123/169] [D loss: 0.686573] [G loss: 0.711712]\n",
      "[Epoch 13/200] [Batch 124/169] [D loss: 0.675931] [G loss: 0.752489]\n",
      "[Epoch 13/200] [Batch 125/169] [D loss: 0.665020] [G loss: 0.795480]\n",
      "[Epoch 13/200] [Batch 126/169] [D loss: 0.651487] [G loss: 0.790648]\n",
      "[Epoch 13/200] [Batch 127/169] [D loss: 0.667436] [G loss: 0.786986]\n",
      "[Epoch 13/200] [Batch 128/169] [D loss: 0.605143] [G loss: 0.842237]\n",
      "[Epoch 13/200] [Batch 129/169] [D loss: 0.587291] [G loss: 0.871631]\n",
      "[Epoch 13/200] [Batch 130/169] [D loss: 0.625032] [G loss: 0.836911]\n",
      "[Epoch 13/200] [Batch 131/169] [D loss: 0.588761] [G loss: 0.873882]\n",
      "[Epoch 13/200] [Batch 132/169] [D loss: 0.586667] [G loss: 0.836803]\n",
      "[Epoch 13/200] [Batch 133/169] [D loss: 0.626864] [G loss: 0.814023]\n",
      "[Epoch 13/200] [Batch 134/169] [D loss: 0.598563] [G loss: 0.803378]\n",
      "[Epoch 13/200] [Batch 135/169] [D loss: 0.600807] [G loss: 0.887125]\n",
      "[Epoch 13/200] [Batch 136/169] [D loss: 0.627828] [G loss: 0.762935]\n",
      "[Epoch 13/200] [Batch 137/169] [D loss: 0.607158] [G loss: 0.804853]\n",
      "[Epoch 13/200] [Batch 138/169] [D loss: 0.661702] [G loss: 0.713039]\n",
      "[Epoch 13/200] [Batch 139/169] [D loss: 0.666490] [G loss: 0.646548]\n",
      "[Epoch 13/200] [Batch 140/169] [D loss: 0.715508] [G loss: 0.596023]\n",
      "[Epoch 13/200] [Batch 141/169] [D loss: 0.728405] [G loss: 0.707538]\n",
      "[Epoch 13/200] [Batch 142/169] [D loss: 0.738528] [G loss: 0.750630]\n",
      "[Epoch 13/200] [Batch 143/169] [D loss: 0.639321] [G loss: 0.914025]\n",
      "[Epoch 13/200] [Batch 144/169] [D loss: 0.700860] [G loss: 0.800221]\n",
      "[Epoch 13/200] [Batch 145/169] [D loss: 0.628127] [G loss: 0.863064]\n",
      "[Epoch 13/200] [Batch 146/169] [D loss: 0.671418] [G loss: 0.689081]\n",
      "[Epoch 13/200] [Batch 147/169] [D loss: 0.714431] [G loss: 0.720643]\n",
      "[Epoch 13/200] [Batch 148/169] [D loss: 0.662676] [G loss: 0.681025]\n",
      "[Epoch 13/200] [Batch 149/169] [D loss: 0.670582] [G loss: 0.719728]\n",
      "[Epoch 13/200] [Batch 150/169] [D loss: 0.631327] [G loss: 0.718910]\n",
      "[Epoch 13/200] [Batch 151/169] [D loss: 0.668101] [G loss: 0.733566]\n",
      "[Epoch 13/200] [Batch 152/169] [D loss: 0.650894] [G loss: 0.791240]\n",
      "[Epoch 13/200] [Batch 153/169] [D loss: 0.647879] [G loss: 0.764028]\n",
      "[Epoch 13/200] [Batch 154/169] [D loss: 0.671196] [G loss: 0.770543]\n",
      "[Epoch 13/200] [Batch 155/169] [D loss: 0.623234] [G loss: 0.727789]\n",
      "[Epoch 13/200] [Batch 156/169] [D loss: 0.663323] [G loss: 0.715345]\n",
      "[Epoch 13/200] [Batch 157/169] [D loss: 0.647095] [G loss: 0.796000]\n",
      "[Epoch 13/200] [Batch 158/169] [D loss: 0.670704] [G loss: 0.784428]\n",
      "[Epoch 13/200] [Batch 159/169] [D loss: 0.643182] [G loss: 0.792813]\n",
      "[Epoch 13/200] [Batch 160/169] [D loss: 0.655645] [G loss: 0.797369]\n",
      "[Epoch 13/200] [Batch 161/169] [D loss: 0.664891] [G loss: 0.856587]\n",
      "[Epoch 13/200] [Batch 162/169] [D loss: 0.637688] [G loss: 0.875481]\n",
      "[Epoch 13/200] [Batch 163/169] [D loss: 0.583882] [G loss: 0.857493]\n",
      "[Epoch 13/200] [Batch 164/169] [D loss: 0.647545] [G loss: 0.804940]\n",
      "[Epoch 13/200] [Batch 165/169] [D loss: 0.620599] [G loss: 0.857379]\n",
      "[Epoch 13/200] [Batch 166/169] [D loss: 0.626343] [G loss: 0.869345]\n",
      "[Epoch 13/200] [Batch 167/169] [D loss: 0.589488] [G loss: 0.832558]\n",
      "[Epoch 13/200] [Batch 168/169] [D loss: 0.650593] [G loss: 0.839875]\n",
      "[Epoch 14/200] [Batch 0/169] [D loss: 0.657623] [G loss: 0.789463]\n",
      "[Epoch 14/200] [Batch 1/169] [D loss: 0.684013] [G loss: 0.758064]\n",
      "[Epoch 14/200] [Batch 2/169] [D loss: 0.710535] [G loss: 0.680438]\n",
      "[Epoch 14/200] [Batch 3/169] [D loss: 0.703119] [G loss: 0.884085]\n",
      "[Epoch 14/200] [Batch 4/169] [D loss: 0.653793] [G loss: 0.867312]\n",
      "[Epoch 14/200] [Batch 5/169] [D loss: 0.682913] [G loss: 0.826086]\n",
      "[Epoch 14/200] [Batch 6/169] [D loss: 0.670502] [G loss: 0.965158]\n",
      "[Epoch 14/200] [Batch 7/169] [D loss: 0.656588] [G loss: 0.885599]\n",
      "[Epoch 14/200] [Batch 8/169] [D loss: 0.669364] [G loss: 0.852875]\n",
      "[Epoch 14/200] [Batch 9/169] [D loss: 0.647879] [G loss: 0.775077]\n",
      "[Epoch 14/200] [Batch 10/169] [D loss: 0.662462] [G loss: 0.774173]\n",
      "[Epoch 14/200] [Batch 11/169] [D loss: 0.648828] [G loss: 0.734662]\n",
      "[Epoch 14/200] [Batch 12/169] [D loss: 0.672125] [G loss: 0.743802]\n",
      "[Epoch 14/200] [Batch 13/169] [D loss: 0.673912] [G loss: 0.744705]\n",
      "[Epoch 14/200] [Batch 14/169] [D loss: 0.673829] [G loss: 0.619425]\n",
      "[Epoch 14/200] [Batch 15/169] [D loss: 0.664434] [G loss: 0.673529]\n",
      "[Epoch 14/200] [Batch 16/169] [D loss: 0.636765] [G loss: 0.713025]\n",
      "[Epoch 14/200] [Batch 17/169] [D loss: 0.619262] [G loss: 0.696763]\n",
      "[Epoch 14/200] [Batch 18/169] [D loss: 0.642742] [G loss: 0.723658]\n",
      "[Epoch 14/200] [Batch 19/169] [D loss: 0.623714] [G loss: 0.772776]\n",
      "[Epoch 14/200] [Batch 20/169] [D loss: 0.616703] [G loss: 0.707978]\n",
      "[Epoch 14/200] [Batch 21/169] [D loss: 0.629343] [G loss: 0.737308]\n",
      "[Epoch 14/200] [Batch 22/169] [D loss: 0.621055] [G loss: 0.712846]\n",
      "[Epoch 14/200] [Batch 23/169] [D loss: 0.604742] [G loss: 0.757270]\n",
      "[Epoch 14/200] [Batch 24/169] [D loss: 0.639144] [G loss: 0.711196]\n",
      "[Epoch 14/200] [Batch 25/169] [D loss: 0.633056] [G loss: 0.776413]\n",
      "[Epoch 14/200] [Batch 26/169] [D loss: 0.670430] [G loss: 0.748890]\n",
      "[Epoch 14/200] [Batch 27/169] [D loss: 0.660188] [G loss: 0.768271]\n",
      "[Epoch 14/200] [Batch 28/169] [D loss: 0.654313] [G loss: 0.733852]\n",
      "[Epoch 14/200] [Batch 29/169] [D loss: 0.666487] [G loss: 0.788399]\n",
      "[Epoch 14/200] [Batch 30/169] [D loss: 0.670655] [G loss: 0.762138]\n",
      "[Epoch 14/200] [Batch 31/169] [D loss: 0.662187] [G loss: 0.788824]\n",
      "[Epoch 14/200] [Batch 32/169] [D loss: 0.703890] [G loss: 0.796551]\n",
      "[Epoch 14/200] [Batch 33/169] [D loss: 0.671940] [G loss: 0.791019]\n",
      "[Epoch 14/200] [Batch 34/169] [D loss: 0.666123] [G loss: 0.768518]\n",
      "[Epoch 14/200] [Batch 35/169] [D loss: 0.643768] [G loss: 0.799798]\n",
      "[Epoch 14/200] [Batch 36/169] [D loss: 0.658835] [G loss: 0.807847]\n",
      "[Epoch 14/200] [Batch 37/169] [D loss: 0.654237] [G loss: 0.760096]\n",
      "[Epoch 14/200] [Batch 38/169] [D loss: 0.671302] [G loss: 0.746513]\n",
      "[Epoch 14/200] [Batch 39/169] [D loss: 0.675567] [G loss: 0.728778]\n",
      "[Epoch 14/200] [Batch 40/169] [D loss: 0.679301] [G loss: 0.778013]\n",
      "[Epoch 14/200] [Batch 41/169] [D loss: 0.683898] [G loss: 0.779832]\n",
      "[Epoch 14/200] [Batch 42/169] [D loss: 0.709288] [G loss: 0.746174]\n",
      "[Epoch 14/200] [Batch 43/169] [D loss: 0.687586] [G loss: 0.774471]\n",
      "[Epoch 14/200] [Batch 44/169] [D loss: 0.677310] [G loss: 0.771078]\n",
      "[Epoch 14/200] [Batch 45/169] [D loss: 0.664973] [G loss: 0.810159]\n",
      "[Epoch 14/200] [Batch 46/169] [D loss: 0.650676] [G loss: 0.738852]\n",
      "[Epoch 14/200] [Batch 47/169] [D loss: 0.668655] [G loss: 0.732467]\n",
      "[Epoch 14/200] [Batch 48/169] [D loss: 0.631546] [G loss: 0.737608]\n",
      "[Epoch 14/200] [Batch 49/169] [D loss: 0.658710] [G loss: 0.799993]\n",
      "[Epoch 14/200] [Batch 50/169] [D loss: 0.632205] [G loss: 0.754197]\n",
      "[Epoch 14/200] [Batch 51/169] [D loss: 0.676038] [G loss: 0.762250]\n",
      "[Epoch 14/200] [Batch 52/169] [D loss: 0.607622] [G loss: 0.771395]\n",
      "[Epoch 14/200] [Batch 53/169] [D loss: 0.659250] [G loss: 0.764342]\n",
      "[Epoch 14/200] [Batch 54/169] [D loss: 0.650706] [G loss: 0.747670]\n",
      "[Epoch 14/200] [Batch 55/169] [D loss: 0.642458] [G loss: 0.746213]\n",
      "[Epoch 14/200] [Batch 56/169] [D loss: 0.614219] [G loss: 0.770529]\n",
      "[Epoch 14/200] [Batch 57/169] [D loss: 0.643966] [G loss: 0.717394]\n",
      "[Epoch 14/200] [Batch 58/169] [D loss: 0.636808] [G loss: 0.764140]\n",
      "[Epoch 14/200] [Batch 59/169] [D loss: 0.678198] [G loss: 0.769664]\n",
      "[Epoch 14/200] [Batch 60/169] [D loss: 0.659244] [G loss: 0.817815]\n",
      "[Epoch 14/200] [Batch 61/169] [D loss: 0.622115] [G loss: 0.826995]\n",
      "[Epoch 14/200] [Batch 62/169] [D loss: 0.661966] [G loss: 0.813851]\n",
      "[Epoch 14/200] [Batch 63/169] [D loss: 0.653787] [G loss: 0.810875]\n",
      "[Epoch 14/200] [Batch 64/169] [D loss: 0.682390] [G loss: 0.819771]\n",
      "[Epoch 14/200] [Batch 65/169] [D loss: 0.641571] [G loss: 0.800419]\n",
      "[Epoch 14/200] [Batch 66/169] [D loss: 0.627573] [G loss: 0.772615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 67/169] [D loss: 0.648551] [G loss: 0.787539]\n",
      "[Epoch 14/200] [Batch 68/169] [D loss: 0.702945] [G loss: 0.789395]\n",
      "[Epoch 14/200] [Batch 69/169] [D loss: 0.656999] [G loss: 0.744155]\n",
      "[Epoch 14/200] [Batch 70/169] [D loss: 0.662556] [G loss: 0.834582]\n",
      "[Epoch 14/200] [Batch 71/169] [D loss: 0.669433] [G loss: 0.778129]\n",
      "[Epoch 14/200] [Batch 72/169] [D loss: 0.630521] [G loss: 0.808928]\n",
      "[Epoch 14/200] [Batch 73/169] [D loss: 0.668744] [G loss: 0.748239]\n",
      "[Epoch 14/200] [Batch 74/169] [D loss: 0.673732] [G loss: 0.745048]\n",
      "[Epoch 14/200] [Batch 75/169] [D loss: 0.672919] [G loss: 0.761151]\n",
      "[Epoch 14/200] [Batch 76/169] [D loss: 0.658593] [G loss: 0.816100]\n",
      "[Epoch 14/200] [Batch 77/169] [D loss: 0.668124] [G loss: 0.782221]\n",
      "[Epoch 14/200] [Batch 78/169] [D loss: 0.640638] [G loss: 0.837296]\n",
      "[Epoch 14/200] [Batch 79/169] [D loss: 0.690421] [G loss: 0.800426]\n",
      "[Epoch 14/200] [Batch 80/169] [D loss: 0.635744] [G loss: 0.821798]\n",
      "[Epoch 14/200] [Batch 81/169] [D loss: 0.638453] [G loss: 0.813986]\n",
      "[Epoch 14/200] [Batch 82/169] [D loss: 0.668173] [G loss: 0.859806]\n",
      "[Epoch 14/200] [Batch 83/169] [D loss: 0.672688] [G loss: 0.762343]\n",
      "[Epoch 14/200] [Batch 84/169] [D loss: 0.663181] [G loss: 0.831678]\n",
      "[Epoch 14/200] [Batch 85/169] [D loss: 0.648550] [G loss: 0.775479]\n",
      "[Epoch 14/200] [Batch 86/169] [D loss: 0.636827] [G loss: 0.806346]\n",
      "[Epoch 14/200] [Batch 87/169] [D loss: 0.663000] [G loss: 0.815833]\n",
      "[Epoch 14/200] [Batch 88/169] [D loss: 0.633116] [G loss: 0.830878]\n",
      "[Epoch 14/200] [Batch 89/169] [D loss: 0.665724] [G loss: 0.774078]\n",
      "[Epoch 14/200] [Batch 90/169] [D loss: 0.641774] [G loss: 0.763045]\n",
      "[Epoch 14/200] [Batch 91/169] [D loss: 0.632103] [G loss: 0.809791]\n",
      "[Epoch 14/200] [Batch 92/169] [D loss: 0.633854] [G loss: 0.790031]\n",
      "[Epoch 14/200] [Batch 93/169] [D loss: 0.640674] [G loss: 0.814033]\n",
      "[Epoch 14/200] [Batch 94/169] [D loss: 0.649460] [G loss: 0.797875]\n",
      "[Epoch 14/200] [Batch 95/169] [D loss: 0.624078] [G loss: 0.784743]\n",
      "[Epoch 14/200] [Batch 96/169] [D loss: 0.679599] [G loss: 0.786755]\n",
      "[Epoch 14/200] [Batch 97/169] [D loss: 0.664063] [G loss: 0.778805]\n",
      "[Epoch 14/200] [Batch 98/169] [D loss: 0.674577] [G loss: 0.831451]\n",
      "[Epoch 14/200] [Batch 99/169] [D loss: 0.700035] [G loss: 0.788032]\n",
      "[Epoch 14/200] [Batch 100/169] [D loss: 0.672516] [G loss: 0.737677]\n",
      "[Epoch 14/200] [Batch 101/169] [D loss: 0.664215] [G loss: 0.790437]\n",
      "[Epoch 14/200] [Batch 102/169] [D loss: 0.671323] [G loss: 0.744331]\n",
      "[Epoch 14/200] [Batch 103/169] [D loss: 0.659572] [G loss: 0.771128]\n",
      "[Epoch 14/200] [Batch 104/169] [D loss: 0.660324] [G loss: 0.748660]\n",
      "[Epoch 14/200] [Batch 105/169] [D loss: 0.681507] [G loss: 0.746006]\n",
      "[Epoch 14/200] [Batch 106/169] [D loss: 0.667083] [G loss: 0.750440]\n",
      "[Epoch 14/200] [Batch 107/169] [D loss: 0.666587] [G loss: 0.717243]\n",
      "[Epoch 14/200] [Batch 108/169] [D loss: 0.645146] [G loss: 0.781486]\n",
      "[Epoch 14/200] [Batch 109/169] [D loss: 0.648818] [G loss: 0.780466]\n",
      "[Epoch 14/200] [Batch 110/169] [D loss: 0.624650] [G loss: 0.782624]\n",
      "[Epoch 14/200] [Batch 111/169] [D loss: 0.669144] [G loss: 0.786730]\n",
      "[Epoch 14/200] [Batch 112/169] [D loss: 0.663612] [G loss: 0.707775]\n",
      "[Epoch 14/200] [Batch 113/169] [D loss: 0.636068] [G loss: 0.809837]\n",
      "[Epoch 14/200] [Batch 114/169] [D loss: 0.626572] [G loss: 0.715957]\n",
      "[Epoch 14/200] [Batch 115/169] [D loss: 0.658516] [G loss: 0.754143]\n",
      "[Epoch 14/200] [Batch 116/169] [D loss: 0.615236] [G loss: 0.747885]\n",
      "[Epoch 14/200] [Batch 117/169] [D loss: 0.667037] [G loss: 0.730152]\n",
      "[Epoch 14/200] [Batch 118/169] [D loss: 0.639067] [G loss: 0.756607]\n",
      "[Epoch 14/200] [Batch 119/169] [D loss: 0.639936] [G loss: 0.780680]\n",
      "[Epoch 14/200] [Batch 120/169] [D loss: 0.636044] [G loss: 0.774026]\n",
      "[Epoch 14/200] [Batch 121/169] [D loss: 0.668506] [G loss: 0.760904]\n",
      "[Epoch 14/200] [Batch 122/169] [D loss: 0.618080] [G loss: 0.776266]\n",
      "[Epoch 14/200] [Batch 123/169] [D loss: 0.636150] [G loss: 0.762983]\n",
      "[Epoch 14/200] [Batch 124/169] [D loss: 0.641687] [G loss: 0.728006]\n",
      "[Epoch 14/200] [Batch 125/169] [D loss: 0.672002] [G loss: 0.779782]\n",
      "[Epoch 14/200] [Batch 126/169] [D loss: 0.656402] [G loss: 0.779893]\n",
      "[Epoch 14/200] [Batch 127/169] [D loss: 0.631935] [G loss: 0.791481]\n",
      "[Epoch 14/200] [Batch 128/169] [D loss: 0.663248] [G loss: 0.792359]\n",
      "[Epoch 14/200] [Batch 129/169] [D loss: 0.625498] [G loss: 0.818809]\n",
      "[Epoch 14/200] [Batch 130/169] [D loss: 0.659009] [G loss: 0.742442]\n",
      "[Epoch 14/200] [Batch 131/169] [D loss: 0.659869] [G loss: 0.694945]\n",
      "[Epoch 14/200] [Batch 132/169] [D loss: 0.655289] [G loss: 0.680828]\n",
      "[Epoch 14/200] [Batch 133/169] [D loss: 0.658997] [G loss: 0.744839]\n",
      "[Epoch 14/200] [Batch 134/169] [D loss: 0.669109] [G loss: 0.732105]\n",
      "[Epoch 14/200] [Batch 135/169] [D loss: 0.628759] [G loss: 0.716322]\n",
      "[Epoch 14/200] [Batch 136/169] [D loss: 0.643227] [G loss: 0.748423]\n",
      "[Epoch 14/200] [Batch 137/169] [D loss: 0.703610] [G loss: 0.733369]\n",
      "[Epoch 14/200] [Batch 138/169] [D loss: 0.687245] [G loss: 0.785208]\n",
      "[Epoch 14/200] [Batch 139/169] [D loss: 0.664358] [G loss: 0.755137]\n",
      "[Epoch 14/200] [Batch 140/169] [D loss: 0.670378] [G loss: 0.757542]\n",
      "[Epoch 14/200] [Batch 141/169] [D loss: 0.625109] [G loss: 0.758890]\n",
      "[Epoch 14/200] [Batch 142/169] [D loss: 0.695047] [G loss: 0.786182]\n",
      "[Epoch 14/200] [Batch 143/169] [D loss: 0.676893] [G loss: 0.746191]\n",
      "[Epoch 14/200] [Batch 144/169] [D loss: 0.680899] [G loss: 0.742402]\n",
      "[Epoch 14/200] [Batch 145/169] [D loss: 0.676363] [G loss: 0.808344]\n",
      "[Epoch 14/200] [Batch 146/169] [D loss: 0.673562] [G loss: 0.817791]\n",
      "[Epoch 14/200] [Batch 147/169] [D loss: 0.666517] [G loss: 0.853453]\n",
      "[Epoch 14/200] [Batch 148/169] [D loss: 0.664575] [G loss: 0.862377]\n",
      "[Epoch 14/200] [Batch 149/169] [D loss: 0.651065] [G loss: 0.828328]\n",
      "[Epoch 14/200] [Batch 150/169] [D loss: 0.610237] [G loss: 0.837923]\n",
      "[Epoch 14/200] [Batch 151/169] [D loss: 0.632498] [G loss: 0.883210]\n",
      "[Epoch 14/200] [Batch 152/169] [D loss: 0.575103] [G loss: 0.895878]\n",
      "[Epoch 14/200] [Batch 153/169] [D loss: 0.556304] [G loss: 0.848016]\n",
      "[Epoch 14/200] [Batch 154/169] [D loss: 0.600048] [G loss: 0.815424]\n",
      "[Epoch 14/200] [Batch 155/169] [D loss: 0.597058] [G loss: 0.825037]\n",
      "[Epoch 14/200] [Batch 156/169] [D loss: 0.616660] [G loss: 0.820068]\n",
      "[Epoch 14/200] [Batch 157/169] [D loss: 0.622608] [G loss: 0.725931]\n",
      "[Epoch 14/200] [Batch 158/169] [D loss: 0.699862] [G loss: 0.622912]\n",
      "[Epoch 14/200] [Batch 159/169] [D loss: 0.635386] [G loss: 0.677106]\n",
      "[Epoch 14/200] [Batch 160/169] [D loss: 0.727342] [G loss: 0.681807]\n",
      "[Epoch 14/200] [Batch 161/169] [D loss: 0.719736] [G loss: 0.767646]\n",
      "[Epoch 14/200] [Batch 162/169] [D loss: 0.656619] [G loss: 0.761429]\n",
      "[Epoch 14/200] [Batch 163/169] [D loss: 0.658759] [G loss: 0.766977]\n",
      "[Epoch 14/200] [Batch 164/169] [D loss: 0.649677] [G loss: 0.768520]\n",
      "[Epoch 14/200] [Batch 165/169] [D loss: 0.710972] [G loss: 0.773568]\n",
      "[Epoch 14/200] [Batch 166/169] [D loss: 0.696913] [G loss: 0.797253]\n",
      "[Epoch 14/200] [Batch 167/169] [D loss: 0.712917] [G loss: 0.788801]\n",
      "[Epoch 14/200] [Batch 168/169] [D loss: 0.586590] [G loss: 0.781535]\n",
      "[Epoch 15/200] [Batch 0/169] [D loss: 0.637856] [G loss: 0.825126]\n",
      "[Epoch 15/200] [Batch 1/169] [D loss: 0.650799] [G loss: 0.752589]\n",
      "[Epoch 15/200] [Batch 2/169] [D loss: 0.621384] [G loss: 0.817599]\n",
      "[Epoch 15/200] [Batch 3/169] [D loss: 0.638727] [G loss: 0.852645]\n",
      "[Epoch 15/200] [Batch 4/169] [D loss: 0.635607] [G loss: 0.859856]\n",
      "[Epoch 15/200] [Batch 5/169] [D loss: 0.656252] [G loss: 0.833268]\n",
      "[Epoch 15/200] [Batch 6/169] [D loss: 0.629917] [G loss: 0.780192]\n",
      "[Epoch 15/200] [Batch 7/169] [D loss: 0.648200] [G loss: 0.755205]\n",
      "[Epoch 15/200] [Batch 8/169] [D loss: 0.669106] [G loss: 0.723583]\n",
      "[Epoch 15/200] [Batch 9/169] [D loss: 0.652147] [G loss: 0.809732]\n",
      "[Epoch 15/200] [Batch 10/169] [D loss: 0.658183] [G loss: 0.767171]\n",
      "[Epoch 15/200] [Batch 11/169] [D loss: 0.639382] [G loss: 0.758134]\n",
      "[Epoch 15/200] [Batch 12/169] [D loss: 0.658648] [G loss: 0.797327]\n",
      "[Epoch 15/200] [Batch 13/169] [D loss: 0.637452] [G loss: 0.760216]\n",
      "[Epoch 15/200] [Batch 14/169] [D loss: 0.658106] [G loss: 0.807426]\n",
      "[Epoch 15/200] [Batch 15/169] [D loss: 0.686868] [G loss: 0.825507]\n",
      "[Epoch 15/200] [Batch 16/169] [D loss: 0.697165] [G loss: 0.785924]\n",
      "[Epoch 15/200] [Batch 17/169] [D loss: 0.669574] [G loss: 0.806846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 18/169] [D loss: 0.668499] [G loss: 0.802875]\n",
      "[Epoch 15/200] [Batch 19/169] [D loss: 0.678509] [G loss: 0.778668]\n",
      "[Epoch 15/200] [Batch 20/169] [D loss: 0.629973] [G loss: 0.840696]\n",
      "[Epoch 15/200] [Batch 21/169] [D loss: 0.625576] [G loss: 0.846441]\n",
      "[Epoch 15/200] [Batch 22/169] [D loss: 0.625145] [G loss: 0.852192]\n",
      "[Epoch 15/200] [Batch 23/169] [D loss: 0.636009] [G loss: 0.810629]\n",
      "[Epoch 15/200] [Batch 24/169] [D loss: 0.620697] [G loss: 0.868103]\n",
      "[Epoch 15/200] [Batch 25/169] [D loss: 0.613553] [G loss: 0.850321]\n",
      "[Epoch 15/200] [Batch 26/169] [D loss: 0.632982] [G loss: 0.808282]\n",
      "[Epoch 15/200] [Batch 27/169] [D loss: 0.595332] [G loss: 0.808671]\n",
      "[Epoch 15/200] [Batch 28/169] [D loss: 0.620265] [G loss: 0.779383]\n",
      "[Epoch 15/200] [Batch 29/169] [D loss: 0.602717] [G loss: 0.762210]\n",
      "[Epoch 15/200] [Batch 30/169] [D loss: 0.647881] [G loss: 0.778974]\n",
      "[Epoch 15/200] [Batch 31/169] [D loss: 0.652927] [G loss: 0.770731]\n",
      "[Epoch 15/200] [Batch 32/169] [D loss: 0.643137] [G loss: 0.714870]\n",
      "[Epoch 15/200] [Batch 33/169] [D loss: 0.681093] [G loss: 0.688427]\n",
      "[Epoch 15/200] [Batch 34/169] [D loss: 0.714690] [G loss: 0.674877]\n",
      "[Epoch 15/200] [Batch 35/169] [D loss: 0.665241] [G loss: 0.686354]\n",
      "[Epoch 15/200] [Batch 36/169] [D loss: 0.654208] [G loss: 0.670139]\n",
      "[Epoch 15/200] [Batch 37/169] [D loss: 0.711571] [G loss: 0.701675]\n",
      "[Epoch 15/200] [Batch 38/169] [D loss: 0.655736] [G loss: 0.826100]\n",
      "[Epoch 15/200] [Batch 39/169] [D loss: 0.646423] [G loss: 0.779295]\n",
      "[Epoch 15/200] [Batch 40/169] [D loss: 0.633943] [G loss: 0.815392]\n",
      "[Epoch 15/200] [Batch 41/169] [D loss: 0.659183] [G loss: 0.822100]\n",
      "[Epoch 15/200] [Batch 42/169] [D loss: 0.567488] [G loss: 0.806878]\n",
      "[Epoch 15/200] [Batch 43/169] [D loss: 0.596895] [G loss: 0.772308]\n",
      "[Epoch 15/200] [Batch 44/169] [D loss: 0.611356] [G loss: 0.784087]\n",
      "[Epoch 15/200] [Batch 45/169] [D loss: 0.608299] [G loss: 0.775433]\n",
      "[Epoch 15/200] [Batch 46/169] [D loss: 0.668000] [G loss: 0.770862]\n",
      "[Epoch 15/200] [Batch 47/169] [D loss: 0.614885] [G loss: 0.732120]\n",
      "[Epoch 15/200] [Batch 48/169] [D loss: 0.661959] [G loss: 0.714936]\n",
      "[Epoch 15/200] [Batch 49/169] [D loss: 0.640414] [G loss: 0.679491]\n",
      "[Epoch 15/200] [Batch 50/169] [D loss: 0.652830] [G loss: 0.690234]\n",
      "[Epoch 15/200] [Batch 51/169] [D loss: 0.624189] [G loss: 0.668141]\n",
      "[Epoch 15/200] [Batch 52/169] [D loss: 0.647207] [G loss: 0.727814]\n",
      "[Epoch 15/200] [Batch 53/169] [D loss: 0.683437] [G loss: 0.700616]\n",
      "[Epoch 15/200] [Batch 54/169] [D loss: 0.651322] [G loss: 0.710576]\n",
      "[Epoch 15/200] [Batch 55/169] [D loss: 0.664058] [G loss: 0.725108]\n",
      "[Epoch 15/200] [Batch 56/169] [D loss: 0.654856] [G loss: 0.773124]\n",
      "[Epoch 15/200] [Batch 57/169] [D loss: 0.645553] [G loss: 0.873635]\n",
      "[Epoch 15/200] [Batch 58/169] [D loss: 0.646702] [G loss: 0.739478]\n",
      "[Epoch 15/200] [Batch 59/169] [D loss: 0.656937] [G loss: 0.702607]\n",
      "[Epoch 15/200] [Batch 60/169] [D loss: 0.628466] [G loss: 0.787553]\n",
      "[Epoch 15/200] [Batch 61/169] [D loss: 0.633127] [G loss: 0.887144]\n",
      "[Epoch 15/200] [Batch 62/169] [D loss: 0.611538] [G loss: 0.795197]\n",
      "[Epoch 15/200] [Batch 63/169] [D loss: 0.683196] [G loss: 0.811750]\n",
      "[Epoch 15/200] [Batch 64/169] [D loss: 0.658016] [G loss: 0.789458]\n",
      "[Epoch 15/200] [Batch 65/169] [D loss: 0.639083] [G loss: 0.770443]\n",
      "[Epoch 15/200] [Batch 66/169] [D loss: 0.672779] [G loss: 0.789080]\n",
      "[Epoch 15/200] [Batch 67/169] [D loss: 0.622099] [G loss: 0.881062]\n",
      "[Epoch 15/200] [Batch 68/169] [D loss: 0.675253] [G loss: 0.790200]\n",
      "[Epoch 15/200] [Batch 69/169] [D loss: 0.675101] [G loss: 0.798978]\n",
      "[Epoch 15/200] [Batch 70/169] [D loss: 0.615066] [G loss: 0.811898]\n",
      "[Epoch 15/200] [Batch 71/169] [D loss: 0.672909] [G loss: 0.807292]\n",
      "[Epoch 15/200] [Batch 72/169] [D loss: 0.668840] [G loss: 0.826330]\n",
      "[Epoch 15/200] [Batch 73/169] [D loss: 0.673580] [G loss: 0.834304]\n",
      "[Epoch 15/200] [Batch 74/169] [D loss: 0.687044] [G loss: 0.810682]\n",
      "[Epoch 15/200] [Batch 75/169] [D loss: 0.637900] [G loss: 0.751880]\n",
      "[Epoch 15/200] [Batch 76/169] [D loss: 0.669935] [G loss: 0.819951]\n",
      "[Epoch 15/200] [Batch 77/169] [D loss: 0.653008] [G loss: 0.767039]\n",
      "[Epoch 15/200] [Batch 78/169] [D loss: 0.661900] [G loss: 0.795982]\n",
      "[Epoch 15/200] [Batch 79/169] [D loss: 0.650085] [G loss: 0.809815]\n",
      "[Epoch 15/200] [Batch 80/169] [D loss: 0.644005] [G loss: 0.792082]\n",
      "[Epoch 15/200] [Batch 81/169] [D loss: 0.620234] [G loss: 0.770997]\n",
      "[Epoch 15/200] [Batch 82/169] [D loss: 0.626089] [G loss: 0.804257]\n",
      "[Epoch 15/200] [Batch 83/169] [D loss: 0.638187] [G loss: 0.756958]\n",
      "[Epoch 15/200] [Batch 84/169] [D loss: 0.667290] [G loss: 0.834887]\n",
      "[Epoch 15/200] [Batch 85/169] [D loss: 0.590874] [G loss: 0.773535]\n",
      "[Epoch 15/200] [Batch 86/169] [D loss: 0.635896] [G loss: 0.784352]\n",
      "[Epoch 15/200] [Batch 87/169] [D loss: 0.694718] [G loss: 0.848894]\n",
      "[Epoch 15/200] [Batch 88/169] [D loss: 0.636915] [G loss: 0.818149]\n",
      "[Epoch 15/200] [Batch 89/169] [D loss: 0.660821] [G loss: 0.810644]\n",
      "[Epoch 15/200] [Batch 90/169] [D loss: 0.674347] [G loss: 0.929041]\n",
      "[Epoch 15/200] [Batch 91/169] [D loss: 0.679286] [G loss: 0.815759]\n",
      "[Epoch 15/200] [Batch 92/169] [D loss: 0.619631] [G loss: 0.767390]\n",
      "[Epoch 15/200] [Batch 93/169] [D loss: 0.640936] [G loss: 0.788519]\n",
      "[Epoch 15/200] [Batch 94/169] [D loss: 0.692202] [G loss: 0.808581]\n",
      "[Epoch 15/200] [Batch 95/169] [D loss: 0.683927] [G loss: 0.722716]\n",
      "[Epoch 15/200] [Batch 96/169] [D loss: 0.687855] [G loss: 0.667974]\n",
      "[Epoch 15/200] [Batch 97/169] [D loss: 0.701617] [G loss: 0.699289]\n",
      "[Epoch 15/200] [Batch 98/169] [D loss: 0.711512] [G loss: 0.728309]\n",
      "[Epoch 15/200] [Batch 99/169] [D loss: 0.653588] [G loss: 0.742288]\n",
      "[Epoch 15/200] [Batch 100/169] [D loss: 0.646691] [G loss: 0.732172]\n",
      "[Epoch 15/200] [Batch 101/169] [D loss: 0.641927] [G loss: 0.750484]\n",
      "[Epoch 15/200] [Batch 102/169] [D loss: 0.637901] [G loss: 0.699320]\n",
      "[Epoch 15/200] [Batch 103/169] [D loss: 0.626685] [G loss: 0.741383]\n",
      "[Epoch 15/200] [Batch 104/169] [D loss: 0.629906] [G loss: 0.770362]\n",
      "[Epoch 15/200] [Batch 105/169] [D loss: 0.612728] [G loss: 0.790442]\n",
      "[Epoch 15/200] [Batch 106/169] [D loss: 0.621716] [G loss: 0.811614]\n",
      "[Epoch 15/200] [Batch 107/169] [D loss: 0.597978] [G loss: 0.834294]\n",
      "[Epoch 15/200] [Batch 108/169] [D loss: 0.679332] [G loss: 0.762483]\n",
      "[Epoch 15/200] [Batch 109/169] [D loss: 0.619960] [G loss: 0.768383]\n",
      "[Epoch 15/200] [Batch 110/169] [D loss: 0.651659] [G loss: 0.895359]\n",
      "[Epoch 15/200] [Batch 111/169] [D loss: 0.649552] [G loss: 0.898598]\n",
      "[Epoch 15/200] [Batch 112/169] [D loss: 0.693895] [G loss: 0.810270]\n",
      "[Epoch 15/200] [Batch 113/169] [D loss: 0.708881] [G loss: 0.762799]\n",
      "[Epoch 15/200] [Batch 114/169] [D loss: 0.650511] [G loss: 0.758791]\n",
      "[Epoch 15/200] [Batch 115/169] [D loss: 0.654987] [G loss: 0.766640]\n",
      "[Epoch 15/200] [Batch 116/169] [D loss: 0.637537] [G loss: 0.737712]\n",
      "[Epoch 15/200] [Batch 117/169] [D loss: 0.646733] [G loss: 0.733110]\n",
      "[Epoch 15/200] [Batch 118/169] [D loss: 0.680995] [G loss: 0.671819]\n",
      "[Epoch 15/200] [Batch 119/169] [D loss: 0.672692] [G loss: 0.791969]\n",
      "[Epoch 15/200] [Batch 120/169] [D loss: 0.694503] [G loss: 0.789649]\n",
      "[Epoch 15/200] [Batch 121/169] [D loss: 0.683037] [G loss: 0.863240]\n",
      "[Epoch 15/200] [Batch 122/169] [D loss: 0.665231] [G loss: 0.839151]\n",
      "[Epoch 15/200] [Batch 123/169] [D loss: 0.661487] [G loss: 0.810195]\n",
      "[Epoch 15/200] [Batch 124/169] [D loss: 0.657048] [G loss: 0.806704]\n",
      "[Epoch 15/200] [Batch 125/169] [D loss: 0.670327] [G loss: 0.736041]\n",
      "[Epoch 15/200] [Batch 126/169] [D loss: 0.674370] [G loss: 0.784989]\n",
      "[Epoch 15/200] [Batch 127/169] [D loss: 0.654679] [G loss: 0.738538]\n",
      "[Epoch 15/200] [Batch 128/169] [D loss: 0.661831] [G loss: 0.759274]\n",
      "[Epoch 15/200] [Batch 129/169] [D loss: 0.668384] [G loss: 0.734131]\n",
      "[Epoch 15/200] [Batch 130/169] [D loss: 0.690351] [G loss: 0.749702]\n",
      "[Epoch 15/200] [Batch 131/169] [D loss: 0.637494] [G loss: 0.778032]\n",
      "[Epoch 15/200] [Batch 132/169] [D loss: 0.687645] [G loss: 0.787382]\n",
      "[Epoch 15/200] [Batch 133/169] [D loss: 0.666803] [G loss: 0.737083]\n",
      "[Epoch 15/200] [Batch 134/169] [D loss: 0.661555] [G loss: 0.781782]\n",
      "[Epoch 15/200] [Batch 135/169] [D loss: 0.707985] [G loss: 0.678276]\n",
      "[Epoch 15/200] [Batch 136/169] [D loss: 0.701293] [G loss: 0.741726]\n",
      "[Epoch 15/200] [Batch 137/169] [D loss: 0.690992] [G loss: 0.776156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 138/169] [D loss: 0.694833] [G loss: 0.744986]\n",
      "[Epoch 15/200] [Batch 139/169] [D loss: 0.674503] [G loss: 0.797460]\n",
      "[Epoch 15/200] [Batch 140/169] [D loss: 0.648181] [G loss: 0.762532]\n",
      "[Epoch 15/200] [Batch 141/169] [D loss: 0.673104] [G loss: 0.789040]\n",
      "[Epoch 15/200] [Batch 142/169] [D loss: 0.664669] [G loss: 0.831736]\n",
      "[Epoch 15/200] [Batch 143/169] [D loss: 0.649807] [G loss: 0.803901]\n",
      "[Epoch 15/200] [Batch 144/169] [D loss: 0.689152] [G loss: 0.788576]\n",
      "[Epoch 15/200] [Batch 145/169] [D loss: 0.621680] [G loss: 0.862980]\n",
      "[Epoch 15/200] [Batch 146/169] [D loss: 0.634333] [G loss: 0.744061]\n",
      "[Epoch 15/200] [Batch 147/169] [D loss: 0.684805] [G loss: 0.775010]\n",
      "[Epoch 15/200] [Batch 148/169] [D loss: 0.639092] [G loss: 0.770754]\n",
      "[Epoch 15/200] [Batch 149/169] [D loss: 0.645155] [G loss: 0.778276]\n",
      "[Epoch 15/200] [Batch 150/169] [D loss: 0.671332] [G loss: 0.761982]\n",
      "[Epoch 15/200] [Batch 151/169] [D loss: 0.702545] [G loss: 0.785679]\n",
      "[Epoch 15/200] [Batch 152/169] [D loss: 0.680657] [G loss: 0.740240]\n",
      "[Epoch 15/200] [Batch 153/169] [D loss: 0.645586] [G loss: 0.757775]\n",
      "[Epoch 15/200] [Batch 154/169] [D loss: 0.699224] [G loss: 0.729156]\n",
      "[Epoch 15/200] [Batch 155/169] [D loss: 0.675188] [G loss: 0.699470]\n",
      "[Epoch 15/200] [Batch 156/169] [D loss: 0.658149] [G loss: 0.819140]\n",
      "[Epoch 15/200] [Batch 157/169] [D loss: 0.658236] [G loss: 0.757518]\n",
      "[Epoch 15/200] [Batch 158/169] [D loss: 0.665053] [G loss: 0.759186]\n",
      "[Epoch 15/200] [Batch 159/169] [D loss: 0.621196] [G loss: 0.830192]\n",
      "[Epoch 15/200] [Batch 160/169] [D loss: 0.672688] [G loss: 0.841948]\n",
      "[Epoch 15/200] [Batch 161/169] [D loss: 0.665757] [G loss: 0.841701]\n",
      "[Epoch 15/200] [Batch 162/169] [D loss: 0.649846] [G loss: 0.819675]\n",
      "[Epoch 15/200] [Batch 163/169] [D loss: 0.650564] [G loss: 0.797584]\n",
      "[Epoch 15/200] [Batch 164/169] [D loss: 0.644804] [G loss: 0.820962]\n",
      "[Epoch 15/200] [Batch 165/169] [D loss: 0.668457] [G loss: 0.820918]\n",
      "[Epoch 15/200] [Batch 166/169] [D loss: 0.650705] [G loss: 0.798537]\n",
      "[Epoch 15/200] [Batch 167/169] [D loss: 0.680956] [G loss: 0.754853]\n",
      "[Epoch 15/200] [Batch 168/169] [D loss: 0.647245] [G loss: 0.778255]\n",
      "[Epoch 16/200] [Batch 0/169] [D loss: 0.653274] [G loss: 0.711169]\n",
      "[Epoch 16/200] [Batch 1/169] [D loss: 0.702075] [G loss: 0.742512]\n",
      "[Epoch 16/200] [Batch 2/169] [D loss: 0.652661] [G loss: 0.749242]\n",
      "[Epoch 16/200] [Batch 3/169] [D loss: 0.700764] [G loss: 0.810324]\n",
      "[Epoch 16/200] [Batch 4/169] [D loss: 0.680607] [G loss: 0.757897]\n",
      "[Epoch 16/200] [Batch 5/169] [D loss: 0.663369] [G loss: 0.820066]\n",
      "[Epoch 16/200] [Batch 6/169] [D loss: 0.678851] [G loss: 0.801735]\n",
      "[Epoch 16/200] [Batch 7/169] [D loss: 0.671445] [G loss: 0.728028]\n",
      "[Epoch 16/200] [Batch 8/169] [D loss: 0.666696] [G loss: 0.771138]\n",
      "[Epoch 16/200] [Batch 9/169] [D loss: 0.662757] [G loss: 0.844491]\n",
      "[Epoch 16/200] [Batch 10/169] [D loss: 0.698596] [G loss: 0.767117]\n",
      "[Epoch 16/200] [Batch 11/169] [D loss: 0.680013] [G loss: 0.832838]\n",
      "[Epoch 16/200] [Batch 12/169] [D loss: 0.605743] [G loss: 0.776474]\n",
      "[Epoch 16/200] [Batch 13/169] [D loss: 0.665311] [G loss: 0.724899]\n",
      "[Epoch 16/200] [Batch 14/169] [D loss: 0.683056] [G loss: 0.804055]\n",
      "[Epoch 16/200] [Batch 15/169] [D loss: 0.643452] [G loss: 0.743864]\n",
      "[Epoch 16/200] [Batch 16/169] [D loss: 0.664324] [G loss: 0.818183]\n",
      "[Epoch 16/200] [Batch 17/169] [D loss: 0.645202] [G loss: 0.768692]\n",
      "[Epoch 16/200] [Batch 18/169] [D loss: 0.649355] [G loss: 0.774427]\n",
      "[Epoch 16/200] [Batch 19/169] [D loss: 0.645098] [G loss: 0.776892]\n",
      "[Epoch 16/200] [Batch 20/169] [D loss: 0.680282] [G loss: 0.812626]\n",
      "[Epoch 16/200] [Batch 21/169] [D loss: 0.617312] [G loss: 0.838441]\n",
      "[Epoch 16/200] [Batch 22/169] [D loss: 0.663116] [G loss: 0.804522]\n",
      "[Epoch 16/200] [Batch 23/169] [D loss: 0.657974] [G loss: 0.812432]\n",
      "[Epoch 16/200] [Batch 24/169] [D loss: 0.678988] [G loss: 0.772341]\n",
      "[Epoch 16/200] [Batch 25/169] [D loss: 0.645489] [G loss: 0.805276]\n",
      "[Epoch 16/200] [Batch 26/169] [D loss: 0.636992] [G loss: 0.817778]\n",
      "[Epoch 16/200] [Batch 27/169] [D loss: 0.656832] [G loss: 0.787833]\n",
      "[Epoch 16/200] [Batch 28/169] [D loss: 0.643452] [G loss: 0.779612]\n",
      "[Epoch 16/200] [Batch 29/169] [D loss: 0.625882] [G loss: 0.750391]\n",
      "[Epoch 16/200] [Batch 30/169] [D loss: 0.668493] [G loss: 0.714045]\n",
      "[Epoch 16/200] [Batch 31/169] [D loss: 0.649453] [G loss: 0.777703]\n",
      "[Epoch 16/200] [Batch 32/169] [D loss: 0.663525] [G loss: 0.769464]\n",
      "[Epoch 16/200] [Batch 33/169] [D loss: 0.649684] [G loss: 0.818007]\n",
      "[Epoch 16/200] [Batch 34/169] [D loss: 0.685539] [G loss: 0.783660]\n",
      "[Epoch 16/200] [Batch 35/169] [D loss: 0.682433] [G loss: 0.828913]\n",
      "[Epoch 16/200] [Batch 36/169] [D loss: 0.664932] [G loss: 0.770613]\n",
      "[Epoch 16/200] [Batch 37/169] [D loss: 0.706227] [G loss: 0.783686]\n",
      "[Epoch 16/200] [Batch 38/169] [D loss: 0.651936] [G loss: 0.792415]\n",
      "[Epoch 16/200] [Batch 39/169] [D loss: 0.656862] [G loss: 0.740861]\n",
      "[Epoch 16/200] [Batch 40/169] [D loss: 0.645847] [G loss: 0.755064]\n",
      "[Epoch 16/200] [Batch 41/169] [D loss: 0.689867] [G loss: 0.743158]\n",
      "[Epoch 16/200] [Batch 42/169] [D loss: 0.668761] [G loss: 0.753296]\n",
      "[Epoch 16/200] [Batch 43/169] [D loss: 0.685491] [G loss: 0.809493]\n",
      "[Epoch 16/200] [Batch 44/169] [D loss: 0.645501] [G loss: 0.837465]\n",
      "[Epoch 16/200] [Batch 45/169] [D loss: 0.651236] [G loss: 0.820091]\n",
      "[Epoch 16/200] [Batch 46/169] [D loss: 0.653535] [G loss: 0.770043]\n",
      "[Epoch 16/200] [Batch 47/169] [D loss: 0.632094] [G loss: 0.829476]\n",
      "[Epoch 16/200] [Batch 48/169] [D loss: 0.620722] [G loss: 0.838056]\n",
      "[Epoch 16/200] [Batch 49/169] [D loss: 0.632932] [G loss: 0.788659]\n",
      "[Epoch 16/200] [Batch 50/169] [D loss: 0.676180] [G loss: 0.797552]\n",
      "[Epoch 16/200] [Batch 51/169] [D loss: 0.640282] [G loss: 0.852508]\n",
      "[Epoch 16/200] [Batch 52/169] [D loss: 0.656424] [G loss: 0.823780]\n",
      "[Epoch 16/200] [Batch 53/169] [D loss: 0.662998] [G loss: 0.800083]\n",
      "[Epoch 16/200] [Batch 54/169] [D loss: 0.634442] [G loss: 0.804764]\n",
      "[Epoch 16/200] [Batch 55/169] [D loss: 0.646127] [G loss: 0.778430]\n",
      "[Epoch 16/200] [Batch 56/169] [D loss: 0.647604] [G loss: 0.786369]\n",
      "[Epoch 16/200] [Batch 57/169] [D loss: 0.625262] [G loss: 0.801304]\n",
      "[Epoch 16/200] [Batch 58/169] [D loss: 0.674914] [G loss: 0.791872]\n",
      "[Epoch 16/200] [Batch 59/169] [D loss: 0.666529] [G loss: 0.774871]\n",
      "[Epoch 16/200] [Batch 60/169] [D loss: 0.664399] [G loss: 0.788563]\n",
      "[Epoch 16/200] [Batch 61/169] [D loss: 0.624860] [G loss: 0.797508]\n",
      "[Epoch 16/200] [Batch 62/169] [D loss: 0.627105] [G loss: 0.747565]\n",
      "[Epoch 16/200] [Batch 63/169] [D loss: 0.661422] [G loss: 0.741345]\n",
      "[Epoch 16/200] [Batch 64/169] [D loss: 0.655012] [G loss: 0.709631]\n",
      "[Epoch 16/200] [Batch 65/169] [D loss: 0.671516] [G loss: 0.736656]\n",
      "[Epoch 16/200] [Batch 66/169] [D loss: 0.706156] [G loss: 0.731300]\n",
      "[Epoch 16/200] [Batch 67/169] [D loss: 0.720978] [G loss: 0.754665]\n",
      "[Epoch 16/200] [Batch 68/169] [D loss: 0.672146] [G loss: 0.763930]\n",
      "[Epoch 16/200] [Batch 69/169] [D loss: 0.651924] [G loss: 0.760626]\n",
      "[Epoch 16/200] [Batch 70/169] [D loss: 0.672933] [G loss: 0.763212]\n",
      "[Epoch 16/200] [Batch 71/169] [D loss: 0.640769] [G loss: 0.815024]\n",
      "[Epoch 16/200] [Batch 72/169] [D loss: 0.658756] [G loss: 0.774572]\n",
      "[Epoch 16/200] [Batch 73/169] [D loss: 0.684264] [G loss: 0.821695]\n",
      "[Epoch 16/200] [Batch 74/169] [D loss: 0.639856] [G loss: 0.761910]\n",
      "[Epoch 16/200] [Batch 75/169] [D loss: 0.664443] [G loss: 0.814146]\n",
      "[Epoch 16/200] [Batch 76/169] [D loss: 0.640059] [G loss: 0.835716]\n",
      "[Epoch 16/200] [Batch 77/169] [D loss: 0.695191] [G loss: 0.786034]\n",
      "[Epoch 16/200] [Batch 78/169] [D loss: 0.658128] [G loss: 0.826617]\n",
      "[Epoch 16/200] [Batch 79/169] [D loss: 0.672754] [G loss: 0.784915]\n",
      "[Epoch 16/200] [Batch 80/169] [D loss: 0.658915] [G loss: 0.745975]\n",
      "[Epoch 16/200] [Batch 81/169] [D loss: 0.643681] [G loss: 0.775800]\n",
      "[Epoch 16/200] [Batch 82/169] [D loss: 0.664731] [G loss: 0.710408]\n",
      "[Epoch 16/200] [Batch 83/169] [D loss: 0.648768] [G loss: 0.723272]\n",
      "[Epoch 16/200] [Batch 84/169] [D loss: 0.631247] [G loss: 0.713614]\n",
      "[Epoch 16/200] [Batch 85/169] [D loss: 0.637373] [G loss: 0.748680]\n",
      "[Epoch 16/200] [Batch 86/169] [D loss: 0.650435] [G loss: 0.751419]\n",
      "[Epoch 16/200] [Batch 87/169] [D loss: 0.635642] [G loss: 0.734385]\n",
      "[Epoch 16/200] [Batch 88/169] [D loss: 0.626538] [G loss: 0.763101]\n",
      "[Epoch 16/200] [Batch 89/169] [D loss: 0.653201] [G loss: 0.778185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 90/169] [D loss: 0.615104] [G loss: 0.761052]\n",
      "[Epoch 16/200] [Batch 91/169] [D loss: 0.688770] [G loss: 0.776914]\n",
      "[Epoch 16/200] [Batch 92/169] [D loss: 0.641919] [G loss: 0.782115]\n",
      "[Epoch 16/200] [Batch 93/169] [D loss: 0.658208] [G loss: 0.777450]\n",
      "[Epoch 16/200] [Batch 94/169] [D loss: 0.685666] [G loss: 0.797644]\n",
      "[Epoch 16/200] [Batch 95/169] [D loss: 0.692054] [G loss: 0.753841]\n",
      "[Epoch 16/200] [Batch 96/169] [D loss: 0.692922] [G loss: 0.728145]\n",
      "[Epoch 16/200] [Batch 97/169] [D loss: 0.634380] [G loss: 0.731592]\n",
      "[Epoch 16/200] [Batch 98/169] [D loss: 0.677068] [G loss: 0.764004]\n",
      "[Epoch 16/200] [Batch 99/169] [D loss: 0.685491] [G loss: 0.737425]\n",
      "[Epoch 16/200] [Batch 100/169] [D loss: 0.704613] [G loss: 0.750975]\n",
      "[Epoch 16/200] [Batch 101/169] [D loss: 0.651886] [G loss: 0.751561]\n",
      "[Epoch 16/200] [Batch 102/169] [D loss: 0.657061] [G loss: 0.745356]\n",
      "[Epoch 16/200] [Batch 103/169] [D loss: 0.679130] [G loss: 0.825084]\n",
      "[Epoch 16/200] [Batch 104/169] [D loss: 0.705378] [G loss: 0.735657]\n",
      "[Epoch 16/200] [Batch 105/169] [D loss: 0.682781] [G loss: 0.757041]\n",
      "[Epoch 16/200] [Batch 106/169] [D loss: 0.658196] [G loss: 0.749921]\n",
      "[Epoch 16/200] [Batch 107/169] [D loss: 0.658864] [G loss: 0.778485]\n",
      "[Epoch 16/200] [Batch 108/169] [D loss: 0.681746] [G loss: 0.717591]\n",
      "[Epoch 16/200] [Batch 109/169] [D loss: 0.676367] [G loss: 0.717585]\n",
      "[Epoch 16/200] [Batch 110/169] [D loss: 0.685001] [G loss: 0.782434]\n",
      "[Epoch 16/200] [Batch 111/169] [D loss: 0.648614] [G loss: 0.777289]\n",
      "[Epoch 16/200] [Batch 112/169] [D loss: 0.654101] [G loss: 0.696686]\n",
      "[Epoch 16/200] [Batch 113/169] [D loss: 0.674015] [G loss: 0.790270]\n",
      "[Epoch 16/200] [Batch 114/169] [D loss: 0.622308] [G loss: 0.742261]\n",
      "[Epoch 16/200] [Batch 115/169] [D loss: 0.653960] [G loss: 0.764186]\n",
      "[Epoch 16/200] [Batch 116/169] [D loss: 0.630086] [G loss: 0.819328]\n",
      "[Epoch 16/200] [Batch 117/169] [D loss: 0.645999] [G loss: 0.765153]\n",
      "[Epoch 16/200] [Batch 118/169] [D loss: 0.649693] [G loss: 0.775263]\n",
      "[Epoch 16/200] [Batch 119/169] [D loss: 0.661139] [G loss: 0.718638]\n",
      "[Epoch 16/200] [Batch 120/169] [D loss: 0.657577] [G loss: 0.730822]\n",
      "[Epoch 16/200] [Batch 121/169] [D loss: 0.658743] [G loss: 0.707587]\n",
      "[Epoch 16/200] [Batch 122/169] [D loss: 0.666114] [G loss: 0.768973]\n",
      "[Epoch 16/200] [Batch 123/169] [D loss: 0.680484] [G loss: 0.754577]\n",
      "[Epoch 16/200] [Batch 124/169] [D loss: 0.639142] [G loss: 0.756827]\n",
      "[Epoch 16/200] [Batch 125/169] [D loss: 0.662220] [G loss: 0.726174]\n",
      "[Epoch 16/200] [Batch 126/169] [D loss: 0.685024] [G loss: 0.822008]\n",
      "[Epoch 16/200] [Batch 127/169] [D loss: 0.674433] [G loss: 0.827033]\n",
      "[Epoch 16/200] [Batch 128/169] [D loss: 0.662709] [G loss: 0.795251]\n",
      "[Epoch 16/200] [Batch 129/169] [D loss: 0.636514] [G loss: 0.775473]\n",
      "[Epoch 16/200] [Batch 130/169] [D loss: 0.660946] [G loss: 0.790335]\n",
      "[Epoch 16/200] [Batch 131/169] [D loss: 0.645525] [G loss: 0.776493]\n",
      "[Epoch 16/200] [Batch 132/169] [D loss: 0.651949] [G loss: 0.781172]\n",
      "[Epoch 16/200] [Batch 133/169] [D loss: 0.626313] [G loss: 0.768681]\n",
      "[Epoch 16/200] [Batch 134/169] [D loss: 0.672691] [G loss: 0.801004]\n",
      "[Epoch 16/200] [Batch 135/169] [D loss: 0.640195] [G loss: 0.770178]\n",
      "[Epoch 16/200] [Batch 136/169] [D loss: 0.651065] [G loss: 0.774763]\n",
      "[Epoch 16/200] [Batch 137/169] [D loss: 0.690554] [G loss: 0.808092]\n",
      "[Epoch 16/200] [Batch 138/169] [D loss: 0.657288] [G loss: 0.761664]\n",
      "[Epoch 16/200] [Batch 139/169] [D loss: 0.636800] [G loss: 0.794974]\n",
      "[Epoch 16/200] [Batch 140/169] [D loss: 0.655368] [G loss: 0.773654]\n",
      "[Epoch 16/200] [Batch 141/169] [D loss: 0.632827] [G loss: 0.764921]\n",
      "[Epoch 16/200] [Batch 142/169] [D loss: 0.669885] [G loss: 0.776267]\n",
      "[Epoch 16/200] [Batch 143/169] [D loss: 0.643071] [G loss: 0.743039]\n",
      "[Epoch 16/200] [Batch 144/169] [D loss: 0.692178] [G loss: 0.780442]\n",
      "[Epoch 16/200] [Batch 145/169] [D loss: 0.682898] [G loss: 0.767338]\n",
      "[Epoch 16/200] [Batch 146/169] [D loss: 0.672055] [G loss: 0.723737]\n",
      "[Epoch 16/200] [Batch 147/169] [D loss: 0.657391] [G loss: 0.737824]\n",
      "[Epoch 16/200] [Batch 148/169] [D loss: 0.639401] [G loss: 0.726958]\n",
      "[Epoch 16/200] [Batch 149/169] [D loss: 0.691061] [G loss: 0.764369]\n",
      "[Epoch 16/200] [Batch 150/169] [D loss: 0.694210] [G loss: 0.743998]\n",
      "[Epoch 16/200] [Batch 151/169] [D loss: 0.695341] [G loss: 0.740887]\n",
      "[Epoch 16/200] [Batch 152/169] [D loss: 0.642410] [G loss: 0.792987]\n",
      "[Epoch 16/200] [Batch 153/169] [D loss: 0.634385] [G loss: 0.736511]\n",
      "[Epoch 16/200] [Batch 154/169] [D loss: 0.637955] [G loss: 0.758499]\n",
      "[Epoch 16/200] [Batch 155/169] [D loss: 0.658989] [G loss: 0.795128]\n",
      "[Epoch 16/200] [Batch 156/169] [D loss: 0.659675] [G loss: 0.750017]\n",
      "[Epoch 16/200] [Batch 157/169] [D loss: 0.645444] [G loss: 0.811155]\n",
      "[Epoch 16/200] [Batch 158/169] [D loss: 0.663336] [G loss: 0.771874]\n",
      "[Epoch 16/200] [Batch 159/169] [D loss: 0.657926] [G loss: 0.743641]\n",
      "[Epoch 16/200] [Batch 160/169] [D loss: 0.659913] [G loss: 0.727869]\n",
      "[Epoch 16/200] [Batch 161/169] [D loss: 0.691146] [G loss: 0.666338]\n",
      "[Epoch 16/200] [Batch 162/169] [D loss: 0.703099] [G loss: 0.674211]\n",
      "[Epoch 16/200] [Batch 163/169] [D loss: 0.731047] [G loss: 0.699861]\n",
      "[Epoch 16/200] [Batch 164/169] [D loss: 0.722421] [G loss: 0.677835]\n",
      "[Epoch 16/200] [Batch 165/169] [D loss: 0.723500] [G loss: 0.694873]\n",
      "[Epoch 16/200] [Batch 166/169] [D loss: 0.645119] [G loss: 0.793545]\n",
      "[Epoch 16/200] [Batch 167/169] [D loss: 0.672685] [G loss: 0.809851]\n",
      "[Epoch 16/200] [Batch 168/169] [D loss: 0.655537] [G loss: 0.893853]\n",
      "[Epoch 17/200] [Batch 0/169] [D loss: 0.635043] [G loss: 0.846326]\n",
      "[Epoch 17/200] [Batch 1/169] [D loss: 0.643910] [G loss: 0.816436]\n",
      "[Epoch 17/200] [Batch 2/169] [D loss: 0.653924] [G loss: 0.761885]\n",
      "[Epoch 17/200] [Batch 3/169] [D loss: 0.697559] [G loss: 0.750660]\n",
      "[Epoch 17/200] [Batch 4/169] [D loss: 0.663045] [G loss: 0.703220]\n",
      "[Epoch 17/200] [Batch 5/169] [D loss: 0.684195] [G loss: 0.713683]\n",
      "[Epoch 17/200] [Batch 6/169] [D loss: 0.663913] [G loss: 0.694648]\n",
      "[Epoch 17/200] [Batch 7/169] [D loss: 0.709791] [G loss: 0.724837]\n",
      "[Epoch 17/200] [Batch 8/169] [D loss: 0.678297] [G loss: 0.783616]\n",
      "[Epoch 17/200] [Batch 9/169] [D loss: 0.660278] [G loss: 0.786232]\n",
      "[Epoch 17/200] [Batch 10/169] [D loss: 0.652462] [G loss: 0.796784]\n",
      "[Epoch 17/200] [Batch 11/169] [D loss: 0.622960] [G loss: 0.834974]\n",
      "[Epoch 17/200] [Batch 12/169] [D loss: 0.645093] [G loss: 0.813559]\n",
      "[Epoch 17/200] [Batch 13/169] [D loss: 0.672653] [G loss: 0.811222]\n",
      "[Epoch 17/200] [Batch 14/169] [D loss: 0.639365] [G loss: 0.851606]\n",
      "[Epoch 17/200] [Batch 15/169] [D loss: 0.657849] [G loss: 0.836067]\n",
      "[Epoch 17/200] [Batch 16/169] [D loss: 0.637705] [G loss: 0.842985]\n",
      "[Epoch 17/200] [Batch 17/169] [D loss: 0.651407] [G loss: 0.776710]\n",
      "[Epoch 17/200] [Batch 18/169] [D loss: 0.627551] [G loss: 0.799763]\n",
      "[Epoch 17/200] [Batch 19/169] [D loss: 0.615417] [G loss: 0.746750]\n",
      "[Epoch 17/200] [Batch 20/169] [D loss: 0.594663] [G loss: 0.760605]\n",
      "[Epoch 17/200] [Batch 21/169] [D loss: 0.626473] [G loss: 0.782784]\n",
      "[Epoch 17/200] [Batch 22/169] [D loss: 0.610551] [G loss: 0.762460]\n",
      "[Epoch 17/200] [Batch 23/169] [D loss: 0.641951] [G loss: 0.788408]\n",
      "[Epoch 17/200] [Batch 24/169] [D loss: 0.631371] [G loss: 0.788159]\n",
      "[Epoch 17/200] [Batch 25/169] [D loss: 0.639410] [G loss: 0.751081]\n",
      "[Epoch 17/200] [Batch 26/169] [D loss: 0.644931] [G loss: 0.799445]\n",
      "[Epoch 17/200] [Batch 27/169] [D loss: 0.644964] [G loss: 0.724123]\n",
      "[Epoch 17/200] [Batch 28/169] [D loss: 0.670337] [G loss: 0.737821]\n",
      "[Epoch 17/200] [Batch 29/169] [D loss: 0.704335] [G loss: 0.707981]\n",
      "[Epoch 17/200] [Batch 30/169] [D loss: 0.675264] [G loss: 0.718581]\n",
      "[Epoch 17/200] [Batch 31/169] [D loss: 0.658412] [G loss: 0.790295]\n",
      "[Epoch 17/200] [Batch 32/169] [D loss: 0.666224] [G loss: 0.824601]\n",
      "[Epoch 17/200] [Batch 33/169] [D loss: 0.668182] [G loss: 0.818489]\n",
      "[Epoch 17/200] [Batch 34/169] [D loss: 0.644882] [G loss: 0.790307]\n",
      "[Epoch 17/200] [Batch 35/169] [D loss: 0.685156] [G loss: 0.735890]\n",
      "[Epoch 17/200] [Batch 36/169] [D loss: 0.618365] [G loss: 0.785580]\n",
      "[Epoch 17/200] [Batch 37/169] [D loss: 0.665954] [G loss: 0.802841]\n",
      "[Epoch 17/200] [Batch 38/169] [D loss: 0.665261] [G loss: 0.838658]\n",
      "[Epoch 17/200] [Batch 39/169] [D loss: 0.651105] [G loss: 0.757682]\n",
      "[Epoch 17/200] [Batch 40/169] [D loss: 0.646888] [G loss: 0.794989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 41/169] [D loss: 0.636220] [G loss: 0.793491]\n",
      "[Epoch 17/200] [Batch 42/169] [D loss: 0.641876] [G loss: 0.841111]\n",
      "[Epoch 17/200] [Batch 43/169] [D loss: 0.648118] [G loss: 0.775995]\n",
      "[Epoch 17/200] [Batch 44/169] [D loss: 0.622502] [G loss: 0.772404]\n",
      "[Epoch 17/200] [Batch 45/169] [D loss: 0.672855] [G loss: 0.787032]\n",
      "[Epoch 17/200] [Batch 46/169] [D loss: 0.654289] [G loss: 0.806559]\n",
      "[Epoch 17/200] [Batch 47/169] [D loss: 0.630736] [G loss: 0.751399]\n",
      "[Epoch 17/200] [Batch 48/169] [D loss: 0.663467] [G loss: 0.750766]\n",
      "[Epoch 17/200] [Batch 49/169] [D loss: 0.641152] [G loss: 0.682446]\n",
      "[Epoch 17/200] [Batch 50/169] [D loss: 0.631767] [G loss: 0.704521]\n",
      "[Epoch 17/200] [Batch 51/169] [D loss: 0.638182] [G loss: 0.713647]\n",
      "[Epoch 17/200] [Batch 52/169] [D loss: 0.644687] [G loss: 0.795246]\n",
      "[Epoch 17/200] [Batch 53/169] [D loss: 0.634073] [G loss: 0.779696]\n",
      "[Epoch 17/200] [Batch 54/169] [D loss: 0.653094] [G loss: 0.787052]\n",
      "[Epoch 17/200] [Batch 55/169] [D loss: 0.634622] [G loss: 0.786842]\n",
      "[Epoch 17/200] [Batch 56/169] [D loss: 0.657499] [G loss: 0.820681]\n",
      "[Epoch 17/200] [Batch 57/169] [D loss: 0.666868] [G loss: 0.750576]\n",
      "[Epoch 17/200] [Batch 58/169] [D loss: 0.657196] [G loss: 0.782814]\n",
      "[Epoch 17/200] [Batch 59/169] [D loss: 0.645367] [G loss: 0.776548]\n",
      "[Epoch 17/200] [Batch 60/169] [D loss: 0.686963] [G loss: 0.747774]\n",
      "[Epoch 17/200] [Batch 61/169] [D loss: 0.677396] [G loss: 0.763782]\n",
      "[Epoch 17/200] [Batch 62/169] [D loss: 0.691691] [G loss: 0.721854]\n",
      "[Epoch 17/200] [Batch 63/169] [D loss: 0.703484] [G loss: 0.739265]\n",
      "[Epoch 17/200] [Batch 64/169] [D loss: 0.642785] [G loss: 0.779026]\n",
      "[Epoch 17/200] [Batch 65/169] [D loss: 0.636058] [G loss: 0.699819]\n",
      "[Epoch 17/200] [Batch 66/169] [D loss: 0.645625] [G loss: 0.833851]\n",
      "[Epoch 17/200] [Batch 67/169] [D loss: 0.640650] [G loss: 0.740758]\n",
      "[Epoch 17/200] [Batch 68/169] [D loss: 0.612594] [G loss: 0.752677]\n",
      "[Epoch 17/200] [Batch 69/169] [D loss: 0.602005] [G loss: 0.815384]\n",
      "[Epoch 17/200] [Batch 70/169] [D loss: 0.626988] [G loss: 0.787081]\n",
      "[Epoch 17/200] [Batch 71/169] [D loss: 0.629920] [G loss: 0.777469]\n",
      "[Epoch 17/200] [Batch 72/169] [D loss: 0.634287] [G loss: 0.795096]\n",
      "[Epoch 17/200] [Batch 73/169] [D loss: 0.674690] [G loss: 0.760764]\n",
      "[Epoch 17/200] [Batch 74/169] [D loss: 0.659274] [G loss: 0.725863]\n",
      "[Epoch 17/200] [Batch 75/169] [D loss: 0.637564] [G loss: 0.673805]\n",
      "[Epoch 17/200] [Batch 76/169] [D loss: 0.741250] [G loss: 0.650675]\n",
      "[Epoch 17/200] [Batch 77/169] [D loss: 0.698251] [G loss: 0.642438]\n",
      "[Epoch 17/200] [Batch 78/169] [D loss: 0.664591] [G loss: 0.783306]\n",
      "[Epoch 17/200] [Batch 79/169] [D loss: 0.644251] [G loss: 0.734724]\n",
      "[Epoch 17/200] [Batch 80/169] [D loss: 0.616727] [G loss: 0.827855]\n",
      "[Epoch 17/200] [Batch 81/169] [D loss: 0.597689] [G loss: 0.756042]\n",
      "[Epoch 17/200] [Batch 82/169] [D loss: 0.592164] [G loss: 0.772233]\n",
      "[Epoch 17/200] [Batch 83/169] [D loss: 0.667015] [G loss: 0.735230]\n",
      "[Epoch 17/200] [Batch 84/169] [D loss: 0.600923] [G loss: 0.766407]\n",
      "[Epoch 17/200] [Batch 85/169] [D loss: 0.667630] [G loss: 0.788946]\n",
      "[Epoch 17/200] [Batch 86/169] [D loss: 0.676470] [G loss: 0.786232]\n",
      "[Epoch 17/200] [Batch 87/169] [D loss: 0.685175] [G loss: 0.801946]\n",
      "[Epoch 17/200] [Batch 88/169] [D loss: 0.687410] [G loss: 0.815112]\n",
      "[Epoch 17/200] [Batch 89/169] [D loss: 0.651238] [G loss: 0.867726]\n",
      "[Epoch 17/200] [Batch 90/169] [D loss: 0.604906] [G loss: 0.906569]\n",
      "[Epoch 17/200] [Batch 91/169] [D loss: 0.700904] [G loss: 0.773340]\n",
      "[Epoch 17/200] [Batch 92/169] [D loss: 0.639622] [G loss: 0.849070]\n",
      "[Epoch 17/200] [Batch 93/169] [D loss: 0.666955] [G loss: 0.872573]\n",
      "[Epoch 17/200] [Batch 94/169] [D loss: 0.626456] [G loss: 0.772658]\n",
      "[Epoch 17/200] [Batch 95/169] [D loss: 0.662246] [G loss: 0.812976]\n",
      "[Epoch 17/200] [Batch 96/169] [D loss: 0.635260] [G loss: 0.780370]\n",
      "[Epoch 17/200] [Batch 97/169] [D loss: 0.635435] [G loss: 0.857320]\n",
      "[Epoch 17/200] [Batch 98/169] [D loss: 0.633364] [G loss: 0.866298]\n",
      "[Epoch 17/200] [Batch 99/169] [D loss: 0.596511] [G loss: 0.863801]\n",
      "[Epoch 17/200] [Batch 100/169] [D loss: 0.571650] [G loss: 0.837806]\n",
      "[Epoch 17/200] [Batch 101/169] [D loss: 0.619564] [G loss: 0.818684]\n",
      "[Epoch 17/200] [Batch 102/169] [D loss: 0.573923] [G loss: 0.884507]\n",
      "[Epoch 17/200] [Batch 103/169] [D loss: 0.635580] [G loss: 0.759352]\n",
      "[Epoch 17/200] [Batch 104/169] [D loss: 0.614928] [G loss: 0.817655]\n",
      "[Epoch 17/200] [Batch 105/169] [D loss: 0.619558] [G loss: 0.717898]\n",
      "[Epoch 17/200] [Batch 106/169] [D loss: 0.622788] [G loss: 0.728774]\n",
      "[Epoch 17/200] [Batch 107/169] [D loss: 0.744960] [G loss: 0.686666]\n",
      "[Epoch 17/200] [Batch 108/169] [D loss: 0.708699] [G loss: 0.659823]\n",
      "[Epoch 17/200] [Batch 109/169] [D loss: 0.692219] [G loss: 0.610342]\n",
      "[Epoch 17/200] [Batch 110/169] [D loss: 0.710920] [G loss: 0.630776]\n",
      "[Epoch 17/200] [Batch 111/169] [D loss: 0.692191] [G loss: 0.688832]\n",
      "[Epoch 17/200] [Batch 112/169] [D loss: 0.683280] [G loss: 0.766106]\n",
      "[Epoch 17/200] [Batch 113/169] [D loss: 0.637433] [G loss: 0.713568]\n",
      "[Epoch 17/200] [Batch 114/169] [D loss: 0.665811] [G loss: 0.715265]\n",
      "[Epoch 17/200] [Batch 115/169] [D loss: 0.637540] [G loss: 0.698430]\n",
      "[Epoch 17/200] [Batch 116/169] [D loss: 0.653321] [G loss: 0.677812]\n",
      "[Epoch 17/200] [Batch 117/169] [D loss: 0.665989] [G loss: 0.686236]\n",
      "[Epoch 17/200] [Batch 118/169] [D loss: 0.690071] [G loss: 0.751142]\n",
      "[Epoch 17/200] [Batch 119/169] [D loss: 0.664571] [G loss: 0.716127]\n",
      "[Epoch 17/200] [Batch 120/169] [D loss: 0.670640] [G loss: 0.718836]\n",
      "[Epoch 17/200] [Batch 121/169] [D loss: 0.688161] [G loss: 0.706089]\n",
      "[Epoch 17/200] [Batch 122/169] [D loss: 0.690557] [G loss: 0.743030]\n",
      "[Epoch 17/200] [Batch 123/169] [D loss: 0.654548] [G loss: 0.723154]\n",
      "[Epoch 17/200] [Batch 124/169] [D loss: 0.649185] [G loss: 0.728532]\n",
      "[Epoch 17/200] [Batch 125/169] [D loss: 0.676174] [G loss: 0.729468]\n",
      "[Epoch 17/200] [Batch 126/169] [D loss: 0.666588] [G loss: 0.725494]\n",
      "[Epoch 17/200] [Batch 127/169] [D loss: 0.691399] [G loss: 0.755224]\n",
      "[Epoch 17/200] [Batch 128/169] [D loss: 0.683285] [G loss: 0.755428]\n",
      "[Epoch 17/200] [Batch 129/169] [D loss: 0.683485] [G loss: 0.805323]\n",
      "[Epoch 17/200] [Batch 130/169] [D loss: 0.693156] [G loss: 0.714869]\n",
      "[Epoch 17/200] [Batch 131/169] [D loss: 0.653957] [G loss: 0.796193]\n",
      "[Epoch 17/200] [Batch 132/169] [D loss: 0.660178] [G loss: 0.751693]\n",
      "[Epoch 17/200] [Batch 133/169] [D loss: 0.701991] [G loss: 0.855044]\n",
      "[Epoch 17/200] [Batch 134/169] [D loss: 0.642549] [G loss: 0.842256]\n",
      "[Epoch 17/200] [Batch 135/169] [D loss: 0.647085] [G loss: 0.773625]\n",
      "[Epoch 17/200] [Batch 136/169] [D loss: 0.669881] [G loss: 0.903925]\n",
      "[Epoch 17/200] [Batch 137/169] [D loss: 0.651431] [G loss: 0.920943]\n",
      "[Epoch 17/200] [Batch 138/169] [D loss: 0.610865] [G loss: 0.870240]\n",
      "[Epoch 17/200] [Batch 139/169] [D loss: 0.603854] [G loss: 0.881631]\n",
      "[Epoch 17/200] [Batch 140/169] [D loss: 0.629088] [G loss: 0.814637]\n",
      "[Epoch 17/200] [Batch 141/169] [D loss: 0.661663] [G loss: 0.723124]\n",
      "[Epoch 17/200] [Batch 142/169] [D loss: 0.667043] [G loss: 0.689704]\n",
      "[Epoch 17/200] [Batch 143/169] [D loss: 0.680594] [G loss: 0.648867]\n",
      "[Epoch 17/200] [Batch 144/169] [D loss: 0.666330] [G loss: 0.692043]\n",
      "[Epoch 17/200] [Batch 145/169] [D loss: 0.691164] [G loss: 0.634913]\n",
      "[Epoch 17/200] [Batch 146/169] [D loss: 0.761685] [G loss: 0.728933]\n",
      "[Epoch 17/200] [Batch 147/169] [D loss: 0.683294] [G loss: 0.869554]\n",
      "[Epoch 17/200] [Batch 148/169] [D loss: 0.664302] [G loss: 0.841182]\n",
      "[Epoch 17/200] [Batch 149/169] [D loss: 0.657443] [G loss: 0.933966]\n",
      "[Epoch 17/200] [Batch 150/169] [D loss: 0.642627] [G loss: 0.963843]\n",
      "[Epoch 17/200] [Batch 151/169] [D loss: 0.648535] [G loss: 0.795700]\n",
      "[Epoch 17/200] [Batch 152/169] [D loss: 0.640357] [G loss: 0.850423]\n",
      "[Epoch 17/200] [Batch 153/169] [D loss: 0.648682] [G loss: 0.756003]\n",
      "[Epoch 17/200] [Batch 154/169] [D loss: 0.704252] [G loss: 0.743509]\n",
      "[Epoch 17/200] [Batch 155/169] [D loss: 0.647507] [G loss: 0.748402]\n",
      "[Epoch 17/200] [Batch 156/169] [D loss: 0.668952] [G loss: 0.704801]\n",
      "[Epoch 17/200] [Batch 157/169] [D loss: 0.673443] [G loss: 0.740800]\n",
      "[Epoch 17/200] [Batch 158/169] [D loss: 0.681085] [G loss: 0.762966]\n",
      "[Epoch 17/200] [Batch 159/169] [D loss: 0.659830] [G loss: 0.808901]\n",
      "[Epoch 17/200] [Batch 160/169] [D loss: 0.653082] [G loss: 0.867146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 161/169] [D loss: 0.645475] [G loss: 0.851653]\n",
      "[Epoch 17/200] [Batch 162/169] [D loss: 0.666515] [G loss: 0.890958]\n",
      "[Epoch 17/200] [Batch 163/169] [D loss: 0.628687] [G loss: 0.811117]\n",
      "[Epoch 17/200] [Batch 164/169] [D loss: 0.661447] [G loss: 0.803839]\n",
      "[Epoch 17/200] [Batch 165/169] [D loss: 0.634428] [G loss: 0.802792]\n",
      "[Epoch 17/200] [Batch 166/169] [D loss: 0.608531] [G loss: 0.831062]\n",
      "[Epoch 17/200] [Batch 167/169] [D loss: 0.584599] [G loss: 0.819913]\n",
      "[Epoch 17/200] [Batch 168/169] [D loss: 0.575435] [G loss: 0.767067]\n",
      "[Epoch 18/200] [Batch 0/169] [D loss: 0.659116] [G loss: 0.792714]\n",
      "[Epoch 18/200] [Batch 1/169] [D loss: 0.683816] [G loss: 0.764745]\n",
      "[Epoch 18/200] [Batch 2/169] [D loss: 0.668493] [G loss: 0.743760]\n",
      "[Epoch 18/200] [Batch 3/169] [D loss: 0.675866] [G loss: 0.682286]\n",
      "[Epoch 18/200] [Batch 4/169] [D loss: 0.703745] [G loss: 0.761146]\n",
      "[Epoch 18/200] [Batch 5/169] [D loss: 0.707636] [G loss: 0.685082]\n",
      "[Epoch 18/200] [Batch 6/169] [D loss: 0.686288] [G loss: 0.671626]\n",
      "[Epoch 18/200] [Batch 7/169] [D loss: 0.642824] [G loss: 0.691310]\n",
      "[Epoch 18/200] [Batch 8/169] [D loss: 0.677856] [G loss: 0.752600]\n",
      "[Epoch 18/200] [Batch 9/169] [D loss: 0.687170] [G loss: 0.671732]\n",
      "[Epoch 18/200] [Batch 10/169] [D loss: 0.673280] [G loss: 0.709763]\n",
      "[Epoch 18/200] [Batch 11/169] [D loss: 0.690124] [G loss: 0.696481]\n",
      "[Epoch 18/200] [Batch 12/169] [D loss: 0.642617] [G loss: 0.742561]\n",
      "[Epoch 18/200] [Batch 13/169] [D loss: 0.666031] [G loss: 0.766645]\n",
      "[Epoch 18/200] [Batch 14/169] [D loss: 0.620194] [G loss: 0.832321]\n",
      "[Epoch 18/200] [Batch 15/169] [D loss: 0.658974] [G loss: 0.733187]\n",
      "[Epoch 18/200] [Batch 16/169] [D loss: 0.677453] [G loss: 0.841609]\n",
      "[Epoch 18/200] [Batch 17/169] [D loss: 0.608875] [G loss: 0.781871]\n",
      "[Epoch 18/200] [Batch 18/169] [D loss: 0.613816] [G loss: 0.788442]\n",
      "[Epoch 18/200] [Batch 19/169] [D loss: 0.653029] [G loss: 0.840375]\n",
      "[Epoch 18/200] [Batch 20/169] [D loss: 0.663555] [G loss: 0.770751]\n",
      "[Epoch 18/200] [Batch 21/169] [D loss: 0.652365] [G loss: 0.766983]\n",
      "[Epoch 18/200] [Batch 22/169] [D loss: 0.657095] [G loss: 0.729910]\n",
      "[Epoch 18/200] [Batch 23/169] [D loss: 0.663700] [G loss: 0.790743]\n",
      "[Epoch 18/200] [Batch 24/169] [D loss: 0.682439] [G loss: 0.735064]\n",
      "[Epoch 18/200] [Batch 25/169] [D loss: 0.679765] [G loss: 0.683434]\n",
      "[Epoch 18/200] [Batch 26/169] [D loss: 0.688000] [G loss: 0.738140]\n",
      "[Epoch 18/200] [Batch 27/169] [D loss: 0.667790] [G loss: 0.804237]\n",
      "[Epoch 18/200] [Batch 28/169] [D loss: 0.675214] [G loss: 0.781635]\n",
      "[Epoch 18/200] [Batch 29/169] [D loss: 0.726342] [G loss: 0.835423]\n",
      "[Epoch 18/200] [Batch 30/169] [D loss: 0.656070] [G loss: 0.773264]\n",
      "[Epoch 18/200] [Batch 31/169] [D loss: 0.676973] [G loss: 0.878247]\n",
      "[Epoch 18/200] [Batch 32/169] [D loss: 0.629870] [G loss: 0.829468]\n",
      "[Epoch 18/200] [Batch 33/169] [D loss: 0.641447] [G loss: 0.815679]\n",
      "[Epoch 18/200] [Batch 34/169] [D loss: 0.650478] [G loss: 0.815094]\n",
      "[Epoch 18/200] [Batch 35/169] [D loss: 0.671822] [G loss: 0.848750]\n",
      "[Epoch 18/200] [Batch 36/169] [D loss: 0.638022] [G loss: 0.899112]\n",
      "[Epoch 18/200] [Batch 37/169] [D loss: 0.642596] [G loss: 0.872982]\n",
      "[Epoch 18/200] [Batch 38/169] [D loss: 0.648234] [G loss: 0.889443]\n",
      "[Epoch 18/200] [Batch 39/169] [D loss: 0.604344] [G loss: 0.861398]\n",
      "[Epoch 18/200] [Batch 40/169] [D loss: 0.651704] [G loss: 0.840619]\n",
      "[Epoch 18/200] [Batch 41/169] [D loss: 0.581401] [G loss: 0.871966]\n",
      "[Epoch 18/200] [Batch 42/169] [D loss: 0.634029] [G loss: 0.776507]\n",
      "[Epoch 18/200] [Batch 43/169] [D loss: 0.604299] [G loss: 0.833800]\n",
      "[Epoch 18/200] [Batch 44/169] [D loss: 0.629181] [G loss: 0.769199]\n",
      "[Epoch 18/200] [Batch 45/169] [D loss: 0.668675] [G loss: 0.680829]\n",
      "[Epoch 18/200] [Batch 46/169] [D loss: 0.656874] [G loss: 0.689202]\n",
      "[Epoch 18/200] [Batch 47/169] [D loss: 0.641752] [G loss: 0.647010]\n",
      "[Epoch 18/200] [Batch 48/169] [D loss: 0.688971] [G loss: 0.666676]\n",
      "[Epoch 18/200] [Batch 49/169] [D loss: 0.664828] [G loss: 0.751492]\n",
      "[Epoch 18/200] [Batch 50/169] [D loss: 0.616336] [G loss: 0.796068]\n",
      "[Epoch 18/200] [Batch 51/169] [D loss: 0.664045] [G loss: 0.729585]\n",
      "[Epoch 18/200] [Batch 52/169] [D loss: 0.650582] [G loss: 0.825765]\n",
      "[Epoch 18/200] [Batch 53/169] [D loss: 0.665663] [G loss: 0.758672]\n",
      "[Epoch 18/200] [Batch 54/169] [D loss: 0.624386] [G loss: 0.816562]\n",
      "[Epoch 18/200] [Batch 55/169] [D loss: 0.623740] [G loss: 0.823411]\n",
      "[Epoch 18/200] [Batch 56/169] [D loss: 0.672838] [G loss: 0.773609]\n",
      "[Epoch 18/200] [Batch 57/169] [D loss: 0.612915] [G loss: 0.753491]\n",
      "[Epoch 18/200] [Batch 58/169] [D loss: 0.609121] [G loss: 0.795298]\n",
      "[Epoch 18/200] [Batch 59/169] [D loss: 0.621273] [G loss: 0.800563]\n",
      "[Epoch 18/200] [Batch 60/169] [D loss: 0.620021] [G loss: 0.735957]\n",
      "[Epoch 18/200] [Batch 61/169] [D loss: 0.632327] [G loss: 0.785154]\n",
      "[Epoch 18/200] [Batch 62/169] [D loss: 0.592814] [G loss: 0.798001]\n",
      "[Epoch 18/200] [Batch 63/169] [D loss: 0.605817] [G loss: 0.748706]\n",
      "[Epoch 18/200] [Batch 64/169] [D loss: 0.625561] [G loss: 0.763544]\n",
      "[Epoch 18/200] [Batch 65/169] [D loss: 0.627053] [G loss: 0.829117]\n",
      "[Epoch 18/200] [Batch 66/169] [D loss: 0.581327] [G loss: 0.807941]\n",
      "[Epoch 18/200] [Batch 67/169] [D loss: 0.629457] [G loss: 0.800853]\n",
      "[Epoch 18/200] [Batch 68/169] [D loss: 0.629748] [G loss: 0.713757]\n",
      "[Epoch 18/200] [Batch 69/169] [D loss: 0.707327] [G loss: 0.666951]\n",
      "[Epoch 18/200] [Batch 70/169] [D loss: 0.670028] [G loss: 0.628185]\n",
      "[Epoch 18/200] [Batch 71/169] [D loss: 0.720060] [G loss: 0.635757]\n",
      "[Epoch 18/200] [Batch 72/169] [D loss: 0.689631] [G loss: 0.730898]\n",
      "[Epoch 18/200] [Batch 73/169] [D loss: 0.634090] [G loss: 0.766613]\n",
      "[Epoch 18/200] [Batch 74/169] [D loss: 0.647873] [G loss: 0.756038]\n",
      "[Epoch 18/200] [Batch 75/169] [D loss: 0.716530] [G loss: 0.824370]\n",
      "[Epoch 18/200] [Batch 76/169] [D loss: 0.668039] [G loss: 0.855037]\n",
      "[Epoch 18/200] [Batch 77/169] [D loss: 0.662346] [G loss: 0.777009]\n",
      "[Epoch 18/200] [Batch 78/169] [D loss: 0.659515] [G loss: 0.734667]\n",
      "[Epoch 18/200] [Batch 79/169] [D loss: 0.697965] [G loss: 0.689912]\n",
      "[Epoch 18/200] [Batch 80/169] [D loss: 0.643072] [G loss: 0.710741]\n",
      "[Epoch 18/200] [Batch 81/169] [D loss: 0.647599] [G loss: 0.769602]\n",
      "[Epoch 18/200] [Batch 82/169] [D loss: 0.728911] [G loss: 0.780893]\n",
      "[Epoch 18/200] [Batch 83/169] [D loss: 0.644307] [G loss: 0.804040]\n",
      "[Epoch 18/200] [Batch 84/169] [D loss: 0.670600] [G loss: 0.738580]\n",
      "[Epoch 18/200] [Batch 85/169] [D loss: 0.667139] [G loss: 0.798555]\n",
      "[Epoch 18/200] [Batch 86/169] [D loss: 0.682675] [G loss: 0.770009]\n",
      "[Epoch 18/200] [Batch 87/169] [D loss: 0.665746] [G loss: 0.769659]\n",
      "[Epoch 18/200] [Batch 88/169] [D loss: 0.644117] [G loss: 0.795176]\n",
      "[Epoch 18/200] [Batch 89/169] [D loss: 0.654889] [G loss: 0.778935]\n",
      "[Epoch 18/200] [Batch 90/169] [D loss: 0.650583] [G loss: 0.771615]\n",
      "[Epoch 18/200] [Batch 91/169] [D loss: 0.694399] [G loss: 0.805994]\n",
      "[Epoch 18/200] [Batch 92/169] [D loss: 0.660553] [G loss: 0.809663]\n",
      "[Epoch 18/200] [Batch 93/169] [D loss: 0.663029] [G loss: 0.811859]\n",
      "[Epoch 18/200] [Batch 94/169] [D loss: 0.647146] [G loss: 0.835453]\n",
      "[Epoch 18/200] [Batch 95/169] [D loss: 0.654859] [G loss: 0.786354]\n",
      "[Epoch 18/200] [Batch 96/169] [D loss: 0.658362] [G loss: 0.812101]\n",
      "[Epoch 18/200] [Batch 97/169] [D loss: 0.646528] [G loss: 0.781894]\n",
      "[Epoch 18/200] [Batch 98/169] [D loss: 0.676146] [G loss: 0.810088]\n",
      "[Epoch 18/200] [Batch 99/169] [D loss: 0.624501] [G loss: 0.755798]\n",
      "[Epoch 18/200] [Batch 100/169] [D loss: 0.643769] [G loss: 0.765871]\n",
      "[Epoch 18/200] [Batch 101/169] [D loss: 0.650347] [G loss: 0.748428]\n",
      "[Epoch 18/200] [Batch 102/169] [D loss: 0.617230] [G loss: 0.770268]\n",
      "[Epoch 18/200] [Batch 103/169] [D loss: 0.642254] [G loss: 0.790571]\n",
      "[Epoch 18/200] [Batch 104/169] [D loss: 0.612436] [G loss: 0.753461]\n",
      "[Epoch 18/200] [Batch 105/169] [D loss: 0.647586] [G loss: 0.716129]\n",
      "[Epoch 18/200] [Batch 106/169] [D loss: 0.659486] [G loss: 0.778061]\n",
      "[Epoch 18/200] [Batch 107/169] [D loss: 0.641783] [G loss: 0.736240]\n",
      "[Epoch 18/200] [Batch 108/169] [D loss: 0.626626] [G loss: 0.795037]\n",
      "[Epoch 18/200] [Batch 109/169] [D loss: 0.655489] [G loss: 0.762606]\n",
      "[Epoch 18/200] [Batch 110/169] [D loss: 0.622854] [G loss: 0.780674]\n",
      "[Epoch 18/200] [Batch 111/169] [D loss: 0.640877] [G loss: 0.727391]\n",
      "[Epoch 18/200] [Batch 112/169] [D loss: 0.645252] [G loss: 0.735072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 113/169] [D loss: 0.660898] [G loss: 0.830141]\n",
      "[Epoch 18/200] [Batch 114/169] [D loss: 0.647853] [G loss: 0.790568]\n",
      "[Epoch 18/200] [Batch 115/169] [D loss: 0.691407] [G loss: 0.801575]\n",
      "[Epoch 18/200] [Batch 116/169] [D loss: 0.668942] [G loss: 0.802143]\n",
      "[Epoch 18/200] [Batch 117/169] [D loss: 0.615990] [G loss: 0.707560]\n",
      "[Epoch 18/200] [Batch 118/169] [D loss: 0.677138] [G loss: 0.734429]\n",
      "[Epoch 18/200] [Batch 119/169] [D loss: 0.691009] [G loss: 0.707965]\n",
      "[Epoch 18/200] [Batch 120/169] [D loss: 0.660340] [G loss: 0.785685]\n",
      "[Epoch 18/200] [Batch 121/169] [D loss: 0.686903] [G loss: 0.797228]\n",
      "[Epoch 18/200] [Batch 122/169] [D loss: 0.635638] [G loss: 0.818721]\n",
      "[Epoch 18/200] [Batch 123/169] [D loss: 0.648241] [G loss: 0.784375]\n",
      "[Epoch 18/200] [Batch 124/169] [D loss: 0.660344] [G loss: 0.733839]\n",
      "[Epoch 18/200] [Batch 125/169] [D loss: 0.630648] [G loss: 0.730283]\n",
      "[Epoch 18/200] [Batch 126/169] [D loss: 0.666067] [G loss: 0.765692]\n",
      "[Epoch 18/200] [Batch 127/169] [D loss: 0.675848] [G loss: 0.790500]\n",
      "[Epoch 18/200] [Batch 128/169] [D loss: 0.660583] [G loss: 0.770135]\n",
      "[Epoch 18/200] [Batch 129/169] [D loss: 0.662471] [G loss: 0.806064]\n",
      "[Epoch 18/200] [Batch 130/169] [D loss: 0.649352] [G loss: 0.806830]\n",
      "[Epoch 18/200] [Batch 131/169] [D loss: 0.667165] [G loss: 0.819742]\n",
      "[Epoch 18/200] [Batch 132/169] [D loss: 0.656527] [G loss: 0.820746]\n",
      "[Epoch 18/200] [Batch 133/169] [D loss: 0.653054] [G loss: 0.769364]\n",
      "[Epoch 18/200] [Batch 134/169] [D loss: 0.647400] [G loss: 0.820678]\n",
      "[Epoch 18/200] [Batch 135/169] [D loss: 0.634314] [G loss: 0.809836]\n",
      "[Epoch 18/200] [Batch 136/169] [D loss: 0.644332] [G loss: 0.767043]\n",
      "[Epoch 18/200] [Batch 137/169] [D loss: 0.674951] [G loss: 0.754297]\n",
      "[Epoch 18/200] [Batch 138/169] [D loss: 0.687325] [G loss: 0.795118]\n",
      "[Epoch 18/200] [Batch 139/169] [D loss: 0.628252] [G loss: 0.805251]\n",
      "[Epoch 18/200] [Batch 140/169] [D loss: 0.650255] [G loss: 0.784055]\n",
      "[Epoch 18/200] [Batch 141/169] [D loss: 0.690292] [G loss: 0.827262]\n",
      "[Epoch 18/200] [Batch 142/169] [D loss: 0.653693] [G loss: 0.876895]\n",
      "[Epoch 18/200] [Batch 143/169] [D loss: 0.661027] [G loss: 0.855689]\n",
      "[Epoch 18/200] [Batch 144/169] [D loss: 0.636488] [G loss: 0.784791]\n",
      "[Epoch 18/200] [Batch 145/169] [D loss: 0.681020] [G loss: 0.766602]\n",
      "[Epoch 18/200] [Batch 146/169] [D loss: 0.661667] [G loss: 0.709336]\n",
      "[Epoch 18/200] [Batch 147/169] [D loss: 0.660591] [G loss: 0.741118]\n",
      "[Epoch 18/200] [Batch 148/169] [D loss: 0.628490] [G loss: 0.733476]\n",
      "[Epoch 18/200] [Batch 149/169] [D loss: 0.658219] [G loss: 0.719750]\n",
      "[Epoch 18/200] [Batch 150/169] [D loss: 0.663325] [G loss: 0.780354]\n",
      "[Epoch 18/200] [Batch 151/169] [D loss: 0.665749] [G loss: 0.747026]\n",
      "[Epoch 18/200] [Batch 152/169] [D loss: 0.677548] [G loss: 0.749589]\n",
      "[Epoch 18/200] [Batch 153/169] [D loss: 0.645890] [G loss: 0.755047]\n",
      "[Epoch 18/200] [Batch 154/169] [D loss: 0.670201] [G loss: 0.766891]\n",
      "[Epoch 18/200] [Batch 155/169] [D loss: 0.671045] [G loss: 0.818690]\n",
      "[Epoch 18/200] [Batch 156/169] [D loss: 0.691519] [G loss: 0.851490]\n",
      "[Epoch 18/200] [Batch 157/169] [D loss: 0.679274] [G loss: 0.776959]\n",
      "[Epoch 18/200] [Batch 158/169] [D loss: 0.644286] [G loss: 0.773030]\n",
      "[Epoch 18/200] [Batch 159/169] [D loss: 0.642502] [G loss: 0.776778]\n",
      "[Epoch 18/200] [Batch 160/169] [D loss: 0.643018] [G loss: 0.782195]\n",
      "[Epoch 18/200] [Batch 161/169] [D loss: 0.685361] [G loss: 0.764817]\n",
      "[Epoch 18/200] [Batch 162/169] [D loss: 0.627507] [G loss: 0.840789]\n",
      "[Epoch 18/200] [Batch 163/169] [D loss: 0.662316] [G loss: 0.760478]\n",
      "[Epoch 18/200] [Batch 164/169] [D loss: 0.630330] [G loss: 0.731116]\n",
      "[Epoch 18/200] [Batch 165/169] [D loss: 0.631586] [G loss: 0.715824]\n",
      "[Epoch 18/200] [Batch 166/169] [D loss: 0.643727] [G loss: 0.752994]\n",
      "[Epoch 18/200] [Batch 167/169] [D loss: 0.652775] [G loss: 0.767107]\n",
      "[Epoch 18/200] [Batch 168/169] [D loss: 0.635168] [G loss: 0.798050]\n",
      "[Epoch 19/200] [Batch 0/169] [D loss: 0.671375] [G loss: 0.753568]\n",
      "[Epoch 19/200] [Batch 1/169] [D loss: 0.648845] [G loss: 0.761003]\n",
      "[Epoch 19/200] [Batch 2/169] [D loss: 0.613705] [G loss: 0.766152]\n",
      "[Epoch 19/200] [Batch 3/169] [D loss: 0.656326] [G loss: 0.708129]\n",
      "[Epoch 19/200] [Batch 4/169] [D loss: 0.687232] [G loss: 0.755386]\n",
      "[Epoch 19/200] [Batch 5/169] [D loss: 0.662666] [G loss: 0.768881]\n",
      "[Epoch 19/200] [Batch 6/169] [D loss: 0.644924] [G loss: 0.728380]\n",
      "[Epoch 19/200] [Batch 7/169] [D loss: 0.680128] [G loss: 0.763688]\n",
      "[Epoch 19/200] [Batch 8/169] [D loss: 0.661812] [G loss: 0.734949]\n",
      "[Epoch 19/200] [Batch 9/169] [D loss: 0.636233] [G loss: 0.802966]\n",
      "[Epoch 19/200] [Batch 10/169] [D loss: 0.651471] [G loss: 0.796084]\n",
      "[Epoch 19/200] [Batch 11/169] [D loss: 0.641219] [G loss: 0.809721]\n",
      "[Epoch 19/200] [Batch 12/169] [D loss: 0.669868] [G loss: 0.756627]\n",
      "[Epoch 19/200] [Batch 13/169] [D loss: 0.690383] [G loss: 0.770420]\n",
      "[Epoch 19/200] [Batch 14/169] [D loss: 0.672389] [G loss: 0.757479]\n",
      "[Epoch 19/200] [Batch 15/169] [D loss: 0.676046] [G loss: 0.717806]\n",
      "[Epoch 19/200] [Batch 16/169] [D loss: 0.715397] [G loss: 0.762897]\n",
      "[Epoch 19/200] [Batch 17/169] [D loss: 0.645450] [G loss: 0.759673]\n",
      "[Epoch 19/200] [Batch 18/169] [D loss: 0.709271] [G loss: 0.697566]\n",
      "[Epoch 19/200] [Batch 19/169] [D loss: 0.654987] [G loss: 0.772627]\n",
      "[Epoch 19/200] [Batch 20/169] [D loss: 0.631590] [G loss: 0.769071]\n",
      "[Epoch 19/200] [Batch 21/169] [D loss: 0.668164] [G loss: 0.778561]\n",
      "[Epoch 19/200] [Batch 22/169] [D loss: 0.626249] [G loss: 0.728693]\n",
      "[Epoch 19/200] [Batch 23/169] [D loss: 0.643456] [G loss: 0.774741]\n",
      "[Epoch 19/200] [Batch 24/169] [D loss: 0.650784] [G loss: 0.842613]\n",
      "[Epoch 19/200] [Batch 25/169] [D loss: 0.624320] [G loss: 0.783790]\n",
      "[Epoch 19/200] [Batch 26/169] [D loss: 0.666531] [G loss: 0.758201]\n",
      "[Epoch 19/200] [Batch 27/169] [D loss: 0.683312] [G loss: 0.781404]\n",
      "[Epoch 19/200] [Batch 28/169] [D loss: 0.618806] [G loss: 0.778681]\n",
      "[Epoch 19/200] [Batch 29/169] [D loss: 0.663172] [G loss: 0.756206]\n",
      "[Epoch 19/200] [Batch 30/169] [D loss: 0.637449] [G loss: 0.760654]\n",
      "[Epoch 19/200] [Batch 31/169] [D loss: 0.667880] [G loss: 0.778228]\n",
      "[Epoch 19/200] [Batch 32/169] [D loss: 0.649397] [G loss: 0.823567]\n",
      "[Epoch 19/200] [Batch 33/169] [D loss: 0.654257] [G loss: 0.778542]\n",
      "[Epoch 19/200] [Batch 34/169] [D loss: 0.676174] [G loss: 0.745735]\n",
      "[Epoch 19/200] [Batch 35/169] [D loss: 0.657443] [G loss: 0.723700]\n",
      "[Epoch 19/200] [Batch 36/169] [D loss: 0.668798] [G loss: 0.737719]\n",
      "[Epoch 19/200] [Batch 37/169] [D loss: 0.695114] [G loss: 0.791261]\n",
      "[Epoch 19/200] [Batch 38/169] [D loss: 0.703341] [G loss: 0.768313]\n",
      "[Epoch 19/200] [Batch 39/169] [D loss: 0.659919] [G loss: 0.743998]\n",
      "[Epoch 19/200] [Batch 40/169] [D loss: 0.688255] [G loss: 0.840118]\n",
      "[Epoch 19/200] [Batch 41/169] [D loss: 0.693865] [G loss: 0.786554]\n",
      "[Epoch 19/200] [Batch 42/169] [D loss: 0.666029] [G loss: 0.759475]\n",
      "[Epoch 19/200] [Batch 43/169] [D loss: 0.649562] [G loss: 0.791802]\n",
      "[Epoch 19/200] [Batch 44/169] [D loss: 0.649543] [G loss: 0.781167]\n",
      "[Epoch 19/200] [Batch 45/169] [D loss: 0.689829] [G loss: 0.795469]\n",
      "[Epoch 19/200] [Batch 46/169] [D loss: 0.736397] [G loss: 0.802817]\n",
      "[Epoch 19/200] [Batch 47/169] [D loss: 0.691776] [G loss: 0.815762]\n",
      "[Epoch 19/200] [Batch 48/169] [D loss: 0.662634] [G loss: 0.804244]\n",
      "[Epoch 19/200] [Batch 49/169] [D loss: 0.687135] [G loss: 0.787769]\n",
      "[Epoch 19/200] [Batch 50/169] [D loss: 0.644036] [G loss: 0.778048]\n",
      "[Epoch 19/200] [Batch 51/169] [D loss: 0.661854] [G loss: 0.746945]\n",
      "[Epoch 19/200] [Batch 52/169] [D loss: 0.632957] [G loss: 0.731594]\n",
      "[Epoch 19/200] [Batch 53/169] [D loss: 0.645546] [G loss: 0.766598]\n",
      "[Epoch 19/200] [Batch 54/169] [D loss: 0.662210] [G loss: 0.764728]\n",
      "[Epoch 19/200] [Batch 55/169] [D loss: 0.623565] [G loss: 0.811208]\n",
      "[Epoch 19/200] [Batch 56/169] [D loss: 0.633004] [G loss: 0.722411]\n",
      "[Epoch 19/200] [Batch 57/169] [D loss: 0.654779] [G loss: 0.755771]\n",
      "[Epoch 19/200] [Batch 58/169] [D loss: 0.626900] [G loss: 0.741518]\n",
      "[Epoch 19/200] [Batch 59/169] [D loss: 0.640833] [G loss: 0.738354]\n",
      "[Epoch 19/200] [Batch 60/169] [D loss: 0.657735] [G loss: 0.738321]\n",
      "[Epoch 19/200] [Batch 61/169] [D loss: 0.642709] [G loss: 0.730748]\n",
      "[Epoch 19/200] [Batch 62/169] [D loss: 0.639597] [G loss: 0.847409]\n",
      "[Epoch 19/200] [Batch 63/169] [D loss: 0.639547] [G loss: 0.755351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 64/169] [D loss: 0.700005] [G loss: 0.802413]\n",
      "[Epoch 19/200] [Batch 65/169] [D loss: 0.631152] [G loss: 0.774244]\n",
      "[Epoch 19/200] [Batch 66/169] [D loss: 0.684299] [G loss: 0.795389]\n",
      "[Epoch 19/200] [Batch 67/169] [D loss: 0.672985] [G loss: 0.816320]\n",
      "[Epoch 19/200] [Batch 68/169] [D loss: 0.698930] [G loss: 0.778362]\n",
      "[Epoch 19/200] [Batch 69/169] [D loss: 0.658732] [G loss: 0.823439]\n",
      "[Epoch 19/200] [Batch 70/169] [D loss: 0.669954] [G loss: 0.800343]\n",
      "[Epoch 19/200] [Batch 71/169] [D loss: 0.671933] [G loss: 0.855494]\n",
      "[Epoch 19/200] [Batch 72/169] [D loss: 0.589733] [G loss: 0.842067]\n",
      "[Epoch 19/200] [Batch 73/169] [D loss: 0.652816] [G loss: 0.794292]\n",
      "[Epoch 19/200] [Batch 74/169] [D loss: 0.598418] [G loss: 0.819636]\n",
      "[Epoch 19/200] [Batch 75/169] [D loss: 0.632720] [G loss: 0.790918]\n",
      "[Epoch 19/200] [Batch 76/169] [D loss: 0.642639] [G loss: 0.768831]\n",
      "[Epoch 19/200] [Batch 77/169] [D loss: 0.615635] [G loss: 0.807846]\n",
      "[Epoch 19/200] [Batch 78/169] [D loss: 0.648562] [G loss: 0.806559]\n",
      "[Epoch 19/200] [Batch 79/169] [D loss: 0.628270] [G loss: 0.764079]\n",
      "[Epoch 19/200] [Batch 80/169] [D loss: 0.636583] [G loss: 0.794015]\n",
      "[Epoch 19/200] [Batch 81/169] [D loss: 0.668195] [G loss: 0.798917]\n",
      "[Epoch 19/200] [Batch 82/169] [D loss: 0.677236] [G loss: 0.700447]\n",
      "[Epoch 19/200] [Batch 83/169] [D loss: 0.685784] [G loss: 0.807240]\n",
      "[Epoch 19/200] [Batch 84/169] [D loss: 0.628817] [G loss: 0.802366]\n",
      "[Epoch 19/200] [Batch 85/169] [D loss: 0.630534] [G loss: 0.839388]\n",
      "[Epoch 19/200] [Batch 86/169] [D loss: 0.701453] [G loss: 0.837918]\n",
      "[Epoch 19/200] [Batch 87/169] [D loss: 0.633049] [G loss: 0.798159]\n",
      "[Epoch 19/200] [Batch 88/169] [D loss: 0.605581] [G loss: 0.744616]\n",
      "[Epoch 19/200] [Batch 89/169] [D loss: 0.625920] [G loss: 0.820332]\n",
      "[Epoch 19/200] [Batch 90/169] [D loss: 0.595872] [G loss: 0.739748]\n",
      "[Epoch 19/200] [Batch 91/169] [D loss: 0.625514] [G loss: 0.675720]\n",
      "[Epoch 19/200] [Batch 92/169] [D loss: 0.665827] [G loss: 0.698889]\n",
      "[Epoch 19/200] [Batch 93/169] [D loss: 0.645913] [G loss: 0.697987]\n",
      "[Epoch 19/200] [Batch 94/169] [D loss: 0.672759] [G loss: 0.665726]\n",
      "[Epoch 19/200] [Batch 95/169] [D loss: 0.653855] [G loss: 0.748488]\n",
      "[Epoch 19/200] [Batch 96/169] [D loss: 0.660753] [G loss: 0.737212]\n",
      "[Epoch 19/200] [Batch 97/169] [D loss: 0.630275] [G loss: 0.833867]\n",
      "[Epoch 19/200] [Batch 98/169] [D loss: 0.573527] [G loss: 0.812519]\n",
      "[Epoch 19/200] [Batch 99/169] [D loss: 0.639980] [G loss: 0.768633]\n",
      "[Epoch 19/200] [Batch 100/169] [D loss: 0.634376] [G loss: 0.828655]\n",
      "[Epoch 19/200] [Batch 101/169] [D loss: 0.644714] [G loss: 0.805379]\n",
      "[Epoch 19/200] [Batch 102/169] [D loss: 0.629829] [G loss: 0.728070]\n",
      "[Epoch 19/200] [Batch 103/169] [D loss: 0.668687] [G loss: 0.758109]\n",
      "[Epoch 19/200] [Batch 104/169] [D loss: 0.643424] [G loss: 0.748623]\n",
      "[Epoch 19/200] [Batch 105/169] [D loss: 0.718102] [G loss: 0.699143]\n",
      "[Epoch 19/200] [Batch 106/169] [D loss: 0.653557] [G loss: 0.791861]\n",
      "[Epoch 19/200] [Batch 107/169] [D loss: 0.691216] [G loss: 0.809848]\n",
      "[Epoch 19/200] [Batch 108/169] [D loss: 0.712956] [G loss: 0.725603]\n",
      "[Epoch 19/200] [Batch 109/169] [D loss: 0.659111] [G loss: 0.771703]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0373297a5ae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0msavepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'image_cov_GD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-acd13e2ff54d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m             print(\n\u001b[0;32m     49\u001b[0m                 \u001b[1;34m\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             )\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### 加载状态字典\n",
    "load2 = torch.load('net_state_dict.pth')\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "\n",
    "\n",
    "generator.load_state_dict(load2['generator'])\n",
    "generator.apply(init_cov)              ### 初始化模型，保留卷积层\n",
    "discriminator.load_state_dict(load2['discriminator'])\n",
    "discriminator.apply(init_cov)\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "optimizer_G.load_state_dict(load2['optimizer_G'])\n",
    "optimizer_D.load_state_dict(load2['optimizer_D'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "savepath = 'image_cov_GD'\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188e5f1",
   "metadata": {},
   "source": [
    "### 仅保留G的线性层，D不做处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c626f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/169] [D loss: 0.633516] [G loss: 0.806468]\n",
      "[Epoch 0/200] [Batch 1/169] [D loss: 0.592361] [G loss: 0.811975]\n",
      "[Epoch 0/200] [Batch 2/169] [D loss: 0.557337] [G loss: 0.770235]\n",
      "[Epoch 0/200] [Batch 3/169] [D loss: 0.502352] [G loss: 0.761865]\n",
      "[Epoch 0/200] [Batch 4/169] [D loss: 0.448823] [G loss: 0.793076]\n",
      "[Epoch 0/200] [Batch 5/169] [D loss: 0.400065] [G loss: 0.828836]\n",
      "[Epoch 0/200] [Batch 6/169] [D loss: 0.361847] [G loss: 0.895304]\n",
      "[Epoch 0/200] [Batch 7/169] [D loss: 0.331110] [G loss: 0.964124]\n",
      "[Epoch 0/200] [Batch 8/169] [D loss: 0.286881] [G loss: 1.032322]\n",
      "[Epoch 0/200] [Batch 9/169] [D loss: 0.251141] [G loss: 1.071444]\n",
      "[Epoch 0/200] [Batch 10/169] [D loss: 0.261408] [G loss: 1.100053]\n",
      "[Epoch 0/200] [Batch 11/169] [D loss: 0.414744] [G loss: 0.678054]\n",
      "[Epoch 0/200] [Batch 12/169] [D loss: 0.520654] [G loss: 0.501257]\n",
      "[Epoch 0/200] [Batch 13/169] [D loss: 0.400857] [G loss: 1.134336]\n",
      "[Epoch 0/200] [Batch 14/169] [D loss: 0.462394] [G loss: 1.323805]\n",
      "[Epoch 0/200] [Batch 15/169] [D loss: 0.474570] [G loss: 1.206834]\n",
      "[Epoch 0/200] [Batch 16/169] [D loss: 0.478330] [G loss: 1.031060]\n",
      "[Epoch 0/200] [Batch 17/169] [D loss: 0.486242] [G loss: 0.922926]\n",
      "[Epoch 0/200] [Batch 18/169] [D loss: 0.513711] [G loss: 0.886900]\n",
      "[Epoch 0/200] [Batch 19/169] [D loss: 0.503830] [G loss: 0.983685]\n",
      "[Epoch 0/200] [Batch 20/169] [D loss: 0.468232] [G loss: 0.965321]\n",
      "[Epoch 0/200] [Batch 21/169] [D loss: 0.484061] [G loss: 0.972794]\n",
      "[Epoch 0/200] [Batch 22/169] [D loss: 0.546201] [G loss: 0.948108]\n",
      "[Epoch 0/200] [Batch 23/169] [D loss: 0.535075] [G loss: 1.059135]\n",
      "[Epoch 0/200] [Batch 24/169] [D loss: 0.482641] [G loss: 1.131509]\n",
      "[Epoch 0/200] [Batch 25/169] [D loss: 0.541661] [G loss: 1.153240]\n",
      "[Epoch 0/200] [Batch 26/169] [D loss: 0.497209] [G loss: 1.185163]\n",
      "[Epoch 0/200] [Batch 27/169] [D loss: 0.515688] [G loss: 1.191738]\n",
      "[Epoch 0/200] [Batch 28/169] [D loss: 0.543030] [G loss: 1.307343]\n",
      "[Epoch 0/200] [Batch 29/169] [D loss: 0.465978] [G loss: 1.222590]\n",
      "[Epoch 0/200] [Batch 30/169] [D loss: 0.485904] [G loss: 1.251448]\n",
      "[Epoch 0/200] [Batch 31/169] [D loss: 0.495231] [G loss: 1.303432]\n",
      "[Epoch 0/200] [Batch 32/169] [D loss: 0.486272] [G loss: 1.211030]\n",
      "[Epoch 0/200] [Batch 33/169] [D loss: 0.411617] [G loss: 1.643816]\n",
      "[Epoch 0/200] [Batch 34/169] [D loss: 0.423019] [G loss: 1.392783]\n",
      "[Epoch 0/200] [Batch 35/169] [D loss: 0.407000] [G loss: 1.411180]\n",
      "[Epoch 0/200] [Batch 36/169] [D loss: 0.432463] [G loss: 1.249700]\n",
      "[Epoch 0/200] [Batch 37/169] [D loss: 0.401216] [G loss: 1.337379]\n",
      "[Epoch 0/200] [Batch 38/169] [D loss: 0.465834] [G loss: 1.193766]\n",
      "[Epoch 0/200] [Batch 39/169] [D loss: 0.431289] [G loss: 1.523575]\n",
      "[Epoch 0/200] [Batch 40/169] [D loss: 0.389902] [G loss: 1.601029]\n",
      "[Epoch 0/200] [Batch 41/169] [D loss: 0.424392] [G loss: 1.692991]\n",
      "[Epoch 0/200] [Batch 42/169] [D loss: 0.389691] [G loss: 1.235398]\n",
      "[Epoch 0/200] [Batch 43/169] [D loss: 0.457583] [G loss: 1.403656]\n",
      "[Epoch 0/200] [Batch 44/169] [D loss: 0.347177] [G loss: 1.468043]\n",
      "[Epoch 0/200] [Batch 45/169] [D loss: 0.363276] [G loss: 1.500281]\n",
      "[Epoch 0/200] [Batch 46/169] [D loss: 0.454671] [G loss: 1.098189]\n",
      "[Epoch 0/200] [Batch 47/169] [D loss: 0.397992] [G loss: 1.090077]\n",
      "[Epoch 0/200] [Batch 48/169] [D loss: 0.359922] [G loss: 1.218362]\n",
      "[Epoch 0/200] [Batch 49/169] [D loss: 0.380724] [G loss: 1.147950]\n",
      "[Epoch 0/200] [Batch 50/169] [D loss: 0.335188] [G loss: 1.078967]\n",
      "[Epoch 0/200] [Batch 51/169] [D loss: 0.342572] [G loss: 1.343325]\n",
      "[Epoch 0/200] [Batch 52/169] [D loss: 0.326835] [G loss: 1.547531]\n",
      "[Epoch 0/200] [Batch 53/169] [D loss: 0.311192] [G loss: 1.544599]\n",
      "[Epoch 0/200] [Batch 54/169] [D loss: 0.340677] [G loss: 1.254272]\n",
      "[Epoch 0/200] [Batch 55/169] [D loss: 0.522825] [G loss: 1.013134]\n",
      "[Epoch 0/200] [Batch 56/169] [D loss: 0.415475] [G loss: 1.283273]\n",
      "[Epoch 0/200] [Batch 57/169] [D loss: 0.392129] [G loss: 1.447902]\n",
      "[Epoch 0/200] [Batch 58/169] [D loss: 0.416064] [G loss: 1.126625]\n",
      "[Epoch 0/200] [Batch 59/169] [D loss: 0.497109] [G loss: 0.955122]\n",
      "[Epoch 0/200] [Batch 60/169] [D loss: 0.569984] [G loss: 0.865200]\n",
      "[Epoch 0/200] [Batch 61/169] [D loss: 0.653029] [G loss: 0.651463]\n",
      "[Epoch 0/200] [Batch 62/169] [D loss: 0.523181] [G loss: 0.954160]\n",
      "[Epoch 0/200] [Batch 63/169] [D loss: 0.527772] [G loss: 1.176005]\n",
      "[Epoch 0/200] [Batch 64/169] [D loss: 0.442918] [G loss: 1.166692]\n",
      "[Epoch 0/200] [Batch 65/169] [D loss: 0.381082] [G loss: 1.258243]\n",
      "[Epoch 0/200] [Batch 66/169] [D loss: 0.439629] [G loss: 1.251389]\n",
      "[Epoch 0/200] [Batch 67/169] [D loss: 0.466687] [G loss: 1.346246]\n",
      "[Epoch 0/200] [Batch 68/169] [D loss: 0.426438] [G loss: 1.358794]\n",
      "[Epoch 0/200] [Batch 69/169] [D loss: 0.439283] [G loss: 1.443005]\n",
      "[Epoch 0/200] [Batch 70/169] [D loss: 0.404195] [G loss: 1.225537]\n",
      "[Epoch 0/200] [Batch 71/169] [D loss: 0.435832] [G loss: 1.199786]\n",
      "[Epoch 0/200] [Batch 72/169] [D loss: 0.423666] [G loss: 1.219359]\n",
      "[Epoch 0/200] [Batch 73/169] [D loss: 0.439566] [G loss: 1.424909]\n",
      "[Epoch 0/200] [Batch 74/169] [D loss: 0.426512] [G loss: 1.469661]\n",
      "[Epoch 0/200] [Batch 75/169] [D loss: 0.403103] [G loss: 1.347890]\n",
      "[Epoch 0/200] [Batch 76/169] [D loss: 0.410250] [G loss: 1.335567]\n",
      "[Epoch 0/200] [Batch 77/169] [D loss: 0.381016] [G loss: 1.272301]\n",
      "[Epoch 0/200] [Batch 78/169] [D loss: 0.401397] [G loss: 1.290852]\n",
      "[Epoch 0/200] [Batch 79/169] [D loss: 0.372286] [G loss: 1.475212]\n",
      "[Epoch 0/200] [Batch 80/169] [D loss: 0.333417] [G loss: 1.561730]\n",
      "[Epoch 0/200] [Batch 81/169] [D loss: 0.352706] [G loss: 1.458844]\n",
      "[Epoch 0/200] [Batch 82/169] [D loss: 0.450868] [G loss: 1.350000]\n",
      "[Epoch 0/200] [Batch 83/169] [D loss: 0.434011] [G loss: 1.254370]\n",
      "[Epoch 0/200] [Batch 84/169] [D loss: 0.462780] [G loss: 1.317607]\n",
      "[Epoch 0/200] [Batch 85/169] [D loss: 0.473608] [G loss: 1.104125]\n",
      "[Epoch 0/200] [Batch 86/169] [D loss: 0.517920] [G loss: 1.249098]\n",
      "[Epoch 0/200] [Batch 87/169] [D loss: 0.477344] [G loss: 1.324011]\n",
      "[Epoch 0/200] [Batch 88/169] [D loss: 0.429246] [G loss: 1.118095]\n",
      "[Epoch 0/200] [Batch 89/169] [D loss: 0.434806] [G loss: 0.988205]\n",
      "[Epoch 0/200] [Batch 90/169] [D loss: 0.386096] [G loss: 1.226246]\n",
      "[Epoch 0/200] [Batch 91/169] [D loss: 0.422348] [G loss: 1.496408]\n",
      "[Epoch 0/200] [Batch 92/169] [D loss: 0.377155] [G loss: 1.383705]\n",
      "[Epoch 0/200] [Batch 93/169] [D loss: 0.391765] [G loss: 1.313623]\n",
      "[Epoch 0/200] [Batch 94/169] [D loss: 0.430549] [G loss: 1.250383]\n",
      "[Epoch 0/200] [Batch 95/169] [D loss: 0.464343] [G loss: 1.401905]\n",
      "[Epoch 0/200] [Batch 96/169] [D loss: 0.440909] [G loss: 1.526311]\n",
      "[Epoch 0/200] [Batch 97/169] [D loss: 0.441622] [G loss: 1.134646]\n",
      "[Epoch 0/200] [Batch 98/169] [D loss: 0.459888] [G loss: 1.193059]\n",
      "[Epoch 0/200] [Batch 99/169] [D loss: 0.425605] [G loss: 1.101091]\n",
      "[Epoch 0/200] [Batch 100/169] [D loss: 0.426141] [G loss: 1.284158]\n",
      "[Epoch 0/200] [Batch 101/169] [D loss: 0.412903] [G loss: 1.154268]\n",
      "[Epoch 0/200] [Batch 102/169] [D loss: 0.402713] [G loss: 1.325343]\n",
      "[Epoch 0/200] [Batch 103/169] [D loss: 0.356956] [G loss: 1.372099]\n",
      "[Epoch 0/200] [Batch 104/169] [D loss: 0.410587] [G loss: 1.579567]\n",
      "[Epoch 0/200] [Batch 105/169] [D loss: 0.451953] [G loss: 1.365588]\n",
      "[Epoch 0/200] [Batch 106/169] [D loss: 0.381554] [G loss: 1.595191]\n",
      "[Epoch 0/200] [Batch 107/169] [D loss: 0.389147] [G loss: 1.435143]\n",
      "[Epoch 0/200] [Batch 108/169] [D loss: 0.417030] [G loss: 1.267599]\n",
      "[Epoch 0/200] [Batch 109/169] [D loss: 0.439295] [G loss: 1.153485]\n",
      "[Epoch 0/200] [Batch 110/169] [D loss: 0.491599] [G loss: 1.328277]\n",
      "[Epoch 0/200] [Batch 111/169] [D loss: 0.475348] [G loss: 1.344621]\n",
      "[Epoch 0/200] [Batch 112/169] [D loss: 0.498692] [G loss: 1.097759]\n",
      "[Epoch 0/200] [Batch 113/169] [D loss: 0.427491] [G loss: 1.266122]\n",
      "[Epoch 0/200] [Batch 114/169] [D loss: 0.420335] [G loss: 1.893538]\n",
      "[Epoch 0/200] [Batch 115/169] [D loss: 0.424690] [G loss: 1.776441]\n",
      "[Epoch 0/200] [Batch 116/169] [D loss: 0.443669] [G loss: 1.303324]\n",
      "[Epoch 0/200] [Batch 117/169] [D loss: 0.438231] [G loss: 1.546401]\n",
      "[Epoch 0/200] [Batch 118/169] [D loss: 0.448190] [G loss: 1.826881]\n",
      "[Epoch 0/200] [Batch 119/169] [D loss: 0.425895] [G loss: 1.562427]\n",
      "[Epoch 0/200] [Batch 120/169] [D loss: 0.340830] [G loss: 1.714418]\n",
      "[Epoch 0/200] [Batch 121/169] [D loss: 0.361392] [G loss: 1.527422]\n",
      "[Epoch 0/200] [Batch 122/169] [D loss: 0.316246] [G loss: 1.548844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 123/169] [D loss: 0.315394] [G loss: 1.705764]\n",
      "[Epoch 0/200] [Batch 124/169] [D loss: 0.359927] [G loss: 1.421839]\n",
      "[Epoch 0/200] [Batch 125/169] [D loss: 0.355187] [G loss: 1.287701]\n",
      "[Epoch 0/200] [Batch 126/169] [D loss: 0.437496] [G loss: 1.508587]\n",
      "[Epoch 0/200] [Batch 127/169] [D loss: 0.334847] [G loss: 1.349447]\n",
      "[Epoch 0/200] [Batch 128/169] [D loss: 0.359207] [G loss: 1.161592]\n",
      "[Epoch 0/200] [Batch 129/169] [D loss: 0.310756] [G loss: 1.729981]\n",
      "[Epoch 0/200] [Batch 130/169] [D loss: 0.362552] [G loss: 1.591016]\n",
      "[Epoch 0/200] [Batch 131/169] [D loss: 0.329293] [G loss: 1.169724]\n",
      "[Epoch 0/200] [Batch 132/169] [D loss: 0.434769] [G loss: 1.068933]\n",
      "[Epoch 0/200] [Batch 133/169] [D loss: 0.512508] [G loss: 1.071960]\n",
      "[Epoch 0/200] [Batch 134/169] [D loss: 0.512405] [G loss: 1.014188]\n",
      "[Epoch 0/200] [Batch 135/169] [D loss: 0.447722] [G loss: 1.418639]\n",
      "[Epoch 0/200] [Batch 136/169] [D loss: 0.356259] [G loss: 1.585665]\n",
      "[Epoch 0/200] [Batch 137/169] [D loss: 0.374182] [G loss: 1.351308]\n",
      "[Epoch 0/200] [Batch 138/169] [D loss: 0.332607] [G loss: 1.424264]\n",
      "[Epoch 0/200] [Batch 139/169] [D loss: 0.416742] [G loss: 1.156758]\n",
      "[Epoch 0/200] [Batch 140/169] [D loss: 0.406762] [G loss: 1.404119]\n",
      "[Epoch 0/200] [Batch 141/169] [D loss: 0.442859] [G loss: 1.921788]\n",
      "[Epoch 0/200] [Batch 142/169] [D loss: 0.453278] [G loss: 1.675533]\n",
      "[Epoch 0/200] [Batch 143/169] [D loss: 0.498115] [G loss: 1.466975]\n",
      "[Epoch 0/200] [Batch 144/169] [D loss: 0.387091] [G loss: 1.300314]\n",
      "[Epoch 0/200] [Batch 145/169] [D loss: 0.383956] [G loss: 1.506276]\n",
      "[Epoch 0/200] [Batch 146/169] [D loss: 0.456862] [G loss: 1.300974]\n",
      "[Epoch 0/200] [Batch 147/169] [D loss: 0.484951] [G loss: 1.242918]\n",
      "[Epoch 0/200] [Batch 148/169] [D loss: 0.401794] [G loss: 1.606608]\n",
      "[Epoch 0/200] [Batch 149/169] [D loss: 0.490585] [G loss: 1.196591]\n",
      "[Epoch 0/200] [Batch 150/169] [D loss: 0.473448] [G loss: 1.218214]\n",
      "[Epoch 0/200] [Batch 151/169] [D loss: 0.471495] [G loss: 1.480260]\n",
      "[Epoch 0/200] [Batch 152/169] [D loss: 0.446895] [G loss: 1.479757]\n",
      "[Epoch 0/200] [Batch 153/169] [D loss: 0.459503] [G loss: 1.384217]\n",
      "[Epoch 0/200] [Batch 154/169] [D loss: 0.450020] [G loss: 1.464382]\n",
      "[Epoch 0/200] [Batch 155/169] [D loss: 0.405393] [G loss: 1.173127]\n",
      "[Epoch 0/200] [Batch 156/169] [D loss: 0.451201] [G loss: 1.232343]\n",
      "[Epoch 0/200] [Batch 157/169] [D loss: 0.393105] [G loss: 1.435421]\n",
      "[Epoch 0/200] [Batch 158/169] [D loss: 0.414861] [G loss: 0.973088]\n",
      "[Epoch 0/200] [Batch 159/169] [D loss: 0.468019] [G loss: 1.213308]\n",
      "[Epoch 0/200] [Batch 160/169] [D loss: 0.511802] [G loss: 1.784550]\n",
      "[Epoch 0/200] [Batch 161/169] [D loss: 0.331855] [G loss: 1.448839]\n",
      "[Epoch 0/200] [Batch 162/169] [D loss: 0.423126] [G loss: 1.156987]\n",
      "[Epoch 0/200] [Batch 163/169] [D loss: 0.380774] [G loss: 1.297968]\n",
      "[Epoch 0/200] [Batch 164/169] [D loss: 0.390694] [G loss: 1.540976]\n",
      "[Epoch 0/200] [Batch 165/169] [D loss: 0.372661] [G loss: 1.388436]\n",
      "[Epoch 0/200] [Batch 166/169] [D loss: 0.414619] [G loss: 1.143086]\n",
      "[Epoch 0/200] [Batch 167/169] [D loss: 0.507863] [G loss: 1.381739]\n",
      "[Epoch 0/200] [Batch 168/169] [D loss: 0.514300] [G loss: 1.057314]\n",
      "[Epoch 1/200] [Batch 0/169] [D loss: 0.481095] [G loss: 1.352593]\n",
      "[Epoch 1/200] [Batch 1/169] [D loss: 0.464437] [G loss: 1.500597]\n",
      "[Epoch 1/200] [Batch 2/169] [D loss: 0.407231] [G loss: 1.377410]\n",
      "[Epoch 1/200] [Batch 3/169] [D loss: 0.409847] [G loss: 1.177153]\n",
      "[Epoch 1/200] [Batch 4/169] [D loss: 0.397970] [G loss: 1.474506]\n",
      "[Epoch 1/200] [Batch 5/169] [D loss: 0.441594] [G loss: 1.630107]\n",
      "[Epoch 1/200] [Batch 6/169] [D loss: 0.380423] [G loss: 1.408862]\n",
      "[Epoch 1/200] [Batch 7/169] [D loss: 0.428895] [G loss: 1.649700]\n",
      "[Epoch 1/200] [Batch 8/169] [D loss: 0.422259] [G loss: 1.283321]\n",
      "[Epoch 1/200] [Batch 9/169] [D loss: 0.412014] [G loss: 1.406746]\n",
      "[Epoch 1/200] [Batch 10/169] [D loss: 0.320338] [G loss: 1.255426]\n",
      "[Epoch 1/200] [Batch 11/169] [D loss: 0.372753] [G loss: 1.329720]\n",
      "[Epoch 1/200] [Batch 12/169] [D loss: 0.349138] [G loss: 1.478191]\n",
      "[Epoch 1/200] [Batch 13/169] [D loss: 0.347903] [G loss: 1.547093]\n",
      "[Epoch 1/200] [Batch 14/169] [D loss: 0.319163] [G loss: 1.473267]\n",
      "[Epoch 1/200] [Batch 15/169] [D loss: 0.339719] [G loss: 1.348441]\n",
      "[Epoch 1/200] [Batch 16/169] [D loss: 0.382928] [G loss: 1.216509]\n",
      "[Epoch 1/200] [Batch 17/169] [D loss: 0.365348] [G loss: 1.468174]\n",
      "[Epoch 1/200] [Batch 18/169] [D loss: 0.356748] [G loss: 1.459279]\n",
      "[Epoch 1/200] [Batch 19/169] [D loss: 0.402565] [G loss: 1.232261]\n",
      "[Epoch 1/200] [Batch 20/169] [D loss: 0.403776] [G loss: 1.324560]\n",
      "[Epoch 1/200] [Batch 21/169] [D loss: 0.398049] [G loss: 1.552273]\n",
      "[Epoch 1/200] [Batch 22/169] [D loss: 0.394943] [G loss: 1.697722]\n",
      "[Epoch 1/200] [Batch 23/169] [D loss: 0.355175] [G loss: 1.239931]\n",
      "[Epoch 1/200] [Batch 24/169] [D loss: 0.470499] [G loss: 1.082004]\n",
      "[Epoch 1/200] [Batch 25/169] [D loss: 0.379226] [G loss: 1.322403]\n",
      "[Epoch 1/200] [Batch 26/169] [D loss: 0.417951] [G loss: 1.674195]\n",
      "[Epoch 1/200] [Batch 27/169] [D loss: 0.445600] [G loss: 1.682539]\n",
      "[Epoch 1/200] [Batch 28/169] [D loss: 0.398684] [G loss: 1.382672]\n",
      "[Epoch 1/200] [Batch 29/169] [D loss: 0.397299] [G loss: 1.285320]\n",
      "[Epoch 1/200] [Batch 30/169] [D loss: 0.485567] [G loss: 1.047893]\n",
      "[Epoch 1/200] [Batch 31/169] [D loss: 0.442412] [G loss: 1.463522]\n",
      "[Epoch 1/200] [Batch 32/169] [D loss: 0.419967] [G loss: 1.581013]\n",
      "[Epoch 1/200] [Batch 33/169] [D loss: 0.358550] [G loss: 1.159091]\n",
      "[Epoch 1/200] [Batch 34/169] [D loss: 0.423445] [G loss: 1.292461]\n",
      "[Epoch 1/200] [Batch 35/169] [D loss: 0.370276] [G loss: 1.658396]\n",
      "[Epoch 1/200] [Batch 36/169] [D loss: 0.445968] [G loss: 1.092257]\n",
      "[Epoch 1/200] [Batch 37/169] [D loss: 0.399209] [G loss: 1.280050]\n",
      "[Epoch 1/200] [Batch 38/169] [D loss: 0.479723] [G loss: 1.514607]\n",
      "[Epoch 1/200] [Batch 39/169] [D loss: 0.401271] [G loss: 1.306092]\n",
      "[Epoch 1/200] [Batch 40/169] [D loss: 0.425933] [G loss: 1.327367]\n",
      "[Epoch 1/200] [Batch 41/169] [D loss: 0.379346] [G loss: 1.519627]\n",
      "[Epoch 1/200] [Batch 42/169] [D loss: 0.410358] [G loss: 1.126580]\n",
      "[Epoch 1/200] [Batch 43/169] [D loss: 0.513308] [G loss: 1.771693]\n",
      "[Epoch 1/200] [Batch 44/169] [D loss: 0.422359] [G loss: 1.593542]\n",
      "[Epoch 1/200] [Batch 45/169] [D loss: 0.398713] [G loss: 1.365499]\n",
      "[Epoch 1/200] [Batch 46/169] [D loss: 0.365940] [G loss: 1.266050]\n",
      "[Epoch 1/200] [Batch 47/169] [D loss: 0.374795] [G loss: 1.655483]\n",
      "[Epoch 1/200] [Batch 48/169] [D loss: 0.363230] [G loss: 1.614297]\n",
      "[Epoch 1/200] [Batch 49/169] [D loss: 0.382076] [G loss: 1.390826]\n",
      "[Epoch 1/200] [Batch 50/169] [D loss: 0.348970] [G loss: 1.563875]\n",
      "[Epoch 1/200] [Batch 51/169] [D loss: 0.384273] [G loss: 1.231208]\n",
      "[Epoch 1/200] [Batch 52/169] [D loss: 0.388882] [G loss: 1.255025]\n",
      "[Epoch 1/200] [Batch 53/169] [D loss: 0.388289] [G loss: 1.177326]\n",
      "[Epoch 1/200] [Batch 54/169] [D loss: 0.386190] [G loss: 1.198205]\n",
      "[Epoch 1/200] [Batch 55/169] [D loss: 0.373287] [G loss: 1.321569]\n",
      "[Epoch 1/200] [Batch 56/169] [D loss: 0.467001] [G loss: 1.147004]\n",
      "[Epoch 1/200] [Batch 57/169] [D loss: 0.409980] [G loss: 1.243197]\n",
      "[Epoch 1/200] [Batch 58/169] [D loss: 0.404514] [G loss: 1.653582]\n",
      "[Epoch 1/200] [Batch 59/169] [D loss: 0.334549] [G loss: 1.597915]\n",
      "[Epoch 1/200] [Batch 60/169] [D loss: 0.381095] [G loss: 1.526329]\n",
      "[Epoch 1/200] [Batch 61/169] [D loss: 0.353265] [G loss: 1.641642]\n",
      "[Epoch 1/200] [Batch 62/169] [D loss: 0.466200] [G loss: 1.545295]\n",
      "[Epoch 1/200] [Batch 63/169] [D loss: 0.387709] [G loss: 1.535156]\n",
      "[Epoch 1/200] [Batch 64/169] [D loss: 0.383775] [G loss: 1.454094]\n",
      "[Epoch 1/200] [Batch 65/169] [D loss: 0.443457] [G loss: 1.041674]\n",
      "[Epoch 1/200] [Batch 66/169] [D loss: 0.378827] [G loss: 1.435748]\n",
      "[Epoch 1/200] [Batch 67/169] [D loss: 0.299654] [G loss: 1.383039]\n",
      "[Epoch 1/200] [Batch 68/169] [D loss: 0.303715] [G loss: 1.453711]\n",
      "[Epoch 1/200] [Batch 69/169] [D loss: 0.465445] [G loss: 1.131887]\n",
      "[Epoch 1/200] [Batch 70/169] [D loss: 0.439273] [G loss: 1.448388]\n",
      "[Epoch 1/200] [Batch 71/169] [D loss: 0.463642] [G loss: 1.341277]\n",
      "[Epoch 1/200] [Batch 72/169] [D loss: 0.456996] [G loss: 1.117773]\n",
      "[Epoch 1/200] [Batch 73/169] [D loss: 0.467785] [G loss: 1.220360]\n",
      "[Epoch 1/200] [Batch 74/169] [D loss: 0.442479] [G loss: 1.466201]\n",
      "[Epoch 1/200] [Batch 75/169] [D loss: 0.434999] [G loss: 1.608493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 76/169] [D loss: 0.416418] [G loss: 1.458290]\n",
      "[Epoch 1/200] [Batch 77/169] [D loss: 0.470969] [G loss: 1.286572]\n",
      "[Epoch 1/200] [Batch 78/169] [D loss: 0.439757] [G loss: 1.666142]\n",
      "[Epoch 1/200] [Batch 79/169] [D loss: 0.422269] [G loss: 1.121773]\n",
      "[Epoch 1/200] [Batch 80/169] [D loss: 0.567231] [G loss: 0.912717]\n",
      "[Epoch 1/200] [Batch 81/169] [D loss: 0.481072] [G loss: 1.446947]\n",
      "[Epoch 1/200] [Batch 82/169] [D loss: 0.468481] [G loss: 1.665012]\n",
      "[Epoch 1/200] [Batch 83/169] [D loss: 0.379102] [G loss: 1.251382]\n",
      "[Epoch 1/200] [Batch 84/169] [D loss: 0.347056] [G loss: 1.153430]\n",
      "[Epoch 1/200] [Batch 85/169] [D loss: 0.409285] [G loss: 1.734902]\n",
      "[Epoch 1/200] [Batch 86/169] [D loss: 0.369239] [G loss: 1.608764]\n",
      "[Epoch 1/200] [Batch 87/169] [D loss: 0.471345] [G loss: 1.547538]\n",
      "[Epoch 1/200] [Batch 88/169] [D loss: 0.361150] [G loss: 1.065293]\n",
      "[Epoch 1/200] [Batch 89/169] [D loss: 0.343259] [G loss: 1.567381]\n",
      "[Epoch 1/200] [Batch 90/169] [D loss: 0.477899] [G loss: 1.356028]\n",
      "[Epoch 1/200] [Batch 91/169] [D loss: 0.480181] [G loss: 1.125673]\n",
      "[Epoch 1/200] [Batch 92/169] [D loss: 0.463225] [G loss: 1.157557]\n",
      "[Epoch 1/200] [Batch 93/169] [D loss: 0.576467] [G loss: 1.259948]\n",
      "[Epoch 1/200] [Batch 94/169] [D loss: 0.444352] [G loss: 0.990928]\n",
      "[Epoch 1/200] [Batch 95/169] [D loss: 0.489366] [G loss: 1.348163]\n",
      "[Epoch 1/200] [Batch 96/169] [D loss: 0.539662] [G loss: 1.701630]\n",
      "[Epoch 1/200] [Batch 97/169] [D loss: 0.540232] [G loss: 1.027182]\n",
      "[Epoch 1/200] [Batch 98/169] [D loss: 0.467641] [G loss: 1.218355]\n",
      "[Epoch 1/200] [Batch 99/169] [D loss: 0.429834] [G loss: 1.315372]\n",
      "[Epoch 1/200] [Batch 100/169] [D loss: 0.396693] [G loss: 0.989528]\n",
      "[Epoch 1/200] [Batch 101/169] [D loss: 0.548202] [G loss: 1.258097]\n",
      "[Epoch 1/200] [Batch 102/169] [D loss: 0.405959] [G loss: 1.258841]\n",
      "[Epoch 1/200] [Batch 103/169] [D loss: 0.366355] [G loss: 1.168996]\n",
      "[Epoch 1/200] [Batch 104/169] [D loss: 0.445106] [G loss: 1.200227]\n",
      "[Epoch 1/200] [Batch 105/169] [D loss: 0.418384] [G loss: 1.346623]\n",
      "[Epoch 1/200] [Batch 106/169] [D loss: 0.437379] [G loss: 1.214785]\n",
      "[Epoch 1/200] [Batch 107/169] [D loss: 0.426777] [G loss: 1.428737]\n",
      "[Epoch 1/200] [Batch 108/169] [D loss: 0.359708] [G loss: 1.511614]\n",
      "[Epoch 1/200] [Batch 109/169] [D loss: 0.379754] [G loss: 1.320993]\n",
      "[Epoch 1/200] [Batch 110/169] [D loss: 0.457474] [G loss: 1.173606]\n",
      "[Epoch 1/200] [Batch 111/169] [D loss: 0.418174] [G loss: 1.286578]\n",
      "[Epoch 1/200] [Batch 112/169] [D loss: 0.405290] [G loss: 1.625656]\n",
      "[Epoch 1/200] [Batch 113/169] [D loss: 0.345652] [G loss: 1.335550]\n",
      "[Epoch 1/200] [Batch 114/169] [D loss: 0.447346] [G loss: 1.132975]\n",
      "[Epoch 1/200] [Batch 115/169] [D loss: 0.371674] [G loss: 1.263568]\n",
      "[Epoch 1/200] [Batch 116/169] [D loss: 0.393400] [G loss: 1.266138]\n",
      "[Epoch 1/200] [Batch 117/169] [D loss: 0.354772] [G loss: 1.341377]\n",
      "[Epoch 1/200] [Batch 118/169] [D loss: 0.412845] [G loss: 1.108331]\n",
      "[Epoch 1/200] [Batch 119/169] [D loss: 0.465110] [G loss: 1.281800]\n",
      "[Epoch 1/200] [Batch 120/169] [D loss: 0.394210] [G loss: 1.327531]\n",
      "[Epoch 1/200] [Batch 121/169] [D loss: 0.389169] [G loss: 1.284593]\n",
      "[Epoch 1/200] [Batch 122/169] [D loss: 0.475608] [G loss: 1.436332]\n",
      "[Epoch 1/200] [Batch 123/169] [D loss: 0.474340] [G loss: 1.513597]\n",
      "[Epoch 1/200] [Batch 124/169] [D loss: 0.374028] [G loss: 1.476677]\n",
      "[Epoch 1/200] [Batch 125/169] [D loss: 0.445263] [G loss: 1.244261]\n",
      "[Epoch 1/200] [Batch 126/169] [D loss: 0.492848] [G loss: 1.361982]\n",
      "[Epoch 1/200] [Batch 127/169] [D loss: 0.453733] [G loss: 1.656343]\n",
      "[Epoch 1/200] [Batch 128/169] [D loss: 0.500145] [G loss: 1.356390]\n",
      "[Epoch 1/200] [Batch 129/169] [D loss: 0.517295] [G loss: 1.010771]\n",
      "[Epoch 1/200] [Batch 130/169] [D loss: 0.431274] [G loss: 1.216335]\n",
      "[Epoch 1/200] [Batch 131/169] [D loss: 0.536748] [G loss: 1.479237]\n",
      "[Epoch 1/200] [Batch 132/169] [D loss: 0.468043] [G loss: 1.146560]\n",
      "[Epoch 1/200] [Batch 133/169] [D loss: 0.491119] [G loss: 1.173218]\n",
      "[Epoch 1/200] [Batch 134/169] [D loss: 0.477440] [G loss: 1.345322]\n",
      "[Epoch 1/200] [Batch 135/169] [D loss: 0.430300] [G loss: 1.271155]\n",
      "[Epoch 1/200] [Batch 136/169] [D loss: 0.369715] [G loss: 1.565989]\n",
      "[Epoch 1/200] [Batch 137/169] [D loss: 0.375462] [G loss: 1.681025]\n",
      "[Epoch 1/200] [Batch 138/169] [D loss: 0.339507] [G loss: 1.598014]\n",
      "[Epoch 1/200] [Batch 139/169] [D loss: 0.453081] [G loss: 1.381610]\n",
      "[Epoch 1/200] [Batch 140/169] [D loss: 0.395359] [G loss: 1.447935]\n",
      "[Epoch 1/200] [Batch 141/169] [D loss: 0.439503] [G loss: 1.487533]\n",
      "[Epoch 1/200] [Batch 142/169] [D loss: 0.425252] [G loss: 1.204443]\n",
      "[Epoch 1/200] [Batch 143/169] [D loss: 0.433193] [G loss: 1.310418]\n",
      "[Epoch 1/200] [Batch 144/169] [D loss: 0.443407] [G loss: 1.361161]\n",
      "[Epoch 1/200] [Batch 145/169] [D loss: 0.396878] [G loss: 1.426926]\n",
      "[Epoch 1/200] [Batch 146/169] [D loss: 0.412567] [G loss: 1.326918]\n",
      "[Epoch 1/200] [Batch 147/169] [D loss: 0.511327] [G loss: 1.029035]\n",
      "[Epoch 1/200] [Batch 148/169] [D loss: 0.558527] [G loss: 1.180140]\n",
      "[Epoch 1/200] [Batch 149/169] [D loss: 0.534312] [G loss: 1.492296]\n",
      "[Epoch 1/200] [Batch 150/169] [D loss: 0.550772] [G loss: 1.195245]\n",
      "[Epoch 1/200] [Batch 151/169] [D loss: 0.555839] [G loss: 0.967776]\n",
      "[Epoch 1/200] [Batch 152/169] [D loss: 0.442213] [G loss: 1.146297]\n",
      "[Epoch 1/200] [Batch 153/169] [D loss: 0.386961] [G loss: 1.227089]\n",
      "[Epoch 1/200] [Batch 154/169] [D loss: 0.319159] [G loss: 1.381210]\n",
      "[Epoch 1/200] [Batch 155/169] [D loss: 0.425174] [G loss: 1.392830]\n",
      "[Epoch 1/200] [Batch 156/169] [D loss: 0.475175] [G loss: 1.121846]\n",
      "[Epoch 1/200] [Batch 157/169] [D loss: 0.391977] [G loss: 1.404033]\n",
      "[Epoch 1/200] [Batch 158/169] [D loss: 0.459739] [G loss: 1.248054]\n",
      "[Epoch 1/200] [Batch 159/169] [D loss: 0.481974] [G loss: 1.118574]\n",
      "[Epoch 1/200] [Batch 160/169] [D loss: 0.457858] [G loss: 0.942622]\n",
      "[Epoch 1/200] [Batch 161/169] [D loss: 0.388623] [G loss: 1.514110]\n",
      "[Epoch 1/200] [Batch 162/169] [D loss: 0.430547] [G loss: 1.308479]\n",
      "[Epoch 1/200] [Batch 163/169] [D loss: 0.429113] [G loss: 1.293636]\n",
      "[Epoch 1/200] [Batch 164/169] [D loss: 0.430367] [G loss: 1.332124]\n",
      "[Epoch 1/200] [Batch 165/169] [D loss: 0.441098] [G loss: 1.198044]\n",
      "[Epoch 1/200] [Batch 166/169] [D loss: 0.547618] [G loss: 1.212134]\n",
      "[Epoch 1/200] [Batch 167/169] [D loss: 0.471660] [G loss: 1.101577]\n",
      "[Epoch 1/200] [Batch 168/169] [D loss: 0.554911] [G loss: 0.702938]\n",
      "[Epoch 2/200] [Batch 0/169] [D loss: 0.516531] [G loss: 1.803628]\n",
      "[Epoch 2/200] [Batch 1/169] [D loss: 0.393496] [G loss: 1.424935]\n",
      "[Epoch 2/200] [Batch 2/169] [D loss: 0.448815] [G loss: 1.204655]\n",
      "[Epoch 2/200] [Batch 3/169] [D loss: 0.500149] [G loss: 1.442883]\n",
      "[Epoch 2/200] [Batch 4/169] [D loss: 0.390834] [G loss: 1.538934]\n",
      "[Epoch 2/200] [Batch 5/169] [D loss: 0.498034] [G loss: 1.469553]\n",
      "[Epoch 2/200] [Batch 6/169] [D loss: 0.432285] [G loss: 1.318229]\n",
      "[Epoch 2/200] [Batch 7/169] [D loss: 0.453284] [G loss: 1.172546]\n",
      "[Epoch 2/200] [Batch 8/169] [D loss: 0.563815] [G loss: 1.294593]\n",
      "[Epoch 2/200] [Batch 9/169] [D loss: 0.419578] [G loss: 1.329055]\n",
      "[Epoch 2/200] [Batch 10/169] [D loss: 0.483709] [G loss: 1.198909]\n",
      "[Epoch 2/200] [Batch 11/169] [D loss: 0.489336] [G loss: 1.164452]\n",
      "[Epoch 2/200] [Batch 12/169] [D loss: 0.423468] [G loss: 1.515028]\n",
      "[Epoch 2/200] [Batch 13/169] [D loss: 0.526775] [G loss: 1.261184]\n",
      "[Epoch 2/200] [Batch 14/169] [D loss: 0.465818] [G loss: 1.245249]\n",
      "[Epoch 2/200] [Batch 15/169] [D loss: 0.530646] [G loss: 1.256800]\n",
      "[Epoch 2/200] [Batch 16/169] [D loss: 0.600022] [G loss: 0.966206]\n",
      "[Epoch 2/200] [Batch 17/169] [D loss: 0.518239] [G loss: 0.969679]\n",
      "[Epoch 2/200] [Batch 18/169] [D loss: 0.533493] [G loss: 1.304523]\n",
      "[Epoch 2/200] [Batch 19/169] [D loss: 0.487872] [G loss: 1.156883]\n",
      "[Epoch 2/200] [Batch 20/169] [D loss: 0.432452] [G loss: 1.145042]\n",
      "[Epoch 2/200] [Batch 21/169] [D loss: 0.477540] [G loss: 1.354620]\n",
      "[Epoch 2/200] [Batch 22/169] [D loss: 0.407202] [G loss: 1.294801]\n",
      "[Epoch 2/200] [Batch 23/169] [D loss: 0.399875] [G loss: 1.267815]\n",
      "[Epoch 2/200] [Batch 24/169] [D loss: 0.448988] [G loss: 1.120894]\n",
      "[Epoch 2/200] [Batch 25/169] [D loss: 0.246029] [G loss: 1.419782]\n",
      "[Epoch 2/200] [Batch 26/169] [D loss: 0.408325] [G loss: 1.650721]\n",
      "[Epoch 2/200] [Batch 27/169] [D loss: 0.409112] [G loss: 1.166949]\n",
      "[Epoch 2/200] [Batch 28/169] [D loss: 0.329478] [G loss: 1.140413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 29/169] [D loss: 0.434096] [G loss: 1.603717]\n",
      "[Epoch 2/200] [Batch 30/169] [D loss: 0.366027] [G loss: 1.304499]\n",
      "[Epoch 2/200] [Batch 31/169] [D loss: 0.470500] [G loss: 1.447893]\n",
      "[Epoch 2/200] [Batch 32/169] [D loss: 0.433932] [G loss: 1.170518]\n",
      "[Epoch 2/200] [Batch 33/169] [D loss: 0.439516] [G loss: 1.079688]\n",
      "[Epoch 2/200] [Batch 34/169] [D loss: 0.543160] [G loss: 1.241057]\n",
      "[Epoch 2/200] [Batch 35/169] [D loss: 0.540585] [G loss: 1.345958]\n",
      "[Epoch 2/200] [Batch 36/169] [D loss: 0.469526] [G loss: 1.174294]\n",
      "[Epoch 2/200] [Batch 37/169] [D loss: 0.412536] [G loss: 1.261625]\n",
      "[Epoch 2/200] [Batch 38/169] [D loss: 0.464145] [G loss: 1.162982]\n",
      "[Epoch 2/200] [Batch 39/169] [D loss: 0.558890] [G loss: 1.003444]\n",
      "[Epoch 2/200] [Batch 40/169] [D loss: 0.634569] [G loss: 1.109731]\n",
      "[Epoch 2/200] [Batch 41/169] [D loss: 0.527214] [G loss: 1.264539]\n",
      "[Epoch 2/200] [Batch 42/169] [D loss: 0.599894] [G loss: 1.526613]\n",
      "[Epoch 2/200] [Batch 43/169] [D loss: 0.432345] [G loss: 1.291279]\n",
      "[Epoch 2/200] [Batch 44/169] [D loss: 0.472292] [G loss: 1.123793]\n",
      "[Epoch 2/200] [Batch 45/169] [D loss: 0.532107] [G loss: 1.353366]\n",
      "[Epoch 2/200] [Batch 46/169] [D loss: 0.394656] [G loss: 1.247665]\n",
      "[Epoch 2/200] [Batch 47/169] [D loss: 0.396134] [G loss: 1.331545]\n",
      "[Epoch 2/200] [Batch 48/169] [D loss: 0.433217] [G loss: 1.419677]\n",
      "[Epoch 2/200] [Batch 49/169] [D loss: 0.447921] [G loss: 1.072150]\n",
      "[Epoch 2/200] [Batch 50/169] [D loss: 0.403307] [G loss: 1.435828]\n",
      "[Epoch 2/200] [Batch 51/169] [D loss: 0.423859] [G loss: 1.479699]\n",
      "[Epoch 2/200] [Batch 52/169] [D loss: 0.395298] [G loss: 1.340602]\n",
      "[Epoch 2/200] [Batch 53/169] [D loss: 0.427901] [G loss: 1.197709]\n",
      "[Epoch 2/200] [Batch 54/169] [D loss: 0.459413] [G loss: 1.374040]\n",
      "[Epoch 2/200] [Batch 55/169] [D loss: 0.439991] [G loss: 1.533294]\n",
      "[Epoch 2/200] [Batch 56/169] [D loss: 0.404715] [G loss: 1.045323]\n",
      "[Epoch 2/200] [Batch 57/169] [D loss: 0.410335] [G loss: 1.225610]\n",
      "[Epoch 2/200] [Batch 58/169] [D loss: 0.397481] [G loss: 1.558633]\n",
      "[Epoch 2/200] [Batch 59/169] [D loss: 0.418218] [G loss: 1.330014]\n",
      "[Epoch 2/200] [Batch 60/169] [D loss: 0.464653] [G loss: 1.113057]\n",
      "[Epoch 2/200] [Batch 61/169] [D loss: 0.438833] [G loss: 1.296808]\n",
      "[Epoch 2/200] [Batch 62/169] [D loss: 0.459092] [G loss: 1.120800]\n",
      "[Epoch 2/200] [Batch 63/169] [D loss: 0.448949] [G loss: 1.297267]\n",
      "[Epoch 2/200] [Batch 64/169] [D loss: 0.576535] [G loss: 1.641500]\n",
      "[Epoch 2/200] [Batch 65/169] [D loss: 0.439925] [G loss: 1.337323]\n",
      "[Epoch 2/200] [Batch 66/169] [D loss: 0.499790] [G loss: 0.952025]\n",
      "[Epoch 2/200] [Batch 67/169] [D loss: 0.507860] [G loss: 1.208147]\n",
      "[Epoch 2/200] [Batch 68/169] [D loss: 0.522555] [G loss: 1.519096]\n",
      "[Epoch 2/200] [Batch 69/169] [D loss: 0.502354] [G loss: 1.212396]\n",
      "[Epoch 2/200] [Batch 70/169] [D loss: 0.450179] [G loss: 1.071750]\n",
      "[Epoch 2/200] [Batch 71/169] [D loss: 0.529878] [G loss: 1.139931]\n",
      "[Epoch 2/200] [Batch 72/169] [D loss: 0.522767] [G loss: 1.114214]\n",
      "[Epoch 2/200] [Batch 73/169] [D loss: 0.493371] [G loss: 1.478347]\n",
      "[Epoch 2/200] [Batch 74/169] [D loss: 0.526077] [G loss: 1.301225]\n",
      "[Epoch 2/200] [Batch 75/169] [D loss: 0.469358] [G loss: 1.350456]\n",
      "[Epoch 2/200] [Batch 76/169] [D loss: 0.439260] [G loss: 1.237656]\n",
      "[Epoch 2/200] [Batch 77/169] [D loss: 0.525027] [G loss: 1.364039]\n",
      "[Epoch 2/200] [Batch 78/169] [D loss: 0.494058] [G loss: 1.252225]\n",
      "[Epoch 2/200] [Batch 79/169] [D loss: 0.456450] [G loss: 1.558980]\n",
      "[Epoch 2/200] [Batch 80/169] [D loss: 0.438107] [G loss: 1.329898]\n",
      "[Epoch 2/200] [Batch 81/169] [D loss: 0.425313] [G loss: 1.084684]\n",
      "[Epoch 2/200] [Batch 82/169] [D loss: 0.417146] [G loss: 1.213318]\n",
      "[Epoch 2/200] [Batch 83/169] [D loss: 0.390498] [G loss: 1.434544]\n",
      "[Epoch 2/200] [Batch 84/169] [D loss: 0.366546] [G loss: 1.525919]\n",
      "[Epoch 2/200] [Batch 85/169] [D loss: 0.490097] [G loss: 1.416782]\n",
      "[Epoch 2/200] [Batch 86/169] [D loss: 0.453925] [G loss: 1.301447]\n",
      "[Epoch 2/200] [Batch 87/169] [D loss: 0.540842] [G loss: 1.106639]\n",
      "[Epoch 2/200] [Batch 88/169] [D loss: 0.475720] [G loss: 1.178137]\n",
      "[Epoch 2/200] [Batch 89/169] [D loss: 0.552936] [G loss: 1.182037]\n",
      "[Epoch 2/200] [Batch 90/169] [D loss: 0.440305] [G loss: 1.001219]\n",
      "[Epoch 2/200] [Batch 91/169] [D loss: 0.488168] [G loss: 1.158016]\n",
      "[Epoch 2/200] [Batch 92/169] [D loss: 0.502793] [G loss: 1.317470]\n",
      "[Epoch 2/200] [Batch 93/169] [D loss: 0.516579] [G loss: 1.256965]\n",
      "[Epoch 2/200] [Batch 94/169] [D loss: 0.432550] [G loss: 1.311515]\n",
      "[Epoch 2/200] [Batch 95/169] [D loss: 0.441668] [G loss: 1.326976]\n",
      "[Epoch 2/200] [Batch 96/169] [D loss: 0.593482] [G loss: 1.170857]\n",
      "[Epoch 2/200] [Batch 97/169] [D loss: 0.509410] [G loss: 1.060934]\n",
      "[Epoch 2/200] [Batch 98/169] [D loss: 0.547415] [G loss: 1.189429]\n",
      "[Epoch 2/200] [Batch 99/169] [D loss: 0.583538] [G loss: 0.949344]\n",
      "[Epoch 2/200] [Batch 100/169] [D loss: 0.487616] [G loss: 1.095063]\n",
      "[Epoch 2/200] [Batch 101/169] [D loss: 0.571191] [G loss: 1.226604]\n",
      "[Epoch 2/200] [Batch 102/169] [D loss: 0.486680] [G loss: 1.121345]\n",
      "[Epoch 2/200] [Batch 103/169] [D loss: 0.414516] [G loss: 1.796685]\n",
      "[Epoch 2/200] [Batch 104/169] [D loss: 0.421554] [G loss: 1.457049]\n",
      "[Epoch 2/200] [Batch 105/169] [D loss: 0.493230] [G loss: 1.277918]\n",
      "[Epoch 2/200] [Batch 106/169] [D loss: 0.575579] [G loss: 1.199050]\n",
      "[Epoch 2/200] [Batch 107/169] [D loss: 0.483864] [G loss: 1.175939]\n",
      "[Epoch 2/200] [Batch 108/169] [D loss: 0.512662] [G loss: 1.277347]\n",
      "[Epoch 2/200] [Batch 109/169] [D loss: 0.465777] [G loss: 1.398209]\n",
      "[Epoch 2/200] [Batch 110/169] [D loss: 0.409155] [G loss: 1.288366]\n",
      "[Epoch 2/200] [Batch 111/169] [D loss: 0.474209] [G loss: 1.092035]\n",
      "[Epoch 2/200] [Batch 112/169] [D loss: 0.471735] [G loss: 1.128285]\n",
      "[Epoch 2/200] [Batch 113/169] [D loss: 0.361619] [G loss: 1.358042]\n",
      "[Epoch 2/200] [Batch 114/169] [D loss: 0.434393] [G loss: 1.385591]\n",
      "[Epoch 2/200] [Batch 115/169] [D loss: 0.472421] [G loss: 1.425456]\n",
      "[Epoch 2/200] [Batch 116/169] [D loss: 0.460121] [G loss: 0.993852]\n",
      "[Epoch 2/200] [Batch 117/169] [D loss: 0.369831] [G loss: 1.267882]\n",
      "[Epoch 2/200] [Batch 118/169] [D loss: 0.448755] [G loss: 1.253745]\n",
      "[Epoch 2/200] [Batch 119/169] [D loss: 0.434933] [G loss: 1.272319]\n",
      "[Epoch 2/200] [Batch 120/169] [D loss: 0.451279] [G loss: 1.462373]\n",
      "[Epoch 2/200] [Batch 121/169] [D loss: 0.481761] [G loss: 0.946000]\n",
      "[Epoch 2/200] [Batch 122/169] [D loss: 0.441127] [G loss: 1.461387]\n",
      "[Epoch 2/200] [Batch 123/169] [D loss: 0.536261] [G loss: 1.540913]\n",
      "[Epoch 2/200] [Batch 124/169] [D loss: 0.544908] [G loss: 1.176097]\n",
      "[Epoch 2/200] [Batch 125/169] [D loss: 0.487476] [G loss: 1.457513]\n",
      "[Epoch 2/200] [Batch 126/169] [D loss: 0.502573] [G loss: 1.472971]\n",
      "[Epoch 2/200] [Batch 127/169] [D loss: 0.576258] [G loss: 1.206011]\n",
      "[Epoch 2/200] [Batch 128/169] [D loss: 0.450184] [G loss: 1.203395]\n",
      "[Epoch 2/200] [Batch 129/169] [D loss: 0.456732] [G loss: 1.186006]\n",
      "[Epoch 2/200] [Batch 130/169] [D loss: 0.458876] [G loss: 1.396204]\n",
      "[Epoch 2/200] [Batch 131/169] [D loss: 0.496148] [G loss: 1.220726]\n",
      "[Epoch 2/200] [Batch 132/169] [D loss: 0.572882] [G loss: 1.135679]\n",
      "[Epoch 2/200] [Batch 133/169] [D loss: 0.490129] [G loss: 1.383768]\n",
      "[Epoch 2/200] [Batch 134/169] [D loss: 0.460317] [G loss: 1.287011]\n",
      "[Epoch 2/200] [Batch 135/169] [D loss: 0.458094] [G loss: 1.243121]\n",
      "[Epoch 2/200] [Batch 136/169] [D loss: 0.505249] [G loss: 1.118260]\n",
      "[Epoch 2/200] [Batch 137/169] [D loss: 0.568353] [G loss: 1.316908]\n",
      "[Epoch 2/200] [Batch 138/169] [D loss: 0.447075] [G loss: 1.229366]\n",
      "[Epoch 2/200] [Batch 139/169] [D loss: 0.509134] [G loss: 1.161254]\n",
      "[Epoch 2/200] [Batch 140/169] [D loss: 0.525410] [G loss: 1.232377]\n",
      "[Epoch 2/200] [Batch 141/169] [D loss: 0.421179] [G loss: 1.220544]\n",
      "[Epoch 2/200] [Batch 142/169] [D loss: 0.397395] [G loss: 1.127980]\n",
      "[Epoch 2/200] [Batch 143/169] [D loss: 0.428130] [G loss: 1.318062]\n",
      "[Epoch 2/200] [Batch 144/169] [D loss: 0.441837] [G loss: 1.154610]\n",
      "[Epoch 2/200] [Batch 145/169] [D loss: 0.405949] [G loss: 1.215720]\n",
      "[Epoch 2/200] [Batch 146/169] [D loss: 0.436462] [G loss: 1.455203]\n",
      "[Epoch 2/200] [Batch 147/169] [D loss: 0.511402] [G loss: 1.367459]\n",
      "[Epoch 2/200] [Batch 148/169] [D loss: 0.468043] [G loss: 1.069715]\n",
      "[Epoch 2/200] [Batch 149/169] [D loss: 0.411115] [G loss: 1.084923]\n",
      "[Epoch 2/200] [Batch 150/169] [D loss: 0.380533] [G loss: 0.946711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 151/169] [D loss: 0.442059] [G loss: 1.339650]\n",
      "[Epoch 2/200] [Batch 152/169] [D loss: 0.522238] [G loss: 1.253146]\n",
      "[Epoch 2/200] [Batch 153/169] [D loss: 0.405250] [G loss: 1.257505]\n",
      "[Epoch 2/200] [Batch 154/169] [D loss: 0.417771] [G loss: 1.328095]\n",
      "[Epoch 2/200] [Batch 155/169] [D loss: 0.537224] [G loss: 1.229562]\n",
      "[Epoch 2/200] [Batch 156/169] [D loss: 0.523301] [G loss: 1.086520]\n",
      "[Epoch 2/200] [Batch 157/169] [D loss: 0.381888] [G loss: 1.204915]\n",
      "[Epoch 2/200] [Batch 158/169] [D loss: 0.456532] [G loss: 1.101616]\n",
      "[Epoch 2/200] [Batch 159/169] [D loss: 0.549308] [G loss: 1.086226]\n",
      "[Epoch 2/200] [Batch 160/169] [D loss: 0.446790] [G loss: 1.012947]\n",
      "[Epoch 2/200] [Batch 161/169] [D loss: 0.594074] [G loss: 0.802258]\n",
      "[Epoch 2/200] [Batch 162/169] [D loss: 0.472157] [G loss: 1.522649]\n",
      "[Epoch 2/200] [Batch 163/169] [D loss: 0.579624] [G loss: 1.719599]\n",
      "[Epoch 2/200] [Batch 164/169] [D loss: 0.447098] [G loss: 1.160898]\n",
      "[Epoch 2/200] [Batch 165/169] [D loss: 0.419785] [G loss: 0.954600]\n",
      "[Epoch 2/200] [Batch 166/169] [D loss: 0.396273] [G loss: 0.937854]\n",
      "[Epoch 2/200] [Batch 167/169] [D loss: 0.494197] [G loss: 1.341506]\n",
      "[Epoch 2/200] [Batch 168/169] [D loss: 0.430540] [G loss: 1.421152]\n",
      "[Epoch 3/200] [Batch 0/169] [D loss: 0.493315] [G loss: 1.022656]\n",
      "[Epoch 3/200] [Batch 1/169] [D loss: 0.456825] [G loss: 1.156652]\n",
      "[Epoch 3/200] [Batch 2/169] [D loss: 0.509885] [G loss: 1.113615]\n",
      "[Epoch 3/200] [Batch 3/169] [D loss: 0.525936] [G loss: 1.451907]\n",
      "[Epoch 3/200] [Batch 4/169] [D loss: 0.445489] [G loss: 1.183298]\n",
      "[Epoch 3/200] [Batch 5/169] [D loss: 0.397568] [G loss: 1.339259]\n",
      "[Epoch 3/200] [Batch 6/169] [D loss: 0.488177] [G loss: 1.252396]\n",
      "[Epoch 3/200] [Batch 7/169] [D loss: 0.505514] [G loss: 0.957822]\n",
      "[Epoch 3/200] [Batch 8/169] [D loss: 0.570683] [G loss: 1.329437]\n",
      "[Epoch 3/200] [Batch 9/169] [D loss: 0.463157] [G loss: 1.137978]\n",
      "[Epoch 3/200] [Batch 10/169] [D loss: 0.491426] [G loss: 1.248823]\n",
      "[Epoch 3/200] [Batch 11/169] [D loss: 0.436805] [G loss: 0.955742]\n",
      "[Epoch 3/200] [Batch 12/169] [D loss: 0.481407] [G loss: 0.887324]\n",
      "[Epoch 3/200] [Batch 13/169] [D loss: 0.457103] [G loss: 1.468833]\n",
      "[Epoch 3/200] [Batch 14/169] [D loss: 0.417906] [G loss: 1.827278]\n",
      "[Epoch 3/200] [Batch 15/169] [D loss: 0.544616] [G loss: 1.302737]\n",
      "[Epoch 3/200] [Batch 16/169] [D loss: 0.527801] [G loss: 1.071418]\n",
      "[Epoch 3/200] [Batch 17/169] [D loss: 0.493223] [G loss: 1.224353]\n",
      "[Epoch 3/200] [Batch 18/169] [D loss: 0.438384] [G loss: 1.322944]\n",
      "[Epoch 3/200] [Batch 19/169] [D loss: 0.430969] [G loss: 1.374607]\n",
      "[Epoch 3/200] [Batch 20/169] [D loss: 0.582352] [G loss: 1.324722]\n",
      "[Epoch 3/200] [Batch 21/169] [D loss: 0.475964] [G loss: 1.196710]\n",
      "[Epoch 3/200] [Batch 22/169] [D loss: 0.443320] [G loss: 1.372826]\n",
      "[Epoch 3/200] [Batch 23/169] [D loss: 0.565711] [G loss: 1.080197]\n",
      "[Epoch 3/200] [Batch 24/169] [D loss: 0.454128] [G loss: 1.008728]\n",
      "[Epoch 3/200] [Batch 25/169] [D loss: 0.477306] [G loss: 1.357447]\n",
      "[Epoch 3/200] [Batch 26/169] [D loss: 0.531368] [G loss: 1.205818]\n",
      "[Epoch 3/200] [Batch 27/169] [D loss: 0.561936] [G loss: 1.449202]\n",
      "[Epoch 3/200] [Batch 28/169] [D loss: 0.576916] [G loss: 1.248313]\n",
      "[Epoch 3/200] [Batch 29/169] [D loss: 0.604696] [G loss: 1.220461]\n",
      "[Epoch 3/200] [Batch 30/169] [D loss: 0.496986] [G loss: 1.069744]\n",
      "[Epoch 3/200] [Batch 31/169] [D loss: 0.463741] [G loss: 1.218088]\n",
      "[Epoch 3/200] [Batch 32/169] [D loss: 0.428175] [G loss: 1.166387]\n",
      "[Epoch 3/200] [Batch 33/169] [D loss: 0.416967] [G loss: 1.177201]\n",
      "[Epoch 3/200] [Batch 34/169] [D loss: 0.482995] [G loss: 1.336554]\n",
      "[Epoch 3/200] [Batch 35/169] [D loss: 0.458347] [G loss: 1.355575]\n",
      "[Epoch 3/200] [Batch 36/169] [D loss: 0.450960] [G loss: 1.011129]\n",
      "[Epoch 3/200] [Batch 37/169] [D loss: 0.498767] [G loss: 1.259586]\n",
      "[Epoch 3/200] [Batch 38/169] [D loss: 0.431809] [G loss: 1.046924]\n",
      "[Epoch 3/200] [Batch 39/169] [D loss: 0.478776] [G loss: 1.533612]\n",
      "[Epoch 3/200] [Batch 40/169] [D loss: 0.432995] [G loss: 0.990656]\n",
      "[Epoch 3/200] [Batch 41/169] [D loss: 0.480257] [G loss: 1.171046]\n",
      "[Epoch 3/200] [Batch 42/169] [D loss: 0.438648] [G loss: 1.160820]\n",
      "[Epoch 3/200] [Batch 43/169] [D loss: 0.600244] [G loss: 1.285878]\n",
      "[Epoch 3/200] [Batch 44/169] [D loss: 0.470239] [G loss: 1.310336]\n",
      "[Epoch 3/200] [Batch 45/169] [D loss: 0.549745] [G loss: 1.185109]\n",
      "[Epoch 3/200] [Batch 46/169] [D loss: 0.506197] [G loss: 1.025778]\n",
      "[Epoch 3/200] [Batch 47/169] [D loss: 0.528652] [G loss: 1.165932]\n",
      "[Epoch 3/200] [Batch 48/169] [D loss: 0.558858] [G loss: 1.385815]\n",
      "[Epoch 3/200] [Batch 49/169] [D loss: 0.515249] [G loss: 1.259285]\n",
      "[Epoch 3/200] [Batch 50/169] [D loss: 0.580857] [G loss: 1.088705]\n",
      "[Epoch 3/200] [Batch 51/169] [D loss: 0.520193] [G loss: 1.257003]\n",
      "[Epoch 3/200] [Batch 52/169] [D loss: 0.621284] [G loss: 1.263447]\n",
      "[Epoch 3/200] [Batch 53/169] [D loss: 0.492885] [G loss: 1.315200]\n",
      "[Epoch 3/200] [Batch 54/169] [D loss: 0.489156] [G loss: 0.956825]\n",
      "[Epoch 3/200] [Batch 55/169] [D loss: 0.604298] [G loss: 1.186471]\n",
      "[Epoch 3/200] [Batch 56/169] [D loss: 0.560348] [G loss: 1.042164]\n",
      "[Epoch 3/200] [Batch 57/169] [D loss: 0.487447] [G loss: 0.935842]\n",
      "[Epoch 3/200] [Batch 58/169] [D loss: 0.447620] [G loss: 1.356737]\n",
      "[Epoch 3/200] [Batch 59/169] [D loss: 0.507399] [G loss: 1.247732]\n",
      "[Epoch 3/200] [Batch 60/169] [D loss: 0.541855] [G loss: 1.434606]\n",
      "[Epoch 3/200] [Batch 61/169] [D loss: 0.627620] [G loss: 1.084849]\n",
      "[Epoch 3/200] [Batch 62/169] [D loss: 0.508048] [G loss: 1.098854]\n",
      "[Epoch 3/200] [Batch 63/169] [D loss: 0.544656] [G loss: 0.948611]\n",
      "[Epoch 3/200] [Batch 64/169] [D loss: 0.494379] [G loss: 1.165809]\n",
      "[Epoch 3/200] [Batch 65/169] [D loss: 0.547761] [G loss: 1.087573]\n",
      "[Epoch 3/200] [Batch 66/169] [D loss: 0.550240] [G loss: 1.221295]\n",
      "[Epoch 3/200] [Batch 67/169] [D loss: 0.507469] [G loss: 1.219114]\n",
      "[Epoch 3/200] [Batch 68/169] [D loss: 0.443842] [G loss: 1.189317]\n",
      "[Epoch 3/200] [Batch 69/169] [D loss: 0.457470] [G loss: 1.195277]\n",
      "[Epoch 3/200] [Batch 70/169] [D loss: 0.462144] [G loss: 1.457050]\n",
      "[Epoch 3/200] [Batch 71/169] [D loss: 0.429291] [G loss: 1.254960]\n",
      "[Epoch 3/200] [Batch 72/169] [D loss: 0.465488] [G loss: 1.077718]\n",
      "[Epoch 3/200] [Batch 73/169] [D loss: 0.474133] [G loss: 1.037380]\n",
      "[Epoch 3/200] [Batch 74/169] [D loss: 0.508861] [G loss: 1.201025]\n",
      "[Epoch 3/200] [Batch 75/169] [D loss: 0.407429] [G loss: 1.308711]\n",
      "[Epoch 3/200] [Batch 76/169] [D loss: 0.528339] [G loss: 1.331948]\n",
      "[Epoch 3/200] [Batch 77/169] [D loss: 0.443969] [G loss: 1.254638]\n",
      "[Epoch 3/200] [Batch 78/169] [D loss: 0.549966] [G loss: 1.057418]\n",
      "[Epoch 3/200] [Batch 79/169] [D loss: 0.447480] [G loss: 1.196799]\n",
      "[Epoch 3/200] [Batch 80/169] [D loss: 0.479492] [G loss: 1.143319]\n",
      "[Epoch 3/200] [Batch 81/169] [D loss: 0.413324] [G loss: 0.944954]\n",
      "[Epoch 3/200] [Batch 82/169] [D loss: 0.461503] [G loss: 1.187338]\n",
      "[Epoch 3/200] [Batch 83/169] [D loss: 0.523665] [G loss: 1.184739]\n",
      "[Epoch 3/200] [Batch 84/169] [D loss: 0.459212] [G loss: 1.211189]\n",
      "[Epoch 3/200] [Batch 85/169] [D loss: 0.586698] [G loss: 1.224350]\n",
      "[Epoch 3/200] [Batch 86/169] [D loss: 0.472268] [G loss: 1.472259]\n",
      "[Epoch 3/200] [Batch 87/169] [D loss: 0.499326] [G loss: 1.063863]\n",
      "[Epoch 3/200] [Batch 88/169] [D loss: 0.479265] [G loss: 1.077371]\n",
      "[Epoch 3/200] [Batch 89/169] [D loss: 0.503004] [G loss: 1.099063]\n",
      "[Epoch 3/200] [Batch 90/169] [D loss: 0.476727] [G loss: 1.381053]\n",
      "[Epoch 3/200] [Batch 91/169] [D loss: 0.496450] [G loss: 1.199416]\n",
      "[Epoch 3/200] [Batch 92/169] [D loss: 0.585577] [G loss: 1.379928]\n",
      "[Epoch 3/200] [Batch 93/169] [D loss: 0.484933] [G loss: 1.165096]\n",
      "[Epoch 3/200] [Batch 94/169] [D loss: 0.426120] [G loss: 1.370013]\n",
      "[Epoch 3/200] [Batch 95/169] [D loss: 0.453655] [G loss: 1.229302]\n",
      "[Epoch 3/200] [Batch 96/169] [D loss: 0.498762] [G loss: 1.190592]\n",
      "[Epoch 3/200] [Batch 97/169] [D loss: 0.585446] [G loss: 1.281546]\n",
      "[Epoch 3/200] [Batch 98/169] [D loss: 0.559853] [G loss: 1.242980]\n",
      "[Epoch 3/200] [Batch 99/169] [D loss: 0.625547] [G loss: 1.449659]\n",
      "[Epoch 3/200] [Batch 100/169] [D loss: 0.499482] [G loss: 1.317096]\n",
      "[Epoch 3/200] [Batch 101/169] [D loss: 0.547052] [G loss: 1.197063]\n",
      "[Epoch 3/200] [Batch 102/169] [D loss: 0.490747] [G loss: 1.080747]\n",
      "[Epoch 3/200] [Batch 103/169] [D loss: 0.530339] [G loss: 1.330247]\n",
      "[Epoch 3/200] [Batch 104/169] [D loss: 0.496629] [G loss: 1.185763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 105/169] [D loss: 0.517411] [G loss: 1.111318]\n",
      "[Epoch 3/200] [Batch 106/169] [D loss: 0.618442] [G loss: 0.904176]\n",
      "[Epoch 3/200] [Batch 107/169] [D loss: 0.544386] [G loss: 0.997265]\n",
      "[Epoch 3/200] [Batch 108/169] [D loss: 0.551374] [G loss: 1.425750]\n",
      "[Epoch 3/200] [Batch 109/169] [D loss: 0.627546] [G loss: 1.046683]\n",
      "[Epoch 3/200] [Batch 110/169] [D loss: 0.481282] [G loss: 1.103156]\n",
      "[Epoch 3/200] [Batch 111/169] [D loss: 0.473748] [G loss: 1.245546]\n",
      "[Epoch 3/200] [Batch 112/169] [D loss: 0.461638] [G loss: 1.031259]\n",
      "[Epoch 3/200] [Batch 113/169] [D loss: 0.520501] [G loss: 1.112871]\n",
      "[Epoch 3/200] [Batch 114/169] [D loss: 0.501506] [G loss: 1.079816]\n",
      "[Epoch 3/200] [Batch 115/169] [D loss: 0.575260] [G loss: 1.110835]\n",
      "[Epoch 3/200] [Batch 116/169] [D loss: 0.497090] [G loss: 1.265141]\n",
      "[Epoch 3/200] [Batch 117/169] [D loss: 0.508111] [G loss: 1.142905]\n",
      "[Epoch 3/200] [Batch 118/169] [D loss: 0.508118] [G loss: 1.464655]\n",
      "[Epoch 3/200] [Batch 119/169] [D loss: 0.464445] [G loss: 1.346224]\n",
      "[Epoch 3/200] [Batch 120/169] [D loss: 0.485243] [G loss: 1.120095]\n",
      "[Epoch 3/200] [Batch 121/169] [D loss: 0.467967] [G loss: 1.206090]\n",
      "[Epoch 3/200] [Batch 122/169] [D loss: 0.445891] [G loss: 0.881890]\n",
      "[Epoch 3/200] [Batch 123/169] [D loss: 0.423311] [G loss: 1.073731]\n",
      "[Epoch 3/200] [Batch 124/169] [D loss: 0.438311] [G loss: 1.433134]\n",
      "[Epoch 3/200] [Batch 125/169] [D loss: 0.483083] [G loss: 1.168751]\n",
      "[Epoch 3/200] [Batch 126/169] [D loss: 0.440762] [G loss: 1.245530]\n",
      "[Epoch 3/200] [Batch 127/169] [D loss: 0.525314] [G loss: 0.909034]\n",
      "[Epoch 3/200] [Batch 128/169] [D loss: 0.511975] [G loss: 1.003886]\n",
      "[Epoch 3/200] [Batch 129/169] [D loss: 0.486913] [G loss: 1.386798]\n",
      "[Epoch 3/200] [Batch 130/169] [D loss: 0.449629] [G loss: 1.088794]\n",
      "[Epoch 3/200] [Batch 131/169] [D loss: 0.435973] [G loss: 0.912415]\n",
      "[Epoch 3/200] [Batch 132/169] [D loss: 0.421078] [G loss: 1.082918]\n",
      "[Epoch 3/200] [Batch 133/169] [D loss: 0.480487] [G loss: 1.017744]\n",
      "[Epoch 3/200] [Batch 134/169] [D loss: 0.601595] [G loss: 1.221286]\n",
      "[Epoch 3/200] [Batch 135/169] [D loss: 0.492844] [G loss: 1.222425]\n",
      "[Epoch 3/200] [Batch 136/169] [D loss: 0.465088] [G loss: 1.283248]\n",
      "[Epoch 3/200] [Batch 137/169] [D loss: 0.501123] [G loss: 1.053450]\n",
      "[Epoch 3/200] [Batch 138/169] [D loss: 0.481300] [G loss: 1.202812]\n",
      "[Epoch 3/200] [Batch 139/169] [D loss: 0.471496] [G loss: 1.228425]\n",
      "[Epoch 3/200] [Batch 140/169] [D loss: 0.440782] [G loss: 1.255047]\n",
      "[Epoch 3/200] [Batch 141/169] [D loss: 0.510358] [G loss: 1.401133]\n",
      "[Epoch 3/200] [Batch 142/169] [D loss: 0.496869] [G loss: 1.213023]\n",
      "[Epoch 3/200] [Batch 143/169] [D loss: 0.500355] [G loss: 1.334007]\n",
      "[Epoch 3/200] [Batch 144/169] [D loss: 0.528971] [G loss: 1.127411]\n",
      "[Epoch 3/200] [Batch 145/169] [D loss: 0.553937] [G loss: 1.169755]\n",
      "[Epoch 3/200] [Batch 146/169] [D loss: 0.533764] [G loss: 1.166245]\n",
      "[Epoch 3/200] [Batch 147/169] [D loss: 0.585269] [G loss: 1.322231]\n",
      "[Epoch 3/200] [Batch 148/169] [D loss: 0.610812] [G loss: 1.239991]\n",
      "[Epoch 3/200] [Batch 149/169] [D loss: 0.632002] [G loss: 0.980738]\n",
      "[Epoch 3/200] [Batch 150/169] [D loss: 0.518095] [G loss: 1.047884]\n",
      "[Epoch 3/200] [Batch 151/169] [D loss: 0.601951] [G loss: 1.166132]\n",
      "[Epoch 3/200] [Batch 152/169] [D loss: 0.555836] [G loss: 1.285418]\n",
      "[Epoch 3/200] [Batch 153/169] [D loss: 0.517651] [G loss: 1.020236]\n",
      "[Epoch 3/200] [Batch 154/169] [D loss: 0.594722] [G loss: 1.207254]\n",
      "[Epoch 3/200] [Batch 155/169] [D loss: 0.547565] [G loss: 1.114184]\n",
      "[Epoch 3/200] [Batch 156/169] [D loss: 0.570594] [G loss: 1.247229]\n",
      "[Epoch 3/200] [Batch 157/169] [D loss: 0.462139] [G loss: 1.175152]\n",
      "[Epoch 3/200] [Batch 158/169] [D loss: 0.506109] [G loss: 1.309483]\n",
      "[Epoch 3/200] [Batch 159/169] [D loss: 0.497008] [G loss: 1.230089]\n",
      "[Epoch 3/200] [Batch 160/169] [D loss: 0.473521] [G loss: 1.256974]\n",
      "[Epoch 3/200] [Batch 161/169] [D loss: 0.472541] [G loss: 0.956348]\n",
      "[Epoch 3/200] [Batch 162/169] [D loss: 0.547650] [G loss: 1.371363]\n",
      "[Epoch 3/200] [Batch 163/169] [D loss: 0.562479] [G loss: 1.232420]\n",
      "[Epoch 3/200] [Batch 164/169] [D loss: 0.488769] [G loss: 1.188941]\n",
      "[Epoch 3/200] [Batch 165/169] [D loss: 0.445773] [G loss: 1.150151]\n",
      "[Epoch 3/200] [Batch 166/169] [D loss: 0.470596] [G loss: 1.310736]\n",
      "[Epoch 3/200] [Batch 167/169] [D loss: 0.447496] [G loss: 1.364419]\n",
      "[Epoch 3/200] [Batch 168/169] [D loss: 0.634826] [G loss: 1.159313]\n",
      "[Epoch 4/200] [Batch 0/169] [D loss: 0.499994] [G loss: 1.087998]\n",
      "[Epoch 4/200] [Batch 1/169] [D loss: 0.526810] [G loss: 1.076103]\n",
      "[Epoch 4/200] [Batch 2/169] [D loss: 0.433165] [G loss: 1.089492]\n",
      "[Epoch 4/200] [Batch 3/169] [D loss: 0.482639] [G loss: 1.293576]\n",
      "[Epoch 4/200] [Batch 4/169] [D loss: 0.463867] [G loss: 1.063786]\n",
      "[Epoch 4/200] [Batch 5/169] [D loss: 0.431774] [G loss: 1.342018]\n",
      "[Epoch 4/200] [Batch 6/169] [D loss: 0.468189] [G loss: 0.929650]\n",
      "[Epoch 4/200] [Batch 7/169] [D loss: 0.494557] [G loss: 1.074140]\n",
      "[Epoch 4/200] [Batch 8/169] [D loss: 0.485983] [G loss: 1.023805]\n",
      "[Epoch 4/200] [Batch 9/169] [D loss: 0.460457] [G loss: 1.279870]\n",
      "[Epoch 4/200] [Batch 10/169] [D loss: 0.608340] [G loss: 1.297559]\n",
      "[Epoch 4/200] [Batch 11/169] [D loss: 0.533503] [G loss: 1.000570]\n",
      "[Epoch 4/200] [Batch 12/169] [D loss: 0.509918] [G loss: 1.089452]\n",
      "[Epoch 4/200] [Batch 13/169] [D loss: 0.551599] [G loss: 1.078737]\n",
      "[Epoch 4/200] [Batch 14/169] [D loss: 0.544316] [G loss: 1.064456]\n",
      "[Epoch 4/200] [Batch 15/169] [D loss: 0.478683] [G loss: 1.104513]\n",
      "[Epoch 4/200] [Batch 16/169] [D loss: 0.496396] [G loss: 1.180279]\n",
      "[Epoch 4/200] [Batch 17/169] [D loss: 0.510780] [G loss: 1.167529]\n",
      "[Epoch 4/200] [Batch 18/169] [D loss: 0.630944] [G loss: 1.051001]\n",
      "[Epoch 4/200] [Batch 19/169] [D loss: 0.499584] [G loss: 1.396802]\n",
      "[Epoch 4/200] [Batch 20/169] [D loss: 0.532737] [G loss: 1.144246]\n",
      "[Epoch 4/200] [Batch 21/169] [D loss: 0.519133] [G loss: 1.215451]\n",
      "[Epoch 4/200] [Batch 22/169] [D loss: 0.508299] [G loss: 0.979721]\n",
      "[Epoch 4/200] [Batch 23/169] [D loss: 0.480751] [G loss: 1.017882]\n",
      "[Epoch 4/200] [Batch 24/169] [D loss: 0.530310] [G loss: 1.177198]\n",
      "[Epoch 4/200] [Batch 25/169] [D loss: 0.617781] [G loss: 1.382995]\n",
      "[Epoch 4/200] [Batch 26/169] [D loss: 0.525502] [G loss: 1.088081]\n",
      "[Epoch 4/200] [Batch 27/169] [D loss: 0.495687] [G loss: 1.154505]\n",
      "[Epoch 4/200] [Batch 28/169] [D loss: 0.445264] [G loss: 1.078953]\n",
      "[Epoch 4/200] [Batch 29/169] [D loss: 0.505509] [G loss: 1.118518]\n",
      "[Epoch 4/200] [Batch 30/169] [D loss: 0.516567] [G loss: 1.007272]\n",
      "[Epoch 4/200] [Batch 31/169] [D loss: 0.461783] [G loss: 1.226305]\n",
      "[Epoch 4/200] [Batch 32/169] [D loss: 0.625206] [G loss: 1.007167]\n",
      "[Epoch 4/200] [Batch 33/169] [D loss: 0.591140] [G loss: 0.839105]\n",
      "[Epoch 4/200] [Batch 34/169] [D loss: 0.572192] [G loss: 1.238675]\n",
      "[Epoch 4/200] [Batch 35/169] [D loss: 0.452441] [G loss: 1.096201]\n",
      "[Epoch 4/200] [Batch 36/169] [D loss: 0.475765] [G loss: 1.240163]\n",
      "[Epoch 4/200] [Batch 37/169] [D loss: 0.552539] [G loss: 1.087362]\n",
      "[Epoch 4/200] [Batch 38/169] [D loss: 0.441575] [G loss: 0.955119]\n",
      "[Epoch 4/200] [Batch 39/169] [D loss: 0.432149] [G loss: 1.091386]\n",
      "[Epoch 4/200] [Batch 40/169] [D loss: 0.538332] [G loss: 1.191693]\n",
      "[Epoch 4/200] [Batch 41/169] [D loss: 0.461413] [G loss: 1.198894]\n",
      "[Epoch 4/200] [Batch 42/169] [D loss: 0.427642] [G loss: 1.212315]\n",
      "[Epoch 4/200] [Batch 43/169] [D loss: 0.457198] [G loss: 1.247277]\n",
      "[Epoch 4/200] [Batch 44/169] [D loss: 0.418372] [G loss: 1.136284]\n",
      "[Epoch 4/200] [Batch 45/169] [D loss: 0.431712] [G loss: 1.290937]\n",
      "[Epoch 4/200] [Batch 46/169] [D loss: 0.473227] [G loss: 1.255943]\n",
      "[Epoch 4/200] [Batch 47/169] [D loss: 0.480269] [G loss: 1.115477]\n",
      "[Epoch 4/200] [Batch 48/169] [D loss: 0.502982] [G loss: 1.099755]\n",
      "[Epoch 4/200] [Batch 49/169] [D loss: 0.490600] [G loss: 1.192463]\n",
      "[Epoch 4/200] [Batch 50/169] [D loss: 0.480234] [G loss: 1.339755]\n",
      "[Epoch 4/200] [Batch 51/169] [D loss: 0.548367] [G loss: 1.340384]\n",
      "[Epoch 4/200] [Batch 52/169] [D loss: 0.457432] [G loss: 1.192223]\n",
      "[Epoch 4/200] [Batch 53/169] [D loss: 0.498173] [G loss: 1.224594]\n",
      "[Epoch 4/200] [Batch 54/169] [D loss: 0.523241] [G loss: 1.282847]\n",
      "[Epoch 4/200] [Batch 55/169] [D loss: 0.469054] [G loss: 1.336710]\n",
      "[Epoch 4/200] [Batch 56/169] [D loss: 0.587311] [G loss: 0.932945]\n",
      "[Epoch 4/200] [Batch 57/169] [D loss: 0.448234] [G loss: 1.063811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 58/169] [D loss: 0.539128] [G loss: 1.244151]\n",
      "[Epoch 4/200] [Batch 59/169] [D loss: 0.534512] [G loss: 1.099578]\n",
      "[Epoch 4/200] [Batch 60/169] [D loss: 0.498716] [G loss: 1.115450]\n",
      "[Epoch 4/200] [Batch 61/169] [D loss: 0.553471] [G loss: 1.302114]\n",
      "[Epoch 4/200] [Batch 62/169] [D loss: 0.541769] [G loss: 1.047894]\n",
      "[Epoch 4/200] [Batch 63/169] [D loss: 0.568590] [G loss: 1.225744]\n",
      "[Epoch 4/200] [Batch 64/169] [D loss: 0.517463] [G loss: 1.252741]\n",
      "[Epoch 4/200] [Batch 65/169] [D loss: 0.550910] [G loss: 1.167808]\n",
      "[Epoch 4/200] [Batch 66/169] [D loss: 0.500014] [G loss: 1.109863]\n",
      "[Epoch 4/200] [Batch 67/169] [D loss: 0.661964] [G loss: 0.915780]\n",
      "[Epoch 4/200] [Batch 68/169] [D loss: 0.492070] [G loss: 1.264393]\n",
      "[Epoch 4/200] [Batch 69/169] [D loss: 0.613006] [G loss: 0.931409]\n",
      "[Epoch 4/200] [Batch 70/169] [D loss: 0.532874] [G loss: 0.918586]\n",
      "[Epoch 4/200] [Batch 71/169] [D loss: 0.476623] [G loss: 0.980678]\n",
      "[Epoch 4/200] [Batch 72/169] [D loss: 0.525823] [G loss: 1.202993]\n",
      "[Epoch 4/200] [Batch 73/169] [D loss: 0.486036] [G loss: 1.253637]\n",
      "[Epoch 4/200] [Batch 74/169] [D loss: 0.487643] [G loss: 0.956778]\n",
      "[Epoch 4/200] [Batch 75/169] [D loss: 0.467712] [G loss: 1.123392]\n",
      "[Epoch 4/200] [Batch 76/169] [D loss: 0.603408] [G loss: 1.223477]\n",
      "[Epoch 4/200] [Batch 77/169] [D loss: 0.485922] [G loss: 1.075223]\n",
      "[Epoch 4/200] [Batch 78/169] [D loss: 0.526123] [G loss: 0.976438]\n",
      "[Epoch 4/200] [Batch 79/169] [D loss: 0.526280] [G loss: 1.167349]\n",
      "[Epoch 4/200] [Batch 80/169] [D loss: 0.543285] [G loss: 1.430962]\n",
      "[Epoch 4/200] [Batch 81/169] [D loss: 0.414665] [G loss: 1.008964]\n",
      "[Epoch 4/200] [Batch 82/169] [D loss: 0.435924] [G loss: 1.063950]\n",
      "[Epoch 4/200] [Batch 83/169] [D loss: 0.496919] [G loss: 1.082093]\n",
      "[Epoch 4/200] [Batch 84/169] [D loss: 0.451263] [G loss: 1.237068]\n",
      "[Epoch 4/200] [Batch 85/169] [D loss: 0.487409] [G loss: 1.206552]\n",
      "[Epoch 4/200] [Batch 86/169] [D loss: 0.464297] [G loss: 1.153351]\n",
      "[Epoch 4/200] [Batch 87/169] [D loss: 0.483837] [G loss: 1.079120]\n",
      "[Epoch 4/200] [Batch 88/169] [D loss: 0.546421] [G loss: 1.211274]\n",
      "[Epoch 4/200] [Batch 89/169] [D loss: 0.512520] [G loss: 1.175775]\n",
      "[Epoch 4/200] [Batch 90/169] [D loss: 0.506101] [G loss: 1.217490]\n",
      "[Epoch 4/200] [Batch 91/169] [D loss: 0.380269] [G loss: 1.164921]\n",
      "[Epoch 4/200] [Batch 92/169] [D loss: 0.436598] [G loss: 1.225156]\n",
      "[Epoch 4/200] [Batch 93/169] [D loss: 0.542855] [G loss: 1.087797]\n",
      "[Epoch 4/200] [Batch 94/169] [D loss: 0.467362] [G loss: 0.983351]\n",
      "[Epoch 4/200] [Batch 95/169] [D loss: 0.453975] [G loss: 1.215503]\n",
      "[Epoch 4/200] [Batch 96/169] [D loss: 0.545634] [G loss: 1.482961]\n",
      "[Epoch 4/200] [Batch 97/169] [D loss: 0.474788] [G loss: 1.071029]\n",
      "[Epoch 4/200] [Batch 98/169] [D loss: 0.618663] [G loss: 0.940729]\n",
      "[Epoch 4/200] [Batch 99/169] [D loss: 0.608746] [G loss: 1.338234]\n",
      "[Epoch 4/200] [Batch 100/169] [D loss: 0.592558] [G loss: 1.185955]\n",
      "[Epoch 4/200] [Batch 101/169] [D loss: 0.557031] [G loss: 0.946648]\n",
      "[Epoch 4/200] [Batch 102/169] [D loss: 0.615713] [G loss: 0.952702]\n",
      "[Epoch 4/200] [Batch 103/169] [D loss: 0.479816] [G loss: 1.558951]\n",
      "[Epoch 4/200] [Batch 104/169] [D loss: 0.536295] [G loss: 1.235847]\n",
      "[Epoch 4/200] [Batch 105/169] [D loss: 0.472792] [G loss: 0.943572]\n",
      "[Epoch 4/200] [Batch 106/169] [D loss: 0.623253] [G loss: 1.056679]\n",
      "[Epoch 4/200] [Batch 107/169] [D loss: 0.623111] [G loss: 1.063362]\n",
      "[Epoch 4/200] [Batch 108/169] [D loss: 0.606829] [G loss: 1.072929]\n",
      "[Epoch 4/200] [Batch 109/169] [D loss: 0.641749] [G loss: 1.140988]\n",
      "[Epoch 4/200] [Batch 110/169] [D loss: 0.568843] [G loss: 1.068726]\n",
      "[Epoch 4/200] [Batch 111/169] [D loss: 0.458167] [G loss: 1.061416]\n",
      "[Epoch 4/200] [Batch 112/169] [D loss: 0.631795] [G loss: 1.186441]\n",
      "[Epoch 4/200] [Batch 113/169] [D loss: 0.586463] [G loss: 0.804102]\n",
      "[Epoch 4/200] [Batch 114/169] [D loss: 0.536099] [G loss: 1.015492]\n",
      "[Epoch 4/200] [Batch 115/169] [D loss: 0.556604] [G loss: 1.238348]\n",
      "[Epoch 4/200] [Batch 116/169] [D loss: 0.443092] [G loss: 1.218341]\n",
      "[Epoch 4/200] [Batch 117/169] [D loss: 0.487015] [G loss: 1.117956]\n",
      "[Epoch 4/200] [Batch 118/169] [D loss: 0.574120] [G loss: 1.131087]\n",
      "[Epoch 4/200] [Batch 119/169] [D loss: 0.484744] [G loss: 0.993719]\n",
      "[Epoch 4/200] [Batch 120/169] [D loss: 0.552436] [G loss: 1.066832]\n",
      "[Epoch 4/200] [Batch 121/169] [D loss: 0.514688] [G loss: 0.964182]\n",
      "[Epoch 4/200] [Batch 122/169] [D loss: 0.500387] [G loss: 1.308240]\n",
      "[Epoch 4/200] [Batch 123/169] [D loss: 0.556101] [G loss: 1.413527]\n",
      "[Epoch 4/200] [Batch 124/169] [D loss: 0.454463] [G loss: 1.321876]\n",
      "[Epoch 4/200] [Batch 125/169] [D loss: 0.415210] [G loss: 1.235962]\n",
      "[Epoch 4/200] [Batch 126/169] [D loss: 0.511443] [G loss: 0.990772]\n",
      "[Epoch 4/200] [Batch 127/169] [D loss: 0.517883] [G loss: 1.102810]\n",
      "[Epoch 4/200] [Batch 128/169] [D loss: 0.567116] [G loss: 1.151139]\n",
      "[Epoch 4/200] [Batch 129/169] [D loss: 0.442045] [G loss: 1.185477]\n",
      "[Epoch 4/200] [Batch 130/169] [D loss: 0.497214] [G loss: 1.136543]\n",
      "[Epoch 4/200] [Batch 131/169] [D loss: 0.516400] [G loss: 0.936524]\n",
      "[Epoch 4/200] [Batch 132/169] [D loss: 0.500127] [G loss: 1.010626]\n",
      "[Epoch 4/200] [Batch 133/169] [D loss: 0.551512] [G loss: 1.073158]\n",
      "[Epoch 4/200] [Batch 134/169] [D loss: 0.538250] [G loss: 1.447687]\n",
      "[Epoch 4/200] [Batch 135/169] [D loss: 0.506824] [G loss: 1.098452]\n",
      "[Epoch 4/200] [Batch 136/169] [D loss: 0.534001] [G loss: 0.961701]\n",
      "[Epoch 4/200] [Batch 137/169] [D loss: 0.490796] [G loss: 0.940619]\n",
      "[Epoch 4/200] [Batch 138/169] [D loss: 0.357252] [G loss: 1.035816]\n",
      "[Epoch 4/200] [Batch 139/169] [D loss: 0.528481] [G loss: 1.094652]\n",
      "[Epoch 4/200] [Batch 140/169] [D loss: 0.513451] [G loss: 1.373703]\n",
      "[Epoch 4/200] [Batch 141/169] [D loss: 0.487948] [G loss: 1.460590]\n",
      "[Epoch 4/200] [Batch 142/169] [D loss: 0.519533] [G loss: 1.259062]\n",
      "[Epoch 4/200] [Batch 143/169] [D loss: 0.419139] [G loss: 1.049690]\n",
      "[Epoch 4/200] [Batch 144/169] [D loss: 0.506619] [G loss: 1.062074]\n",
      "[Epoch 4/200] [Batch 145/169] [D loss: 0.472139] [G loss: 1.494087]\n",
      "[Epoch 4/200] [Batch 146/169] [D loss: 0.501255] [G loss: 1.130377]\n",
      "[Epoch 4/200] [Batch 147/169] [D loss: 0.570743] [G loss: 1.160201]\n",
      "[Epoch 4/200] [Batch 148/169] [D loss: 0.575532] [G loss: 0.945813]\n",
      "[Epoch 4/200] [Batch 149/169] [D loss: 0.461047] [G loss: 0.989604]\n",
      "[Epoch 4/200] [Batch 150/169] [D loss: 0.528078] [G loss: 1.168719]\n",
      "[Epoch 4/200] [Batch 151/169] [D loss: 0.552524] [G loss: 1.247571]\n",
      "[Epoch 4/200] [Batch 152/169] [D loss: 0.527370] [G loss: 1.043599]\n",
      "[Epoch 4/200] [Batch 153/169] [D loss: 0.600214] [G loss: 1.040007]\n",
      "[Epoch 4/200] [Batch 154/169] [D loss: 0.484302] [G loss: 1.285805]\n",
      "[Epoch 4/200] [Batch 155/169] [D loss: 0.612920] [G loss: 1.006414]\n",
      "[Epoch 4/200] [Batch 156/169] [D loss: 0.593343] [G loss: 0.907213]\n",
      "[Epoch 4/200] [Batch 157/169] [D loss: 0.551260] [G loss: 1.003584]\n",
      "[Epoch 4/200] [Batch 158/169] [D loss: 0.480312] [G loss: 0.844596]\n",
      "[Epoch 4/200] [Batch 159/169] [D loss: 0.548963] [G loss: 1.173568]\n",
      "[Epoch 4/200] [Batch 160/169] [D loss: 0.490562] [G loss: 0.964621]\n",
      "[Epoch 4/200] [Batch 161/169] [D loss: 0.535267] [G loss: 0.994952]\n",
      "[Epoch 4/200] [Batch 162/169] [D loss: 0.591821] [G loss: 1.209507]\n",
      "[Epoch 4/200] [Batch 163/169] [D loss: 0.574121] [G loss: 1.146121]\n",
      "[Epoch 4/200] [Batch 164/169] [D loss: 0.524958] [G loss: 1.345451]\n",
      "[Epoch 4/200] [Batch 165/169] [D loss: 0.565337] [G loss: 0.866625]\n",
      "[Epoch 4/200] [Batch 166/169] [D loss: 0.592158] [G loss: 1.129515]\n",
      "[Epoch 4/200] [Batch 167/169] [D loss: 0.517167] [G loss: 1.022721]\n",
      "[Epoch 4/200] [Batch 168/169] [D loss: 0.475475] [G loss: 0.935440]\n",
      "[Epoch 5/200] [Batch 0/169] [D loss: 0.527890] [G loss: 1.426816]\n",
      "[Epoch 5/200] [Batch 1/169] [D loss: 0.505952] [G loss: 1.702428]\n",
      "[Epoch 5/200] [Batch 2/169] [D loss: 0.487815] [G loss: 1.221183]\n",
      "[Epoch 5/200] [Batch 3/169] [D loss: 0.457799] [G loss: 1.023676]\n",
      "[Epoch 5/200] [Batch 4/169] [D loss: 0.475431] [G loss: 1.068195]\n",
      "[Epoch 5/200] [Batch 5/169] [D loss: 0.528530] [G loss: 1.418025]\n",
      "[Epoch 5/200] [Batch 6/169] [D loss: 0.416538] [G loss: 1.359740]\n",
      "[Epoch 5/200] [Batch 7/169] [D loss: 0.496686] [G loss: 1.193116]\n",
      "[Epoch 5/200] [Batch 8/169] [D loss: 0.493657] [G loss: 1.027320]\n",
      "[Epoch 5/200] [Batch 9/169] [D loss: 0.454772] [G loss: 1.127511]\n",
      "[Epoch 5/200] [Batch 10/169] [D loss: 0.567186] [G loss: 1.132685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 11/169] [D loss: 0.515554] [G loss: 0.976232]\n",
      "[Epoch 5/200] [Batch 12/169] [D loss: 0.492976] [G loss: 1.070886]\n",
      "[Epoch 5/200] [Batch 13/169] [D loss: 0.525140] [G loss: 1.108992]\n",
      "[Epoch 5/200] [Batch 14/169] [D loss: 0.563352] [G loss: 1.075448]\n",
      "[Epoch 5/200] [Batch 15/169] [D loss: 0.440223] [G loss: 1.106582]\n",
      "[Epoch 5/200] [Batch 16/169] [D loss: 0.544424] [G loss: 0.803810]\n",
      "[Epoch 5/200] [Batch 17/169] [D loss: 0.402540] [G loss: 1.160254]\n",
      "[Epoch 5/200] [Batch 18/169] [D loss: 0.508062] [G loss: 1.262468]\n",
      "[Epoch 5/200] [Batch 19/169] [D loss: 0.505874] [G loss: 0.928613]\n",
      "[Epoch 5/200] [Batch 20/169] [D loss: 0.374075] [G loss: 1.031296]\n",
      "[Epoch 5/200] [Batch 21/169] [D loss: 0.470839] [G loss: 0.986890]\n",
      "[Epoch 5/200] [Batch 22/169] [D loss: 0.584332] [G loss: 0.929138]\n",
      "[Epoch 5/200] [Batch 23/169] [D loss: 0.529709] [G loss: 0.937477]\n",
      "[Epoch 5/200] [Batch 24/169] [D loss: 0.600783] [G loss: 1.059500]\n",
      "[Epoch 5/200] [Batch 25/169] [D loss: 0.479534] [G loss: 1.101477]\n",
      "[Epoch 5/200] [Batch 26/169] [D loss: 0.467895] [G loss: 1.039802]\n",
      "[Epoch 5/200] [Batch 27/169] [D loss: 0.492337] [G loss: 1.251280]\n",
      "[Epoch 5/200] [Batch 28/169] [D loss: 0.477230] [G loss: 1.230605]\n",
      "[Epoch 5/200] [Batch 29/169] [D loss: 0.560689] [G loss: 1.065510]\n",
      "[Epoch 5/200] [Batch 30/169] [D loss: 0.570267] [G loss: 1.160602]\n",
      "[Epoch 5/200] [Batch 31/169] [D loss: 0.506110] [G loss: 1.141819]\n",
      "[Epoch 5/200] [Batch 32/169] [D loss: 0.595395] [G loss: 0.920705]\n",
      "[Epoch 5/200] [Batch 33/169] [D loss: 0.539868] [G loss: 1.140211]\n",
      "[Epoch 5/200] [Batch 34/169] [D loss: 0.541951] [G loss: 1.425169]\n",
      "[Epoch 5/200] [Batch 35/169] [D loss: 0.576706] [G loss: 1.210932]\n",
      "[Epoch 5/200] [Batch 36/169] [D loss: 0.546344] [G loss: 1.098851]\n",
      "[Epoch 5/200] [Batch 37/169] [D loss: 0.548816] [G loss: 1.101292]\n",
      "[Epoch 5/200] [Batch 38/169] [D loss: 0.497912] [G loss: 0.999247]\n",
      "[Epoch 5/200] [Batch 39/169] [D loss: 0.611673] [G loss: 1.060027]\n",
      "[Epoch 5/200] [Batch 40/169] [D loss: 0.597333] [G loss: 1.119020]\n",
      "[Epoch 5/200] [Batch 41/169] [D loss: 0.490989] [G loss: 1.430953]\n",
      "[Epoch 5/200] [Batch 42/169] [D loss: 0.474386] [G loss: 1.153716]\n",
      "[Epoch 5/200] [Batch 43/169] [D loss: 0.475030] [G loss: 1.004142]\n",
      "[Epoch 5/200] [Batch 44/169] [D loss: 0.585648] [G loss: 0.991077]\n",
      "[Epoch 5/200] [Batch 45/169] [D loss: 0.484232] [G loss: 1.143550]\n",
      "[Epoch 5/200] [Batch 46/169] [D loss: 0.525383] [G loss: 1.386266]\n",
      "[Epoch 5/200] [Batch 47/169] [D loss: 0.511630] [G loss: 1.238824]\n",
      "[Epoch 5/200] [Batch 48/169] [D loss: 0.470221] [G loss: 1.000077]\n",
      "[Epoch 5/200] [Batch 49/169] [D loss: 0.498770] [G loss: 1.074296]\n",
      "[Epoch 5/200] [Batch 50/169] [D loss: 0.458044] [G loss: 1.253158]\n",
      "[Epoch 5/200] [Batch 51/169] [D loss: 0.522008] [G loss: 1.204395]\n",
      "[Epoch 5/200] [Batch 52/169] [D loss: 0.554035] [G loss: 0.901319]\n",
      "[Epoch 5/200] [Batch 53/169] [D loss: 0.459292] [G loss: 0.961421]\n",
      "[Epoch 5/200] [Batch 54/169] [D loss: 0.520147] [G loss: 1.235777]\n",
      "[Epoch 5/200] [Batch 55/169] [D loss: 0.477590] [G loss: 1.076552]\n",
      "[Epoch 5/200] [Batch 56/169] [D loss: 0.562964] [G loss: 1.051043]\n",
      "[Epoch 5/200] [Batch 57/169] [D loss: 0.581683] [G loss: 1.257766]\n",
      "[Epoch 5/200] [Batch 58/169] [D loss: 0.498475] [G loss: 1.149214]\n",
      "[Epoch 5/200] [Batch 59/169] [D loss: 0.568614] [G loss: 1.170619]\n",
      "[Epoch 5/200] [Batch 60/169] [D loss: 0.476252] [G loss: 1.144211]\n",
      "[Epoch 5/200] [Batch 61/169] [D loss: 0.565789] [G loss: 1.084858]\n",
      "[Epoch 5/200] [Batch 62/169] [D loss: 0.512874] [G loss: 1.063556]\n",
      "[Epoch 5/200] [Batch 63/169] [D loss: 0.545657] [G loss: 1.252701]\n",
      "[Epoch 5/200] [Batch 64/169] [D loss: 0.516050] [G loss: 1.115725]\n",
      "[Epoch 5/200] [Batch 65/169] [D loss: 0.497990] [G loss: 0.913234]\n",
      "[Epoch 5/200] [Batch 66/169] [D loss: 0.539069] [G loss: 1.172704]\n",
      "[Epoch 5/200] [Batch 67/169] [D loss: 0.567220] [G loss: 1.139397]\n",
      "[Epoch 5/200] [Batch 68/169] [D loss: 0.606149] [G loss: 1.482393]\n",
      "[Epoch 5/200] [Batch 69/169] [D loss: 0.504773] [G loss: 1.009139]\n",
      "[Epoch 5/200] [Batch 70/169] [D loss: 0.513292] [G loss: 1.088549]\n",
      "[Epoch 5/200] [Batch 71/169] [D loss: 0.539946] [G loss: 0.976256]\n",
      "[Epoch 5/200] [Batch 72/169] [D loss: 0.563655] [G loss: 1.092313]\n",
      "[Epoch 5/200] [Batch 73/169] [D loss: 0.527895] [G loss: 1.153051]\n",
      "[Epoch 5/200] [Batch 74/169] [D loss: 0.613787] [G loss: 1.235006]\n",
      "[Epoch 5/200] [Batch 75/169] [D loss: 0.597945] [G loss: 0.948608]\n",
      "[Epoch 5/200] [Batch 76/169] [D loss: 0.675199] [G loss: 1.097861]\n",
      "[Epoch 5/200] [Batch 77/169] [D loss: 0.520599] [G loss: 1.072623]\n",
      "[Epoch 5/200] [Batch 78/169] [D loss: 0.591727] [G loss: 1.166111]\n",
      "[Epoch 5/200] [Batch 79/169] [D loss: 0.538710] [G loss: 0.934797]\n",
      "[Epoch 5/200] [Batch 80/169] [D loss: 0.584171] [G loss: 0.803608]\n",
      "[Epoch 5/200] [Batch 81/169] [D loss: 0.560151] [G loss: 0.969514]\n",
      "[Epoch 5/200] [Batch 82/169] [D loss: 0.678977] [G loss: 0.829681]\n",
      "[Epoch 5/200] [Batch 83/169] [D loss: 0.631534] [G loss: 1.174641]\n",
      "[Epoch 5/200] [Batch 84/169] [D loss: 0.577991] [G loss: 1.433820]\n",
      "[Epoch 5/200] [Batch 85/169] [D loss: 0.516095] [G loss: 0.990178]\n",
      "[Epoch 5/200] [Batch 86/169] [D loss: 0.538203] [G loss: 0.879930]\n",
      "[Epoch 5/200] [Batch 87/169] [D loss: 0.555751] [G loss: 1.183812]\n",
      "[Epoch 5/200] [Batch 88/169] [D loss: 0.544459] [G loss: 0.899238]\n",
      "[Epoch 5/200] [Batch 89/169] [D loss: 0.486426] [G loss: 1.261711]\n",
      "[Epoch 5/200] [Batch 90/169] [D loss: 0.487703] [G loss: 1.219038]\n",
      "[Epoch 5/200] [Batch 91/169] [D loss: 0.516833] [G loss: 0.903384]\n",
      "[Epoch 5/200] [Batch 92/169] [D loss: 0.524045] [G loss: 0.849601]\n",
      "[Epoch 5/200] [Batch 93/169] [D loss: 0.547489] [G loss: 1.256905]\n",
      "[Epoch 5/200] [Batch 94/169] [D loss: 0.563623] [G loss: 1.422813]\n",
      "[Epoch 5/200] [Batch 95/169] [D loss: 0.552024] [G loss: 1.353625]\n",
      "[Epoch 5/200] [Batch 96/169] [D loss: 0.560910] [G loss: 0.899926]\n",
      "[Epoch 5/200] [Batch 97/169] [D loss: 0.459048] [G loss: 0.922167]\n",
      "[Epoch 5/200] [Batch 98/169] [D loss: 0.480767] [G loss: 1.217086]\n",
      "[Epoch 5/200] [Batch 99/169] [D loss: 0.483216] [G loss: 1.081856]\n",
      "[Epoch 5/200] [Batch 100/169] [D loss: 0.468666] [G loss: 1.038574]\n",
      "[Epoch 5/200] [Batch 101/169] [D loss: 0.520644] [G loss: 1.020419]\n",
      "[Epoch 5/200] [Batch 102/169] [D loss: 0.487668] [G loss: 1.437020]\n",
      "[Epoch 5/200] [Batch 103/169] [D loss: 0.534915] [G loss: 1.063023]\n",
      "[Epoch 5/200] [Batch 104/169] [D loss: 0.575599] [G loss: 1.077167]\n",
      "[Epoch 5/200] [Batch 105/169] [D loss: 0.482069] [G loss: 1.116012]\n",
      "[Epoch 5/200] [Batch 106/169] [D loss: 0.608861] [G loss: 0.996910]\n",
      "[Epoch 5/200] [Batch 107/169] [D loss: 0.545902] [G loss: 0.919392]\n",
      "[Epoch 5/200] [Batch 108/169] [D loss: 0.485307] [G loss: 1.003224]\n",
      "[Epoch 5/200] [Batch 109/169] [D loss: 0.582522] [G loss: 1.055362]\n",
      "[Epoch 5/200] [Batch 110/169] [D loss: 0.577572] [G loss: 0.994501]\n",
      "[Epoch 5/200] [Batch 111/169] [D loss: 0.488543] [G loss: 1.028303]\n",
      "[Epoch 5/200] [Batch 112/169] [D loss: 0.527137] [G loss: 1.234435]\n",
      "[Epoch 5/200] [Batch 113/169] [D loss: 0.516337] [G loss: 1.173278]\n",
      "[Epoch 5/200] [Batch 114/169] [D loss: 0.460124] [G loss: 1.141415]\n",
      "[Epoch 5/200] [Batch 115/169] [D loss: 0.514269] [G loss: 1.004402]\n",
      "[Epoch 5/200] [Batch 116/169] [D loss: 0.437858] [G loss: 1.099387]\n",
      "[Epoch 5/200] [Batch 117/169] [D loss: 0.491211] [G loss: 1.146633]\n",
      "[Epoch 5/200] [Batch 118/169] [D loss: 0.597958] [G loss: 1.069191]\n",
      "[Epoch 5/200] [Batch 119/169] [D loss: 0.651222] [G loss: 0.996792]\n",
      "[Epoch 5/200] [Batch 120/169] [D loss: 0.571768] [G loss: 1.127558]\n",
      "[Epoch 5/200] [Batch 121/169] [D loss: 0.527458] [G loss: 1.093716]\n",
      "[Epoch 5/200] [Batch 122/169] [D loss: 0.501384] [G loss: 1.276530]\n",
      "[Epoch 5/200] [Batch 123/169] [D loss: 0.516454] [G loss: 1.125768]\n",
      "[Epoch 5/200] [Batch 124/169] [D loss: 0.532186] [G loss: 0.987882]\n",
      "[Epoch 5/200] [Batch 125/169] [D loss: 0.538084] [G loss: 1.028125]\n",
      "[Epoch 5/200] [Batch 126/169] [D loss: 0.543495] [G loss: 1.097090]\n",
      "[Epoch 5/200] [Batch 127/169] [D loss: 0.539452] [G loss: 1.423149]\n",
      "[Epoch 5/200] [Batch 128/169] [D loss: 0.553493] [G loss: 1.077236]\n",
      "[Epoch 5/200] [Batch 129/169] [D loss: 0.481373] [G loss: 1.220705]\n",
      "[Epoch 5/200] [Batch 130/169] [D loss: 0.514758] [G loss: 1.117709]\n",
      "[Epoch 5/200] [Batch 131/169] [D loss: 0.529210] [G loss: 0.843292]\n",
      "[Epoch 5/200] [Batch 132/169] [D loss: 0.616745] [G loss: 1.042034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 133/169] [D loss: 0.557061] [G loss: 1.312245]\n",
      "[Epoch 5/200] [Batch 134/169] [D loss: 0.566412] [G loss: 0.891496]\n",
      "[Epoch 5/200] [Batch 135/169] [D loss: 0.628347] [G loss: 1.077357]\n",
      "[Epoch 5/200] [Batch 136/169] [D loss: 0.508889] [G loss: 1.034709]\n",
      "[Epoch 5/200] [Batch 137/169] [D loss: 0.558472] [G loss: 1.207006]\n",
      "[Epoch 5/200] [Batch 138/169] [D loss: 0.589467] [G loss: 0.850082]\n",
      "[Epoch 5/200] [Batch 139/169] [D loss: 0.629472] [G loss: 1.165346]\n",
      "[Epoch 5/200] [Batch 140/169] [D loss: 0.562288] [G loss: 1.116742]\n",
      "[Epoch 5/200] [Batch 141/169] [D loss: 0.564495] [G loss: 1.159724]\n",
      "[Epoch 5/200] [Batch 142/169] [D loss: 0.579273] [G loss: 0.947655]\n",
      "[Epoch 5/200] [Batch 143/169] [D loss: 0.642846] [G loss: 1.107258]\n",
      "[Epoch 5/200] [Batch 144/169] [D loss: 0.589205] [G loss: 1.201308]\n",
      "[Epoch 5/200] [Batch 145/169] [D loss: 0.574496] [G loss: 1.367324]\n",
      "[Epoch 5/200] [Batch 146/169] [D loss: 0.490565] [G loss: 1.261532]\n",
      "[Epoch 5/200] [Batch 147/169] [D loss: 0.575606] [G loss: 1.171496]\n",
      "[Epoch 5/200] [Batch 148/169] [D loss: 0.480090] [G loss: 0.909759]\n",
      "[Epoch 5/200] [Batch 149/169] [D loss: 0.498503] [G loss: 0.927498]\n",
      "[Epoch 5/200] [Batch 150/169] [D loss: 0.614869] [G loss: 1.099344]\n",
      "[Epoch 5/200] [Batch 151/169] [D loss: 0.573465] [G loss: 1.158356]\n",
      "[Epoch 5/200] [Batch 152/169] [D loss: 0.546630] [G loss: 1.136062]\n",
      "[Epoch 5/200] [Batch 153/169] [D loss: 0.546017] [G loss: 1.188249]\n",
      "[Epoch 5/200] [Batch 154/169] [D loss: 0.592583] [G loss: 0.918377]\n",
      "[Epoch 5/200] [Batch 155/169] [D loss: 0.502465] [G loss: 1.149801]\n",
      "[Epoch 5/200] [Batch 156/169] [D loss: 0.545628] [G loss: 1.262648]\n",
      "[Epoch 5/200] [Batch 157/169] [D loss: 0.517820] [G loss: 1.181294]\n",
      "[Epoch 5/200] [Batch 158/169] [D loss: 0.524590] [G loss: 1.137464]\n",
      "[Epoch 5/200] [Batch 159/169] [D loss: 0.548881] [G loss: 1.148889]\n",
      "[Epoch 5/200] [Batch 160/169] [D loss: 0.542344] [G loss: 1.060535]\n",
      "[Epoch 5/200] [Batch 161/169] [D loss: 0.511870] [G loss: 0.921714]\n",
      "[Epoch 5/200] [Batch 162/169] [D loss: 0.494019] [G loss: 1.046602]\n",
      "[Epoch 5/200] [Batch 163/169] [D loss: 0.644647] [G loss: 1.065314]\n",
      "[Epoch 5/200] [Batch 164/169] [D loss: 0.536149] [G loss: 0.984008]\n",
      "[Epoch 5/200] [Batch 165/169] [D loss: 0.576660] [G loss: 1.009638]\n",
      "[Epoch 5/200] [Batch 166/169] [D loss: 0.575006] [G loss: 1.056475]\n",
      "[Epoch 5/200] [Batch 167/169] [D loss: 0.572383] [G loss: 0.979029]\n",
      "[Epoch 5/200] [Batch 168/169] [D loss: 0.497761] [G loss: 1.122500]\n",
      "[Epoch 6/200] [Batch 0/169] [D loss: 0.503192] [G loss: 0.979797]\n",
      "[Epoch 6/200] [Batch 1/169] [D loss: 0.599941] [G loss: 1.197790]\n",
      "[Epoch 6/200] [Batch 2/169] [D loss: 0.541923] [G loss: 1.147333]\n",
      "[Epoch 6/200] [Batch 3/169] [D loss: 0.484124] [G loss: 1.057220]\n",
      "[Epoch 6/200] [Batch 4/169] [D loss: 0.561543] [G loss: 1.016792]\n",
      "[Epoch 6/200] [Batch 5/169] [D loss: 0.584143] [G loss: 0.968902]\n",
      "[Epoch 6/200] [Batch 6/169] [D loss: 0.531698] [G loss: 1.286412]\n",
      "[Epoch 6/200] [Batch 7/169] [D loss: 0.534771] [G loss: 1.339856]\n",
      "[Epoch 6/200] [Batch 8/169] [D loss: 0.542683] [G loss: 0.900025]\n",
      "[Epoch 6/200] [Batch 9/169] [D loss: 0.580797] [G loss: 1.033282]\n",
      "[Epoch 6/200] [Batch 10/169] [D loss: 0.519172] [G loss: 1.090186]\n",
      "[Epoch 6/200] [Batch 11/169] [D loss: 0.603313] [G loss: 1.161497]\n",
      "[Epoch 6/200] [Batch 12/169] [D loss: 0.538308] [G loss: 1.089826]\n",
      "[Epoch 6/200] [Batch 13/169] [D loss: 0.511573] [G loss: 0.836429]\n",
      "[Epoch 6/200] [Batch 14/169] [D loss: 0.658162] [G loss: 1.061667]\n",
      "[Epoch 6/200] [Batch 15/169] [D loss: 0.520444] [G loss: 1.362679]\n",
      "[Epoch 6/200] [Batch 16/169] [D loss: 0.575939] [G loss: 1.071990]\n",
      "[Epoch 6/200] [Batch 17/169] [D loss: 0.597692] [G loss: 1.120442]\n",
      "[Epoch 6/200] [Batch 18/169] [D loss: 0.582882] [G loss: 0.955827]\n",
      "[Epoch 6/200] [Batch 19/169] [D loss: 0.597375] [G loss: 1.064705]\n",
      "[Epoch 6/200] [Batch 20/169] [D loss: 0.598628] [G loss: 0.872562]\n",
      "[Epoch 6/200] [Batch 21/169] [D loss: 0.537919] [G loss: 1.333019]\n",
      "[Epoch 6/200] [Batch 22/169] [D loss: 0.494520] [G loss: 1.530455]\n",
      "[Epoch 6/200] [Batch 23/169] [D loss: 0.445339] [G loss: 1.148042]\n",
      "[Epoch 6/200] [Batch 24/169] [D loss: 0.441897] [G loss: 1.037498]\n",
      "[Epoch 6/200] [Batch 25/169] [D loss: 0.501802] [G loss: 0.992429]\n",
      "[Epoch 6/200] [Batch 26/169] [D loss: 0.485581] [G loss: 1.168186]\n",
      "[Epoch 6/200] [Batch 27/169] [D loss: 0.515587] [G loss: 0.828443]\n",
      "[Epoch 6/200] [Batch 28/169] [D loss: 0.522542] [G loss: 1.275264]\n",
      "[Epoch 6/200] [Batch 29/169] [D loss: 0.555774] [G loss: 0.971618]\n",
      "[Epoch 6/200] [Batch 30/169] [D loss: 0.580649] [G loss: 1.003435]\n",
      "[Epoch 6/200] [Batch 31/169] [D loss: 0.609587] [G loss: 1.098344]\n",
      "[Epoch 6/200] [Batch 32/169] [D loss: 0.531301] [G loss: 1.076300]\n",
      "[Epoch 6/200] [Batch 33/169] [D loss: 0.560623] [G loss: 0.865140]\n",
      "[Epoch 6/200] [Batch 34/169] [D loss: 0.555900] [G loss: 1.120454]\n",
      "[Epoch 6/200] [Batch 35/169] [D loss: 0.671050] [G loss: 1.084655]\n",
      "[Epoch 6/200] [Batch 36/169] [D loss: 0.644758] [G loss: 1.290311]\n",
      "[Epoch 6/200] [Batch 37/169] [D loss: 0.595045] [G loss: 1.028883]\n",
      "[Epoch 6/200] [Batch 38/169] [D loss: 0.651670] [G loss: 0.967853]\n",
      "[Epoch 6/200] [Batch 39/169] [D loss: 0.647971] [G loss: 1.098194]\n",
      "[Epoch 6/200] [Batch 40/169] [D loss: 0.538981] [G loss: 1.047740]\n",
      "[Epoch 6/200] [Batch 41/169] [D loss: 0.603538] [G loss: 1.082384]\n",
      "[Epoch 6/200] [Batch 42/169] [D loss: 0.548011] [G loss: 1.021119]\n",
      "[Epoch 6/200] [Batch 43/169] [D loss: 0.609367] [G loss: 0.995768]\n",
      "[Epoch 6/200] [Batch 44/169] [D loss: 0.508875] [G loss: 1.179118]\n",
      "[Epoch 6/200] [Batch 45/169] [D loss: 0.690159] [G loss: 1.139282]\n",
      "[Epoch 6/200] [Batch 46/169] [D loss: 0.576033] [G loss: 1.018734]\n",
      "[Epoch 6/200] [Batch 47/169] [D loss: 0.555273] [G loss: 1.129336]\n",
      "[Epoch 6/200] [Batch 48/169] [D loss: 0.531791] [G loss: 1.054895]\n",
      "[Epoch 6/200] [Batch 49/169] [D loss: 0.502704] [G loss: 1.074213]\n",
      "[Epoch 6/200] [Batch 50/169] [D loss: 0.697182] [G loss: 1.242695]\n",
      "[Epoch 6/200] [Batch 51/169] [D loss: 0.509239] [G loss: 1.030064]\n",
      "[Epoch 6/200] [Batch 52/169] [D loss: 0.580067] [G loss: 1.094921]\n",
      "[Epoch 6/200] [Batch 53/169] [D loss: 0.543136] [G loss: 1.177077]\n",
      "[Epoch 6/200] [Batch 54/169] [D loss: 0.586136] [G loss: 1.049728]\n",
      "[Epoch 6/200] [Batch 55/169] [D loss: 0.549641] [G loss: 1.188926]\n",
      "[Epoch 6/200] [Batch 56/169] [D loss: 0.583099] [G loss: 0.961945]\n",
      "[Epoch 6/200] [Batch 57/169] [D loss: 0.546605] [G loss: 1.199983]\n",
      "[Epoch 6/200] [Batch 58/169] [D loss: 0.583839] [G loss: 1.140857]\n",
      "[Epoch 6/200] [Batch 59/169] [D loss: 0.551260] [G loss: 1.080161]\n",
      "[Epoch 6/200] [Batch 60/169] [D loss: 0.553592] [G loss: 1.134163]\n",
      "[Epoch 6/200] [Batch 61/169] [D loss: 0.609153] [G loss: 0.958715]\n",
      "[Epoch 6/200] [Batch 62/169] [D loss: 0.564063] [G loss: 0.968958]\n",
      "[Epoch 6/200] [Batch 63/169] [D loss: 0.487413] [G loss: 1.007067]\n",
      "[Epoch 6/200] [Batch 64/169] [D loss: 0.510004] [G loss: 0.766332]\n",
      "[Epoch 6/200] [Batch 65/169] [D loss: 0.557992] [G loss: 1.118625]\n",
      "[Epoch 6/200] [Batch 66/169] [D loss: 0.539972] [G loss: 0.934852]\n",
      "[Epoch 6/200] [Batch 67/169] [D loss: 0.441295] [G loss: 1.215147]\n",
      "[Epoch 6/200] [Batch 68/169] [D loss: 0.587476] [G loss: 1.099766]\n",
      "[Epoch 6/200] [Batch 69/169] [D loss: 0.489750] [G loss: 1.089928]\n",
      "[Epoch 6/200] [Batch 70/169] [D loss: 0.514267] [G loss: 1.186617]\n",
      "[Epoch 6/200] [Batch 71/169] [D loss: 0.657616] [G loss: 1.089671]\n",
      "[Epoch 6/200] [Batch 72/169] [D loss: 0.547525] [G loss: 0.918217]\n",
      "[Epoch 6/200] [Batch 73/169] [D loss: 0.568227] [G loss: 0.953957]\n",
      "[Epoch 6/200] [Batch 74/169] [D loss: 0.668420] [G loss: 1.085068]\n",
      "[Epoch 6/200] [Batch 75/169] [D loss: 0.525079] [G loss: 1.108442]\n",
      "[Epoch 6/200] [Batch 76/169] [D loss: 0.548753] [G loss: 0.854228]\n",
      "[Epoch 6/200] [Batch 77/169] [D loss: 0.533478] [G loss: 1.001968]\n",
      "[Epoch 6/200] [Batch 78/169] [D loss: 0.604883] [G loss: 1.278040]\n",
      "[Epoch 6/200] [Batch 79/169] [D loss: 0.510698] [G loss: 0.972255]\n",
      "[Epoch 6/200] [Batch 80/169] [D loss: 0.500650] [G loss: 1.073466]\n",
      "[Epoch 6/200] [Batch 81/169] [D loss: 0.577918] [G loss: 1.313462]\n",
      "[Epoch 6/200] [Batch 82/169] [D loss: 0.503421] [G loss: 1.307784]\n",
      "[Epoch 6/200] [Batch 83/169] [D loss: 0.544932] [G loss: 1.184392]\n",
      "[Epoch 6/200] [Batch 84/169] [D loss: 0.601570] [G loss: 1.089173]\n",
      "[Epoch 6/200] [Batch 85/169] [D loss: 0.524744] [G loss: 1.302262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 86/169] [D loss: 0.517569] [G loss: 1.201418]\n",
      "[Epoch 6/200] [Batch 87/169] [D loss: 0.604873] [G loss: 1.145400]\n",
      "[Epoch 6/200] [Batch 88/169] [D loss: 0.539390] [G loss: 1.086318]\n",
      "[Epoch 6/200] [Batch 89/169] [D loss: 0.585996] [G loss: 1.028402]\n",
      "[Epoch 6/200] [Batch 90/169] [D loss: 0.562434] [G loss: 1.002144]\n",
      "[Epoch 6/200] [Batch 91/169] [D loss: 0.499477] [G loss: 0.979613]\n",
      "[Epoch 6/200] [Batch 92/169] [D loss: 0.549292] [G loss: 1.220474]\n",
      "[Epoch 6/200] [Batch 93/169] [D loss: 0.600547] [G loss: 1.006924]\n",
      "[Epoch 6/200] [Batch 94/169] [D loss: 0.575876] [G loss: 1.229714]\n",
      "[Epoch 6/200] [Batch 95/169] [D loss: 0.573150] [G loss: 1.053826]\n",
      "[Epoch 6/200] [Batch 96/169] [D loss: 0.560387] [G loss: 1.114047]\n",
      "[Epoch 6/200] [Batch 97/169] [D loss: 0.497952] [G loss: 1.109315]\n",
      "[Epoch 6/200] [Batch 98/169] [D loss: 0.488019] [G loss: 0.952801]\n",
      "[Epoch 6/200] [Batch 99/169] [D loss: 0.648193] [G loss: 1.037969]\n",
      "[Epoch 6/200] [Batch 100/169] [D loss: 0.607873] [G loss: 1.144489]\n",
      "[Epoch 6/200] [Batch 101/169] [D loss: 0.590016] [G loss: 0.972214]\n",
      "[Epoch 6/200] [Batch 102/169] [D loss: 0.555467] [G loss: 1.191486]\n",
      "[Epoch 6/200] [Batch 103/169] [D loss: 0.567408] [G loss: 0.975924]\n",
      "[Epoch 6/200] [Batch 104/169] [D loss: 0.552554] [G loss: 0.992985]\n",
      "[Epoch 6/200] [Batch 105/169] [D loss: 0.463039] [G loss: 1.047775]\n",
      "[Epoch 6/200] [Batch 106/169] [D loss: 0.553432] [G loss: 1.085880]\n",
      "[Epoch 6/200] [Batch 107/169] [D loss: 0.551619] [G loss: 1.024444]\n",
      "[Epoch 6/200] [Batch 108/169] [D loss: 0.492945] [G loss: 0.874702]\n",
      "[Epoch 6/200] [Batch 109/169] [D loss: 0.508231] [G loss: 0.847055]\n",
      "[Epoch 6/200] [Batch 110/169] [D loss: 0.650371] [G loss: 0.977715]\n",
      "[Epoch 6/200] [Batch 111/169] [D loss: 0.565292] [G loss: 0.932581]\n",
      "[Epoch 6/200] [Batch 112/169] [D loss: 0.499438] [G loss: 1.046689]\n",
      "[Epoch 6/200] [Batch 113/169] [D loss: 0.551855] [G loss: 1.109308]\n",
      "[Epoch 6/200] [Batch 114/169] [D loss: 0.567103] [G loss: 1.053353]\n",
      "[Epoch 6/200] [Batch 115/169] [D loss: 0.619000] [G loss: 0.841814]\n",
      "[Epoch 6/200] [Batch 116/169] [D loss: 0.531612] [G loss: 1.096266]\n",
      "[Epoch 6/200] [Batch 117/169] [D loss: 0.559394] [G loss: 0.985416]\n",
      "[Epoch 6/200] [Batch 118/169] [D loss: 0.567339] [G loss: 1.138330]\n",
      "[Epoch 6/200] [Batch 119/169] [D loss: 0.614649] [G loss: 0.861540]\n",
      "[Epoch 6/200] [Batch 120/169] [D loss: 0.594587] [G loss: 0.979631]\n",
      "[Epoch 6/200] [Batch 121/169] [D loss: 0.637801] [G loss: 1.036873]\n",
      "[Epoch 6/200] [Batch 122/169] [D loss: 0.586757] [G loss: 1.266410]\n",
      "[Epoch 6/200] [Batch 123/169] [D loss: 0.547691] [G loss: 0.879142]\n",
      "[Epoch 6/200] [Batch 124/169] [D loss: 0.577878] [G loss: 1.022821]\n",
      "[Epoch 6/200] [Batch 125/169] [D loss: 0.630220] [G loss: 0.928224]\n",
      "[Epoch 6/200] [Batch 126/169] [D loss: 0.504469] [G loss: 0.921478]\n",
      "[Epoch 6/200] [Batch 127/169] [D loss: 0.575270] [G loss: 1.337760]\n",
      "[Epoch 6/200] [Batch 128/169] [D loss: 0.573216] [G loss: 1.273506]\n",
      "[Epoch 6/200] [Batch 129/169] [D loss: 0.556908] [G loss: 1.083049]\n",
      "[Epoch 6/200] [Batch 130/169] [D loss: 0.553721] [G loss: 0.908522]\n",
      "[Epoch 6/200] [Batch 131/169] [D loss: 0.500278] [G loss: 0.886269]\n",
      "[Epoch 6/200] [Batch 132/169] [D loss: 0.567593] [G loss: 1.028502]\n",
      "[Epoch 6/200] [Batch 133/169] [D loss: 0.584994] [G loss: 1.117544]\n",
      "[Epoch 6/200] [Batch 134/169] [D loss: 0.489875] [G loss: 1.008035]\n",
      "[Epoch 6/200] [Batch 135/169] [D loss: 0.478784] [G loss: 1.357217]\n",
      "[Epoch 6/200] [Batch 136/169] [D loss: 0.480987] [G loss: 0.995756]\n",
      "[Epoch 6/200] [Batch 137/169] [D loss: 0.592624] [G loss: 1.139643]\n",
      "[Epoch 6/200] [Batch 138/169] [D loss: 0.547028] [G loss: 1.296829]\n",
      "[Epoch 6/200] [Batch 139/169] [D loss: 0.556334] [G loss: 1.065350]\n",
      "[Epoch 6/200] [Batch 140/169] [D loss: 0.458366] [G loss: 1.152831]\n",
      "[Epoch 6/200] [Batch 141/169] [D loss: 0.497044] [G loss: 1.052513]\n",
      "[Epoch 6/200] [Batch 142/169] [D loss: 0.572931] [G loss: 0.961784]\n",
      "[Epoch 6/200] [Batch 143/169] [D loss: 0.518063] [G loss: 0.983160]\n",
      "[Epoch 6/200] [Batch 144/169] [D loss: 0.587415] [G loss: 0.662760]\n",
      "[Epoch 6/200] [Batch 145/169] [D loss: 0.513428] [G loss: 0.846965]\n",
      "[Epoch 6/200] [Batch 146/169] [D loss: 0.536341] [G loss: 1.001527]\n",
      "[Epoch 6/200] [Batch 147/169] [D loss: 0.508956] [G loss: 1.095352]\n",
      "[Epoch 6/200] [Batch 148/169] [D loss: 0.569305] [G loss: 0.987324]\n",
      "[Epoch 6/200] [Batch 149/169] [D loss: 0.545743] [G loss: 1.032760]\n",
      "[Epoch 6/200] [Batch 150/169] [D loss: 0.522918] [G loss: 0.966390]\n",
      "[Epoch 6/200] [Batch 151/169] [D loss: 0.582809] [G loss: 1.018119]\n",
      "[Epoch 6/200] [Batch 152/169] [D loss: 0.578279] [G loss: 1.151347]\n",
      "[Epoch 6/200] [Batch 153/169] [D loss: 0.562905] [G loss: 1.002075]\n",
      "[Epoch 6/200] [Batch 154/169] [D loss: 0.601249] [G loss: 0.909791]\n",
      "[Epoch 6/200] [Batch 155/169] [D loss: 0.624773] [G loss: 0.968017]\n",
      "[Epoch 6/200] [Batch 156/169] [D loss: 0.521401] [G loss: 1.176184]\n",
      "[Epoch 6/200] [Batch 157/169] [D loss: 0.616879] [G loss: 1.054360]\n",
      "[Epoch 6/200] [Batch 158/169] [D loss: 0.558445] [G loss: 1.066946]\n",
      "[Epoch 6/200] [Batch 159/169] [D loss: 0.521831] [G loss: 0.845045]\n",
      "[Epoch 6/200] [Batch 160/169] [D loss: 0.560993] [G loss: 0.886449]\n",
      "[Epoch 6/200] [Batch 161/169] [D loss: 0.524346] [G loss: 1.081240]\n",
      "[Epoch 6/200] [Batch 162/169] [D loss: 0.569021] [G loss: 1.029183]\n",
      "[Epoch 6/200] [Batch 163/169] [D loss: 0.570945] [G loss: 0.741395]\n",
      "[Epoch 6/200] [Batch 164/169] [D loss: 0.533083] [G loss: 1.264196]\n",
      "[Epoch 6/200] [Batch 165/169] [D loss: 0.579488] [G loss: 1.222750]\n",
      "[Epoch 6/200] [Batch 166/169] [D loss: 0.561525] [G loss: 1.243582]\n",
      "[Epoch 6/200] [Batch 167/169] [D loss: 0.518694] [G loss: 0.958941]\n",
      "[Epoch 6/200] [Batch 168/169] [D loss: 0.599272] [G loss: 0.864678]\n",
      "[Epoch 7/200] [Batch 0/169] [D loss: 0.557257] [G loss: 0.773375]\n",
      "[Epoch 7/200] [Batch 1/169] [D loss: 0.577051] [G loss: 1.109454]\n",
      "[Epoch 7/200] [Batch 2/169] [D loss: 0.575508] [G loss: 1.147085]\n",
      "[Epoch 7/200] [Batch 3/169] [D loss: 0.593287] [G loss: 1.076576]\n",
      "[Epoch 7/200] [Batch 4/169] [D loss: 0.527710] [G loss: 0.920480]\n",
      "[Epoch 7/200] [Batch 5/169] [D loss: 0.612664] [G loss: 1.030842]\n",
      "[Epoch 7/200] [Batch 6/169] [D loss: 0.576507] [G loss: 1.212542]\n",
      "[Epoch 7/200] [Batch 7/169] [D loss: 0.546982] [G loss: 0.984974]\n",
      "[Epoch 7/200] [Batch 8/169] [D loss: 0.537303] [G loss: 0.888516]\n",
      "[Epoch 7/200] [Batch 9/169] [D loss: 0.566932] [G loss: 0.877980]\n",
      "[Epoch 7/200] [Batch 10/169] [D loss: 0.624896] [G loss: 0.840614]\n",
      "[Epoch 7/200] [Batch 11/169] [D loss: 0.453210] [G loss: 0.912970]\n",
      "[Epoch 7/200] [Batch 12/169] [D loss: 0.527948] [G loss: 1.255782]\n",
      "[Epoch 7/200] [Batch 13/169] [D loss: 0.593846] [G loss: 1.183003]\n",
      "[Epoch 7/200] [Batch 14/169] [D loss: 0.548963] [G loss: 1.162049]\n",
      "[Epoch 7/200] [Batch 15/169] [D loss: 0.494765] [G loss: 0.914366]\n",
      "[Epoch 7/200] [Batch 16/169] [D loss: 0.552651] [G loss: 0.894471]\n",
      "[Epoch 7/200] [Batch 17/169] [D loss: 0.607262] [G loss: 0.951872]\n",
      "[Epoch 7/200] [Batch 18/169] [D loss: 0.561914] [G loss: 1.064131]\n",
      "[Epoch 7/200] [Batch 19/169] [D loss: 0.448113] [G loss: 1.034635]\n",
      "[Epoch 7/200] [Batch 20/169] [D loss: 0.509834] [G loss: 0.981366]\n",
      "[Epoch 7/200] [Batch 21/169] [D loss: 0.604225] [G loss: 1.098719]\n",
      "[Epoch 7/200] [Batch 22/169] [D loss: 0.526804] [G loss: 1.073943]\n",
      "[Epoch 7/200] [Batch 23/169] [D loss: 0.536426] [G loss: 1.081698]\n",
      "[Epoch 7/200] [Batch 24/169] [D loss: 0.588350] [G loss: 0.939547]\n",
      "[Epoch 7/200] [Batch 25/169] [D loss: 0.515878] [G loss: 0.992275]\n",
      "[Epoch 7/200] [Batch 26/169] [D loss: 0.580875] [G loss: 0.915476]\n",
      "[Epoch 7/200] [Batch 27/169] [D loss: 0.493386] [G loss: 0.956488]\n",
      "[Epoch 7/200] [Batch 28/169] [D loss: 0.527176] [G loss: 1.047953]\n",
      "[Epoch 7/200] [Batch 29/169] [D loss: 0.524097] [G loss: 1.032305]\n",
      "[Epoch 7/200] [Batch 30/169] [D loss: 0.588772] [G loss: 0.999917]\n",
      "[Epoch 7/200] [Batch 31/169] [D loss: 0.600996] [G loss: 1.136047]\n",
      "[Epoch 7/200] [Batch 32/169] [D loss: 0.527707] [G loss: 1.049666]\n",
      "[Epoch 7/200] [Batch 33/169] [D loss: 0.573160] [G loss: 0.814507]\n",
      "[Epoch 7/200] [Batch 34/169] [D loss: 0.549227] [G loss: 0.929004]\n",
      "[Epoch 7/200] [Batch 35/169] [D loss: 0.589082] [G loss: 1.086334]\n",
      "[Epoch 7/200] [Batch 36/169] [D loss: 0.583438] [G loss: 0.982544]\n",
      "[Epoch 7/200] [Batch 37/169] [D loss: 0.523446] [G loss: 1.160472]\n",
      "[Epoch 7/200] [Batch 38/169] [D loss: 0.592779] [G loss: 0.939363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 39/169] [D loss: 0.615951] [G loss: 0.715258]\n",
      "[Epoch 7/200] [Batch 40/169] [D loss: 0.576359] [G loss: 0.962311]\n",
      "[Epoch 7/200] [Batch 41/169] [D loss: 0.564321] [G loss: 1.424663]\n",
      "[Epoch 7/200] [Batch 42/169] [D loss: 0.498469] [G loss: 0.975148]\n",
      "[Epoch 7/200] [Batch 43/169] [D loss: 0.589677] [G loss: 1.054578]\n",
      "[Epoch 7/200] [Batch 44/169] [D loss: 0.560838] [G loss: 0.837607]\n",
      "[Epoch 7/200] [Batch 45/169] [D loss: 0.566079] [G loss: 0.940725]\n",
      "[Epoch 7/200] [Batch 46/169] [D loss: 0.699791] [G loss: 1.045830]\n",
      "[Epoch 7/200] [Batch 47/169] [D loss: 0.555175] [G loss: 0.863785]\n",
      "[Epoch 7/200] [Batch 48/169] [D loss: 0.489595] [G loss: 1.151481]\n",
      "[Epoch 7/200] [Batch 49/169] [D loss: 0.581166] [G loss: 0.979762]\n",
      "[Epoch 7/200] [Batch 50/169] [D loss: 0.533980] [G loss: 0.913191]\n",
      "[Epoch 7/200] [Batch 51/169] [D loss: 0.587357] [G loss: 1.327531]\n",
      "[Epoch 7/200] [Batch 52/169] [D loss: 0.562645] [G loss: 1.031693]\n",
      "[Epoch 7/200] [Batch 53/169] [D loss: 0.576500] [G loss: 1.206146]\n",
      "[Epoch 7/200] [Batch 54/169] [D loss: 0.515608] [G loss: 1.010888]\n",
      "[Epoch 7/200] [Batch 55/169] [D loss: 0.490549] [G loss: 1.131930]\n",
      "[Epoch 7/200] [Batch 56/169] [D loss: 0.553386] [G loss: 1.250291]\n",
      "[Epoch 7/200] [Batch 57/169] [D loss: 0.620244] [G loss: 1.041644]\n",
      "[Epoch 7/200] [Batch 58/169] [D loss: 0.646087] [G loss: 1.070367]\n",
      "[Epoch 7/200] [Batch 59/169] [D loss: 0.539005] [G loss: 1.155823]\n",
      "[Epoch 7/200] [Batch 60/169] [D loss: 0.665816] [G loss: 1.153533]\n",
      "[Epoch 7/200] [Batch 61/169] [D loss: 0.584866] [G loss: 1.167430]\n",
      "[Epoch 7/200] [Batch 62/169] [D loss: 0.529100] [G loss: 1.108897]\n",
      "[Epoch 7/200] [Batch 63/169] [D loss: 0.608858] [G loss: 0.975127]\n",
      "[Epoch 7/200] [Batch 64/169] [D loss: 0.704373] [G loss: 1.021881]\n",
      "[Epoch 7/200] [Batch 65/169] [D loss: 0.595023] [G loss: 1.218125]\n",
      "[Epoch 7/200] [Batch 66/169] [D loss: 0.533446] [G loss: 1.064272]\n",
      "[Epoch 7/200] [Batch 67/169] [D loss: 0.531093] [G loss: 0.862938]\n",
      "[Epoch 7/200] [Batch 68/169] [D loss: 0.578794] [G loss: 1.142794]\n",
      "[Epoch 7/200] [Batch 69/169] [D loss: 0.633156] [G loss: 1.028223]\n",
      "[Epoch 7/200] [Batch 70/169] [D loss: 0.633942] [G loss: 0.972207]\n",
      "[Epoch 7/200] [Batch 71/169] [D loss: 0.556504] [G loss: 1.193179]\n",
      "[Epoch 7/200] [Batch 72/169] [D loss: 0.555693] [G loss: 0.912369]\n",
      "[Epoch 7/200] [Batch 73/169] [D loss: 0.572840] [G loss: 1.094401]\n",
      "[Epoch 7/200] [Batch 74/169] [D loss: 0.559786] [G loss: 0.960630]\n",
      "[Epoch 7/200] [Batch 75/169] [D loss: 0.591785] [G loss: 1.059781]\n",
      "[Epoch 7/200] [Batch 76/169] [D loss: 0.627016] [G loss: 0.925820]\n",
      "[Epoch 7/200] [Batch 77/169] [D loss: 0.566644] [G loss: 1.005009]\n",
      "[Epoch 7/200] [Batch 78/169] [D loss: 0.584709] [G loss: 1.110317]\n",
      "[Epoch 7/200] [Batch 79/169] [D loss: 0.529973] [G loss: 1.188053]\n",
      "[Epoch 7/200] [Batch 80/169] [D loss: 0.474408] [G loss: 0.925889]\n",
      "[Epoch 7/200] [Batch 81/169] [D loss: 0.575511] [G loss: 0.940872]\n",
      "[Epoch 7/200] [Batch 82/169] [D loss: 0.543616] [G loss: 0.870802]\n",
      "[Epoch 7/200] [Batch 83/169] [D loss: 0.574229] [G loss: 1.209611]\n",
      "[Epoch 7/200] [Batch 84/169] [D loss: 0.584010] [G loss: 1.016386]\n",
      "[Epoch 7/200] [Batch 85/169] [D loss: 0.607074] [G loss: 0.943772]\n",
      "[Epoch 7/200] [Batch 86/169] [D loss: 0.553220] [G loss: 0.972226]\n",
      "[Epoch 7/200] [Batch 87/169] [D loss: 0.687658] [G loss: 0.868524]\n",
      "[Epoch 7/200] [Batch 88/169] [D loss: 0.531389] [G loss: 0.894675]\n",
      "[Epoch 7/200] [Batch 89/169] [D loss: 0.576426] [G loss: 1.177999]\n",
      "[Epoch 7/200] [Batch 90/169] [D loss: 0.521158] [G loss: 1.204260]\n",
      "[Epoch 7/200] [Batch 91/169] [D loss: 0.550514] [G loss: 0.969379]\n",
      "[Epoch 7/200] [Batch 92/169] [D loss: 0.715489] [G loss: 0.922731]\n",
      "[Epoch 7/200] [Batch 93/169] [D loss: 0.606066] [G loss: 0.854396]\n",
      "[Epoch 7/200] [Batch 94/169] [D loss: 0.559489] [G loss: 1.083628]\n",
      "[Epoch 7/200] [Batch 95/169] [D loss: 0.606715] [G loss: 1.162115]\n",
      "[Epoch 7/200] [Batch 96/169] [D loss: 0.512404] [G loss: 1.049359]\n",
      "[Epoch 7/200] [Batch 97/169] [D loss: 0.563584] [G loss: 0.902294]\n",
      "[Epoch 7/200] [Batch 98/169] [D loss: 0.536748] [G loss: 1.102227]\n",
      "[Epoch 7/200] [Batch 99/169] [D loss: 0.549297] [G loss: 1.258279]\n",
      "[Epoch 7/200] [Batch 100/169] [D loss: 0.584029] [G loss: 1.044313]\n",
      "[Epoch 7/200] [Batch 101/169] [D loss: 0.575385] [G loss: 1.184394]\n",
      "[Epoch 7/200] [Batch 102/169] [D loss: 0.537865] [G loss: 1.087384]\n",
      "[Epoch 7/200] [Batch 103/169] [D loss: 0.566292] [G loss: 1.124992]\n",
      "[Epoch 7/200] [Batch 104/169] [D loss: 0.576033] [G loss: 0.914840]\n",
      "[Epoch 7/200] [Batch 105/169] [D loss: 0.609362] [G loss: 0.797285]\n",
      "[Epoch 7/200] [Batch 106/169] [D loss: 0.576231] [G loss: 0.868499]\n",
      "[Epoch 7/200] [Batch 107/169] [D loss: 0.513140] [G loss: 1.019202]\n",
      "[Epoch 7/200] [Batch 108/169] [D loss: 0.582863] [G loss: 1.098490]\n",
      "[Epoch 7/200] [Batch 109/169] [D loss: 0.514863] [G loss: 1.092083]\n",
      "[Epoch 7/200] [Batch 110/169] [D loss: 0.574586] [G loss: 1.056395]\n",
      "[Epoch 7/200] [Batch 111/169] [D loss: 0.636812] [G loss: 0.837952]\n",
      "[Epoch 7/200] [Batch 112/169] [D loss: 0.642425] [G loss: 1.261162]\n",
      "[Epoch 7/200] [Batch 113/169] [D loss: 0.617441] [G loss: 0.993156]\n",
      "[Epoch 7/200] [Batch 114/169] [D loss: 0.433711] [G loss: 1.136549]\n",
      "[Epoch 7/200] [Batch 115/169] [D loss: 0.621513] [G loss: 0.942029]\n",
      "[Epoch 7/200] [Batch 116/169] [D loss: 0.526037] [G loss: 1.013379]\n",
      "[Epoch 7/200] [Batch 117/169] [D loss: 0.536411] [G loss: 1.045228]\n",
      "[Epoch 7/200] [Batch 118/169] [D loss: 0.575949] [G loss: 0.882894]\n",
      "[Epoch 7/200] [Batch 119/169] [D loss: 0.541000] [G loss: 1.005059]\n",
      "[Epoch 7/200] [Batch 120/169] [D loss: 0.540690] [G loss: 0.914664]\n",
      "[Epoch 7/200] [Batch 121/169] [D loss: 0.580653] [G loss: 1.175341]\n",
      "[Epoch 7/200] [Batch 122/169] [D loss: 0.615009] [G loss: 0.886368]\n",
      "[Epoch 7/200] [Batch 123/169] [D loss: 0.633261] [G loss: 1.080016]\n",
      "[Epoch 7/200] [Batch 124/169] [D loss: 0.598820] [G loss: 1.113520]\n",
      "[Epoch 7/200] [Batch 125/169] [D loss: 0.645407] [G loss: 0.894101]\n",
      "[Epoch 7/200] [Batch 126/169] [D loss: 0.624625] [G loss: 0.896919]\n",
      "[Epoch 7/200] [Batch 127/169] [D loss: 0.666609] [G loss: 0.955011]\n",
      "[Epoch 7/200] [Batch 128/169] [D loss: 0.584889] [G loss: 0.971495]\n",
      "[Epoch 7/200] [Batch 129/169] [D loss: 0.666152] [G loss: 1.029065]\n",
      "[Epoch 7/200] [Batch 130/169] [D loss: 0.493369] [G loss: 0.920914]\n",
      "[Epoch 7/200] [Batch 131/169] [D loss: 0.594759] [G loss: 1.320047]\n",
      "[Epoch 7/200] [Batch 132/169] [D loss: 0.507631] [G loss: 1.162441]\n",
      "[Epoch 7/200] [Batch 133/169] [D loss: 0.389106] [G loss: 1.258874]\n",
      "[Epoch 7/200] [Batch 134/169] [D loss: 0.479358] [G loss: 0.937964]\n",
      "[Epoch 7/200] [Batch 135/169] [D loss: 0.441612] [G loss: 1.153641]\n",
      "[Epoch 7/200] [Batch 136/169] [D loss: 0.457122] [G loss: 1.097120]\n",
      "[Epoch 7/200] [Batch 137/169] [D loss: 0.500004] [G loss: 0.986030]\n",
      "[Epoch 7/200] [Batch 138/169] [D loss: 0.529602] [G loss: 1.186295]\n",
      "[Epoch 7/200] [Batch 139/169] [D loss: 0.460792] [G loss: 1.085825]\n",
      "[Epoch 7/200] [Batch 140/169] [D loss: 0.594498] [G loss: 1.203625]\n",
      "[Epoch 7/200] [Batch 141/169] [D loss: 0.577299] [G loss: 1.126797]\n",
      "[Epoch 7/200] [Batch 142/169] [D loss: 0.535293] [G loss: 0.924457]\n",
      "[Epoch 7/200] [Batch 143/169] [D loss: 0.504272] [G loss: 1.048168]\n",
      "[Epoch 7/200] [Batch 144/169] [D loss: 0.572079] [G loss: 1.186130]\n",
      "[Epoch 7/200] [Batch 145/169] [D loss: 0.528454] [G loss: 1.253367]\n",
      "[Epoch 7/200] [Batch 146/169] [D loss: 0.539148] [G loss: 0.814751]\n",
      "[Epoch 7/200] [Batch 147/169] [D loss: 0.501293] [G loss: 0.967041]\n",
      "[Epoch 7/200] [Batch 148/169] [D loss: 0.581942] [G loss: 1.042919]\n",
      "[Epoch 7/200] [Batch 149/169] [D loss: 0.578925] [G loss: 1.006222]\n",
      "[Epoch 7/200] [Batch 150/169] [D loss: 0.562573] [G loss: 1.305592]\n",
      "[Epoch 7/200] [Batch 151/169] [D loss: 0.609336] [G loss: 1.024519]\n",
      "[Epoch 7/200] [Batch 152/169] [D loss: 0.599577] [G loss: 0.946775]\n",
      "[Epoch 7/200] [Batch 153/169] [D loss: 0.564054] [G loss: 1.038092]\n",
      "[Epoch 7/200] [Batch 154/169] [D loss: 0.609197] [G loss: 0.991131]\n",
      "[Epoch 7/200] [Batch 155/169] [D loss: 0.527621] [G loss: 0.921598]\n",
      "[Epoch 7/200] [Batch 156/169] [D loss: 0.695499] [G loss: 0.709321]\n",
      "[Epoch 7/200] [Batch 157/169] [D loss: 0.612187] [G loss: 1.181416]\n",
      "[Epoch 7/200] [Batch 158/169] [D loss: 0.631631] [G loss: 1.029511]\n",
      "[Epoch 7/200] [Batch 159/169] [D loss: 0.492059] [G loss: 1.105084]\n",
      "[Epoch 7/200] [Batch 160/169] [D loss: 0.616265] [G loss: 0.942831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 161/169] [D loss: 0.551537] [G loss: 0.951589]\n",
      "[Epoch 7/200] [Batch 162/169] [D loss: 0.505673] [G loss: 1.084078]\n",
      "[Epoch 7/200] [Batch 163/169] [D loss: 0.558355] [G loss: 0.906533]\n",
      "[Epoch 7/200] [Batch 164/169] [D loss: 0.618171] [G loss: 1.061163]\n",
      "[Epoch 7/200] [Batch 165/169] [D loss: 0.566461] [G loss: 1.192187]\n",
      "[Epoch 7/200] [Batch 166/169] [D loss: 0.549178] [G loss: 1.092216]\n",
      "[Epoch 7/200] [Batch 167/169] [D loss: 0.450304] [G loss: 1.020559]\n",
      "[Epoch 7/200] [Batch 168/169] [D loss: 0.595002] [G loss: 0.869232]\n",
      "[Epoch 8/200] [Batch 0/169] [D loss: 0.536005] [G loss: 0.878409]\n",
      "[Epoch 8/200] [Batch 1/169] [D loss: 0.623062] [G loss: 1.327865]\n",
      "[Epoch 8/200] [Batch 2/169] [D loss: 0.608679] [G loss: 1.007864]\n",
      "[Epoch 8/200] [Batch 3/169] [D loss: 0.639799] [G loss: 1.266251]\n",
      "[Epoch 8/200] [Batch 4/169] [D loss: 0.681270] [G loss: 1.200284]\n",
      "[Epoch 8/200] [Batch 5/169] [D loss: 0.610735] [G loss: 1.173516]\n",
      "[Epoch 8/200] [Batch 6/169] [D loss: 0.707665] [G loss: 0.892542]\n",
      "[Epoch 8/200] [Batch 7/169] [D loss: 0.553617] [G loss: 1.208848]\n",
      "[Epoch 8/200] [Batch 8/169] [D loss: 0.612187] [G loss: 1.204327]\n",
      "[Epoch 8/200] [Batch 9/169] [D loss: 0.609754] [G loss: 1.116881]\n",
      "[Epoch 8/200] [Batch 10/169] [D loss: 0.713294] [G loss: 1.156445]\n",
      "[Epoch 8/200] [Batch 11/169] [D loss: 0.609441] [G loss: 0.910061]\n",
      "[Epoch 8/200] [Batch 12/169] [D loss: 0.560440] [G loss: 1.019759]\n",
      "[Epoch 8/200] [Batch 13/169] [D loss: 0.686965] [G loss: 1.012792]\n",
      "[Epoch 8/200] [Batch 14/169] [D loss: 0.614699] [G loss: 0.999124]\n",
      "[Epoch 8/200] [Batch 15/169] [D loss: 0.620046] [G loss: 0.906518]\n",
      "[Epoch 8/200] [Batch 16/169] [D loss: 0.590123] [G loss: 0.810897]\n",
      "[Epoch 8/200] [Batch 17/169] [D loss: 0.608735] [G loss: 0.903010]\n",
      "[Epoch 8/200] [Batch 18/169] [D loss: 0.604099] [G loss: 0.835624]\n",
      "[Epoch 8/200] [Batch 19/169] [D loss: 0.597187] [G loss: 0.864728]\n",
      "[Epoch 8/200] [Batch 20/169] [D loss: 0.559421] [G loss: 0.946780]\n",
      "[Epoch 8/200] [Batch 21/169] [D loss: 0.541398] [G loss: 1.048029]\n",
      "[Epoch 8/200] [Batch 22/169] [D loss: 0.618176] [G loss: 1.099313]\n",
      "[Epoch 8/200] [Batch 23/169] [D loss: 0.591684] [G loss: 1.011166]\n",
      "[Epoch 8/200] [Batch 24/169] [D loss: 0.603672] [G loss: 0.993380]\n",
      "[Epoch 8/200] [Batch 25/169] [D loss: 0.578593] [G loss: 0.845720]\n",
      "[Epoch 8/200] [Batch 26/169] [D loss: 0.543689] [G loss: 0.821438]\n",
      "[Epoch 8/200] [Batch 27/169] [D loss: 0.627056] [G loss: 0.930935]\n",
      "[Epoch 8/200] [Batch 28/169] [D loss: 0.563190] [G loss: 0.957565]\n",
      "[Epoch 8/200] [Batch 29/169] [D loss: 0.586724] [G loss: 1.164759]\n",
      "[Epoch 8/200] [Batch 30/169] [D loss: 0.578251] [G loss: 0.938381]\n",
      "[Epoch 8/200] [Batch 31/169] [D loss: 0.667136] [G loss: 0.880837]\n",
      "[Epoch 8/200] [Batch 32/169] [D loss: 0.667169] [G loss: 0.829721]\n",
      "[Epoch 8/200] [Batch 33/169] [D loss: 0.597591] [G loss: 1.102904]\n",
      "[Epoch 8/200] [Batch 34/169] [D loss: 0.588234] [G loss: 1.390834]\n",
      "[Epoch 8/200] [Batch 35/169] [D loss: 0.548074] [G loss: 1.022994]\n",
      "[Epoch 8/200] [Batch 36/169] [D loss: 0.615566] [G loss: 0.834515]\n",
      "[Epoch 8/200] [Batch 37/169] [D loss: 0.555601] [G loss: 0.871629]\n",
      "[Epoch 8/200] [Batch 38/169] [D loss: 0.614930] [G loss: 0.850604]\n",
      "[Epoch 8/200] [Batch 39/169] [D loss: 0.593656] [G loss: 1.052718]\n",
      "[Epoch 8/200] [Batch 40/169] [D loss: 0.729696] [G loss: 0.999155]\n",
      "[Epoch 8/200] [Batch 41/169] [D loss: 0.551733] [G loss: 0.946652]\n",
      "[Epoch 8/200] [Batch 42/169] [D loss: 0.631656] [G loss: 0.918923]\n",
      "[Epoch 8/200] [Batch 43/169] [D loss: 0.606011] [G loss: 1.098481]\n",
      "[Epoch 8/200] [Batch 44/169] [D loss: 0.635163] [G loss: 1.147703]\n",
      "[Epoch 8/200] [Batch 45/169] [D loss: 0.632662] [G loss: 1.049110]\n",
      "[Epoch 8/200] [Batch 46/169] [D loss: 0.555168] [G loss: 1.003930]\n",
      "[Epoch 8/200] [Batch 47/169] [D loss: 0.620131] [G loss: 1.009525]\n",
      "[Epoch 8/200] [Batch 48/169] [D loss: 0.540152] [G loss: 1.050683]\n",
      "[Epoch 8/200] [Batch 49/169] [D loss: 0.572906] [G loss: 0.990522]\n",
      "[Epoch 8/200] [Batch 50/169] [D loss: 0.577486] [G loss: 1.132975]\n",
      "[Epoch 8/200] [Batch 51/169] [D loss: 0.486490] [G loss: 1.072378]\n",
      "[Epoch 8/200] [Batch 52/169] [D loss: 0.512490] [G loss: 1.013958]\n",
      "[Epoch 8/200] [Batch 53/169] [D loss: 0.563473] [G loss: 0.923907]\n",
      "[Epoch 8/200] [Batch 54/169] [D loss: 0.609385] [G loss: 0.911278]\n",
      "[Epoch 8/200] [Batch 55/169] [D loss: 0.475785] [G loss: 0.939915]\n",
      "[Epoch 8/200] [Batch 56/169] [D loss: 0.580453] [G loss: 0.801419]\n",
      "[Epoch 8/200] [Batch 57/169] [D loss: 0.552140] [G loss: 1.184760]\n",
      "[Epoch 8/200] [Batch 58/169] [D loss: 0.545054] [G loss: 1.136383]\n",
      "[Epoch 8/200] [Batch 59/169] [D loss: 0.617015] [G loss: 0.937251]\n",
      "[Epoch 8/200] [Batch 60/169] [D loss: 0.603708] [G loss: 0.923483]\n",
      "[Epoch 8/200] [Batch 61/169] [D loss: 0.637047] [G loss: 1.270255]\n",
      "[Epoch 8/200] [Batch 62/169] [D loss: 0.531311] [G loss: 1.019493]\n",
      "[Epoch 8/200] [Batch 63/169] [D loss: 0.582977] [G loss: 0.983775]\n",
      "[Epoch 8/200] [Batch 64/169] [D loss: 0.605196] [G loss: 0.957684]\n",
      "[Epoch 8/200] [Batch 65/169] [D loss: 0.611055] [G loss: 1.092213]\n",
      "[Epoch 8/200] [Batch 66/169] [D loss: 0.548396] [G loss: 1.133145]\n",
      "[Epoch 8/200] [Batch 67/169] [D loss: 0.619206] [G loss: 1.214911]\n",
      "[Epoch 8/200] [Batch 68/169] [D loss: 0.595909] [G loss: 1.028031]\n",
      "[Epoch 8/200] [Batch 69/169] [D loss: 0.537059] [G loss: 0.908200]\n",
      "[Epoch 8/200] [Batch 70/169] [D loss: 0.480518] [G loss: 0.886313]\n",
      "[Epoch 8/200] [Batch 71/169] [D loss: 0.603427] [G loss: 0.970512]\n",
      "[Epoch 8/200] [Batch 72/169] [D loss: 0.606274] [G loss: 0.997081]\n",
      "[Epoch 8/200] [Batch 73/169] [D loss: 0.501414] [G loss: 1.299487]\n",
      "[Epoch 8/200] [Batch 74/169] [D loss: 0.578833] [G loss: 0.881298]\n",
      "[Epoch 8/200] [Batch 75/169] [D loss: 0.613614] [G loss: 0.795000]\n",
      "[Epoch 8/200] [Batch 76/169] [D loss: 0.561324] [G loss: 0.978217]\n",
      "[Epoch 8/200] [Batch 77/169] [D loss: 0.568123] [G loss: 1.049894]\n",
      "[Epoch 8/200] [Batch 78/169] [D loss: 0.575015] [G loss: 1.296562]\n",
      "[Epoch 8/200] [Batch 79/169] [D loss: 0.588004] [G loss: 1.200475]\n",
      "[Epoch 8/200] [Batch 80/169] [D loss: 0.631940] [G loss: 0.843182]\n",
      "[Epoch 8/200] [Batch 81/169] [D loss: 0.615567] [G loss: 1.248044]\n",
      "[Epoch 8/200] [Batch 82/169] [D loss: 0.508949] [G loss: 0.905490]\n",
      "[Epoch 8/200] [Batch 83/169] [D loss: 0.487072] [G loss: 1.071518]\n",
      "[Epoch 8/200] [Batch 84/169] [D loss: 0.527706] [G loss: 1.128226]\n",
      "[Epoch 8/200] [Batch 85/169] [D loss: 0.563469] [G loss: 0.893952]\n",
      "[Epoch 8/200] [Batch 86/169] [D loss: 0.518373] [G loss: 1.063039]\n",
      "[Epoch 8/200] [Batch 87/169] [D loss: 0.561046] [G loss: 1.069458]\n",
      "[Epoch 8/200] [Batch 88/169] [D loss: 0.541205] [G loss: 0.961589]\n",
      "[Epoch 8/200] [Batch 89/169] [D loss: 0.596878] [G loss: 0.971977]\n",
      "[Epoch 8/200] [Batch 90/169] [D loss: 0.543387] [G loss: 1.153566]\n",
      "[Epoch 8/200] [Batch 91/169] [D loss: 0.476476] [G loss: 0.931212]\n",
      "[Epoch 8/200] [Batch 92/169] [D loss: 0.530017] [G loss: 0.893738]\n",
      "[Epoch 8/200] [Batch 93/169] [D loss: 0.575616] [G loss: 0.993709]\n",
      "[Epoch 8/200] [Batch 94/169] [D loss: 0.498418] [G loss: 0.950219]\n",
      "[Epoch 8/200] [Batch 95/169] [D loss: 0.657703] [G loss: 0.949485]\n",
      "[Epoch 8/200] [Batch 96/169] [D loss: 0.586110] [G loss: 0.956244]\n",
      "[Epoch 8/200] [Batch 97/169] [D loss: 0.648518] [G loss: 0.942682]\n",
      "[Epoch 8/200] [Batch 98/169] [D loss: 0.590114] [G loss: 1.084676]\n",
      "[Epoch 8/200] [Batch 99/169] [D loss: 0.536446] [G loss: 0.842594]\n",
      "[Epoch 8/200] [Batch 100/169] [D loss: 0.617169] [G loss: 0.907436]\n",
      "[Epoch 8/200] [Batch 101/169] [D loss: 0.658788] [G loss: 0.817396]\n",
      "[Epoch 8/200] [Batch 102/169] [D loss: 0.687914] [G loss: 0.872613]\n",
      "[Epoch 8/200] [Batch 103/169] [D loss: 0.640444] [G loss: 0.911485]\n",
      "[Epoch 8/200] [Batch 104/169] [D loss: 0.680429] [G loss: 0.807071]\n",
      "[Epoch 8/200] [Batch 105/169] [D loss: 0.605597] [G loss: 0.934084]\n",
      "[Epoch 8/200] [Batch 106/169] [D loss: 0.620826] [G loss: 0.830643]\n",
      "[Epoch 8/200] [Batch 107/169] [D loss: 0.582385] [G loss: 1.101507]\n",
      "[Epoch 8/200] [Batch 108/169] [D loss: 0.606377] [G loss: 1.092514]\n",
      "[Epoch 8/200] [Batch 109/169] [D loss: 0.581185] [G loss: 0.977114]\n",
      "[Epoch 8/200] [Batch 110/169] [D loss: 0.693755] [G loss: 0.930327]\n",
      "[Epoch 8/200] [Batch 111/169] [D loss: 0.581560] [G loss: 0.993970]\n",
      "[Epoch 8/200] [Batch 112/169] [D loss: 0.555824] [G loss: 1.026201]\n",
      "[Epoch 8/200] [Batch 113/169] [D loss: 0.522144] [G loss: 1.038119]\n",
      "[Epoch 8/200] [Batch 114/169] [D loss: 0.539341] [G loss: 1.042171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 115/169] [D loss: 0.488972] [G loss: 1.068984]\n",
      "[Epoch 8/200] [Batch 116/169] [D loss: 0.496626] [G loss: 1.096324]\n",
      "[Epoch 8/200] [Batch 117/169] [D loss: 0.481888] [G loss: 1.252891]\n",
      "[Epoch 8/200] [Batch 118/169] [D loss: 0.503223] [G loss: 1.245668]\n",
      "[Epoch 8/200] [Batch 119/169] [D loss: 0.518388] [G loss: 1.083434]\n",
      "[Epoch 8/200] [Batch 120/169] [D loss: 0.544230] [G loss: 1.116722]\n",
      "[Epoch 8/200] [Batch 121/169] [D loss: 0.547457] [G loss: 0.994282]\n",
      "[Epoch 8/200] [Batch 122/169] [D loss: 0.623647] [G loss: 1.189484]\n",
      "[Epoch 8/200] [Batch 123/169] [D loss: 0.513644] [G loss: 1.197626]\n",
      "[Epoch 8/200] [Batch 124/169] [D loss: 0.529353] [G loss: 0.926173]\n",
      "[Epoch 8/200] [Batch 125/169] [D loss: 0.585058] [G loss: 1.138877]\n",
      "[Epoch 8/200] [Batch 126/169] [D loss: 0.542465] [G loss: 1.138595]\n",
      "[Epoch 8/200] [Batch 127/169] [D loss: 0.502742] [G loss: 1.287792]\n",
      "[Epoch 8/200] [Batch 128/169] [D loss: 0.647023] [G loss: 1.062573]\n",
      "[Epoch 8/200] [Batch 129/169] [D loss: 0.586642] [G loss: 1.214370]\n",
      "[Epoch 8/200] [Batch 130/169] [D loss: 0.577176] [G loss: 1.153229]\n",
      "[Epoch 8/200] [Batch 131/169] [D loss: 0.557169] [G loss: 1.063711]\n",
      "[Epoch 8/200] [Batch 132/169] [D loss: 0.589604] [G loss: 1.054742]\n",
      "[Epoch 8/200] [Batch 133/169] [D loss: 0.531490] [G loss: 1.192729]\n",
      "[Epoch 8/200] [Batch 134/169] [D loss: 0.468511] [G loss: 1.037374]\n",
      "[Epoch 8/200] [Batch 135/169] [D loss: 0.525993] [G loss: 1.029356]\n",
      "[Epoch 8/200] [Batch 136/169] [D loss: 0.588278] [G loss: 1.203196]\n",
      "[Epoch 8/200] [Batch 137/169] [D loss: 0.479584] [G loss: 0.929823]\n",
      "[Epoch 8/200] [Batch 138/169] [D loss: 0.559831] [G loss: 1.039696]\n",
      "[Epoch 8/200] [Batch 139/169] [D loss: 0.530118] [G loss: 1.073468]\n",
      "[Epoch 8/200] [Batch 140/169] [D loss: 0.572164] [G loss: 0.856877]\n",
      "[Epoch 8/200] [Batch 141/169] [D loss: 0.530754] [G loss: 0.962032]\n",
      "[Epoch 8/200] [Batch 142/169] [D loss: 0.606527] [G loss: 0.823754]\n",
      "[Epoch 8/200] [Batch 143/169] [D loss: 0.557790] [G loss: 0.901882]\n",
      "[Epoch 8/200] [Batch 144/169] [D loss: 0.610045] [G loss: 0.995125]\n",
      "[Epoch 8/200] [Batch 145/169] [D loss: 0.644837] [G loss: 1.023147]\n",
      "[Epoch 8/200] [Batch 146/169] [D loss: 0.594232] [G loss: 1.265683]\n",
      "[Epoch 8/200] [Batch 147/169] [D loss: 0.596817] [G loss: 1.005438]\n",
      "[Epoch 8/200] [Batch 148/169] [D loss: 0.473004] [G loss: 0.844212]\n",
      "[Epoch 8/200] [Batch 149/169] [D loss: 0.572768] [G loss: 0.750722]\n",
      "[Epoch 8/200] [Batch 150/169] [D loss: 0.526501] [G loss: 1.002001]\n",
      "[Epoch 8/200] [Batch 151/169] [D loss: 0.655480] [G loss: 0.961673]\n",
      "[Epoch 8/200] [Batch 152/169] [D loss: 0.567427] [G loss: 1.074709]\n",
      "[Epoch 8/200] [Batch 153/169] [D loss: 0.534438] [G loss: 0.913371]\n",
      "[Epoch 8/200] [Batch 154/169] [D loss: 0.676009] [G loss: 1.127951]\n",
      "[Epoch 8/200] [Batch 155/169] [D loss: 0.577513] [G loss: 1.147392]\n",
      "[Epoch 8/200] [Batch 156/169] [D loss: 0.573490] [G loss: 1.028467]\n",
      "[Epoch 8/200] [Batch 157/169] [D loss: 0.602908] [G loss: 0.953826]\n",
      "[Epoch 8/200] [Batch 158/169] [D loss: 0.628567] [G loss: 1.278496]\n",
      "[Epoch 8/200] [Batch 159/169] [D loss: 0.586953] [G loss: 1.214962]\n",
      "[Epoch 8/200] [Batch 160/169] [D loss: 0.532686] [G loss: 1.137415]\n",
      "[Epoch 8/200] [Batch 161/169] [D loss: 0.598173] [G loss: 1.215537]\n",
      "[Epoch 8/200] [Batch 162/169] [D loss: 0.596937] [G loss: 1.014637]\n",
      "[Epoch 8/200] [Batch 163/169] [D loss: 0.584647] [G loss: 0.975344]\n",
      "[Epoch 8/200] [Batch 164/169] [D loss: 0.596962] [G loss: 0.944075]\n",
      "[Epoch 8/200] [Batch 165/169] [D loss: 0.570317] [G loss: 1.075327]\n",
      "[Epoch 8/200] [Batch 166/169] [D loss: 0.591483] [G loss: 0.908557]\n",
      "[Epoch 8/200] [Batch 167/169] [D loss: 0.544561] [G loss: 0.798450]\n",
      "[Epoch 8/200] [Batch 168/169] [D loss: 0.417030] [G loss: 0.931806]\n",
      "[Epoch 9/200] [Batch 0/169] [D loss: 0.567514] [G loss: 0.915454]\n",
      "[Epoch 9/200] [Batch 1/169] [D loss: 0.536828] [G loss: 0.949613]\n",
      "[Epoch 9/200] [Batch 2/169] [D loss: 0.542622] [G loss: 0.895935]\n",
      "[Epoch 9/200] [Batch 3/169] [D loss: 0.573574] [G loss: 0.762488]\n",
      "[Epoch 9/200] [Batch 4/169] [D loss: 0.620461] [G loss: 0.974407]\n",
      "[Epoch 9/200] [Batch 5/169] [D loss: 0.646009] [G loss: 1.017826]\n",
      "[Epoch 9/200] [Batch 6/169] [D loss: 0.638081] [G loss: 0.891400]\n",
      "[Epoch 9/200] [Batch 7/169] [D loss: 0.513638] [G loss: 0.908166]\n",
      "[Epoch 9/200] [Batch 8/169] [D loss: 0.586632] [G loss: 1.028830]\n",
      "[Epoch 9/200] [Batch 9/169] [D loss: 0.531512] [G loss: 0.954747]\n",
      "[Epoch 9/200] [Batch 10/169] [D loss: 0.592888] [G loss: 0.698570]\n",
      "[Epoch 9/200] [Batch 11/169] [D loss: 0.721830] [G loss: 0.806854]\n",
      "[Epoch 9/200] [Batch 12/169] [D loss: 0.616657] [G loss: 0.925710]\n",
      "[Epoch 9/200] [Batch 13/169] [D loss: 0.596543] [G loss: 1.001730]\n",
      "[Epoch 9/200] [Batch 14/169] [D loss: 0.585125] [G loss: 1.127639]\n",
      "[Epoch 9/200] [Batch 15/169] [D loss: 0.561285] [G loss: 1.086346]\n",
      "[Epoch 9/200] [Batch 16/169] [D loss: 0.494158] [G loss: 1.229635]\n",
      "[Epoch 9/200] [Batch 17/169] [D loss: 0.632609] [G loss: 1.020904]\n",
      "[Epoch 9/200] [Batch 18/169] [D loss: 0.570900] [G loss: 0.848262]\n",
      "[Epoch 9/200] [Batch 19/169] [D loss: 0.553931] [G loss: 1.015833]\n",
      "[Epoch 9/200] [Batch 20/169] [D loss: 0.617338] [G loss: 1.135792]\n",
      "[Epoch 9/200] [Batch 21/169] [D loss: 0.639584] [G loss: 1.107085]\n",
      "[Epoch 9/200] [Batch 22/169] [D loss: 0.577149] [G loss: 1.064761]\n",
      "[Epoch 9/200] [Batch 23/169] [D loss: 0.647168] [G loss: 0.783435]\n",
      "[Epoch 9/200] [Batch 24/169] [D loss: 0.544227] [G loss: 1.018820]\n",
      "[Epoch 9/200] [Batch 25/169] [D loss: 0.560656] [G loss: 1.185184]\n",
      "[Epoch 9/200] [Batch 26/169] [D loss: 0.614490] [G loss: 0.886655]\n",
      "[Epoch 9/200] [Batch 27/169] [D loss: 0.551888] [G loss: 0.885171]\n",
      "[Epoch 9/200] [Batch 28/169] [D loss: 0.611989] [G loss: 0.846397]\n",
      "[Epoch 9/200] [Batch 29/169] [D loss: 0.574417] [G loss: 0.884452]\n",
      "[Epoch 9/200] [Batch 30/169] [D loss: 0.584440] [G loss: 1.122653]\n",
      "[Epoch 9/200] [Batch 31/169] [D loss: 0.656669] [G loss: 0.952670]\n",
      "[Epoch 9/200] [Batch 32/169] [D loss: 0.576698] [G loss: 0.964460]\n",
      "[Epoch 9/200] [Batch 33/169] [D loss: 0.652221] [G loss: 0.750563]\n",
      "[Epoch 9/200] [Batch 34/169] [D loss: 0.597116] [G loss: 0.961989]\n",
      "[Epoch 9/200] [Batch 35/169] [D loss: 0.571990] [G loss: 0.996862]\n",
      "[Epoch 9/200] [Batch 36/169] [D loss: 0.612556] [G loss: 1.294164]\n",
      "[Epoch 9/200] [Batch 37/169] [D loss: 0.583133] [G loss: 0.959392]\n",
      "[Epoch 9/200] [Batch 38/169] [D loss: 0.549081] [G loss: 0.954527]\n",
      "[Epoch 9/200] [Batch 39/169] [D loss: 0.499232] [G loss: 1.000931]\n",
      "[Epoch 9/200] [Batch 40/169] [D loss: 0.610326] [G loss: 0.983358]\n",
      "[Epoch 9/200] [Batch 41/169] [D loss: 0.598461] [G loss: 1.023267]\n",
      "[Epoch 9/200] [Batch 42/169] [D loss: 0.627053] [G loss: 1.164757]\n",
      "[Epoch 9/200] [Batch 43/169] [D loss: 0.602456] [G loss: 1.165423]\n",
      "[Epoch 9/200] [Batch 44/169] [D loss: 0.616822] [G loss: 0.906321]\n",
      "[Epoch 9/200] [Batch 45/169] [D loss: 0.575291] [G loss: 0.844945]\n",
      "[Epoch 9/200] [Batch 46/169] [D loss: 0.648734] [G loss: 0.944591]\n",
      "[Epoch 9/200] [Batch 47/169] [D loss: 0.682386] [G loss: 1.054438]\n",
      "[Epoch 9/200] [Batch 48/169] [D loss: 0.553335] [G loss: 0.910789]\n",
      "[Epoch 9/200] [Batch 49/169] [D loss: 0.716254] [G loss: 0.877697]\n",
      "[Epoch 9/200] [Batch 50/169] [D loss: 0.661508] [G loss: 1.040396]\n",
      "[Epoch 9/200] [Batch 51/169] [D loss: 0.635408] [G loss: 0.924905]\n",
      "[Epoch 9/200] [Batch 52/169] [D loss: 0.614951] [G loss: 0.991875]\n",
      "[Epoch 9/200] [Batch 53/169] [D loss: 0.578020] [G loss: 1.028931]\n",
      "[Epoch 9/200] [Batch 54/169] [D loss: 0.612047] [G loss: 0.769200]\n",
      "[Epoch 9/200] [Batch 55/169] [D loss: 0.564230] [G loss: 0.808016]\n",
      "[Epoch 9/200] [Batch 56/169] [D loss: 0.570727] [G loss: 1.108206]\n",
      "[Epoch 9/200] [Batch 57/169] [D loss: 0.597244] [G loss: 0.997313]\n",
      "[Epoch 9/200] [Batch 58/169] [D loss: 0.542549] [G loss: 1.134610]\n",
      "[Epoch 9/200] [Batch 59/169] [D loss: 0.638228] [G loss: 0.899293]\n",
      "[Epoch 9/200] [Batch 60/169] [D loss: 0.651143] [G loss: 0.719530]\n",
      "[Epoch 9/200] [Batch 61/169] [D loss: 0.584059] [G loss: 0.774140]\n",
      "[Epoch 9/200] [Batch 62/169] [D loss: 0.550062] [G loss: 1.226878]\n",
      "[Epoch 9/200] [Batch 63/169] [D loss: 0.614377] [G loss: 1.030075]\n",
      "[Epoch 9/200] [Batch 64/169] [D loss: 0.579749] [G loss: 0.872290]\n",
      "[Epoch 9/200] [Batch 65/169] [D loss: 0.555811] [G loss: 0.793763]\n",
      "[Epoch 9/200] [Batch 66/169] [D loss: 0.605410] [G loss: 0.908795]\n",
      "[Epoch 9/200] [Batch 67/169] [D loss: 0.593437] [G loss: 1.158291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 68/169] [D loss: 0.588452] [G loss: 1.147495]\n",
      "[Epoch 9/200] [Batch 69/169] [D loss: 0.634539] [G loss: 1.053412]\n",
      "[Epoch 9/200] [Batch 70/169] [D loss: 0.558749] [G loss: 0.729008]\n",
      "[Epoch 9/200] [Batch 71/169] [D loss: 0.525159] [G loss: 0.847729]\n",
      "[Epoch 9/200] [Batch 72/169] [D loss: 0.599361] [G loss: 0.792184]\n",
      "[Epoch 9/200] [Batch 73/169] [D loss: 0.598358] [G loss: 0.876995]\n",
      "[Epoch 9/200] [Batch 74/169] [D loss: 0.527104] [G loss: 1.188517]\n",
      "[Epoch 9/200] [Batch 75/169] [D loss: 0.534223] [G loss: 1.078352]\n",
      "[Epoch 9/200] [Batch 76/169] [D loss: 0.595974] [G loss: 0.695213]\n",
      "[Epoch 9/200] [Batch 77/169] [D loss: 0.570215] [G loss: 1.151311]\n",
      "[Epoch 9/200] [Batch 78/169] [D loss: 0.541180] [G loss: 1.160719]\n",
      "[Epoch 9/200] [Batch 79/169] [D loss: 0.572501] [G loss: 0.955489]\n",
      "[Epoch 9/200] [Batch 80/169] [D loss: 0.600918] [G loss: 1.226267]\n",
      "[Epoch 9/200] [Batch 81/169] [D loss: 0.595578] [G loss: 1.127937]\n",
      "[Epoch 9/200] [Batch 82/169] [D loss: 0.605826] [G loss: 1.097748]\n",
      "[Epoch 9/200] [Batch 83/169] [D loss: 0.557701] [G loss: 1.011348]\n",
      "[Epoch 9/200] [Batch 84/169] [D loss: 0.560032] [G loss: 1.053229]\n",
      "[Epoch 9/200] [Batch 85/169] [D loss: 0.645983] [G loss: 0.951006]\n",
      "[Epoch 9/200] [Batch 86/169] [D loss: 0.564630] [G loss: 0.968729]\n",
      "[Epoch 9/200] [Batch 87/169] [D loss: 0.548671] [G loss: 0.876872]\n",
      "[Epoch 9/200] [Batch 88/169] [D loss: 0.502491] [G loss: 0.822440]\n",
      "[Epoch 9/200] [Batch 89/169] [D loss: 0.597376] [G loss: 1.036859]\n",
      "[Epoch 9/200] [Batch 90/169] [D loss: 0.604171] [G loss: 0.903484]\n",
      "[Epoch 9/200] [Batch 91/169] [D loss: 0.597850] [G loss: 0.900568]\n",
      "[Epoch 9/200] [Batch 92/169] [D loss: 0.597185] [G loss: 1.144787]\n",
      "[Epoch 9/200] [Batch 93/169] [D loss: 0.575642] [G loss: 0.983543]\n",
      "[Epoch 9/200] [Batch 94/169] [D loss: 0.704676] [G loss: 1.028529]\n",
      "[Epoch 9/200] [Batch 95/169] [D loss: 0.588287] [G loss: 0.983447]\n",
      "[Epoch 9/200] [Batch 96/169] [D loss: 0.616560] [G loss: 0.889425]\n",
      "[Epoch 9/200] [Batch 97/169] [D loss: 0.592468] [G loss: 1.105384]\n",
      "[Epoch 9/200] [Batch 98/169] [D loss: 0.591668] [G loss: 1.025967]\n",
      "[Epoch 9/200] [Batch 99/169] [D loss: 0.582080] [G loss: 1.052623]\n",
      "[Epoch 9/200] [Batch 100/169] [D loss: 0.629206] [G loss: 1.070866]\n",
      "[Epoch 9/200] [Batch 101/169] [D loss: 0.681531] [G loss: 1.059022]\n",
      "[Epoch 9/200] [Batch 102/169] [D loss: 0.583200] [G loss: 0.969450]\n",
      "[Epoch 9/200] [Batch 103/169] [D loss: 0.591919] [G loss: 0.726364]\n",
      "[Epoch 9/200] [Batch 104/169] [D loss: 0.664411] [G loss: 0.742899]\n",
      "[Epoch 9/200] [Batch 105/169] [D loss: 0.574481] [G loss: 1.213549]\n",
      "[Epoch 9/200] [Batch 106/169] [D loss: 0.580249] [G loss: 1.296413]\n",
      "[Epoch 9/200] [Batch 107/169] [D loss: 0.532152] [G loss: 1.085591]\n",
      "[Epoch 9/200] [Batch 108/169] [D loss: 0.609145] [G loss: 0.962411]\n",
      "[Epoch 9/200] [Batch 109/169] [D loss: 0.528756] [G loss: 1.146133]\n",
      "[Epoch 9/200] [Batch 110/169] [D loss: 0.622793] [G loss: 0.930413]\n",
      "[Epoch 9/200] [Batch 111/169] [D loss: 0.564492] [G loss: 1.090265]\n",
      "[Epoch 9/200] [Batch 112/169] [D loss: 0.519207] [G loss: 0.881352]\n",
      "[Epoch 9/200] [Batch 113/169] [D loss: 0.635691] [G loss: 1.037038]\n",
      "[Epoch 9/200] [Batch 114/169] [D loss: 0.581105] [G loss: 0.959516]\n",
      "[Epoch 9/200] [Batch 115/169] [D loss: 0.588170] [G loss: 0.957770]\n",
      "[Epoch 9/200] [Batch 116/169] [D loss: 0.563011] [G loss: 1.076302]\n",
      "[Epoch 9/200] [Batch 117/169] [D loss: 0.503528] [G loss: 1.460394]\n",
      "[Epoch 9/200] [Batch 118/169] [D loss: 0.484647] [G loss: 1.171446]\n",
      "[Epoch 9/200] [Batch 119/169] [D loss: 0.515772] [G loss: 0.945282]\n",
      "[Epoch 9/200] [Batch 120/169] [D loss: 0.630140] [G loss: 0.800409]\n",
      "[Epoch 9/200] [Batch 121/169] [D loss: 0.637294] [G loss: 0.875672]\n",
      "[Epoch 9/200] [Batch 122/169] [D loss: 0.647940] [G loss: 0.981378]\n",
      "[Epoch 9/200] [Batch 123/169] [D loss: 0.639595] [G loss: 1.001376]\n",
      "[Epoch 9/200] [Batch 124/169] [D loss: 0.617361] [G loss: 0.678273]\n",
      "[Epoch 9/200] [Batch 125/169] [D loss: 0.522463] [G loss: 0.977681]\n",
      "[Epoch 9/200] [Batch 126/169] [D loss: 0.576150] [G loss: 0.951550]\n",
      "[Epoch 9/200] [Batch 127/169] [D loss: 0.634347] [G loss: 1.180794]\n",
      "[Epoch 9/200] [Batch 128/169] [D loss: 0.552137] [G loss: 0.977397]\n",
      "[Epoch 9/200] [Batch 129/169] [D loss: 0.591308] [G loss: 0.979501]\n",
      "[Epoch 9/200] [Batch 130/169] [D loss: 0.601683] [G loss: 1.306820]\n",
      "[Epoch 9/200] [Batch 131/169] [D loss: 0.495496] [G loss: 1.075208]\n",
      "[Epoch 9/200] [Batch 132/169] [D loss: 0.633767] [G loss: 1.094460]\n",
      "[Epoch 9/200] [Batch 133/169] [D loss: 0.742765] [G loss: 0.964608]\n",
      "[Epoch 9/200] [Batch 134/169] [D loss: 0.541385] [G loss: 0.956259]\n",
      "[Epoch 9/200] [Batch 135/169] [D loss: 0.625887] [G loss: 0.983501]\n",
      "[Epoch 9/200] [Batch 136/169] [D loss: 0.660647] [G loss: 1.134002]\n",
      "[Epoch 9/200] [Batch 137/169] [D loss: 0.532065] [G loss: 1.091311]\n",
      "[Epoch 9/200] [Batch 138/169] [D loss: 0.603904] [G loss: 1.075549]\n",
      "[Epoch 9/200] [Batch 139/169] [D loss: 0.622689] [G loss: 1.132639]\n",
      "[Epoch 9/200] [Batch 140/169] [D loss: 0.584220] [G loss: 1.010951]\n",
      "[Epoch 9/200] [Batch 141/169] [D loss: 0.588552] [G loss: 1.071292]\n",
      "[Epoch 9/200] [Batch 142/169] [D loss: 0.665138] [G loss: 0.972330]\n",
      "[Epoch 9/200] [Batch 143/169] [D loss: 0.605701] [G loss: 1.043051]\n",
      "[Epoch 9/200] [Batch 144/169] [D loss: 0.700386] [G loss: 1.046062]\n",
      "[Epoch 9/200] [Batch 145/169] [D loss: 0.649536] [G loss: 1.045429]\n",
      "[Epoch 9/200] [Batch 146/169] [D loss: 0.722159] [G loss: 1.040201]\n",
      "[Epoch 9/200] [Batch 147/169] [D loss: 0.645655] [G loss: 0.844559]\n",
      "[Epoch 9/200] [Batch 148/169] [D loss: 0.635297] [G loss: 1.035882]\n",
      "[Epoch 9/200] [Batch 149/169] [D loss: 0.607847] [G loss: 0.968584]\n",
      "[Epoch 9/200] [Batch 150/169] [D loss: 0.531539] [G loss: 0.899978]\n",
      "[Epoch 9/200] [Batch 151/169] [D loss: 0.527440] [G loss: 1.124879]\n",
      "[Epoch 9/200] [Batch 152/169] [D loss: 0.523237] [G loss: 0.916727]\n",
      "[Epoch 9/200] [Batch 153/169] [D loss: 0.548870] [G loss: 1.099243]\n",
      "[Epoch 9/200] [Batch 154/169] [D loss: 0.572560] [G loss: 0.946067]\n",
      "[Epoch 9/200] [Batch 155/169] [D loss: 0.522951] [G loss: 0.834382]\n",
      "[Epoch 9/200] [Batch 156/169] [D loss: 0.590310] [G loss: 0.953301]\n",
      "[Epoch 9/200] [Batch 157/169] [D loss: 0.651939] [G loss: 0.740983]\n",
      "[Epoch 9/200] [Batch 158/169] [D loss: 0.544326] [G loss: 0.919946]\n",
      "[Epoch 9/200] [Batch 159/169] [D loss: 0.567172] [G loss: 0.985854]\n",
      "[Epoch 9/200] [Batch 160/169] [D loss: 0.546398] [G loss: 1.183568]\n",
      "[Epoch 9/200] [Batch 161/169] [D loss: 0.554922] [G loss: 0.974754]\n",
      "[Epoch 9/200] [Batch 162/169] [D loss: 0.567080] [G loss: 1.005633]\n",
      "[Epoch 9/200] [Batch 163/169] [D loss: 0.577969] [G loss: 0.888779]\n",
      "[Epoch 9/200] [Batch 164/169] [D loss: 0.640959] [G loss: 1.077519]\n",
      "[Epoch 9/200] [Batch 165/169] [D loss: 0.603492] [G loss: 0.853700]\n",
      "[Epoch 9/200] [Batch 166/169] [D loss: 0.583628] [G loss: 0.969118]\n",
      "[Epoch 9/200] [Batch 167/169] [D loss: 0.494987] [G loss: 0.967178]\n",
      "[Epoch 9/200] [Batch 168/169] [D loss: 0.494240] [G loss: 0.831572]\n",
      "[Epoch 10/200] [Batch 0/169] [D loss: 0.556101] [G loss: 1.057053]\n",
      "[Epoch 10/200] [Batch 1/169] [D loss: 0.582859] [G loss: 1.076879]\n",
      "[Epoch 10/200] [Batch 2/169] [D loss: 0.605471] [G loss: 0.779026]\n",
      "[Epoch 10/200] [Batch 3/169] [D loss: 0.609153] [G loss: 0.903625]\n",
      "[Epoch 10/200] [Batch 4/169] [D loss: 0.689435] [G loss: 0.820717]\n",
      "[Epoch 10/200] [Batch 5/169] [D loss: 0.532421] [G loss: 0.994141]\n",
      "[Epoch 10/200] [Batch 6/169] [D loss: 0.550941] [G loss: 0.856445]\n",
      "[Epoch 10/200] [Batch 7/169] [D loss: 0.685947] [G loss: 0.889591]\n",
      "[Epoch 10/200] [Batch 8/169] [D loss: 0.609531] [G loss: 0.859235]\n",
      "[Epoch 10/200] [Batch 9/169] [D loss: 0.653125] [G loss: 0.909457]\n",
      "[Epoch 10/200] [Batch 10/169] [D loss: 0.652176] [G loss: 0.973792]\n",
      "[Epoch 10/200] [Batch 11/169] [D loss: 0.615594] [G loss: 0.774669]\n",
      "[Epoch 10/200] [Batch 12/169] [D loss: 0.593467] [G loss: 0.863739]\n",
      "[Epoch 10/200] [Batch 13/169] [D loss: 0.641692] [G loss: 1.048993]\n",
      "[Epoch 10/200] [Batch 14/169] [D loss: 0.598913] [G loss: 1.050889]\n",
      "[Epoch 10/200] [Batch 15/169] [D loss: 0.621765] [G loss: 0.893366]\n",
      "[Epoch 10/200] [Batch 16/169] [D loss: 0.664688] [G loss: 0.918558]\n",
      "[Epoch 10/200] [Batch 17/169] [D loss: 0.562604] [G loss: 1.194454]\n",
      "[Epoch 10/200] [Batch 18/169] [D loss: 0.609664] [G loss: 1.175269]\n",
      "[Epoch 10/200] [Batch 19/169] [D loss: 0.657971] [G loss: 1.048615]\n",
      "[Epoch 10/200] [Batch 20/169] [D loss: 0.608801] [G loss: 0.770264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 21/169] [D loss: 0.666228] [G loss: 0.919091]\n",
      "[Epoch 10/200] [Batch 22/169] [D loss: 0.558989] [G loss: 0.815710]\n",
      "[Epoch 10/200] [Batch 23/169] [D loss: 0.596815] [G loss: 0.932773]\n",
      "[Epoch 10/200] [Batch 24/169] [D loss: 0.586361] [G loss: 0.962701]\n",
      "[Epoch 10/200] [Batch 25/169] [D loss: 0.551742] [G loss: 0.816834]\n",
      "[Epoch 10/200] [Batch 26/169] [D loss: 0.702524] [G loss: 0.860610]\n",
      "[Epoch 10/200] [Batch 27/169] [D loss: 0.596330] [G loss: 0.836702]\n",
      "[Epoch 10/200] [Batch 28/169] [D loss: 0.534598] [G loss: 0.852210]\n",
      "[Epoch 10/200] [Batch 29/169] [D loss: 0.690258] [G loss: 0.897155]\n",
      "[Epoch 10/200] [Batch 30/169] [D loss: 0.573025] [G loss: 0.984738]\n",
      "[Epoch 10/200] [Batch 31/169] [D loss: 0.528141] [G loss: 1.005944]\n",
      "[Epoch 10/200] [Batch 32/169] [D loss: 0.652288] [G loss: 0.810708]\n",
      "[Epoch 10/200] [Batch 33/169] [D loss: 0.554056] [G loss: 0.976888]\n",
      "[Epoch 10/200] [Batch 34/169] [D loss: 0.581897] [G loss: 1.031036]\n",
      "[Epoch 10/200] [Batch 35/169] [D loss: 0.587543] [G loss: 0.959422]\n",
      "[Epoch 10/200] [Batch 36/169] [D loss: 0.652847] [G loss: 0.971561]\n",
      "[Epoch 10/200] [Batch 37/169] [D loss: 0.667439] [G loss: 1.163362]\n",
      "[Epoch 10/200] [Batch 38/169] [D loss: 0.662791] [G loss: 1.106430]\n",
      "[Epoch 10/200] [Batch 39/169] [D loss: 0.653481] [G loss: 1.018014]\n",
      "[Epoch 10/200] [Batch 40/169] [D loss: 0.613668] [G loss: 0.825095]\n",
      "[Epoch 10/200] [Batch 41/169] [D loss: 0.561796] [G loss: 1.028185]\n",
      "[Epoch 10/200] [Batch 42/169] [D loss: 0.611698] [G loss: 1.057974]\n",
      "[Epoch 10/200] [Batch 43/169] [D loss: 0.641757] [G loss: 0.926190]\n",
      "[Epoch 10/200] [Batch 44/169] [D loss: 0.615126] [G loss: 0.849508]\n",
      "[Epoch 10/200] [Batch 45/169] [D loss: 0.608542] [G loss: 1.003081]\n",
      "[Epoch 10/200] [Batch 46/169] [D loss: 0.623204] [G loss: 1.029800]\n",
      "[Epoch 10/200] [Batch 47/169] [D loss: 0.591079] [G loss: 1.018070]\n",
      "[Epoch 10/200] [Batch 48/169] [D loss: 0.663771] [G loss: 0.957414]\n",
      "[Epoch 10/200] [Batch 49/169] [D loss: 0.685661] [G loss: 0.854632]\n",
      "[Epoch 10/200] [Batch 50/169] [D loss: 0.638645] [G loss: 0.875190]\n",
      "[Epoch 10/200] [Batch 51/169] [D loss: 0.604465] [G loss: 0.989123]\n",
      "[Epoch 10/200] [Batch 52/169] [D loss: 0.620731] [G loss: 0.920675]\n",
      "[Epoch 10/200] [Batch 53/169] [D loss: 0.603234] [G loss: 0.781198]\n",
      "[Epoch 10/200] [Batch 54/169] [D loss: 0.716444] [G loss: 1.101707]\n",
      "[Epoch 10/200] [Batch 55/169] [D loss: 0.567432] [G loss: 0.920435]\n",
      "[Epoch 10/200] [Batch 56/169] [D loss: 0.617918] [G loss: 1.134206]\n",
      "[Epoch 10/200] [Batch 57/169] [D loss: 0.641151] [G loss: 0.964333]\n",
      "[Epoch 10/200] [Batch 58/169] [D loss: 0.665389] [G loss: 1.087839]\n",
      "[Epoch 10/200] [Batch 59/169] [D loss: 0.551484] [G loss: 0.846080]\n",
      "[Epoch 10/200] [Batch 60/169] [D loss: 0.624726] [G loss: 0.855641]\n",
      "[Epoch 10/200] [Batch 61/169] [D loss: 0.552121] [G loss: 0.952070]\n",
      "[Epoch 10/200] [Batch 62/169] [D loss: 0.599063] [G loss: 0.727571]\n",
      "[Epoch 10/200] [Batch 63/169] [D loss: 0.543735] [G loss: 0.976724]\n",
      "[Epoch 10/200] [Batch 64/169] [D loss: 0.537595] [G loss: 0.936738]\n",
      "[Epoch 10/200] [Batch 65/169] [D loss: 0.587280] [G loss: 0.954002]\n",
      "[Epoch 10/200] [Batch 66/169] [D loss: 0.675365] [G loss: 0.944347]\n",
      "[Epoch 10/200] [Batch 67/169] [D loss: 0.582484] [G loss: 0.921548]\n",
      "[Epoch 10/200] [Batch 68/169] [D loss: 0.513787] [G loss: 0.887155]\n",
      "[Epoch 10/200] [Batch 69/169] [D loss: 0.743837] [G loss: 1.172657]\n",
      "[Epoch 10/200] [Batch 70/169] [D loss: 0.594131] [G loss: 1.077005]\n",
      "[Epoch 10/200] [Batch 71/169] [D loss: 0.712917] [G loss: 0.816985]\n",
      "[Epoch 10/200] [Batch 72/169] [D loss: 0.663565] [G loss: 1.017837]\n",
      "[Epoch 10/200] [Batch 73/169] [D loss: 0.581735] [G loss: 0.828357]\n",
      "[Epoch 10/200] [Batch 74/169] [D loss: 0.581605] [G loss: 0.864692]\n",
      "[Epoch 10/200] [Batch 75/169] [D loss: 0.633179] [G loss: 0.930034]\n",
      "[Epoch 10/200] [Batch 76/169] [D loss: 0.642442] [G loss: 0.950539]\n",
      "[Epoch 10/200] [Batch 77/169] [D loss: 0.534552] [G loss: 0.968074]\n",
      "[Epoch 10/200] [Batch 78/169] [D loss: 0.552492] [G loss: 0.982408]\n",
      "[Epoch 10/200] [Batch 79/169] [D loss: 0.593489] [G loss: 1.051470]\n",
      "[Epoch 10/200] [Batch 80/169] [D loss: 0.686690] [G loss: 0.868738]\n",
      "[Epoch 10/200] [Batch 81/169] [D loss: 0.618242] [G loss: 0.839421]\n",
      "[Epoch 10/200] [Batch 82/169] [D loss: 0.736823] [G loss: 0.952383]\n",
      "[Epoch 10/200] [Batch 83/169] [D loss: 0.653259] [G loss: 1.145297]\n",
      "[Epoch 10/200] [Batch 84/169] [D loss: 0.656487] [G loss: 0.814717]\n",
      "[Epoch 10/200] [Batch 85/169] [D loss: 0.603799] [G loss: 0.982269]\n",
      "[Epoch 10/200] [Batch 86/169] [D loss: 0.564255] [G loss: 0.810632]\n",
      "[Epoch 10/200] [Batch 87/169] [D loss: 0.632926] [G loss: 1.035111]\n",
      "[Epoch 10/200] [Batch 88/169] [D loss: 0.581274] [G loss: 0.846832]\n",
      "[Epoch 10/200] [Batch 89/169] [D loss: 0.588145] [G loss: 0.921499]\n",
      "[Epoch 10/200] [Batch 90/169] [D loss: 0.615229] [G loss: 0.978167]\n",
      "[Epoch 10/200] [Batch 91/169] [D loss: 0.645289] [G loss: 0.955800]\n",
      "[Epoch 10/200] [Batch 92/169] [D loss: 0.585327] [G loss: 0.898296]\n",
      "[Epoch 10/200] [Batch 93/169] [D loss: 0.656283] [G loss: 0.870209]\n",
      "[Epoch 10/200] [Batch 94/169] [D loss: 0.560396] [G loss: 0.969664]\n",
      "[Epoch 10/200] [Batch 95/169] [D loss: 0.630547] [G loss: 0.803332]\n",
      "[Epoch 10/200] [Batch 96/169] [D loss: 0.553100] [G loss: 0.961473]\n",
      "[Epoch 10/200] [Batch 97/169] [D loss: 0.640561] [G loss: 0.825667]\n",
      "[Epoch 10/200] [Batch 98/169] [D loss: 0.662541] [G loss: 0.849361]\n",
      "[Epoch 10/200] [Batch 99/169] [D loss: 0.677750] [G loss: 0.819064]\n",
      "[Epoch 10/200] [Batch 100/169] [D loss: 0.674457] [G loss: 0.946423]\n",
      "[Epoch 10/200] [Batch 101/169] [D loss: 0.741086] [G loss: 1.037369]\n",
      "[Epoch 10/200] [Batch 102/169] [D loss: 0.670672] [G loss: 0.993767]\n",
      "[Epoch 10/200] [Batch 103/169] [D loss: 0.613508] [G loss: 0.966148]\n",
      "[Epoch 10/200] [Batch 104/169] [D loss: 0.601123] [G loss: 0.948778]\n",
      "[Epoch 10/200] [Batch 105/169] [D loss: 0.576569] [G loss: 0.972985]\n",
      "[Epoch 10/200] [Batch 106/169] [D loss: 0.566290] [G loss: 0.751602]\n",
      "[Epoch 10/200] [Batch 107/169] [D loss: 0.642359] [G loss: 1.004593]\n",
      "[Epoch 10/200] [Batch 108/169] [D loss: 0.557693] [G loss: 0.954507]\n",
      "[Epoch 10/200] [Batch 109/169] [D loss: 0.593531] [G loss: 0.955271]\n",
      "[Epoch 10/200] [Batch 110/169] [D loss: 0.564488] [G loss: 1.004997]\n",
      "[Epoch 10/200] [Batch 111/169] [D loss: 0.682779] [G loss: 0.953468]\n",
      "[Epoch 10/200] [Batch 112/169] [D loss: 0.562874] [G loss: 1.005163]\n",
      "[Epoch 10/200] [Batch 113/169] [D loss: 0.594272] [G loss: 0.859023]\n",
      "[Epoch 10/200] [Batch 114/169] [D loss: 0.568519] [G loss: 0.840367]\n",
      "[Epoch 10/200] [Batch 115/169] [D loss: 0.572986] [G loss: 1.101685]\n",
      "[Epoch 10/200] [Batch 116/169] [D loss: 0.548212] [G loss: 1.000277]\n",
      "[Epoch 10/200] [Batch 117/169] [D loss: 0.608861] [G loss: 1.071044]\n",
      "[Epoch 10/200] [Batch 118/169] [D loss: 0.580190] [G loss: 0.986608]\n",
      "[Epoch 10/200] [Batch 119/169] [D loss: 0.520235] [G loss: 0.920340]\n",
      "[Epoch 10/200] [Batch 120/169] [D loss: 0.609351] [G loss: 0.937298]\n",
      "[Epoch 10/200] [Batch 121/169] [D loss: 0.590542] [G loss: 0.894543]\n",
      "[Epoch 10/200] [Batch 122/169] [D loss: 0.665146] [G loss: 0.797614]\n",
      "[Epoch 10/200] [Batch 123/169] [D loss: 0.525672] [G loss: 0.917262]\n",
      "[Epoch 10/200] [Batch 124/169] [D loss: 0.526672] [G loss: 0.895178]\n",
      "[Epoch 10/200] [Batch 125/169] [D loss: 0.698440] [G loss: 0.915748]\n",
      "[Epoch 10/200] [Batch 126/169] [D loss: 0.584286] [G loss: 1.116366]\n",
      "[Epoch 10/200] [Batch 127/169] [D loss: 0.571208] [G loss: 1.101000]\n",
      "[Epoch 10/200] [Batch 128/169] [D loss: 0.588193] [G loss: 0.888665]\n",
      "[Epoch 10/200] [Batch 129/169] [D loss: 0.569076] [G loss: 1.028142]\n",
      "[Epoch 10/200] [Batch 130/169] [D loss: 0.550539] [G loss: 0.727657]\n",
      "[Epoch 10/200] [Batch 131/169] [D loss: 0.650498] [G loss: 0.957917]\n",
      "[Epoch 10/200] [Batch 132/169] [D loss: 0.550722] [G loss: 1.050708]\n",
      "[Epoch 10/200] [Batch 133/169] [D loss: 0.584465] [G loss: 0.870732]\n",
      "[Epoch 10/200] [Batch 134/169] [D loss: 0.551948] [G loss: 0.977848]\n",
      "[Epoch 10/200] [Batch 135/169] [D loss: 0.596709] [G loss: 1.048710]\n",
      "[Epoch 10/200] [Batch 136/169] [D loss: 0.535752] [G loss: 1.229346]\n",
      "[Epoch 10/200] [Batch 137/169] [D loss: 0.527416] [G loss: 0.940291]\n",
      "[Epoch 10/200] [Batch 138/169] [D loss: 0.697857] [G loss: 0.876605]\n",
      "[Epoch 10/200] [Batch 139/169] [D loss: 0.563925] [G loss: 0.849700]\n",
      "[Epoch 10/200] [Batch 140/169] [D loss: 0.645781] [G loss: 1.155316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 141/169] [D loss: 0.579346] [G loss: 0.898047]\n",
      "[Epoch 10/200] [Batch 142/169] [D loss: 0.654112] [G loss: 0.899810]\n",
      "[Epoch 10/200] [Batch 143/169] [D loss: 0.637791] [G loss: 0.909244]\n",
      "[Epoch 10/200] [Batch 144/169] [D loss: 0.544880] [G loss: 0.887038]\n",
      "[Epoch 10/200] [Batch 145/169] [D loss: 0.665213] [G loss: 0.725723]\n",
      "[Epoch 10/200] [Batch 146/169] [D loss: 0.661739] [G loss: 0.979044]\n",
      "[Epoch 10/200] [Batch 147/169] [D loss: 0.633793] [G loss: 1.128516]\n",
      "[Epoch 10/200] [Batch 148/169] [D loss: 0.633695] [G loss: 1.171080]\n",
      "[Epoch 10/200] [Batch 149/169] [D loss: 0.598797] [G loss: 1.116326]\n",
      "[Epoch 10/200] [Batch 150/169] [D loss: 0.579470] [G loss: 0.881176]\n",
      "[Epoch 10/200] [Batch 151/169] [D loss: 0.677038] [G loss: 0.964827]\n",
      "[Epoch 10/200] [Batch 152/169] [D loss: 0.678473] [G loss: 0.941931]\n",
      "[Epoch 10/200] [Batch 153/169] [D loss: 0.560840] [G loss: 0.902677]\n",
      "[Epoch 10/200] [Batch 154/169] [D loss: 0.620159] [G loss: 0.906580]\n",
      "[Epoch 10/200] [Batch 155/169] [D loss: 0.646379] [G loss: 0.882521]\n",
      "[Epoch 10/200] [Batch 156/169] [D loss: 0.544906] [G loss: 0.927875]\n",
      "[Epoch 10/200] [Batch 157/169] [D loss: 0.568541] [G loss: 1.080277]\n",
      "[Epoch 10/200] [Batch 158/169] [D loss: 0.640153] [G loss: 1.014774]\n",
      "[Epoch 10/200] [Batch 159/169] [D loss: 0.576813] [G loss: 0.849016]\n",
      "[Epoch 10/200] [Batch 160/169] [D loss: 0.579162] [G loss: 0.757701]\n",
      "[Epoch 10/200] [Batch 161/169] [D loss: 0.529658] [G loss: 0.962077]\n",
      "[Epoch 10/200] [Batch 162/169] [D loss: 0.633368] [G loss: 0.971270]\n",
      "[Epoch 10/200] [Batch 163/169] [D loss: 0.582415] [G loss: 0.958263]\n",
      "[Epoch 10/200] [Batch 164/169] [D loss: 0.592441] [G loss: 0.826154]\n",
      "[Epoch 10/200] [Batch 165/169] [D loss: 0.542957] [G loss: 1.059733]\n",
      "[Epoch 10/200] [Batch 166/169] [D loss: 0.636491] [G loss: 0.988736]\n",
      "[Epoch 10/200] [Batch 167/169] [D loss: 0.602642] [G loss: 1.082564]\n",
      "[Epoch 10/200] [Batch 168/169] [D loss: 0.648312] [G loss: 0.909294]\n",
      "[Epoch 11/200] [Batch 0/169] [D loss: 0.582973] [G loss: 0.980311]\n",
      "[Epoch 11/200] [Batch 1/169] [D loss: 0.632689] [G loss: 0.878026]\n",
      "[Epoch 11/200] [Batch 2/169] [D loss: 0.615333] [G loss: 0.936562]\n",
      "[Epoch 11/200] [Batch 3/169] [D loss: 0.672419] [G loss: 0.928788]\n",
      "[Epoch 11/200] [Batch 4/169] [D loss: 0.593931] [G loss: 0.963106]\n",
      "[Epoch 11/200] [Batch 5/169] [D loss: 0.566199] [G loss: 0.906332]\n",
      "[Epoch 11/200] [Batch 6/169] [D loss: 0.664003] [G loss: 0.932008]\n",
      "[Epoch 11/200] [Batch 7/169] [D loss: 0.657201] [G loss: 0.946566]\n",
      "[Epoch 11/200] [Batch 8/169] [D loss: 0.589065] [G loss: 0.812693]\n",
      "[Epoch 11/200] [Batch 9/169] [D loss: 0.573812] [G loss: 0.791201]\n",
      "[Epoch 11/200] [Batch 10/169] [D loss: 0.583147] [G loss: 0.908193]\n",
      "[Epoch 11/200] [Batch 11/169] [D loss: 0.646919] [G loss: 1.069222]\n",
      "[Epoch 11/200] [Batch 12/169] [D loss: 0.520518] [G loss: 1.158737]\n",
      "[Epoch 11/200] [Batch 13/169] [D loss: 0.544400] [G loss: 1.004182]\n",
      "[Epoch 11/200] [Batch 14/169] [D loss: 0.581490] [G loss: 0.890204]\n",
      "[Epoch 11/200] [Batch 15/169] [D loss: 0.635296] [G loss: 0.967640]\n",
      "[Epoch 11/200] [Batch 16/169] [D loss: 0.636452] [G loss: 0.909912]\n",
      "[Epoch 11/200] [Batch 17/169] [D loss: 0.579465] [G loss: 1.203919]\n",
      "[Epoch 11/200] [Batch 18/169] [D loss: 0.574187] [G loss: 1.184112]\n",
      "[Epoch 11/200] [Batch 19/169] [D loss: 0.634933] [G loss: 1.137261]\n",
      "[Epoch 11/200] [Batch 20/169] [D loss: 0.590581] [G loss: 1.047428]\n",
      "[Epoch 11/200] [Batch 21/169] [D loss: 0.608998] [G loss: 0.939899]\n",
      "[Epoch 11/200] [Batch 22/169] [D loss: 0.484197] [G loss: 1.001537]\n",
      "[Epoch 11/200] [Batch 23/169] [D loss: 0.622087] [G loss: 0.797932]\n",
      "[Epoch 11/200] [Batch 24/169] [D loss: 0.607645] [G loss: 0.934917]\n",
      "[Epoch 11/200] [Batch 25/169] [D loss: 0.528680] [G loss: 1.010067]\n",
      "[Epoch 11/200] [Batch 26/169] [D loss: 0.622586] [G loss: 1.084435]\n",
      "[Epoch 11/200] [Batch 27/169] [D loss: 0.620846] [G loss: 0.813810]\n",
      "[Epoch 11/200] [Batch 28/169] [D loss: 0.677342] [G loss: 1.019627]\n",
      "[Epoch 11/200] [Batch 29/169] [D loss: 0.665405] [G loss: 0.913462]\n",
      "[Epoch 11/200] [Batch 30/169] [D loss: 0.589990] [G loss: 1.041152]\n",
      "[Epoch 11/200] [Batch 31/169] [D loss: 0.621507] [G loss: 0.902434]\n",
      "[Epoch 11/200] [Batch 32/169] [D loss: 0.640397] [G loss: 1.093093]\n",
      "[Epoch 11/200] [Batch 33/169] [D loss: 0.573802] [G loss: 1.045118]\n",
      "[Epoch 11/200] [Batch 34/169] [D loss: 0.616826] [G loss: 0.844920]\n",
      "[Epoch 11/200] [Batch 35/169] [D loss: 0.568179] [G loss: 0.861935]\n",
      "[Epoch 11/200] [Batch 36/169] [D loss: 0.616725] [G loss: 0.955781]\n",
      "[Epoch 11/200] [Batch 37/169] [D loss: 0.680279] [G loss: 0.876336]\n",
      "[Epoch 11/200] [Batch 38/169] [D loss: 0.580235] [G loss: 0.982821]\n",
      "[Epoch 11/200] [Batch 39/169] [D loss: 0.602601] [G loss: 1.042606]\n",
      "[Epoch 11/200] [Batch 40/169] [D loss: 0.590935] [G loss: 0.759413]\n",
      "[Epoch 11/200] [Batch 41/169] [D loss: 0.650322] [G loss: 0.936870]\n",
      "[Epoch 11/200] [Batch 42/169] [D loss: 0.602377] [G loss: 0.637587]\n",
      "[Epoch 11/200] [Batch 43/169] [D loss: 0.611988] [G loss: 0.797016]\n",
      "[Epoch 11/200] [Batch 44/169] [D loss: 0.586717] [G loss: 1.069794]\n",
      "[Epoch 11/200] [Batch 45/169] [D loss: 0.611459] [G loss: 1.070086]\n",
      "[Epoch 11/200] [Batch 46/169] [D loss: 0.617144] [G loss: 1.017205]\n",
      "[Epoch 11/200] [Batch 47/169] [D loss: 0.518093] [G loss: 0.919509]\n",
      "[Epoch 11/200] [Batch 48/169] [D loss: 0.673875] [G loss: 1.049628]\n",
      "[Epoch 11/200] [Batch 49/169] [D loss: 0.590534] [G loss: 1.106043]\n",
      "[Epoch 11/200] [Batch 50/169] [D loss: 0.679821] [G loss: 0.969696]\n",
      "[Epoch 11/200] [Batch 51/169] [D loss: 0.614930] [G loss: 0.933268]\n",
      "[Epoch 11/200] [Batch 52/169] [D loss: 0.694748] [G loss: 0.915557]\n",
      "[Epoch 11/200] [Batch 53/169] [D loss: 0.654830] [G loss: 0.916805]\n",
      "[Epoch 11/200] [Batch 54/169] [D loss: 0.590366] [G loss: 0.965165]\n",
      "[Epoch 11/200] [Batch 55/169] [D loss: 0.671086] [G loss: 0.879999]\n",
      "[Epoch 11/200] [Batch 56/169] [D loss: 0.609325] [G loss: 1.125356]\n",
      "[Epoch 11/200] [Batch 57/169] [D loss: 0.665138] [G loss: 0.971403]\n",
      "[Epoch 11/200] [Batch 58/169] [D loss: 0.554037] [G loss: 0.925473]\n",
      "[Epoch 11/200] [Batch 59/169] [D loss: 0.651058] [G loss: 0.910827]\n",
      "[Epoch 11/200] [Batch 60/169] [D loss: 0.580878] [G loss: 1.001907]\n",
      "[Epoch 11/200] [Batch 61/169] [D loss: 0.598791] [G loss: 1.113725]\n",
      "[Epoch 11/200] [Batch 62/169] [D loss: 0.600230] [G loss: 1.103305]\n",
      "[Epoch 11/200] [Batch 63/169] [D loss: 0.568609] [G loss: 0.896569]\n",
      "[Epoch 11/200] [Batch 64/169] [D loss: 0.576155] [G loss: 0.904360]\n",
      "[Epoch 11/200] [Batch 65/169] [D loss: 0.648991] [G loss: 0.991474]\n",
      "[Epoch 11/200] [Batch 66/169] [D loss: 0.550603] [G loss: 0.856747]\n",
      "[Epoch 11/200] [Batch 67/169] [D loss: 0.568998] [G loss: 1.013526]\n",
      "[Epoch 11/200] [Batch 68/169] [D loss: 0.701696] [G loss: 1.070913]\n",
      "[Epoch 11/200] [Batch 69/169] [D loss: 0.639751] [G loss: 0.946680]\n",
      "[Epoch 11/200] [Batch 70/169] [D loss: 0.598147] [G loss: 0.977078]\n",
      "[Epoch 11/200] [Batch 71/169] [D loss: 0.652187] [G loss: 0.831331]\n",
      "[Epoch 11/200] [Batch 72/169] [D loss: 0.471646] [G loss: 0.742768]\n",
      "[Epoch 11/200] [Batch 73/169] [D loss: 0.523808] [G loss: 0.796606]\n",
      "[Epoch 11/200] [Batch 74/169] [D loss: 0.564628] [G loss: 1.075163]\n",
      "[Epoch 11/200] [Batch 75/169] [D loss: 0.624488] [G loss: 1.012449]\n",
      "[Epoch 11/200] [Batch 76/169] [D loss: 0.562400] [G loss: 0.946200]\n",
      "[Epoch 11/200] [Batch 77/169] [D loss: 0.647495] [G loss: 0.967966]\n",
      "[Epoch 11/200] [Batch 78/169] [D loss: 0.607837] [G loss: 0.896321]\n",
      "[Epoch 11/200] [Batch 79/169] [D loss: 0.641596] [G loss: 0.696338]\n",
      "[Epoch 11/200] [Batch 80/169] [D loss: 0.605859] [G loss: 1.018907]\n",
      "[Epoch 11/200] [Batch 81/169] [D loss: 0.549221] [G loss: 1.040450]\n",
      "[Epoch 11/200] [Batch 82/169] [D loss: 0.523746] [G loss: 1.082512]\n",
      "[Epoch 11/200] [Batch 83/169] [D loss: 0.522374] [G loss: 1.051716]\n",
      "[Epoch 11/200] [Batch 84/169] [D loss: 0.573119] [G loss: 0.976906]\n",
      "[Epoch 11/200] [Batch 85/169] [D loss: 0.644753] [G loss: 0.910578]\n",
      "[Epoch 11/200] [Batch 86/169] [D loss: 0.526008] [G loss: 0.928512]\n",
      "[Epoch 11/200] [Batch 87/169] [D loss: 0.618339] [G loss: 0.927323]\n",
      "[Epoch 11/200] [Batch 88/169] [D loss: 0.668702] [G loss: 0.719381]\n",
      "[Epoch 11/200] [Batch 89/169] [D loss: 0.654375] [G loss: 0.793175]\n",
      "[Epoch 11/200] [Batch 90/169] [D loss: 0.654481] [G loss: 0.801994]\n",
      "[Epoch 11/200] [Batch 91/169] [D loss: 0.575045] [G loss: 1.034841]\n",
      "[Epoch 11/200] [Batch 92/169] [D loss: 0.651085] [G loss: 1.078762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 93/169] [D loss: 0.563833] [G loss: 1.089484]\n",
      "[Epoch 11/200] [Batch 94/169] [D loss: 0.689367] [G loss: 0.974366]\n",
      "[Epoch 11/200] [Batch 95/169] [D loss: 0.605530] [G loss: 0.878884]\n",
      "[Epoch 11/200] [Batch 96/169] [D loss: 0.608812] [G loss: 0.817585]\n",
      "[Epoch 11/200] [Batch 97/169] [D loss: 0.590098] [G loss: 0.950027]\n",
      "[Epoch 11/200] [Batch 98/169] [D loss: 0.628743] [G loss: 0.896316]\n",
      "[Epoch 11/200] [Batch 99/169] [D loss: 0.595857] [G loss: 0.801325]\n",
      "[Epoch 11/200] [Batch 100/169] [D loss: 0.588855] [G loss: 0.893742]\n",
      "[Epoch 11/200] [Batch 101/169] [D loss: 0.618379] [G loss: 1.077739]\n",
      "[Epoch 11/200] [Batch 102/169] [D loss: 0.541202] [G loss: 0.935772]\n",
      "[Epoch 11/200] [Batch 103/169] [D loss: 0.589453] [G loss: 1.027929]\n",
      "[Epoch 11/200] [Batch 104/169] [D loss: 0.595977] [G loss: 0.867857]\n",
      "[Epoch 11/200] [Batch 105/169] [D loss: 0.566805] [G loss: 0.895081]\n",
      "[Epoch 11/200] [Batch 106/169] [D loss: 0.619546] [G loss: 0.870927]\n",
      "[Epoch 11/200] [Batch 107/169] [D loss: 0.634545] [G loss: 0.777735]\n",
      "[Epoch 11/200] [Batch 108/169] [D loss: 0.552098] [G loss: 0.902897]\n",
      "[Epoch 11/200] [Batch 109/169] [D loss: 0.592886] [G loss: 0.789767]\n",
      "[Epoch 11/200] [Batch 110/169] [D loss: 0.619533] [G loss: 0.892245]\n",
      "[Epoch 11/200] [Batch 111/169] [D loss: 0.618449] [G loss: 0.819527]\n",
      "[Epoch 11/200] [Batch 112/169] [D loss: 0.486928] [G loss: 0.908213]\n",
      "[Epoch 11/200] [Batch 113/169] [D loss: 0.635770] [G loss: 1.140427]\n",
      "[Epoch 11/200] [Batch 114/169] [D loss: 0.665805] [G loss: 0.964372]\n",
      "[Epoch 11/200] [Batch 115/169] [D loss: 0.593698] [G loss: 0.993346]\n",
      "[Epoch 11/200] [Batch 116/169] [D loss: 0.544126] [G loss: 0.848241]\n",
      "[Epoch 11/200] [Batch 117/169] [D loss: 0.606426] [G loss: 0.762323]\n",
      "[Epoch 11/200] [Batch 118/169] [D loss: 0.563957] [G loss: 1.058137]\n",
      "[Epoch 11/200] [Batch 119/169] [D loss: 0.664003] [G loss: 1.005923]\n",
      "[Epoch 11/200] [Batch 120/169] [D loss: 0.566525] [G loss: 0.839447]\n",
      "[Epoch 11/200] [Batch 121/169] [D loss: 0.598911] [G loss: 0.890059]\n",
      "[Epoch 11/200] [Batch 122/169] [D loss: 0.537291] [G loss: 0.945681]\n",
      "[Epoch 11/200] [Batch 123/169] [D loss: 0.526362] [G loss: 1.003916]\n",
      "[Epoch 11/200] [Batch 124/169] [D loss: 0.579337] [G loss: 0.892420]\n",
      "[Epoch 11/200] [Batch 125/169] [D loss: 0.614628] [G loss: 0.809235]\n",
      "[Epoch 11/200] [Batch 126/169] [D loss: 0.690361] [G loss: 1.041617]\n",
      "[Epoch 11/200] [Batch 127/169] [D loss: 0.570503] [G loss: 0.942440]\n",
      "[Epoch 11/200] [Batch 128/169] [D loss: 0.564867] [G loss: 0.960701]\n",
      "[Epoch 11/200] [Batch 129/169] [D loss: 0.564371] [G loss: 0.792305]\n",
      "[Epoch 11/200] [Batch 130/169] [D loss: 0.602026] [G loss: 0.872133]\n",
      "[Epoch 11/200] [Batch 131/169] [D loss: 0.580462] [G loss: 0.843111]\n",
      "[Epoch 11/200] [Batch 132/169] [D loss: 0.516383] [G loss: 0.915893]\n",
      "[Epoch 11/200] [Batch 133/169] [D loss: 0.631145] [G loss: 0.855627]\n",
      "[Epoch 11/200] [Batch 134/169] [D loss: 0.533607] [G loss: 0.778301]\n",
      "[Epoch 11/200] [Batch 135/169] [D loss: 0.681811] [G loss: 1.183084]\n",
      "[Epoch 11/200] [Batch 136/169] [D loss: 0.586145] [G loss: 1.026927]\n",
      "[Epoch 11/200] [Batch 137/169] [D loss: 0.574004] [G loss: 1.073299]\n",
      "[Epoch 11/200] [Batch 138/169] [D loss: 0.546701] [G loss: 1.044044]\n",
      "[Epoch 11/200] [Batch 139/169] [D loss: 0.562148] [G loss: 1.111225]\n",
      "[Epoch 11/200] [Batch 140/169] [D loss: 0.622148] [G loss: 0.846833]\n",
      "[Epoch 11/200] [Batch 141/169] [D loss: 0.544771] [G loss: 0.910804]\n",
      "[Epoch 11/200] [Batch 142/169] [D loss: 0.634941] [G loss: 1.079739]\n",
      "[Epoch 11/200] [Batch 143/169] [D loss: 0.598120] [G loss: 0.829804]\n",
      "[Epoch 11/200] [Batch 144/169] [D loss: 0.603424] [G loss: 0.855932]\n",
      "[Epoch 11/200] [Batch 145/169] [D loss: 0.563828] [G loss: 0.870078]\n",
      "[Epoch 11/200] [Batch 146/169] [D loss: 0.605801] [G loss: 0.914785]\n",
      "[Epoch 11/200] [Batch 147/169] [D loss: 0.642606] [G loss: 0.818145]\n",
      "[Epoch 11/200] [Batch 148/169] [D loss: 0.590716] [G loss: 0.870848]\n",
      "[Epoch 11/200] [Batch 149/169] [D loss: 0.596384] [G loss: 0.830890]\n",
      "[Epoch 11/200] [Batch 150/169] [D loss: 0.611095] [G loss: 0.922925]\n",
      "[Epoch 11/200] [Batch 151/169] [D loss: 0.535127] [G loss: 1.000639]\n",
      "[Epoch 11/200] [Batch 152/169] [D loss: 0.587363] [G loss: 0.956457]\n",
      "[Epoch 11/200] [Batch 153/169] [D loss: 0.575695] [G loss: 1.114658]\n",
      "[Epoch 11/200] [Batch 154/169] [D loss: 0.567597] [G loss: 1.145004]\n",
      "[Epoch 11/200] [Batch 155/169] [D loss: 0.612874] [G loss: 1.055534]\n",
      "[Epoch 11/200] [Batch 156/169] [D loss: 0.536603] [G loss: 0.719746]\n",
      "[Epoch 11/200] [Batch 157/169] [D loss: 0.588360] [G loss: 0.805914]\n",
      "[Epoch 11/200] [Batch 158/169] [D loss: 0.626308] [G loss: 0.908517]\n",
      "[Epoch 11/200] [Batch 159/169] [D loss: 0.672253] [G loss: 0.994239]\n",
      "[Epoch 11/200] [Batch 160/169] [D loss: 0.633340] [G loss: 0.758950]\n",
      "[Epoch 11/200] [Batch 161/169] [D loss: 0.619299] [G loss: 0.900468]\n",
      "[Epoch 11/200] [Batch 162/169] [D loss: 0.557444] [G loss: 1.149504]\n",
      "[Epoch 11/200] [Batch 163/169] [D loss: 0.604914] [G loss: 1.081300]\n",
      "[Epoch 11/200] [Batch 164/169] [D loss: 0.612319] [G loss: 1.033152]\n",
      "[Epoch 11/200] [Batch 165/169] [D loss: 0.542935] [G loss: 0.911201]\n",
      "[Epoch 11/200] [Batch 166/169] [D loss: 0.558846] [G loss: 0.875997]\n",
      "[Epoch 11/200] [Batch 167/169] [D loss: 0.511385] [G loss: 1.074523]\n",
      "[Epoch 11/200] [Batch 168/169] [D loss: 0.721623] [G loss: 0.931322]\n",
      "[Epoch 12/200] [Batch 0/169] [D loss: 0.621500] [G loss: 0.734239]\n",
      "[Epoch 12/200] [Batch 1/169] [D loss: 0.592228] [G loss: 1.031099]\n",
      "[Epoch 12/200] [Batch 2/169] [D loss: 0.635997] [G loss: 0.971162]\n",
      "[Epoch 12/200] [Batch 3/169] [D loss: 0.645436] [G loss: 1.125348]\n",
      "[Epoch 12/200] [Batch 4/169] [D loss: 0.605203] [G loss: 0.979898]\n",
      "[Epoch 12/200] [Batch 5/169] [D loss: 0.645931] [G loss: 0.914618]\n",
      "[Epoch 12/200] [Batch 6/169] [D loss: 0.562163] [G loss: 0.905354]\n",
      "[Epoch 12/200] [Batch 7/169] [D loss: 0.711969] [G loss: 0.717130]\n",
      "[Epoch 12/200] [Batch 8/169] [D loss: 0.651621] [G loss: 0.834416]\n",
      "[Epoch 12/200] [Batch 9/169] [D loss: 0.579797] [G loss: 0.881978]\n",
      "[Epoch 12/200] [Batch 10/169] [D loss: 0.692200] [G loss: 0.997535]\n",
      "[Epoch 12/200] [Batch 11/169] [D loss: 0.591184] [G loss: 0.777446]\n",
      "[Epoch 12/200] [Batch 12/169] [D loss: 0.595866] [G loss: 0.804449]\n",
      "[Epoch 12/200] [Batch 13/169] [D loss: 0.673727] [G loss: 1.086254]\n",
      "[Epoch 12/200] [Batch 14/169] [D loss: 0.677608] [G loss: 0.904306]\n",
      "[Epoch 12/200] [Batch 15/169] [D loss: 0.620659] [G loss: 1.001908]\n",
      "[Epoch 12/200] [Batch 16/169] [D loss: 0.664628] [G loss: 0.865236]\n",
      "[Epoch 12/200] [Batch 17/169] [D loss: 0.554603] [G loss: 0.845265]\n",
      "[Epoch 12/200] [Batch 18/169] [D loss: 0.528364] [G loss: 0.801447]\n",
      "[Epoch 12/200] [Batch 19/169] [D loss: 0.526736] [G loss: 0.879811]\n",
      "[Epoch 12/200] [Batch 20/169] [D loss: 0.679317] [G loss: 1.115025]\n",
      "[Epoch 12/200] [Batch 21/169] [D loss: 0.720856] [G loss: 0.760097]\n",
      "[Epoch 12/200] [Batch 22/169] [D loss: 0.584312] [G loss: 0.768147]\n",
      "[Epoch 12/200] [Batch 23/169] [D loss: 0.547900] [G loss: 1.100556]\n",
      "[Epoch 12/200] [Batch 24/169] [D loss: 0.617572] [G loss: 0.957544]\n",
      "[Epoch 12/200] [Batch 25/169] [D loss: 0.572975] [G loss: 0.834825]\n",
      "[Epoch 12/200] [Batch 26/169] [D loss: 0.636878] [G loss: 0.792360]\n",
      "[Epoch 12/200] [Batch 27/169] [D loss: 0.564992] [G loss: 0.951133]\n",
      "[Epoch 12/200] [Batch 28/169] [D loss: 0.632291] [G loss: 1.231883]\n",
      "[Epoch 12/200] [Batch 29/169] [D loss: 0.570547] [G loss: 0.935040]\n",
      "[Epoch 12/200] [Batch 30/169] [D loss: 0.606030] [G loss: 0.887633]\n",
      "[Epoch 12/200] [Batch 31/169] [D loss: 0.573711] [G loss: 0.931009]\n",
      "[Epoch 12/200] [Batch 32/169] [D loss: 0.610307] [G loss: 0.754474]\n",
      "[Epoch 12/200] [Batch 33/169] [D loss: 0.629975] [G loss: 0.893876]\n",
      "[Epoch 12/200] [Batch 34/169] [D loss: 0.499671] [G loss: 1.035684]\n",
      "[Epoch 12/200] [Batch 35/169] [D loss: 0.556200] [G loss: 1.072107]\n",
      "[Epoch 12/200] [Batch 36/169] [D loss: 0.589482] [G loss: 1.202101]\n",
      "[Epoch 12/200] [Batch 37/169] [D loss: 0.547504] [G loss: 0.909454]\n",
      "[Epoch 12/200] [Batch 38/169] [D loss: 0.579525] [G loss: 0.883553]\n",
      "[Epoch 12/200] [Batch 39/169] [D loss: 0.660473] [G loss: 0.803421]\n",
      "[Epoch 12/200] [Batch 40/169] [D loss: 0.620770] [G loss: 0.845728]\n",
      "[Epoch 12/200] [Batch 41/169] [D loss: 0.654243] [G loss: 0.845254]\n",
      "[Epoch 12/200] [Batch 42/169] [D loss: 0.536340] [G loss: 0.859081]\n",
      "[Epoch 12/200] [Batch 43/169] [D loss: 0.614816] [G loss: 0.788247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 44/169] [D loss: 0.603426] [G loss: 0.859030]\n",
      "[Epoch 12/200] [Batch 45/169] [D loss: 0.621243] [G loss: 0.908022]\n",
      "[Epoch 12/200] [Batch 46/169] [D loss: 0.664602] [G loss: 0.936659]\n",
      "[Epoch 12/200] [Batch 47/169] [D loss: 0.568203] [G loss: 0.993611]\n",
      "[Epoch 12/200] [Batch 48/169] [D loss: 0.583457] [G loss: 1.245922]\n",
      "[Epoch 12/200] [Batch 49/169] [D loss: 0.611178] [G loss: 1.023442]\n",
      "[Epoch 12/200] [Batch 50/169] [D loss: 0.585695] [G loss: 1.024648]\n",
      "[Epoch 12/200] [Batch 51/169] [D loss: 0.516833] [G loss: 0.863027]\n",
      "[Epoch 12/200] [Batch 52/169] [D loss: 0.636733] [G loss: 1.039314]\n",
      "[Epoch 12/200] [Batch 53/169] [D loss: 0.591792] [G loss: 0.953152]\n",
      "[Epoch 12/200] [Batch 54/169] [D loss: 0.582079] [G loss: 0.960343]\n",
      "[Epoch 12/200] [Batch 55/169] [D loss: 0.687274] [G loss: 0.962222]\n",
      "[Epoch 12/200] [Batch 56/169] [D loss: 0.572051] [G loss: 1.067576]\n",
      "[Epoch 12/200] [Batch 57/169] [D loss: 0.582387] [G loss: 0.886306]\n",
      "[Epoch 12/200] [Batch 58/169] [D loss: 0.557061] [G loss: 0.871839]\n",
      "[Epoch 12/200] [Batch 59/169] [D loss: 0.504804] [G loss: 0.907209]\n",
      "[Epoch 12/200] [Batch 60/169] [D loss: 0.585570] [G loss: 0.916436]\n",
      "[Epoch 12/200] [Batch 61/169] [D loss: 0.544950] [G loss: 0.884582]\n",
      "[Epoch 12/200] [Batch 62/169] [D loss: 0.607717] [G loss: 0.787881]\n",
      "[Epoch 12/200] [Batch 63/169] [D loss: 0.673075] [G loss: 0.801527]\n",
      "[Epoch 12/200] [Batch 64/169] [D loss: 0.629727] [G loss: 0.903189]\n",
      "[Epoch 12/200] [Batch 65/169] [D loss: 0.644207] [G loss: 1.012758]\n",
      "[Epoch 12/200] [Batch 66/169] [D loss: 0.628418] [G loss: 0.775174]\n",
      "[Epoch 12/200] [Batch 67/169] [D loss: 0.582401] [G loss: 0.861990]\n",
      "[Epoch 12/200] [Batch 68/169] [D loss: 0.675827] [G loss: 0.949584]\n",
      "[Epoch 12/200] [Batch 69/169] [D loss: 0.582490] [G loss: 0.885757]\n",
      "[Epoch 12/200] [Batch 70/169] [D loss: 0.605327] [G loss: 0.980172]\n",
      "[Epoch 12/200] [Batch 71/169] [D loss: 0.594529] [G loss: 0.997510]\n",
      "[Epoch 12/200] [Batch 72/169] [D loss: 0.653617] [G loss: 1.040433]\n",
      "[Epoch 12/200] [Batch 73/169] [D loss: 0.600935] [G loss: 1.135762]\n",
      "[Epoch 12/200] [Batch 74/169] [D loss: 0.529394] [G loss: 0.873786]\n",
      "[Epoch 12/200] [Batch 75/169] [D loss: 0.662071] [G loss: 0.975818]\n",
      "[Epoch 12/200] [Batch 76/169] [D loss: 0.565869] [G loss: 0.902382]\n",
      "[Epoch 12/200] [Batch 77/169] [D loss: 0.623534] [G loss: 1.142581]\n",
      "[Epoch 12/200] [Batch 78/169] [D loss: 0.560640] [G loss: 1.068338]\n",
      "[Epoch 12/200] [Batch 79/169] [D loss: 0.602998] [G loss: 1.019379]\n",
      "[Epoch 12/200] [Batch 80/169] [D loss: 0.575716] [G loss: 0.989642]\n",
      "[Epoch 12/200] [Batch 81/169] [D loss: 0.697020] [G loss: 0.839650]\n",
      "[Epoch 12/200] [Batch 82/169] [D loss: 0.644153] [G loss: 0.968139]\n",
      "[Epoch 12/200] [Batch 83/169] [D loss: 0.676106] [G loss: 0.951409]\n",
      "[Epoch 12/200] [Batch 84/169] [D loss: 0.553195] [G loss: 0.764040]\n",
      "[Epoch 12/200] [Batch 85/169] [D loss: 0.711117] [G loss: 1.047137]\n",
      "[Epoch 12/200] [Batch 86/169] [D loss: 0.568192] [G loss: 1.013548]\n",
      "[Epoch 12/200] [Batch 87/169] [D loss: 0.573377] [G loss: 0.924261]\n",
      "[Epoch 12/200] [Batch 88/169] [D loss: 0.689909] [G loss: 1.015596]\n",
      "[Epoch 12/200] [Batch 89/169] [D loss: 0.671353] [G loss: 0.884978]\n",
      "[Epoch 12/200] [Batch 90/169] [D loss: 0.625613] [G loss: 0.948381]\n",
      "[Epoch 12/200] [Batch 91/169] [D loss: 0.624275] [G loss: 0.893560]\n",
      "[Epoch 12/200] [Batch 92/169] [D loss: 0.628937] [G loss: 0.737493]\n",
      "[Epoch 12/200] [Batch 93/169] [D loss: 0.553707] [G loss: 0.785347]\n",
      "[Epoch 12/200] [Batch 94/169] [D loss: 0.635501] [G loss: 0.860288]\n",
      "[Epoch 12/200] [Batch 95/169] [D loss: 0.620909] [G loss: 0.869426]\n",
      "[Epoch 12/200] [Batch 96/169] [D loss: 0.600235] [G loss: 1.126348]\n",
      "[Epoch 12/200] [Batch 97/169] [D loss: 0.633177] [G loss: 1.039950]\n",
      "[Epoch 12/200] [Batch 98/169] [D loss: 0.566575] [G loss: 0.749272]\n",
      "[Epoch 12/200] [Batch 99/169] [D loss: 0.589105] [G loss: 0.773713]\n",
      "[Epoch 12/200] [Batch 100/169] [D loss: 0.572838] [G loss: 0.799217]\n",
      "[Epoch 12/200] [Batch 101/169] [D loss: 0.619291] [G loss: 0.966898]\n",
      "[Epoch 12/200] [Batch 102/169] [D loss: 0.603228] [G loss: 0.880396]\n",
      "[Epoch 12/200] [Batch 103/169] [D loss: 0.597897] [G loss: 0.880158]\n",
      "[Epoch 12/200] [Batch 104/169] [D loss: 0.536235] [G loss: 0.853606]\n",
      "[Epoch 12/200] [Batch 105/169] [D loss: 0.698599] [G loss: 0.812967]\n",
      "[Epoch 12/200] [Batch 106/169] [D loss: 0.612838] [G loss: 0.770462]\n",
      "[Epoch 12/200] [Batch 107/169] [D loss: 0.665897] [G loss: 0.914415]\n",
      "[Epoch 12/200] [Batch 108/169] [D loss: 0.677030] [G loss: 0.852752]\n",
      "[Epoch 12/200] [Batch 109/169] [D loss: 0.639393] [G loss: 0.839651]\n",
      "[Epoch 12/200] [Batch 110/169] [D loss: 0.586133] [G loss: 0.847564]\n",
      "[Epoch 12/200] [Batch 111/169] [D loss: 0.698565] [G loss: 1.038991]\n",
      "[Epoch 12/200] [Batch 112/169] [D loss: 0.507255] [G loss: 0.914396]\n",
      "[Epoch 12/200] [Batch 113/169] [D loss: 0.495041] [G loss: 0.960816]\n",
      "[Epoch 12/200] [Batch 114/169] [D loss: 0.539783] [G loss: 0.953101]\n",
      "[Epoch 12/200] [Batch 115/169] [D loss: 0.579230] [G loss: 0.790336]\n",
      "[Epoch 12/200] [Batch 116/169] [D loss: 0.619175] [G loss: 0.896249]\n",
      "[Epoch 12/200] [Batch 117/169] [D loss: 0.643441] [G loss: 0.850581]\n",
      "[Epoch 12/200] [Batch 118/169] [D loss: 0.604353] [G loss: 0.908670]\n",
      "[Epoch 12/200] [Batch 119/169] [D loss: 0.618869] [G loss: 0.862677]\n",
      "[Epoch 12/200] [Batch 120/169] [D loss: 0.639856] [G loss: 0.965326]\n",
      "[Epoch 12/200] [Batch 121/169] [D loss: 0.561378] [G loss: 1.036562]\n",
      "[Epoch 12/200] [Batch 122/169] [D loss: 0.613105] [G loss: 0.966596]\n",
      "[Epoch 12/200] [Batch 123/169] [D loss: 0.593456] [G loss: 0.843026]\n",
      "[Epoch 12/200] [Batch 124/169] [D loss: 0.684143] [G loss: 0.904083]\n",
      "[Epoch 12/200] [Batch 125/169] [D loss: 0.683663] [G loss: 0.920739]\n",
      "[Epoch 12/200] [Batch 126/169] [D loss: 0.620887] [G loss: 1.107014]\n",
      "[Epoch 12/200] [Batch 127/169] [D loss: 0.639865] [G loss: 0.812417]\n",
      "[Epoch 12/200] [Batch 128/169] [D loss: 0.701120] [G loss: 0.747138]\n",
      "[Epoch 12/200] [Batch 129/169] [D loss: 0.564436] [G loss: 0.750329]\n",
      "[Epoch 12/200] [Batch 130/169] [D loss: 0.615264] [G loss: 0.975783]\n",
      "[Epoch 12/200] [Batch 131/169] [D loss: 0.585333] [G loss: 0.943316]\n",
      "[Epoch 12/200] [Batch 132/169] [D loss: 0.625699] [G loss: 1.121919]\n",
      "[Epoch 12/200] [Batch 133/169] [D loss: 0.619760] [G loss: 0.734490]\n",
      "[Epoch 12/200] [Batch 134/169] [D loss: 0.533296] [G loss: 0.752025]\n",
      "[Epoch 12/200] [Batch 135/169] [D loss: 0.670708] [G loss: 0.799414]\n",
      "[Epoch 12/200] [Batch 136/169] [D loss: 0.629427] [G loss: 1.006087]\n",
      "[Epoch 12/200] [Batch 137/169] [D loss: 0.684667] [G loss: 0.925379]\n",
      "[Epoch 12/200] [Batch 138/169] [D loss: 0.613433] [G loss: 0.848079]\n",
      "[Epoch 12/200] [Batch 139/169] [D loss: 0.564183] [G loss: 0.792682]\n",
      "[Epoch 12/200] [Batch 140/169] [D loss: 0.607665] [G loss: 0.925947]\n",
      "[Epoch 12/200] [Batch 141/169] [D loss: 0.600862] [G loss: 0.943764]\n",
      "[Epoch 12/200] [Batch 142/169] [D loss: 0.669292] [G loss: 0.850640]\n",
      "[Epoch 12/200] [Batch 143/169] [D loss: 0.606759] [G loss: 0.975283]\n",
      "[Epoch 12/200] [Batch 144/169] [D loss: 0.638774] [G loss: 0.947946]\n",
      "[Epoch 12/200] [Batch 145/169] [D loss: 0.602534] [G loss: 1.049627]\n",
      "[Epoch 12/200] [Batch 146/169] [D loss: 0.647258] [G loss: 0.935671]\n",
      "[Epoch 12/200] [Batch 147/169] [D loss: 0.534548] [G loss: 0.931101]\n",
      "[Epoch 12/200] [Batch 148/169] [D loss: 0.626862] [G loss: 0.919305]\n",
      "[Epoch 12/200] [Batch 149/169] [D loss: 0.623480] [G loss: 0.873049]\n",
      "[Epoch 12/200] [Batch 150/169] [D loss: 0.696357] [G loss: 0.999837]\n",
      "[Epoch 12/200] [Batch 151/169] [D loss: 0.582178] [G loss: 0.948200]\n",
      "[Epoch 12/200] [Batch 152/169] [D loss: 0.592716] [G loss: 1.072108]\n",
      "[Epoch 12/200] [Batch 153/169] [D loss: 0.562767] [G loss: 0.889645]\n",
      "[Epoch 12/200] [Batch 154/169] [D loss: 0.597891] [G loss: 0.918105]\n",
      "[Epoch 12/200] [Batch 155/169] [D loss: 0.615141] [G loss: 0.842185]\n",
      "[Epoch 12/200] [Batch 156/169] [D loss: 0.673087] [G loss: 0.908976]\n",
      "[Epoch 12/200] [Batch 157/169] [D loss: 0.587968] [G loss: 1.007398]\n",
      "[Epoch 12/200] [Batch 158/169] [D loss: 0.564263] [G loss: 0.994374]\n",
      "[Epoch 12/200] [Batch 159/169] [D loss: 0.552910] [G loss: 0.780298]\n",
      "[Epoch 12/200] [Batch 160/169] [D loss: 0.553126] [G loss: 0.787775]\n",
      "[Epoch 12/200] [Batch 161/169] [D loss: 0.616093] [G loss: 0.910540]\n",
      "[Epoch 12/200] [Batch 162/169] [D loss: 0.587959] [G loss: 0.756447]\n",
      "[Epoch 12/200] [Batch 163/169] [D loss: 0.717427] [G loss: 0.837148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 164/169] [D loss: 0.714342] [G loss: 0.902528]\n",
      "[Epoch 12/200] [Batch 165/169] [D loss: 0.603410] [G loss: 0.878256]\n",
      "[Epoch 12/200] [Batch 166/169] [D loss: 0.651597] [G loss: 0.884645]\n",
      "[Epoch 12/200] [Batch 167/169] [D loss: 0.615439] [G loss: 0.741972]\n",
      "[Epoch 12/200] [Batch 168/169] [D loss: 0.600984] [G loss: 1.017509]\n",
      "[Epoch 13/200] [Batch 0/169] [D loss: 0.749913] [G loss: 0.866154]\n",
      "[Epoch 13/200] [Batch 1/169] [D loss: 0.624972] [G loss: 0.946752]\n",
      "[Epoch 13/200] [Batch 2/169] [D loss: 0.622375] [G loss: 0.935049]\n",
      "[Epoch 13/200] [Batch 3/169] [D loss: 0.661738] [G loss: 0.826743]\n",
      "[Epoch 13/200] [Batch 4/169] [D loss: 0.708712] [G loss: 1.002552]\n",
      "[Epoch 13/200] [Batch 5/169] [D loss: 0.659987] [G loss: 0.972229]\n",
      "[Epoch 13/200] [Batch 6/169] [D loss: 0.619413] [G loss: 0.855662]\n",
      "[Epoch 13/200] [Batch 7/169] [D loss: 0.639369] [G loss: 0.812743]\n",
      "[Epoch 13/200] [Batch 8/169] [D loss: 0.538804] [G loss: 0.918076]\n",
      "[Epoch 13/200] [Batch 9/169] [D loss: 0.600009] [G loss: 0.750430]\n",
      "[Epoch 13/200] [Batch 10/169] [D loss: 0.644414] [G loss: 1.201135]\n",
      "[Epoch 13/200] [Batch 11/169] [D loss: 0.600397] [G loss: 1.017478]\n",
      "[Epoch 13/200] [Batch 12/169] [D loss: 0.576025] [G loss: 0.922199]\n",
      "[Epoch 13/200] [Batch 13/169] [D loss: 0.610654] [G loss: 0.910174]\n",
      "[Epoch 13/200] [Batch 14/169] [D loss: 0.515953] [G loss: 0.756279]\n",
      "[Epoch 13/200] [Batch 15/169] [D loss: 0.594521] [G loss: 0.916194]\n",
      "[Epoch 13/200] [Batch 16/169] [D loss: 0.637621] [G loss: 0.993877]\n",
      "[Epoch 13/200] [Batch 17/169] [D loss: 0.635353] [G loss: 0.853642]\n",
      "[Epoch 13/200] [Batch 18/169] [D loss: 0.630190] [G loss: 0.834992]\n",
      "[Epoch 13/200] [Batch 19/169] [D loss: 0.525923] [G loss: 0.838400]\n",
      "[Epoch 13/200] [Batch 20/169] [D loss: 0.578040] [G loss: 0.849751]\n",
      "[Epoch 13/200] [Batch 21/169] [D loss: 0.651277] [G loss: 0.669686]\n",
      "[Epoch 13/200] [Batch 22/169] [D loss: 0.586035] [G loss: 1.103770]\n",
      "[Epoch 13/200] [Batch 23/169] [D loss: 0.662887] [G loss: 1.109499]\n",
      "[Epoch 13/200] [Batch 24/169] [D loss: 0.648331] [G loss: 1.034384]\n",
      "[Epoch 13/200] [Batch 25/169] [D loss: 0.591133] [G loss: 1.059490]\n",
      "[Epoch 13/200] [Batch 26/169] [D loss: 0.605366] [G loss: 0.986043]\n",
      "[Epoch 13/200] [Batch 27/169] [D loss: 0.573407] [G loss: 0.941016]\n",
      "[Epoch 13/200] [Batch 28/169] [D loss: 0.635966] [G loss: 0.879792]\n",
      "[Epoch 13/200] [Batch 29/169] [D loss: 0.608073] [G loss: 0.866822]\n",
      "[Epoch 13/200] [Batch 30/169] [D loss: 0.583073] [G loss: 0.880499]\n",
      "[Epoch 13/200] [Batch 31/169] [D loss: 0.685520] [G loss: 0.910476]\n",
      "[Epoch 13/200] [Batch 32/169] [D loss: 0.596560] [G loss: 0.911733]\n",
      "[Epoch 13/200] [Batch 33/169] [D loss: 0.537734] [G loss: 0.837709]\n",
      "[Epoch 13/200] [Batch 34/169] [D loss: 0.602190] [G loss: 1.010916]\n",
      "[Epoch 13/200] [Batch 35/169] [D loss: 0.521050] [G loss: 0.897059]\n",
      "[Epoch 13/200] [Batch 36/169] [D loss: 0.615878] [G loss: 0.848103]\n",
      "[Epoch 13/200] [Batch 37/169] [D loss: 0.657768] [G loss: 0.722401]\n",
      "[Epoch 13/200] [Batch 38/169] [D loss: 0.671559] [G loss: 1.000922]\n",
      "[Epoch 13/200] [Batch 39/169] [D loss: 0.610826] [G loss: 0.904467]\n",
      "[Epoch 13/200] [Batch 40/169] [D loss: 0.662077] [G loss: 0.964130]\n",
      "[Epoch 13/200] [Batch 41/169] [D loss: 0.583357] [G loss: 0.850755]\n",
      "[Epoch 13/200] [Batch 42/169] [D loss: 0.679263] [G loss: 0.864924]\n",
      "[Epoch 13/200] [Batch 43/169] [D loss: 0.632601] [G loss: 0.810562]\n",
      "[Epoch 13/200] [Batch 44/169] [D loss: 0.729060] [G loss: 0.835018]\n",
      "[Epoch 13/200] [Batch 45/169] [D loss: 0.619428] [G loss: 1.049403]\n",
      "[Epoch 13/200] [Batch 46/169] [D loss: 0.629854] [G loss: 1.096610]\n",
      "[Epoch 13/200] [Batch 47/169] [D loss: 0.624560] [G loss: 1.053814]\n",
      "[Epoch 13/200] [Batch 48/169] [D loss: 0.566308] [G loss: 0.934342]\n",
      "[Epoch 13/200] [Batch 49/169] [D loss: 0.570376] [G loss: 0.987837]\n",
      "[Epoch 13/200] [Batch 50/169] [D loss: 0.592403] [G loss: 0.985835]\n",
      "[Epoch 13/200] [Batch 51/169] [D loss: 0.662375] [G loss: 0.985385]\n",
      "[Epoch 13/200] [Batch 52/169] [D loss: 0.590953] [G loss: 0.840352]\n",
      "[Epoch 13/200] [Batch 53/169] [D loss: 0.723729] [G loss: 0.840381]\n",
      "[Epoch 13/200] [Batch 54/169] [D loss: 0.567320] [G loss: 1.099345]\n",
      "[Epoch 13/200] [Batch 55/169] [D loss: 0.590304] [G loss: 1.074635]\n",
      "[Epoch 13/200] [Batch 56/169] [D loss: 0.632950] [G loss: 1.061284]\n",
      "[Epoch 13/200] [Batch 57/169] [D loss: 0.666141] [G loss: 0.966267]\n",
      "[Epoch 13/200] [Batch 58/169] [D loss: 0.683357] [G loss: 0.902762]\n",
      "[Epoch 13/200] [Batch 59/169] [D loss: 0.595745] [G loss: 1.012041]\n",
      "[Epoch 13/200] [Batch 60/169] [D loss: 0.627370] [G loss: 1.013601]\n",
      "[Epoch 13/200] [Batch 61/169] [D loss: 0.612125] [G loss: 0.884939]\n",
      "[Epoch 13/200] [Batch 62/169] [D loss: 0.671103] [G loss: 0.907545]\n",
      "[Epoch 13/200] [Batch 63/169] [D loss: 0.668422] [G loss: 0.844648]\n",
      "[Epoch 13/200] [Batch 64/169] [D loss: 0.626749] [G loss: 0.951786]\n",
      "[Epoch 13/200] [Batch 65/169] [D loss: 0.662563] [G loss: 1.010938]\n",
      "[Epoch 13/200] [Batch 66/169] [D loss: 0.607985] [G loss: 0.787164]\n",
      "[Epoch 13/200] [Batch 67/169] [D loss: 0.542836] [G loss: 1.027499]\n",
      "[Epoch 13/200] [Batch 68/169] [D loss: 0.685715] [G loss: 0.904765]\n",
      "[Epoch 13/200] [Batch 69/169] [D loss: 0.564444] [G loss: 0.965286]\n",
      "[Epoch 13/200] [Batch 70/169] [D loss: 0.569080] [G loss: 1.057295]\n",
      "[Epoch 13/200] [Batch 71/169] [D loss: 0.530828] [G loss: 0.866249]\n",
      "[Epoch 13/200] [Batch 72/169] [D loss: 0.577327] [G loss: 0.813546]\n",
      "[Epoch 13/200] [Batch 73/169] [D loss: 0.598264] [G loss: 0.929718]\n",
      "[Epoch 13/200] [Batch 74/169] [D loss: 0.560289] [G loss: 0.767781]\n",
      "[Epoch 13/200] [Batch 75/169] [D loss: 0.599967] [G loss: 0.875141]\n",
      "[Epoch 13/200] [Batch 76/169] [D loss: 0.609137] [G loss: 0.732967]\n",
      "[Epoch 13/200] [Batch 77/169] [D loss: 0.525756] [G loss: 1.115649]\n",
      "[Epoch 13/200] [Batch 78/169] [D loss: 0.626640] [G loss: 0.969245]\n",
      "[Epoch 13/200] [Batch 79/169] [D loss: 0.548759] [G loss: 0.944619]\n",
      "[Epoch 13/200] [Batch 80/169] [D loss: 0.633999] [G loss: 1.192390]\n",
      "[Epoch 13/200] [Batch 81/169] [D loss: 0.633965] [G loss: 0.783630]\n",
      "[Epoch 13/200] [Batch 82/169] [D loss: 0.621806] [G loss: 0.796004]\n",
      "[Epoch 13/200] [Batch 83/169] [D loss: 0.604219] [G loss: 0.803543]\n",
      "[Epoch 13/200] [Batch 84/169] [D loss: 0.625095] [G loss: 1.113048]\n",
      "[Epoch 13/200] [Batch 85/169] [D loss: 0.576151] [G loss: 0.973163]\n",
      "[Epoch 13/200] [Batch 86/169] [D loss: 0.554683] [G loss: 0.898432]\n",
      "[Epoch 13/200] [Batch 87/169] [D loss: 0.649510] [G loss: 0.870213]\n",
      "[Epoch 13/200] [Batch 88/169] [D loss: 0.644443] [G loss: 0.725738]\n",
      "[Epoch 13/200] [Batch 89/169] [D loss: 0.583475] [G loss: 0.888743]\n",
      "[Epoch 13/200] [Batch 90/169] [D loss: 0.583821] [G loss: 0.885674]\n",
      "[Epoch 13/200] [Batch 91/169] [D loss: 0.656617] [G loss: 1.009797]\n",
      "[Epoch 13/200] [Batch 92/169] [D loss: 0.637205] [G loss: 1.013802]\n",
      "[Epoch 13/200] [Batch 93/169] [D loss: 0.643978] [G loss: 0.998866]\n",
      "[Epoch 13/200] [Batch 94/169] [D loss: 0.669900] [G loss: 1.091271]\n",
      "[Epoch 13/200] [Batch 95/169] [D loss: 0.650582] [G loss: 0.817548]\n",
      "[Epoch 13/200] [Batch 96/169] [D loss: 0.565129] [G loss: 0.926547]\n",
      "[Epoch 13/200] [Batch 97/169] [D loss: 0.618708] [G loss: 0.882353]\n",
      "[Epoch 13/200] [Batch 98/169] [D loss: 0.589661] [G loss: 1.056630]\n",
      "[Epoch 13/200] [Batch 99/169] [D loss: 0.627708] [G loss: 1.056895]\n",
      "[Epoch 13/200] [Batch 100/169] [D loss: 0.639365] [G loss: 0.988381]\n",
      "[Epoch 13/200] [Batch 101/169] [D loss: 0.652660] [G loss: 0.973107]\n",
      "[Epoch 13/200] [Batch 102/169] [D loss: 0.605474] [G loss: 0.820621]\n",
      "[Epoch 13/200] [Batch 103/169] [D loss: 0.695659] [G loss: 0.810680]\n",
      "[Epoch 13/200] [Batch 104/169] [D loss: 0.575726] [G loss: 0.895524]\n",
      "[Epoch 13/200] [Batch 105/169] [D loss: 0.674623] [G loss: 0.792754]\n",
      "[Epoch 13/200] [Batch 106/169] [D loss: 0.617374] [G loss: 0.972953]\n",
      "[Epoch 13/200] [Batch 107/169] [D loss: 0.647511] [G loss: 0.740986]\n",
      "[Epoch 13/200] [Batch 108/169] [D loss: 0.632771] [G loss: 0.971246]\n",
      "[Epoch 13/200] [Batch 109/169] [D loss: 0.636869] [G loss: 0.982802]\n",
      "[Epoch 13/200] [Batch 110/169] [D loss: 0.570031] [G loss: 1.031806]\n",
      "[Epoch 13/200] [Batch 111/169] [D loss: 0.663868] [G loss: 0.916945]\n",
      "[Epoch 13/200] [Batch 112/169] [D loss: 0.595738] [G loss: 0.990580]\n",
      "[Epoch 13/200] [Batch 113/169] [D loss: 0.583516] [G loss: 1.004269]\n",
      "[Epoch 13/200] [Batch 114/169] [D loss: 0.624953] [G loss: 0.934724]\n",
      "[Epoch 13/200] [Batch 115/169] [D loss: 0.630343] [G loss: 1.008238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 116/169] [D loss: 0.628983] [G loss: 1.120275]\n",
      "[Epoch 13/200] [Batch 117/169] [D loss: 0.579278] [G loss: 0.862788]\n",
      "[Epoch 13/200] [Batch 118/169] [D loss: 0.576246] [G loss: 0.906710]\n",
      "[Epoch 13/200] [Batch 119/169] [D loss: 0.550965] [G loss: 0.884908]\n",
      "[Epoch 13/200] [Batch 120/169] [D loss: 0.644719] [G loss: 0.762254]\n",
      "[Epoch 13/200] [Batch 121/169] [D loss: 0.644779] [G loss: 0.992934]\n",
      "[Epoch 13/200] [Batch 122/169] [D loss: 0.580209] [G loss: 0.926823]\n",
      "[Epoch 13/200] [Batch 123/169] [D loss: 0.668416] [G loss: 1.100753]\n",
      "[Epoch 13/200] [Batch 124/169] [D loss: 0.597873] [G loss: 0.969006]\n",
      "[Epoch 13/200] [Batch 125/169] [D loss: 0.603763] [G loss: 0.919664]\n",
      "[Epoch 13/200] [Batch 126/169] [D loss: 0.621348] [G loss: 0.953399]\n",
      "[Epoch 13/200] [Batch 127/169] [D loss: 0.599615] [G loss: 1.104100]\n",
      "[Epoch 13/200] [Batch 128/169] [D loss: 0.613689] [G loss: 0.966879]\n",
      "[Epoch 13/200] [Batch 129/169] [D loss: 0.604765] [G loss: 0.804219]\n",
      "[Epoch 13/200] [Batch 130/169] [D loss: 0.561415] [G loss: 0.933489]\n",
      "[Epoch 13/200] [Batch 131/169] [D loss: 0.628375] [G loss: 0.944287]\n",
      "[Epoch 13/200] [Batch 132/169] [D loss: 0.535586] [G loss: 0.955085]\n",
      "[Epoch 13/200] [Batch 133/169] [D loss: 0.566775] [G loss: 0.854755]\n",
      "[Epoch 13/200] [Batch 134/169] [D loss: 0.635476] [G loss: 1.085925]\n",
      "[Epoch 13/200] [Batch 135/169] [D loss: 0.561870] [G loss: 0.975048]\n",
      "[Epoch 13/200] [Batch 136/169] [D loss: 0.593750] [G loss: 1.060969]\n",
      "[Epoch 13/200] [Batch 137/169] [D loss: 0.614577] [G loss: 0.735414]\n",
      "[Epoch 13/200] [Batch 138/169] [D loss: 0.699088] [G loss: 0.848755]\n",
      "[Epoch 13/200] [Batch 139/169] [D loss: 0.670298] [G loss: 0.850252]\n",
      "[Epoch 13/200] [Batch 140/169] [D loss: 0.643256] [G loss: 1.043050]\n",
      "[Epoch 13/200] [Batch 141/169] [D loss: 0.609182] [G loss: 0.939871]\n",
      "[Epoch 13/200] [Batch 142/169] [D loss: 0.679220] [G loss: 0.881217]\n",
      "[Epoch 13/200] [Batch 143/169] [D loss: 0.527627] [G loss: 1.091671]\n",
      "[Epoch 13/200] [Batch 144/169] [D loss: 0.622717] [G loss: 1.090308]\n",
      "[Epoch 13/200] [Batch 145/169] [D loss: 0.538022] [G loss: 0.955258]\n",
      "[Epoch 13/200] [Batch 146/169] [D loss: 0.578310] [G loss: 0.981785]\n",
      "[Epoch 13/200] [Batch 147/169] [D loss: 0.647924] [G loss: 0.921134]\n",
      "[Epoch 13/200] [Batch 148/169] [D loss: 0.612299] [G loss: 0.806132]\n",
      "[Epoch 13/200] [Batch 149/169] [D loss: 0.673983] [G loss: 0.950546]\n",
      "[Epoch 13/200] [Batch 150/169] [D loss: 0.635267] [G loss: 1.097361]\n",
      "[Epoch 13/200] [Batch 151/169] [D loss: 0.672742] [G loss: 1.034450]\n",
      "[Epoch 13/200] [Batch 152/169] [D loss: 0.622984] [G loss: 0.991241]\n",
      "[Epoch 13/200] [Batch 153/169] [D loss: 0.659194] [G loss: 0.851589]\n",
      "[Epoch 13/200] [Batch 154/169] [D loss: 0.650394] [G loss: 0.903632]\n",
      "[Epoch 13/200] [Batch 155/169] [D loss: 0.674009] [G loss: 0.981841]\n",
      "[Epoch 13/200] [Batch 156/169] [D loss: 0.613632] [G loss: 0.784176]\n",
      "[Epoch 13/200] [Batch 157/169] [D loss: 0.697395] [G loss: 1.054753]\n",
      "[Epoch 13/200] [Batch 158/169] [D loss: 0.701645] [G loss: 1.160680]\n",
      "[Epoch 13/200] [Batch 159/169] [D loss: 0.641262] [G loss: 0.935782]\n",
      "[Epoch 13/200] [Batch 160/169] [D loss: 0.605390] [G loss: 0.989459]\n",
      "[Epoch 13/200] [Batch 161/169] [D loss: 0.628886] [G loss: 0.836828]\n",
      "[Epoch 13/200] [Batch 162/169] [D loss: 0.622204] [G loss: 0.958749]\n",
      "[Epoch 13/200] [Batch 163/169] [D loss: 0.627204] [G loss: 0.955851]\n",
      "[Epoch 13/200] [Batch 164/169] [D loss: 0.738857] [G loss: 1.064057]\n",
      "[Epoch 13/200] [Batch 165/169] [D loss: 0.613216] [G loss: 0.886679]\n",
      "[Epoch 13/200] [Batch 166/169] [D loss: 0.548199] [G loss: 0.827890]\n",
      "[Epoch 13/200] [Batch 167/169] [D loss: 0.608330] [G loss: 0.887851]\n",
      "[Epoch 13/200] [Batch 168/169] [D loss: 0.593507] [G loss: 0.838046]\n",
      "[Epoch 14/200] [Batch 0/169] [D loss: 0.670802] [G loss: 0.931421]\n",
      "[Epoch 14/200] [Batch 1/169] [D loss: 0.570683] [G loss: 1.003260]\n",
      "[Epoch 14/200] [Batch 2/169] [D loss: 0.559022] [G loss: 0.844957]\n",
      "[Epoch 14/200] [Batch 3/169] [D loss: 0.605257] [G loss: 0.971320]\n",
      "[Epoch 14/200] [Batch 4/169] [D loss: 0.713760] [G loss: 0.859880]\n",
      "[Epoch 14/200] [Batch 5/169] [D loss: 0.686317] [G loss: 1.108600]\n",
      "[Epoch 14/200] [Batch 6/169] [D loss: 0.631700] [G loss: 0.872573]\n",
      "[Epoch 14/200] [Batch 7/169] [D loss: 0.589202] [G loss: 0.897660]\n",
      "[Epoch 14/200] [Batch 8/169] [D loss: 0.639649] [G loss: 0.888465]\n",
      "[Epoch 14/200] [Batch 9/169] [D loss: 0.584429] [G loss: 0.944681]\n",
      "[Epoch 14/200] [Batch 10/169] [D loss: 0.653027] [G loss: 0.927402]\n",
      "[Epoch 14/200] [Batch 11/169] [D loss: 0.561687] [G loss: 0.979963]\n",
      "[Epoch 14/200] [Batch 12/169] [D loss: 0.585335] [G loss: 0.725099]\n",
      "[Epoch 14/200] [Batch 13/169] [D loss: 0.555843] [G loss: 0.934374]\n",
      "[Epoch 14/200] [Batch 14/169] [D loss: 0.623167] [G loss: 0.934822]\n",
      "[Epoch 14/200] [Batch 15/169] [D loss: 0.583507] [G loss: 1.005734]\n",
      "[Epoch 14/200] [Batch 16/169] [D loss: 0.628960] [G loss: 1.003093]\n",
      "[Epoch 14/200] [Batch 17/169] [D loss: 0.655854] [G loss: 1.038996]\n",
      "[Epoch 14/200] [Batch 18/169] [D loss: 0.597279] [G loss: 1.046770]\n",
      "[Epoch 14/200] [Batch 19/169] [D loss: 0.638369] [G loss: 0.898133]\n",
      "[Epoch 14/200] [Batch 20/169] [D loss: 0.566481] [G loss: 0.906042]\n",
      "[Epoch 14/200] [Batch 21/169] [D loss: 0.597034] [G loss: 0.919006]\n",
      "[Epoch 14/200] [Batch 22/169] [D loss: 0.645619] [G loss: 0.928722]\n",
      "[Epoch 14/200] [Batch 23/169] [D loss: 0.622172] [G loss: 0.853513]\n",
      "[Epoch 14/200] [Batch 24/169] [D loss: 0.591176] [G loss: 0.881685]\n",
      "[Epoch 14/200] [Batch 25/169] [D loss: 0.620201] [G loss: 0.815865]\n",
      "[Epoch 14/200] [Batch 26/169] [D loss: 0.675597] [G loss: 1.025918]\n",
      "[Epoch 14/200] [Batch 27/169] [D loss: 0.644013] [G loss: 1.037842]\n",
      "[Epoch 14/200] [Batch 28/169] [D loss: 0.634110] [G loss: 1.160935]\n",
      "[Epoch 14/200] [Batch 29/169] [D loss: 0.576812] [G loss: 1.224036]\n",
      "[Epoch 14/200] [Batch 30/169] [D loss: 0.613463] [G loss: 0.869508]\n",
      "[Epoch 14/200] [Batch 31/169] [D loss: 0.571703] [G loss: 0.785106]\n",
      "[Epoch 14/200] [Batch 32/169] [D loss: 0.574852] [G loss: 0.757097]\n",
      "[Epoch 14/200] [Batch 33/169] [D loss: 0.518649] [G loss: 0.717026]\n",
      "[Epoch 14/200] [Batch 34/169] [D loss: 0.610229] [G loss: 0.807912]\n",
      "[Epoch 14/200] [Batch 35/169] [D loss: 0.575696] [G loss: 0.822167]\n",
      "[Epoch 14/200] [Batch 36/169] [D loss: 0.608846] [G loss: 0.903054]\n",
      "[Epoch 14/200] [Batch 37/169] [D loss: 0.542436] [G loss: 0.869524]\n",
      "[Epoch 14/200] [Batch 38/169] [D loss: 0.577361] [G loss: 0.749957]\n",
      "[Epoch 14/200] [Batch 39/169] [D loss: 0.587040] [G loss: 0.912662]\n",
      "[Epoch 14/200] [Batch 40/169] [D loss: 0.582586] [G loss: 0.867988]\n",
      "[Epoch 14/200] [Batch 41/169] [D loss: 0.532085] [G loss: 1.020736]\n",
      "[Epoch 14/200] [Batch 42/169] [D loss: 0.585991] [G loss: 1.052604]\n",
      "[Epoch 14/200] [Batch 43/169] [D loss: 0.589328] [G loss: 0.981690]\n",
      "[Epoch 14/200] [Batch 44/169] [D loss: 0.663661] [G loss: 1.064718]\n",
      "[Epoch 14/200] [Batch 45/169] [D loss: 0.725677] [G loss: 0.976310]\n",
      "[Epoch 14/200] [Batch 46/169] [D loss: 0.650546] [G loss: 0.845576]\n",
      "[Epoch 14/200] [Batch 47/169] [D loss: 0.576373] [G loss: 0.872920]\n",
      "[Epoch 14/200] [Batch 48/169] [D loss: 0.675035] [G loss: 0.815697]\n",
      "[Epoch 14/200] [Batch 49/169] [D loss: 0.648103] [G loss: 0.907048]\n",
      "[Epoch 14/200] [Batch 50/169] [D loss: 0.715633] [G loss: 0.869651]\n",
      "[Epoch 14/200] [Batch 51/169] [D loss: 0.638017] [G loss: 0.938771]\n",
      "[Epoch 14/200] [Batch 52/169] [D loss: 0.632072] [G loss: 0.892121]\n",
      "[Epoch 14/200] [Batch 53/169] [D loss: 0.580537] [G loss: 0.898797]\n",
      "[Epoch 14/200] [Batch 54/169] [D loss: 0.583079] [G loss: 0.781196]\n",
      "[Epoch 14/200] [Batch 55/169] [D loss: 0.697234] [G loss: 0.903751]\n",
      "[Epoch 14/200] [Batch 56/169] [D loss: 0.655988] [G loss: 0.899315]\n",
      "[Epoch 14/200] [Batch 57/169] [D loss: 0.653415] [G loss: 0.976704]\n",
      "[Epoch 14/200] [Batch 58/169] [D loss: 0.604698] [G loss: 0.733705]\n",
      "[Epoch 14/200] [Batch 59/169] [D loss: 0.621487] [G loss: 0.728373]\n",
      "[Epoch 14/200] [Batch 60/169] [D loss: 0.586772] [G loss: 0.828295]\n",
      "[Epoch 14/200] [Batch 61/169] [D loss: 0.656945] [G loss: 0.936673]\n",
      "[Epoch 14/200] [Batch 62/169] [D loss: 0.639667] [G loss: 0.855657]\n",
      "[Epoch 14/200] [Batch 63/169] [D loss: 0.653806] [G loss: 0.858754]\n",
      "[Epoch 14/200] [Batch 64/169] [D loss: 0.594977] [G loss: 0.963457]\n",
      "[Epoch 14/200] [Batch 65/169] [D loss: 0.644415] [G loss: 0.948548]\n",
      "[Epoch 14/200] [Batch 66/169] [D loss: 0.674314] [G loss: 0.902451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 67/169] [D loss: 0.562718] [G loss: 0.934336]\n",
      "[Epoch 14/200] [Batch 68/169] [D loss: 0.628798] [G loss: 0.909023]\n",
      "[Epoch 14/200] [Batch 69/169] [D loss: 0.611708] [G loss: 0.997981]\n",
      "[Epoch 14/200] [Batch 70/169] [D loss: 0.640908] [G loss: 1.033906]\n",
      "[Epoch 14/200] [Batch 71/169] [D loss: 0.560884] [G loss: 0.987312]\n",
      "[Epoch 14/200] [Batch 72/169] [D loss: 0.611983] [G loss: 0.850166]\n",
      "[Epoch 14/200] [Batch 73/169] [D loss: 0.565738] [G loss: 1.132462]\n",
      "[Epoch 14/200] [Batch 74/169] [D loss: 0.620930] [G loss: 0.921795]\n",
      "[Epoch 14/200] [Batch 75/169] [D loss: 0.607191] [G loss: 1.040488]\n",
      "[Epoch 14/200] [Batch 76/169] [D loss: 0.612492] [G loss: 0.850708]\n",
      "[Epoch 14/200] [Batch 77/169] [D loss: 0.599541] [G loss: 0.839190]\n",
      "[Epoch 14/200] [Batch 78/169] [D loss: 0.565537] [G loss: 0.812236]\n",
      "[Epoch 14/200] [Batch 79/169] [D loss: 0.581869] [G loss: 0.786877]\n",
      "[Epoch 14/200] [Batch 80/169] [D loss: 0.617189] [G loss: 0.922170]\n",
      "[Epoch 14/200] [Batch 81/169] [D loss: 0.646500] [G loss: 0.944904]\n",
      "[Epoch 14/200] [Batch 82/169] [D loss: 0.654803] [G loss: 0.887873]\n",
      "[Epoch 14/200] [Batch 83/169] [D loss: 0.522085] [G loss: 0.985338]\n",
      "[Epoch 14/200] [Batch 84/169] [D loss: 0.591864] [G loss: 0.988619]\n",
      "[Epoch 14/200] [Batch 85/169] [D loss: 0.598609] [G loss: 0.930263]\n",
      "[Epoch 14/200] [Batch 86/169] [D loss: 0.648592] [G loss: 0.636808]\n",
      "[Epoch 14/200] [Batch 87/169] [D loss: 0.622771] [G loss: 0.774138]\n",
      "[Epoch 14/200] [Batch 88/169] [D loss: 0.554864] [G loss: 0.912235]\n",
      "[Epoch 14/200] [Batch 89/169] [D loss: 0.581693] [G loss: 0.883662]\n",
      "[Epoch 14/200] [Batch 90/169] [D loss: 0.699063] [G loss: 0.722812]\n",
      "[Epoch 14/200] [Batch 91/169] [D loss: 0.690954] [G loss: 0.870084]\n",
      "[Epoch 14/200] [Batch 92/169] [D loss: 0.592493] [G loss: 0.972405]\n",
      "[Epoch 14/200] [Batch 93/169] [D loss: 0.646636] [G loss: 0.843796]\n",
      "[Epoch 14/200] [Batch 94/169] [D loss: 0.636074] [G loss: 0.970222]\n",
      "[Epoch 14/200] [Batch 95/169] [D loss: 0.608576] [G loss: 0.793802]\n",
      "[Epoch 14/200] [Batch 96/169] [D loss: 0.547115] [G loss: 0.778241]\n",
      "[Epoch 14/200] [Batch 97/169] [D loss: 0.628014] [G loss: 0.875066]\n",
      "[Epoch 14/200] [Batch 98/169] [D loss: 0.702855] [G loss: 0.816285]\n",
      "[Epoch 14/200] [Batch 99/169] [D loss: 0.599263] [G loss: 1.164255]\n",
      "[Epoch 14/200] [Batch 100/169] [D loss: 0.560389] [G loss: 1.041106]\n",
      "[Epoch 14/200] [Batch 101/169] [D loss: 0.662802] [G loss: 0.899901]\n",
      "[Epoch 14/200] [Batch 102/169] [D loss: 0.607101] [G loss: 0.908221]\n",
      "[Epoch 14/200] [Batch 103/169] [D loss: 0.628923] [G loss: 0.758876]\n",
      "[Epoch 14/200] [Batch 104/169] [D loss: 0.694245] [G loss: 0.986715]\n",
      "[Epoch 14/200] [Batch 105/169] [D loss: 0.573877] [G loss: 0.864757]\n",
      "[Epoch 14/200] [Batch 106/169] [D loss: 0.576369] [G loss: 0.802607]\n",
      "[Epoch 14/200] [Batch 107/169] [D loss: 0.689531] [G loss: 0.947658]\n",
      "[Epoch 14/200] [Batch 108/169] [D loss: 0.665671] [G loss: 0.989693]\n",
      "[Epoch 14/200] [Batch 109/169] [D loss: 0.657424] [G loss: 0.929751]\n",
      "[Epoch 14/200] [Batch 110/169] [D loss: 0.623682] [G loss: 0.950550]\n",
      "[Epoch 14/200] [Batch 111/169] [D loss: 0.618470] [G loss: 1.020299]\n",
      "[Epoch 14/200] [Batch 112/169] [D loss: 0.627309] [G loss: 0.954063]\n",
      "[Epoch 14/200] [Batch 113/169] [D loss: 0.571856] [G loss: 0.894948]\n",
      "[Epoch 14/200] [Batch 114/169] [D loss: 0.566169] [G loss: 1.017195]\n",
      "[Epoch 14/200] [Batch 115/169] [D loss: 0.640439] [G loss: 0.987738]\n",
      "[Epoch 14/200] [Batch 116/169] [D loss: 0.597276] [G loss: 0.744235]\n",
      "[Epoch 14/200] [Batch 117/169] [D loss: 0.752270] [G loss: 0.956700]\n",
      "[Epoch 14/200] [Batch 118/169] [D loss: 0.566692] [G loss: 0.962742]\n",
      "[Epoch 14/200] [Batch 119/169] [D loss: 0.560084] [G loss: 0.854434]\n",
      "[Epoch 14/200] [Batch 120/169] [D loss: 0.577893] [G loss: 0.941320]\n",
      "[Epoch 14/200] [Batch 121/169] [D loss: 0.640547] [G loss: 0.992357]\n",
      "[Epoch 14/200] [Batch 122/169] [D loss: 0.670578] [G loss: 0.836418]\n",
      "[Epoch 14/200] [Batch 123/169] [D loss: 0.705382] [G loss: 0.860531]\n",
      "[Epoch 14/200] [Batch 124/169] [D loss: 0.587712] [G loss: 0.805609]\n",
      "[Epoch 14/200] [Batch 125/169] [D loss: 0.589205] [G loss: 0.950318]\n",
      "[Epoch 14/200] [Batch 126/169] [D loss: 0.706420] [G loss: 1.139969]\n",
      "[Epoch 14/200] [Batch 127/169] [D loss: 0.636001] [G loss: 1.039325]\n",
      "[Epoch 14/200] [Batch 128/169] [D loss: 0.632388] [G loss: 0.966925]\n",
      "[Epoch 14/200] [Batch 129/169] [D loss: 0.644009] [G loss: 0.724556]\n",
      "[Epoch 14/200] [Batch 130/169] [D loss: 0.612849] [G loss: 0.713281]\n",
      "[Epoch 14/200] [Batch 131/169] [D loss: 0.625671] [G loss: 0.923107]\n",
      "[Epoch 14/200] [Batch 132/169] [D loss: 0.661432] [G loss: 0.849211]\n",
      "[Epoch 14/200] [Batch 133/169] [D loss: 0.653493] [G loss: 0.945857]\n",
      "[Epoch 14/200] [Batch 134/169] [D loss: 0.664441] [G loss: 0.958344]\n",
      "[Epoch 14/200] [Batch 135/169] [D loss: 0.604967] [G loss: 1.104166]\n",
      "[Epoch 14/200] [Batch 136/169] [D loss: 0.639426] [G loss: 0.977589]\n",
      "[Epoch 14/200] [Batch 137/169] [D loss: 0.543312] [G loss: 0.778849]\n",
      "[Epoch 14/200] [Batch 138/169] [D loss: 0.602476] [G loss: 0.823460]\n",
      "[Epoch 14/200] [Batch 139/169] [D loss: 0.588138] [G loss: 0.931038]\n",
      "[Epoch 14/200] [Batch 140/169] [D loss: 0.664379] [G loss: 0.840588]\n",
      "[Epoch 14/200] [Batch 141/169] [D loss: 0.605779] [G loss: 0.814468]\n",
      "[Epoch 14/200] [Batch 142/169] [D loss: 0.606171] [G loss: 1.036061]\n",
      "[Epoch 14/200] [Batch 143/169] [D loss: 0.641745] [G loss: 0.912600]\n",
      "[Epoch 14/200] [Batch 144/169] [D loss: 0.600417] [G loss: 0.949072]\n",
      "[Epoch 14/200] [Batch 145/169] [D loss: 0.531848] [G loss: 0.862807]\n",
      "[Epoch 14/200] [Batch 146/169] [D loss: 0.691062] [G loss: 0.867722]\n",
      "[Epoch 14/200] [Batch 147/169] [D loss: 0.669772] [G loss: 0.727254]\n",
      "[Epoch 14/200] [Batch 148/169] [D loss: 0.610975] [G loss: 0.987913]\n",
      "[Epoch 14/200] [Batch 149/169] [D loss: 0.602932] [G loss: 1.010551]\n",
      "[Epoch 14/200] [Batch 150/169] [D loss: 0.659970] [G loss: 0.956893]\n",
      "[Epoch 14/200] [Batch 151/169] [D loss: 0.608213] [G loss: 0.883114]\n",
      "[Epoch 14/200] [Batch 152/169] [D loss: 0.603569] [G loss: 1.048396]\n",
      "[Epoch 14/200] [Batch 153/169] [D loss: 0.635910] [G loss: 0.939105]\n",
      "[Epoch 14/200] [Batch 154/169] [D loss: 0.647240] [G loss: 0.939212]\n",
      "[Epoch 14/200] [Batch 155/169] [D loss: 0.589700] [G loss: 0.785790]\n",
      "[Epoch 14/200] [Batch 156/169] [D loss: 0.644868] [G loss: 0.949142]\n",
      "[Epoch 14/200] [Batch 157/169] [D loss: 0.643075] [G loss: 0.953799]\n",
      "[Epoch 14/200] [Batch 158/169] [D loss: 0.602887] [G loss: 0.895463]\n",
      "[Epoch 14/200] [Batch 159/169] [D loss: 0.553382] [G loss: 0.823188]\n",
      "[Epoch 14/200] [Batch 160/169] [D loss: 0.623136] [G loss: 0.753197]\n",
      "[Epoch 14/200] [Batch 161/169] [D loss: 0.602630] [G loss: 1.017481]\n",
      "[Epoch 14/200] [Batch 162/169] [D loss: 0.687484] [G loss: 0.863076]\n",
      "[Epoch 14/200] [Batch 163/169] [D loss: 0.617868] [G loss: 0.833990]\n",
      "[Epoch 14/200] [Batch 164/169] [D loss: 0.602808] [G loss: 0.883752]\n",
      "[Epoch 14/200] [Batch 165/169] [D loss: 0.636371] [G loss: 0.885722]\n",
      "[Epoch 14/200] [Batch 166/169] [D loss: 0.670739] [G loss: 0.967762]\n",
      "[Epoch 14/200] [Batch 167/169] [D loss: 0.616847] [G loss: 0.922715]\n",
      "[Epoch 14/200] [Batch 168/169] [D loss: 0.672278] [G loss: 0.991928]\n",
      "[Epoch 15/200] [Batch 0/169] [D loss: 0.709346] [G loss: 0.840379]\n",
      "[Epoch 15/200] [Batch 1/169] [D loss: 0.647476] [G loss: 0.914444]\n",
      "[Epoch 15/200] [Batch 2/169] [D loss: 0.612849] [G loss: 1.051898]\n",
      "[Epoch 15/200] [Batch 3/169] [D loss: 0.633550] [G loss: 0.796170]\n",
      "[Epoch 15/200] [Batch 4/169] [D loss: 0.669857] [G loss: 0.957283]\n",
      "[Epoch 15/200] [Batch 5/169] [D loss: 0.590031] [G loss: 0.879545]\n",
      "[Epoch 15/200] [Batch 6/169] [D loss: 0.651085] [G loss: 1.218810]\n",
      "[Epoch 15/200] [Batch 7/169] [D loss: 0.694724] [G loss: 1.025604]\n",
      "[Epoch 15/200] [Batch 8/169] [D loss: 0.599458] [G loss: 0.872047]\n",
      "[Epoch 15/200] [Batch 9/169] [D loss: 0.551109] [G loss: 1.087704]\n",
      "[Epoch 15/200] [Batch 10/169] [D loss: 0.586585] [G loss: 0.876585]\n",
      "[Epoch 15/200] [Batch 11/169] [D loss: 0.567988] [G loss: 0.929823]\n",
      "[Epoch 15/200] [Batch 12/169] [D loss: 0.626231] [G loss: 0.871983]\n",
      "[Epoch 15/200] [Batch 13/169] [D loss: 0.636195] [G loss: 0.779391]\n",
      "[Epoch 15/200] [Batch 14/169] [D loss: 0.643746] [G loss: 0.706342]\n",
      "[Epoch 15/200] [Batch 15/169] [D loss: 0.699829] [G loss: 0.803068]\n",
      "[Epoch 15/200] [Batch 16/169] [D loss: 0.594884] [G loss: 0.846732]\n",
      "[Epoch 15/200] [Batch 17/169] [D loss: 0.649702] [G loss: 0.687077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 18/169] [D loss: 0.629848] [G loss: 0.840570]\n",
      "[Epoch 15/200] [Batch 19/169] [D loss: 0.642606] [G loss: 0.781380]\n",
      "[Epoch 15/200] [Batch 20/169] [D loss: 0.580618] [G loss: 0.915536]\n",
      "[Epoch 15/200] [Batch 21/169] [D loss: 0.653100] [G loss: 0.866058]\n",
      "[Epoch 15/200] [Batch 22/169] [D loss: 0.674202] [G loss: 1.018954]\n",
      "[Epoch 15/200] [Batch 23/169] [D loss: 0.663669] [G loss: 0.953159]\n",
      "[Epoch 15/200] [Batch 24/169] [D loss: 0.647675] [G loss: 0.845140]\n",
      "[Epoch 15/200] [Batch 25/169] [D loss: 0.559118] [G loss: 0.784790]\n",
      "[Epoch 15/200] [Batch 26/169] [D loss: 0.653010] [G loss: 0.652756]\n",
      "[Epoch 15/200] [Batch 27/169] [D loss: 0.560643] [G loss: 0.936305]\n",
      "[Epoch 15/200] [Batch 28/169] [D loss: 0.633862] [G loss: 0.957076]\n",
      "[Epoch 15/200] [Batch 29/169] [D loss: 0.646899] [G loss: 0.916515]\n",
      "[Epoch 15/200] [Batch 30/169] [D loss: 0.714688] [G loss: 0.948900]\n",
      "[Epoch 15/200] [Batch 31/169] [D loss: 0.633050] [G loss: 0.915244]\n",
      "[Epoch 15/200] [Batch 32/169] [D loss: 0.660715] [G loss: 1.020901]\n",
      "[Epoch 15/200] [Batch 33/169] [D loss: 0.623248] [G loss: 1.019673]\n",
      "[Epoch 15/200] [Batch 34/169] [D loss: 0.622355] [G loss: 0.911929]\n",
      "[Epoch 15/200] [Batch 35/169] [D loss: 0.653569] [G loss: 0.810040]\n",
      "[Epoch 15/200] [Batch 36/169] [D loss: 0.607282] [G loss: 0.976462]\n",
      "[Epoch 15/200] [Batch 37/169] [D loss: 0.619647] [G loss: 1.046147]\n",
      "[Epoch 15/200] [Batch 38/169] [D loss: 0.622601] [G loss: 0.882386]\n",
      "[Epoch 15/200] [Batch 39/169] [D loss: 0.629455] [G loss: 0.856814]\n",
      "[Epoch 15/200] [Batch 40/169] [D loss: 0.609204] [G loss: 0.844624]\n",
      "[Epoch 15/200] [Batch 41/169] [D loss: 0.637708] [G loss: 0.880511]\n",
      "[Epoch 15/200] [Batch 42/169] [D loss: 0.622617] [G loss: 0.932068]\n",
      "[Epoch 15/200] [Batch 43/169] [D loss: 0.642835] [G loss: 0.883187]\n",
      "[Epoch 15/200] [Batch 44/169] [D loss: 0.585407] [G loss: 0.953373]\n",
      "[Epoch 15/200] [Batch 45/169] [D loss: 0.647554] [G loss: 0.691883]\n",
      "[Epoch 15/200] [Batch 46/169] [D loss: 0.563168] [G loss: 0.870683]\n",
      "[Epoch 15/200] [Batch 47/169] [D loss: 0.671683] [G loss: 0.903220]\n",
      "[Epoch 15/200] [Batch 48/169] [D loss: 0.566695] [G loss: 0.812275]\n",
      "[Epoch 15/200] [Batch 49/169] [D loss: 0.499762] [G loss: 0.984286]\n",
      "[Epoch 15/200] [Batch 50/169] [D loss: 0.612573] [G loss: 0.839647]\n",
      "[Epoch 15/200] [Batch 51/169] [D loss: 0.538638] [G loss: 0.995134]\n",
      "[Epoch 15/200] [Batch 52/169] [D loss: 0.633052] [G loss: 0.749485]\n",
      "[Epoch 15/200] [Batch 53/169] [D loss: 0.655515] [G loss: 0.903364]\n",
      "[Epoch 15/200] [Batch 54/169] [D loss: 0.582841] [G loss: 0.748359]\n",
      "[Epoch 15/200] [Batch 55/169] [D loss: 0.687987] [G loss: 0.809405]\n",
      "[Epoch 15/200] [Batch 56/169] [D loss: 0.640295] [G loss: 1.023533]\n",
      "[Epoch 15/200] [Batch 57/169] [D loss: 0.636191] [G loss: 0.801284]\n",
      "[Epoch 15/200] [Batch 58/169] [D loss: 0.601004] [G loss: 0.920062]\n",
      "[Epoch 15/200] [Batch 59/169] [D loss: 0.588740] [G loss: 0.837814]\n",
      "[Epoch 15/200] [Batch 60/169] [D loss: 0.715656] [G loss: 0.846458]\n",
      "[Epoch 15/200] [Batch 61/169] [D loss: 0.613092] [G loss: 0.857435]\n",
      "[Epoch 15/200] [Batch 62/169] [D loss: 0.590617] [G loss: 0.790857]\n",
      "[Epoch 15/200] [Batch 63/169] [D loss: 0.606775] [G loss: 1.045410]\n",
      "[Epoch 15/200] [Batch 64/169] [D loss: 0.591467] [G loss: 0.949811]\n",
      "[Epoch 15/200] [Batch 65/169] [D loss: 0.531788] [G loss: 0.963995]\n",
      "[Epoch 15/200] [Batch 66/169] [D loss: 0.559191] [G loss: 1.055061]\n",
      "[Epoch 15/200] [Batch 67/169] [D loss: 0.588684] [G loss: 0.940410]\n",
      "[Epoch 15/200] [Batch 68/169] [D loss: 0.579952] [G loss: 0.946143]\n",
      "[Epoch 15/200] [Batch 69/169] [D loss: 0.591230] [G loss: 0.985705]\n",
      "[Epoch 15/200] [Batch 70/169] [D loss: 0.605579] [G loss: 0.911984]\n",
      "[Epoch 15/200] [Batch 71/169] [D loss: 0.626649] [G loss: 1.005438]\n",
      "[Epoch 15/200] [Batch 72/169] [D loss: 0.675653] [G loss: 0.900992]\n",
      "[Epoch 15/200] [Batch 73/169] [D loss: 0.657233] [G loss: 0.958420]\n",
      "[Epoch 15/200] [Batch 74/169] [D loss: 0.599364] [G loss: 0.784676]\n",
      "[Epoch 15/200] [Batch 75/169] [D loss: 0.612813] [G loss: 0.881419]\n",
      "[Epoch 15/200] [Batch 76/169] [D loss: 0.606965] [G loss: 1.055856]\n",
      "[Epoch 15/200] [Batch 77/169] [D loss: 0.623548] [G loss: 1.018582]\n",
      "[Epoch 15/200] [Batch 78/169] [D loss: 0.639343] [G loss: 0.885860]\n",
      "[Epoch 15/200] [Batch 79/169] [D loss: 0.667969] [G loss: 0.874253]\n",
      "[Epoch 15/200] [Batch 80/169] [D loss: 0.706786] [G loss: 1.013946]\n",
      "[Epoch 15/200] [Batch 81/169] [D loss: 0.600057] [G loss: 1.022698]\n",
      "[Epoch 15/200] [Batch 82/169] [D loss: 0.652589] [G loss: 0.798267]\n",
      "[Epoch 15/200] [Batch 83/169] [D loss: 0.619356] [G loss: 0.870731]\n",
      "[Epoch 15/200] [Batch 84/169] [D loss: 0.606874] [G loss: 0.866477]\n",
      "[Epoch 15/200] [Batch 85/169] [D loss: 0.550030] [G loss: 0.860683]\n",
      "[Epoch 15/200] [Batch 86/169] [D loss: 0.686845] [G loss: 0.823418]\n",
      "[Epoch 15/200] [Batch 87/169] [D loss: 0.488098] [G loss: 1.034234]\n",
      "[Epoch 15/200] [Batch 88/169] [D loss: 0.587972] [G loss: 0.951170]\n",
      "[Epoch 15/200] [Batch 89/169] [D loss: 0.584062] [G loss: 0.954923]\n",
      "[Epoch 15/200] [Batch 90/169] [D loss: 0.655455] [G loss: 0.989235]\n",
      "[Epoch 15/200] [Batch 91/169] [D loss: 0.625799] [G loss: 0.919513]\n",
      "[Epoch 15/200] [Batch 92/169] [D loss: 0.672316] [G loss: 0.927249]\n",
      "[Epoch 15/200] [Batch 93/169] [D loss: 0.624255] [G loss: 0.881375]\n",
      "[Epoch 15/200] [Batch 94/169] [D loss: 0.633759] [G loss: 0.824797]\n",
      "[Epoch 15/200] [Batch 95/169] [D loss: 0.623212] [G loss: 0.908143]\n",
      "[Epoch 15/200] [Batch 96/169] [D loss: 0.612467] [G loss: 0.849480]\n",
      "[Epoch 15/200] [Batch 97/169] [D loss: 0.560189] [G loss: 0.983719]\n",
      "[Epoch 15/200] [Batch 98/169] [D loss: 0.576396] [G loss: 0.861189]\n",
      "[Epoch 15/200] [Batch 99/169] [D loss: 0.648487] [G loss: 0.817076]\n",
      "[Epoch 15/200] [Batch 100/169] [D loss: 0.626517] [G loss: 0.871437]\n",
      "[Epoch 15/200] [Batch 101/169] [D loss: 0.568479] [G loss: 0.849198]\n",
      "[Epoch 15/200] [Batch 102/169] [D loss: 0.640662] [G loss: 0.970613]\n",
      "[Epoch 15/200] [Batch 103/169] [D loss: 0.585762] [G loss: 0.880086]\n",
      "[Epoch 15/200] [Batch 104/169] [D loss: 0.560552] [G loss: 0.819660]\n",
      "[Epoch 15/200] [Batch 105/169] [D loss: 0.552303] [G loss: 0.807167]\n",
      "[Epoch 15/200] [Batch 106/169] [D loss: 0.555292] [G loss: 0.941973]\n",
      "[Epoch 15/200] [Batch 107/169] [D loss: 0.612861] [G loss: 0.967389]\n",
      "[Epoch 15/200] [Batch 108/169] [D loss: 0.677649] [G loss: 0.774156]\n",
      "[Epoch 15/200] [Batch 109/169] [D loss: 0.645128] [G loss: 0.873711]\n",
      "[Epoch 15/200] [Batch 110/169] [D loss: 0.726473] [G loss: 1.006634]\n",
      "[Epoch 15/200] [Batch 111/169] [D loss: 0.670516] [G loss: 0.891757]\n",
      "[Epoch 15/200] [Batch 112/169] [D loss: 0.616478] [G loss: 0.917536]\n",
      "[Epoch 15/200] [Batch 113/169] [D loss: 0.567176] [G loss: 0.977345]\n",
      "[Epoch 15/200] [Batch 114/169] [D loss: 0.672948] [G loss: 0.922998]\n",
      "[Epoch 15/200] [Batch 115/169] [D loss: 0.634526] [G loss: 0.779215]\n",
      "[Epoch 15/200] [Batch 116/169] [D loss: 0.587709] [G loss: 1.011222]\n",
      "[Epoch 15/200] [Batch 117/169] [D loss: 0.563657] [G loss: 0.943178]\n",
      "[Epoch 15/200] [Batch 118/169] [D loss: 0.658794] [G loss: 0.925149]\n",
      "[Epoch 15/200] [Batch 119/169] [D loss: 0.637939] [G loss: 0.908351]\n",
      "[Epoch 15/200] [Batch 120/169] [D loss: 0.588606] [G loss: 0.706938]\n",
      "[Epoch 15/200] [Batch 121/169] [D loss: 0.641554] [G loss: 0.789824]\n",
      "[Epoch 15/200] [Batch 122/169] [D loss: 0.656296] [G loss: 0.878008]\n",
      "[Epoch 15/200] [Batch 123/169] [D loss: 0.691498] [G loss: 1.040564]\n",
      "[Epoch 15/200] [Batch 124/169] [D loss: 0.598402] [G loss: 0.847131]\n",
      "[Epoch 15/200] [Batch 125/169] [D loss: 0.661228] [G loss: 0.835288]\n",
      "[Epoch 15/200] [Batch 126/169] [D loss: 0.649761] [G loss: 0.836345]\n",
      "[Epoch 15/200] [Batch 127/169] [D loss: 0.703935] [G loss: 0.850125]\n",
      "[Epoch 15/200] [Batch 128/169] [D loss: 0.688135] [G loss: 0.848646]\n",
      "[Epoch 15/200] [Batch 129/169] [D loss: 0.615248] [G loss: 0.865180]\n",
      "[Epoch 15/200] [Batch 130/169] [D loss: 0.626524] [G loss: 0.930839]\n",
      "[Epoch 15/200] [Batch 131/169] [D loss: 0.624550] [G loss: 0.770449]\n",
      "[Epoch 15/200] [Batch 132/169] [D loss: 0.574013] [G loss: 0.915585]\n",
      "[Epoch 15/200] [Batch 133/169] [D loss: 0.592304] [G loss: 0.918969]\n",
      "[Epoch 15/200] [Batch 134/169] [D loss: 0.638198] [G loss: 0.821818]\n",
      "[Epoch 15/200] [Batch 135/169] [D loss: 0.544947] [G loss: 0.914667]\n",
      "[Epoch 15/200] [Batch 136/169] [D loss: 0.561345] [G loss: 0.902507]\n",
      "[Epoch 15/200] [Batch 137/169] [D loss: 0.589843] [G loss: 0.953951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 138/169] [D loss: 0.648407] [G loss: 0.959557]\n",
      "[Epoch 15/200] [Batch 139/169] [D loss: 0.617485] [G loss: 0.941281]\n",
      "[Epoch 15/200] [Batch 140/169] [D loss: 0.606706] [G loss: 0.848828]\n",
      "[Epoch 15/200] [Batch 141/169] [D loss: 0.682801] [G loss: 0.896563]\n",
      "[Epoch 15/200] [Batch 142/169] [D loss: 0.637758] [G loss: 0.908592]\n",
      "[Epoch 15/200] [Batch 143/169] [D loss: 0.531288] [G loss: 0.885877]\n",
      "[Epoch 15/200] [Batch 144/169] [D loss: 0.651258] [G loss: 0.994701]\n",
      "[Epoch 15/200] [Batch 145/169] [D loss: 0.613625] [G loss: 0.790553]\n",
      "[Epoch 15/200] [Batch 146/169] [D loss: 0.585969] [G loss: 1.190910]\n",
      "[Epoch 15/200] [Batch 147/169] [D loss: 0.595098] [G loss: 1.002942]\n",
      "[Epoch 15/200] [Batch 148/169] [D loss: 0.635762] [G loss: 0.904877]\n",
      "[Epoch 15/200] [Batch 149/169] [D loss: 0.658804] [G loss: 1.016225]\n",
      "[Epoch 15/200] [Batch 150/169] [D loss: 0.612271] [G loss: 0.819724]\n",
      "[Epoch 15/200] [Batch 151/169] [D loss: 0.601094] [G loss: 1.000341]\n",
      "[Epoch 15/200] [Batch 152/169] [D loss: 0.582848] [G loss: 0.741944]\n",
      "[Epoch 15/200] [Batch 153/169] [D loss: 0.648136] [G loss: 0.955768]\n",
      "[Epoch 15/200] [Batch 154/169] [D loss: 0.596578] [G loss: 0.789483]\n",
      "[Epoch 15/200] [Batch 155/169] [D loss: 0.598219] [G loss: 0.732970]\n",
      "[Epoch 15/200] [Batch 156/169] [D loss: 0.612189] [G loss: 0.941175]\n",
      "[Epoch 15/200] [Batch 157/169] [D loss: 0.592148] [G loss: 0.857805]\n",
      "[Epoch 15/200] [Batch 158/169] [D loss: 0.631650] [G loss: 1.155580]\n",
      "[Epoch 15/200] [Batch 159/169] [D loss: 0.667832] [G loss: 1.072397]\n",
      "[Epoch 15/200] [Batch 160/169] [D loss: 0.591818] [G loss: 0.880800]\n",
      "[Epoch 15/200] [Batch 161/169] [D loss: 0.607754] [G loss: 0.908829]\n",
      "[Epoch 15/200] [Batch 162/169] [D loss: 0.596209] [G loss: 0.954363]\n",
      "[Epoch 15/200] [Batch 163/169] [D loss: 0.631635] [G loss: 0.959143]\n",
      "[Epoch 15/200] [Batch 164/169] [D loss: 0.633116] [G loss: 0.953322]\n",
      "[Epoch 15/200] [Batch 165/169] [D loss: 0.607518] [G loss: 0.808379]\n",
      "[Epoch 15/200] [Batch 166/169] [D loss: 0.677424] [G loss: 0.749202]\n",
      "[Epoch 15/200] [Batch 167/169] [D loss: 0.654284] [G loss: 0.852976]\n",
      "[Epoch 15/200] [Batch 168/169] [D loss: 0.592949] [G loss: 0.836943]\n",
      "[Epoch 16/200] [Batch 0/169] [D loss: 0.666401] [G loss: 0.842498]\n",
      "[Epoch 16/200] [Batch 1/169] [D loss: 0.660209] [G loss: 0.991094]\n",
      "[Epoch 16/200] [Batch 2/169] [D loss: 0.625356] [G loss: 0.992140]\n",
      "[Epoch 16/200] [Batch 3/169] [D loss: 0.645175] [G loss: 0.820336]\n",
      "[Epoch 16/200] [Batch 4/169] [D loss: 0.593985] [G loss: 0.807546]\n",
      "[Epoch 16/200] [Batch 5/169] [D loss: 0.650735] [G loss: 0.912674]\n",
      "[Epoch 16/200] [Batch 6/169] [D loss: 0.573119] [G loss: 0.875293]\n",
      "[Epoch 16/200] [Batch 7/169] [D loss: 0.679828] [G loss: 0.897357]\n",
      "[Epoch 16/200] [Batch 8/169] [D loss: 0.607751] [G loss: 1.078107]\n",
      "[Epoch 16/200] [Batch 9/169] [D loss: 0.575167] [G loss: 0.845024]\n",
      "[Epoch 16/200] [Batch 10/169] [D loss: 0.629470] [G loss: 0.955090]\n",
      "[Epoch 16/200] [Batch 11/169] [D loss: 0.601487] [G loss: 1.034678]\n",
      "[Epoch 16/200] [Batch 12/169] [D loss: 0.518951] [G loss: 0.960603]\n",
      "[Epoch 16/200] [Batch 13/169] [D loss: 0.572947] [G loss: 0.843099]\n",
      "[Epoch 16/200] [Batch 14/169] [D loss: 0.599863] [G loss: 0.772127]\n",
      "[Epoch 16/200] [Batch 15/169] [D loss: 0.515717] [G loss: 1.011205]\n",
      "[Epoch 16/200] [Batch 16/169] [D loss: 0.604994] [G loss: 0.852639]\n",
      "[Epoch 16/200] [Batch 17/169] [D loss: 0.648096] [G loss: 0.761472]\n",
      "[Epoch 16/200] [Batch 18/169] [D loss: 0.638230] [G loss: 0.916653]\n",
      "[Epoch 16/200] [Batch 19/169] [D loss: 0.648651] [G loss: 0.946068]\n",
      "[Epoch 16/200] [Batch 20/169] [D loss: 0.679428] [G loss: 0.848691]\n",
      "[Epoch 16/200] [Batch 21/169] [D loss: 0.666382] [G loss: 0.818419]\n",
      "[Epoch 16/200] [Batch 22/169] [D loss: 0.556167] [G loss: 0.938954]\n",
      "[Epoch 16/200] [Batch 23/169] [D loss: 0.596112] [G loss: 0.847485]\n",
      "[Epoch 16/200] [Batch 24/169] [D loss: 0.614329] [G loss: 1.024104]\n",
      "[Epoch 16/200] [Batch 25/169] [D loss: 0.626489] [G loss: 1.366481]\n",
      "[Epoch 16/200] [Batch 26/169] [D loss: 0.579958] [G loss: 1.022582]\n",
      "[Epoch 16/200] [Batch 27/169] [D loss: 0.733527] [G loss: 0.894064]\n",
      "[Epoch 16/200] [Batch 28/169] [D loss: 0.659023] [G loss: 0.849943]\n",
      "[Epoch 16/200] [Batch 29/169] [D loss: 0.722326] [G loss: 0.932524]\n",
      "[Epoch 16/200] [Batch 30/169] [D loss: 0.676710] [G loss: 0.975922]\n",
      "[Epoch 16/200] [Batch 31/169] [D loss: 0.734142] [G loss: 0.950927]\n",
      "[Epoch 16/200] [Batch 32/169] [D loss: 0.755848] [G loss: 0.955974]\n",
      "[Epoch 16/200] [Batch 33/169] [D loss: 0.644987] [G loss: 0.813840]\n",
      "[Epoch 16/200] [Batch 34/169] [D loss: 0.694392] [G loss: 0.817190]\n",
      "[Epoch 16/200] [Batch 35/169] [D loss: 0.724340] [G loss: 0.902364]\n",
      "[Epoch 16/200] [Batch 36/169] [D loss: 0.591015] [G loss: 0.817482]\n",
      "[Epoch 16/200] [Batch 37/169] [D loss: 0.656522] [G loss: 0.948169]\n",
      "[Epoch 16/200] [Batch 38/169] [D loss: 0.733773] [G loss: 0.989241]\n",
      "[Epoch 16/200] [Batch 39/169] [D loss: 0.608459] [G loss: 0.862741]\n",
      "[Epoch 16/200] [Batch 40/169] [D loss: 0.653476] [G loss: 0.742510]\n",
      "[Epoch 16/200] [Batch 41/169] [D loss: 0.659179] [G loss: 0.881279]\n",
      "[Epoch 16/200] [Batch 42/169] [D loss: 0.590714] [G loss: 1.026888]\n",
      "[Epoch 16/200] [Batch 43/169] [D loss: 0.666972] [G loss: 1.006445]\n",
      "[Epoch 16/200] [Batch 44/169] [D loss: 0.679405] [G loss: 0.678799]\n",
      "[Epoch 16/200] [Batch 45/169] [D loss: 0.647260] [G loss: 0.843184]\n",
      "[Epoch 16/200] [Batch 46/169] [D loss: 0.629286] [G loss: 1.165801]\n",
      "[Epoch 16/200] [Batch 47/169] [D loss: 0.644448] [G loss: 1.178809]\n",
      "[Epoch 16/200] [Batch 48/169] [D loss: 0.556522] [G loss: 1.040296]\n",
      "[Epoch 16/200] [Batch 49/169] [D loss: 0.652175] [G loss: 0.845506]\n",
      "[Epoch 16/200] [Batch 50/169] [D loss: 0.599163] [G loss: 0.981217]\n",
      "[Epoch 16/200] [Batch 51/169] [D loss: 0.592785] [G loss: 0.953616]\n",
      "[Epoch 16/200] [Batch 52/169] [D loss: 0.632846] [G loss: 0.768745]\n",
      "[Epoch 16/200] [Batch 53/169] [D loss: 0.597872] [G loss: 0.783923]\n",
      "[Epoch 16/200] [Batch 54/169] [D loss: 0.524320] [G loss: 0.882788]\n",
      "[Epoch 16/200] [Batch 55/169] [D loss: 0.691691] [G loss: 0.868840]\n",
      "[Epoch 16/200] [Batch 56/169] [D loss: 0.596452] [G loss: 0.943595]\n",
      "[Epoch 16/200] [Batch 57/169] [D loss: 0.623997] [G loss: 0.911296]\n",
      "[Epoch 16/200] [Batch 58/169] [D loss: 0.703009] [G loss: 0.793948]\n",
      "[Epoch 16/200] [Batch 59/169] [D loss: 0.620790] [G loss: 0.813659]\n",
      "[Epoch 16/200] [Batch 60/169] [D loss: 0.741098] [G loss: 0.817497]\n",
      "[Epoch 16/200] [Batch 61/169] [D loss: 0.629374] [G loss: 0.934893]\n",
      "[Epoch 16/200] [Batch 62/169] [D loss: 0.595065] [G loss: 0.923270]\n",
      "[Epoch 16/200] [Batch 63/169] [D loss: 0.616177] [G loss: 0.949644]\n",
      "[Epoch 16/200] [Batch 64/169] [D loss: 0.654395] [G loss: 0.999185]\n",
      "[Epoch 16/200] [Batch 65/169] [D loss: 0.592816] [G loss: 1.003143]\n",
      "[Epoch 16/200] [Batch 66/169] [D loss: 0.652572] [G loss: 1.011488]\n",
      "[Epoch 16/200] [Batch 67/169] [D loss: 0.666238] [G loss: 1.101246]\n",
      "[Epoch 16/200] [Batch 68/169] [D loss: 0.625470] [G loss: 0.902286]\n",
      "[Epoch 16/200] [Batch 69/169] [D loss: 0.565478] [G loss: 0.799558]\n",
      "[Epoch 16/200] [Batch 70/169] [D loss: 0.623683] [G loss: 0.940036]\n",
      "[Epoch 16/200] [Batch 71/169] [D loss: 0.586362] [G loss: 0.865052]\n",
      "[Epoch 16/200] [Batch 72/169] [D loss: 0.659409] [G loss: 0.875671]\n",
      "[Epoch 16/200] [Batch 73/169] [D loss: 0.725119] [G loss: 0.954470]\n",
      "[Epoch 16/200] [Batch 74/169] [D loss: 0.644226] [G loss: 0.988267]\n",
      "[Epoch 16/200] [Batch 75/169] [D loss: 0.605723] [G loss: 1.028972]\n",
      "[Epoch 16/200] [Batch 76/169] [D loss: 0.674875] [G loss: 0.883745]\n",
      "[Epoch 16/200] [Batch 77/169] [D loss: 0.657008] [G loss: 1.023211]\n",
      "[Epoch 16/200] [Batch 78/169] [D loss: 0.664339] [G loss: 0.956703]\n",
      "[Epoch 16/200] [Batch 79/169] [D loss: 0.636829] [G loss: 0.807525]\n",
      "[Epoch 16/200] [Batch 80/169] [D loss: 0.634227] [G loss: 0.879487]\n",
      "[Epoch 16/200] [Batch 81/169] [D loss: 0.689135] [G loss: 0.949582]\n",
      "[Epoch 16/200] [Batch 82/169] [D loss: 0.584999] [G loss: 0.893691]\n",
      "[Epoch 16/200] [Batch 83/169] [D loss: 0.677085] [G loss: 0.896862]\n",
      "[Epoch 16/200] [Batch 84/169] [D loss: 0.570538] [G loss: 0.977634]\n",
      "[Epoch 16/200] [Batch 85/169] [D loss: 0.569447] [G loss: 0.850178]\n",
      "[Epoch 16/200] [Batch 86/169] [D loss: 0.676707] [G loss: 0.808087]\n",
      "[Epoch 16/200] [Batch 87/169] [D loss: 0.673888] [G loss: 0.759970]\n",
      "[Epoch 16/200] [Batch 88/169] [D loss: 0.623247] [G loss: 0.793627]\n",
      "[Epoch 16/200] [Batch 89/169] [D loss: 0.596439] [G loss: 0.920292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 90/169] [D loss: 0.653878] [G loss: 0.860129]\n",
      "[Epoch 16/200] [Batch 91/169] [D loss: 0.676795] [G loss: 0.800302]\n",
      "[Epoch 16/200] [Batch 92/169] [D loss: 0.643682] [G loss: 0.898428]\n",
      "[Epoch 16/200] [Batch 93/169] [D loss: 0.673432] [G loss: 0.837858]\n",
      "[Epoch 16/200] [Batch 94/169] [D loss: 0.656293] [G loss: 0.847715]\n",
      "[Epoch 16/200] [Batch 95/169] [D loss: 0.629790] [G loss: 0.896658]\n",
      "[Epoch 16/200] [Batch 96/169] [D loss: 0.670723] [G loss: 0.853578]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-cdee5f3eab41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msavepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'image_linear'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-acd13e2ff54d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m             print(\n\u001b[0;32m     49\u001b[0m                 \u001b[1;34m\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             )\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load2 = torch.load('net_state_dict.pth')\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "\n",
    "\n",
    "generator.load_state_dict(load2['generator'])\n",
    "generator.apply(weights_init_normal)             ### 初始化模型，保留线性\n",
    "discriminator.load_state_dict(load2['discriminator'])\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "optimizer_G.load_state_dict(load2['optimizer_G'])\n",
    "optimizer_D.load_state_dict(load2['optimizer_D'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "savepath = 'image_linear'\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf0c61",
   "metadata": {},
   "source": [
    "### 仅保留G的线性层，D也做相同的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d521917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/169] [D loss: 0.693483] [G loss: 0.699025]\n",
      "[Epoch 0/200] [Batch 1/169] [D loss: 0.693487] [G loss: 0.701954]\n",
      "[Epoch 0/200] [Batch 2/169] [D loss: 0.693386] [G loss: 0.702201]\n",
      "[Epoch 0/200] [Batch 3/169] [D loss: 0.693525] [G loss: 0.701149]\n",
      "[Epoch 0/200] [Batch 4/169] [D loss: 0.693290] [G loss: 0.699588]\n",
      "[Epoch 0/200] [Batch 5/169] [D loss: 0.693359] [G loss: 0.698255]\n",
      "[Epoch 0/200] [Batch 6/169] [D loss: 0.693396] [G loss: 0.696796]\n",
      "[Epoch 0/200] [Batch 7/169] [D loss: 0.693517] [G loss: 0.695417]\n",
      "[Epoch 0/200] [Batch 8/169] [D loss: 0.693440] [G loss: 0.694876]\n",
      "[Epoch 0/200] [Batch 9/169] [D loss: 0.693433] [G loss: 0.694103]\n",
      "[Epoch 0/200] [Batch 10/169] [D loss: 0.693267] [G loss: 0.693877]\n",
      "[Epoch 0/200] [Batch 11/169] [D loss: 0.693464] [G loss: 0.693499]\n",
      "[Epoch 0/200] [Batch 12/169] [D loss: 0.693391] [G loss: 0.693278]\n",
      "[Epoch 0/200] [Batch 13/169] [D loss: 0.693476] [G loss: 0.693358]\n",
      "[Epoch 0/200] [Batch 14/169] [D loss: 0.693364] [G loss: 0.693378]\n",
      "[Epoch 0/200] [Batch 15/169] [D loss: 0.693338] [G loss: 0.693265]\n",
      "[Epoch 0/200] [Batch 16/169] [D loss: 0.693356] [G loss: 0.693391]\n",
      "[Epoch 0/200] [Batch 17/169] [D loss: 0.693411] [G loss: 0.693096]\n",
      "[Epoch 0/200] [Batch 18/169] [D loss: 0.693334] [G loss: 0.693404]\n",
      "[Epoch 0/200] [Batch 19/169] [D loss: 0.693305] [G loss: 0.693277]\n",
      "[Epoch 0/200] [Batch 20/169] [D loss: 0.693404] [G loss: 0.693296]\n",
      "[Epoch 0/200] [Batch 21/169] [D loss: 0.693364] [G loss: 0.693277]\n",
      "[Epoch 0/200] [Batch 22/169] [D loss: 0.693260] [G loss: 0.693421]\n",
      "[Epoch 0/200] [Batch 23/169] [D loss: 0.693454] [G loss: 0.693189]\n",
      "[Epoch 0/200] [Batch 24/169] [D loss: 0.693310] [G loss: 0.693410]\n",
      "[Epoch 0/200] [Batch 25/169] [D loss: 0.693319] [G loss: 0.693360]\n",
      "[Epoch 0/200] [Batch 26/169] [D loss: 0.693269] [G loss: 0.693261]\n",
      "[Epoch 0/200] [Batch 27/169] [D loss: 0.693285] [G loss: 0.693444]\n",
      "[Epoch 0/200] [Batch 28/169] [D loss: 0.693299] [G loss: 0.693377]\n",
      "[Epoch 0/200] [Batch 29/169] [D loss: 0.693281] [G loss: 0.693091]\n",
      "[Epoch 0/200] [Batch 30/169] [D loss: 0.693358] [G loss: 0.693203]\n",
      "[Epoch 0/200] [Batch 31/169] [D loss: 0.693503] [G loss: 0.693306]\n",
      "[Epoch 0/200] [Batch 32/169] [D loss: 0.693294] [G loss: 0.693388]\n",
      "[Epoch 0/200] [Batch 33/169] [D loss: 0.693411] [G loss: 0.693331]\n",
      "[Epoch 0/200] [Batch 34/169] [D loss: 0.693202] [G loss: 0.693232]\n",
      "[Epoch 0/200] [Batch 35/169] [D loss: 0.693332] [G loss: 0.693422]\n",
      "[Epoch 0/200] [Batch 36/169] [D loss: 0.693235] [G loss: 0.693529]\n",
      "[Epoch 0/200] [Batch 37/169] [D loss: 0.693402] [G loss: 0.693297]\n",
      "[Epoch 0/200] [Batch 38/169] [D loss: 0.693214] [G loss: 0.693471]\n",
      "[Epoch 0/200] [Batch 39/169] [D loss: 0.693250] [G loss: 0.693302]\n",
      "[Epoch 0/200] [Batch 40/169] [D loss: 0.693400] [G loss: 0.693576]\n",
      "[Epoch 0/200] [Batch 41/169] [D loss: 0.693498] [G loss: 0.693348]\n",
      "[Epoch 0/200] [Batch 42/169] [D loss: 0.693210] [G loss: 0.693544]\n",
      "[Epoch 0/200] [Batch 43/169] [D loss: 0.693202] [G loss: 0.693426]\n",
      "[Epoch 0/200] [Batch 44/169] [D loss: 0.693519] [G loss: 0.693302]\n",
      "[Epoch 0/200] [Batch 45/169] [D loss: 0.693215] [G loss: 0.693619]\n",
      "[Epoch 0/200] [Batch 46/169] [D loss: 0.693240] [G loss: 0.693260]\n",
      "[Epoch 0/200] [Batch 47/169] [D loss: 0.693150] [G loss: 0.693341]\n",
      "[Epoch 0/200] [Batch 48/169] [D loss: 0.693188] [G loss: 0.693180]\n",
      "[Epoch 0/200] [Batch 49/169] [D loss: 0.693297] [G loss: 0.693466]\n",
      "[Epoch 0/200] [Batch 50/169] [D loss: 0.693412] [G loss: 0.693357]\n",
      "[Epoch 0/200] [Batch 51/169] [D loss: 0.693307] [G loss: 0.693479]\n",
      "[Epoch 0/200] [Batch 52/169] [D loss: 0.693409] [G loss: 0.693441]\n",
      "[Epoch 0/200] [Batch 53/169] [D loss: 0.693210] [G loss: 0.693344]\n",
      "[Epoch 0/200] [Batch 54/169] [D loss: 0.693249] [G loss: 0.693530]\n",
      "[Epoch 0/200] [Batch 55/169] [D loss: 0.693215] [G loss: 0.693320]\n",
      "[Epoch 0/200] [Batch 56/169] [D loss: 0.693040] [G loss: 0.693416]\n",
      "[Epoch 0/200] [Batch 57/169] [D loss: 0.693431] [G loss: 0.693406]\n",
      "[Epoch 0/200] [Batch 58/169] [D loss: 0.693437] [G loss: 0.693453]\n",
      "[Epoch 0/200] [Batch 59/169] [D loss: 0.693209] [G loss: 0.693552]\n",
      "[Epoch 0/200] [Batch 60/169] [D loss: 0.693124] [G loss: 0.693343]\n",
      "[Epoch 0/200] [Batch 61/169] [D loss: 0.693223] [G loss: 0.693298]\n",
      "[Epoch 0/200] [Batch 62/169] [D loss: 0.693100] [G loss: 0.693283]\n",
      "[Epoch 0/200] [Batch 63/169] [D loss: 0.693258] [G loss: 0.693332]\n",
      "[Epoch 0/200] [Batch 64/169] [D loss: 0.693196] [G loss: 0.693366]\n",
      "[Epoch 0/200] [Batch 65/169] [D loss: 0.693172] [G loss: 0.693293]\n",
      "[Epoch 0/200] [Batch 66/169] [D loss: 0.693316] [G loss: 0.693373]\n",
      "[Epoch 0/200] [Batch 67/169] [D loss: 0.693392] [G loss: 0.693209]\n",
      "[Epoch 0/200] [Batch 68/169] [D loss: 0.693167] [G loss: 0.693401]\n",
      "[Epoch 0/200] [Batch 69/169] [D loss: 0.693180] [G loss: 0.693438]\n",
      "[Epoch 0/200] [Batch 70/169] [D loss: 0.693282] [G loss: 0.693310]\n",
      "[Epoch 0/200] [Batch 71/169] [D loss: 0.693208] [G loss: 0.693393]\n",
      "[Epoch 0/200] [Batch 72/169] [D loss: 0.693448] [G loss: 0.693439]\n",
      "[Epoch 0/200] [Batch 73/169] [D loss: 0.693171] [G loss: 0.693125]\n",
      "[Epoch 0/200] [Batch 74/169] [D loss: 0.693252] [G loss: 0.693450]\n",
      "[Epoch 0/200] [Batch 75/169] [D loss: 0.693224] [G loss: 0.693025]\n",
      "[Epoch 0/200] [Batch 76/169] [D loss: 0.693248] [G loss: 0.693666]\n",
      "[Epoch 0/200] [Batch 77/169] [D loss: 0.693185] [G loss: 0.693379]\n",
      "[Epoch 0/200] [Batch 78/169] [D loss: 0.693176] [G loss: 0.693533]\n",
      "[Epoch 0/200] [Batch 79/169] [D loss: 0.693200] [G loss: 0.693369]\n",
      "[Epoch 0/200] [Batch 80/169] [D loss: 0.693234] [G loss: 0.693398]\n",
      "[Epoch 0/200] [Batch 81/169] [D loss: 0.693247] [G loss: 0.693470]\n",
      "[Epoch 0/200] [Batch 82/169] [D loss: 0.693250] [G loss: 0.693266]\n",
      "[Epoch 0/200] [Batch 83/169] [D loss: 0.693245] [G loss: 0.693504]\n",
      "[Epoch 0/200] [Batch 84/169] [D loss: 0.693057] [G loss: 0.693523]\n",
      "[Epoch 0/200] [Batch 85/169] [D loss: 0.693217] [G loss: 0.693498]\n",
      "[Epoch 0/200] [Batch 86/169] [D loss: 0.693054] [G loss: 0.693401]\n",
      "[Epoch 0/200] [Batch 87/169] [D loss: 0.693293] [G loss: 0.693458]\n",
      "[Epoch 0/200] [Batch 88/169] [D loss: 0.693198] [G loss: 0.693422]\n",
      "[Epoch 0/200] [Batch 89/169] [D loss: 0.693183] [G loss: 0.693398]\n",
      "[Epoch 0/200] [Batch 90/169] [D loss: 0.693203] [G loss: 0.693548]\n",
      "[Epoch 0/200] [Batch 91/169] [D loss: 0.693442] [G loss: 0.693406]\n",
      "[Epoch 0/200] [Batch 92/169] [D loss: 0.693039] [G loss: 0.693410]\n",
      "[Epoch 0/200] [Batch 93/169] [D loss: 0.693112] [G loss: 0.693576]\n",
      "[Epoch 0/200] [Batch 94/169] [D loss: 0.693287] [G loss: 0.693504]\n",
      "[Epoch 0/200] [Batch 95/169] [D loss: 0.693290] [G loss: 0.693329]\n",
      "[Epoch 0/200] [Batch 96/169] [D loss: 0.693027] [G loss: 0.693440]\n",
      "[Epoch 0/200] [Batch 97/169] [D loss: 0.693142] [G loss: 0.693431]\n",
      "[Epoch 0/200] [Batch 98/169] [D loss: 0.693156] [G loss: 0.693339]\n",
      "[Epoch 0/200] [Batch 99/169] [D loss: 0.693276] [G loss: 0.693607]\n",
      "[Epoch 0/200] [Batch 100/169] [D loss: 0.693123] [G loss: 0.693527]\n",
      "[Epoch 0/200] [Batch 101/169] [D loss: 0.693040] [G loss: 0.693374]\n",
      "[Epoch 0/200] [Batch 102/169] [D loss: 0.693106] [G loss: 0.693591]\n",
      "[Epoch 0/200] [Batch 103/169] [D loss: 0.693111] [G loss: 0.693529]\n",
      "[Epoch 0/200] [Batch 104/169] [D loss: 0.693205] [G loss: 0.693631]\n",
      "[Epoch 0/200] [Batch 105/169] [D loss: 0.693116] [G loss: 0.693426]\n",
      "[Epoch 0/200] [Batch 106/169] [D loss: 0.693241] [G loss: 0.693692]\n",
      "[Epoch 0/200] [Batch 107/169] [D loss: 0.693169] [G loss: 0.693513]\n",
      "[Epoch 0/200] [Batch 108/169] [D loss: 0.693092] [G loss: 0.693439]\n",
      "[Epoch 0/200] [Batch 109/169] [D loss: 0.693088] [G loss: 0.693610]\n",
      "[Epoch 0/200] [Batch 110/169] [D loss: 0.693039] [G loss: 0.693651]\n",
      "[Epoch 0/200] [Batch 111/169] [D loss: 0.693028] [G loss: 0.693368]\n",
      "[Epoch 0/200] [Batch 112/169] [D loss: 0.693147] [G loss: 0.693590]\n",
      "[Epoch 0/200] [Batch 113/169] [D loss: 0.693028] [G loss: 0.693550]\n",
      "[Epoch 0/200] [Batch 114/169] [D loss: 0.693234] [G loss: 0.693573]\n",
      "[Epoch 0/200] [Batch 115/169] [D loss: 0.693120] [G loss: 0.693583]\n",
      "[Epoch 0/200] [Batch 116/169] [D loss: 0.693005] [G loss: 0.693705]\n",
      "[Epoch 0/200] [Batch 117/169] [D loss: 0.693001] [G loss: 0.693783]\n",
      "[Epoch 0/200] [Batch 118/169] [D loss: 0.693057] [G loss: 0.693679]\n",
      "[Epoch 0/200] [Batch 119/169] [D loss: 0.693054] [G loss: 0.693475]\n",
      "[Epoch 0/200] [Batch 120/169] [D loss: 0.693141] [G loss: 0.693631]\n",
      "[Epoch 0/200] [Batch 121/169] [D loss: 0.692960] [G loss: 0.693462]\n",
      "[Epoch 0/200] [Batch 122/169] [D loss: 0.693136] [G loss: 0.693558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 123/169] [D loss: 0.693057] [G loss: 0.693474]\n",
      "[Epoch 0/200] [Batch 124/169] [D loss: 0.692861] [G loss: 0.693617]\n",
      "[Epoch 0/200] [Batch 125/169] [D loss: 0.693024] [G loss: 0.693773]\n",
      "[Epoch 0/200] [Batch 126/169] [D loss: 0.692947] [G loss: 0.693629]\n",
      "[Epoch 0/200] [Batch 127/169] [D loss: 0.693003] [G loss: 0.693518]\n",
      "[Epoch 0/200] [Batch 128/169] [D loss: 0.692984] [G loss: 0.693793]\n",
      "[Epoch 0/200] [Batch 129/169] [D loss: 0.693048] [G loss: 0.693587]\n",
      "[Epoch 0/200] [Batch 130/169] [D loss: 0.693012] [G loss: 0.693763]\n",
      "[Epoch 0/200] [Batch 131/169] [D loss: 0.692884] [G loss: 0.693600]\n",
      "[Epoch 0/200] [Batch 132/169] [D loss: 0.692920] [G loss: 0.693720]\n",
      "[Epoch 0/200] [Batch 133/169] [D loss: 0.692965] [G loss: 0.693474]\n",
      "[Epoch 0/200] [Batch 134/169] [D loss: 0.693029] [G loss: 0.693492]\n",
      "[Epoch 0/200] [Batch 135/169] [D loss: 0.692885] [G loss: 0.693623]\n",
      "[Epoch 0/200] [Batch 136/169] [D loss: 0.692918] [G loss: 0.693716]\n",
      "[Epoch 0/200] [Batch 137/169] [D loss: 0.692807] [G loss: 0.693689]\n",
      "[Epoch 0/200] [Batch 138/169] [D loss: 0.692896] [G loss: 0.693784]\n",
      "[Epoch 0/200] [Batch 139/169] [D loss: 0.692850] [G loss: 0.693596]\n",
      "[Epoch 0/200] [Batch 140/169] [D loss: 0.692929] [G loss: 0.693300]\n",
      "[Epoch 0/200] [Batch 141/169] [D loss: 0.693010] [G loss: 0.693656]\n",
      "[Epoch 0/200] [Batch 142/169] [D loss: 0.692946] [G loss: 0.693745]\n",
      "[Epoch 0/200] [Batch 143/169] [D loss: 0.692977] [G loss: 0.693638]\n",
      "[Epoch 0/200] [Batch 144/169] [D loss: 0.692948] [G loss: 0.693581]\n",
      "[Epoch 0/200] [Batch 145/169] [D loss: 0.692987] [G loss: 0.693608]\n",
      "[Epoch 0/200] [Batch 146/169] [D loss: 0.692832] [G loss: 0.693565]\n",
      "[Epoch 0/200] [Batch 147/169] [D loss: 0.692959] [G loss: 0.693619]\n",
      "[Epoch 0/200] [Batch 148/169] [D loss: 0.692904] [G loss: 0.693624]\n",
      "[Epoch 0/200] [Batch 149/169] [D loss: 0.692928] [G loss: 0.693607]\n",
      "[Epoch 0/200] [Batch 150/169] [D loss: 0.692762] [G loss: 0.693779]\n",
      "[Epoch 0/200] [Batch 151/169] [D loss: 0.693028] [G loss: 0.693685]\n",
      "[Epoch 0/200] [Batch 152/169] [D loss: 0.692897] [G loss: 0.693791]\n",
      "[Epoch 0/200] [Batch 153/169] [D loss: 0.692848] [G loss: 0.693682]\n",
      "[Epoch 0/200] [Batch 154/169] [D loss: 0.692820] [G loss: 0.693803]\n",
      "[Epoch 0/200] [Batch 155/169] [D loss: 0.692837] [G loss: 0.693964]\n",
      "[Epoch 0/200] [Batch 156/169] [D loss: 0.692776] [G loss: 0.693545]\n",
      "[Epoch 0/200] [Batch 157/169] [D loss: 0.692765] [G loss: 0.693626]\n",
      "[Epoch 0/200] [Batch 158/169] [D loss: 0.692731] [G loss: 0.693699]\n",
      "[Epoch 0/200] [Batch 159/169] [D loss: 0.692835] [G loss: 0.693839]\n",
      "[Epoch 0/200] [Batch 160/169] [D loss: 0.692923] [G loss: 0.693746]\n",
      "[Epoch 0/200] [Batch 161/169] [D loss: 0.692850] [G loss: 0.693729]\n",
      "[Epoch 0/200] [Batch 162/169] [D loss: 0.692813] [G loss: 0.693715]\n",
      "[Epoch 0/200] [Batch 163/169] [D loss: 0.692664] [G loss: 0.693641]\n",
      "[Epoch 0/200] [Batch 164/169] [D loss: 0.692664] [G loss: 0.693732]\n",
      "[Epoch 0/200] [Batch 165/169] [D loss: 0.692746] [G loss: 0.693918]\n",
      "[Epoch 0/200] [Batch 166/169] [D loss: 0.692783] [G loss: 0.693709]\n",
      "[Epoch 0/200] [Batch 167/169] [D loss: 0.692693] [G loss: 0.693744]\n",
      "[Epoch 0/200] [Batch 168/169] [D loss: 0.692659] [G loss: 0.693495]\n",
      "[Epoch 1/200] [Batch 0/169] [D loss: 0.692648] [G loss: 0.694032]\n",
      "[Epoch 1/200] [Batch 1/169] [D loss: 0.692722] [G loss: 0.693766]\n",
      "[Epoch 1/200] [Batch 2/169] [D loss: 0.692544] [G loss: 0.694070]\n",
      "[Epoch 1/200] [Batch 3/169] [D loss: 0.692598] [G loss: 0.693877]\n",
      "[Epoch 1/200] [Batch 4/169] [D loss: 0.692603] [G loss: 0.694071]\n",
      "[Epoch 1/200] [Batch 5/169] [D loss: 0.692528] [G loss: 0.694140]\n",
      "[Epoch 1/200] [Batch 6/169] [D loss: 0.692651] [G loss: 0.694118]\n",
      "[Epoch 1/200] [Batch 7/169] [D loss: 0.692784] [G loss: 0.693948]\n",
      "[Epoch 1/200] [Batch 8/169] [D loss: 0.692580] [G loss: 0.693852]\n",
      "[Epoch 1/200] [Batch 9/169] [D loss: 0.692503] [G loss: 0.693855]\n",
      "[Epoch 1/200] [Batch 10/169] [D loss: 0.692421] [G loss: 0.694006]\n",
      "[Epoch 1/200] [Batch 11/169] [D loss: 0.692398] [G loss: 0.693909]\n",
      "[Epoch 1/200] [Batch 12/169] [D loss: 0.692523] [G loss: 0.693915]\n",
      "[Epoch 1/200] [Batch 13/169] [D loss: 0.692428] [G loss: 0.694049]\n",
      "[Epoch 1/200] [Batch 14/169] [D loss: 0.692773] [G loss: 0.694065]\n",
      "[Epoch 1/200] [Batch 15/169] [D loss: 0.692357] [G loss: 0.694117]\n",
      "[Epoch 1/200] [Batch 16/169] [D loss: 0.692251] [G loss: 0.694109]\n",
      "[Epoch 1/200] [Batch 17/169] [D loss: 0.692285] [G loss: 0.694139]\n",
      "[Epoch 1/200] [Batch 18/169] [D loss: 0.692529] [G loss: 0.694179]\n",
      "[Epoch 1/200] [Batch 19/169] [D loss: 0.692419] [G loss: 0.694151]\n",
      "[Epoch 1/200] [Batch 20/169] [D loss: 0.692158] [G loss: 0.694177]\n",
      "[Epoch 1/200] [Batch 21/169] [D loss: 0.692529] [G loss: 0.694168]\n",
      "[Epoch 1/200] [Batch 22/169] [D loss: 0.692290] [G loss: 0.694147]\n",
      "[Epoch 1/200] [Batch 23/169] [D loss: 0.692164] [G loss: 0.694255]\n",
      "[Epoch 1/200] [Batch 24/169] [D loss: 0.692311] [G loss: 0.694406]\n",
      "[Epoch 1/200] [Batch 25/169] [D loss: 0.692174] [G loss: 0.694209]\n",
      "[Epoch 1/200] [Batch 26/169] [D loss: 0.692289] [G loss: 0.694191]\n",
      "[Epoch 1/200] [Batch 27/169] [D loss: 0.691998] [G loss: 0.694242]\n",
      "[Epoch 1/200] [Batch 28/169] [D loss: 0.692018] [G loss: 0.694559]\n",
      "[Epoch 1/200] [Batch 29/169] [D loss: 0.692191] [G loss: 0.694432]\n",
      "[Epoch 1/200] [Batch 30/169] [D loss: 0.691921] [G loss: 0.694575]\n",
      "[Epoch 1/200] [Batch 31/169] [D loss: 0.692133] [G loss: 0.694524]\n",
      "[Epoch 1/200] [Batch 32/169] [D loss: 0.691790] [G loss: 0.694481]\n",
      "[Epoch 1/200] [Batch 33/169] [D loss: 0.691922] [G loss: 0.694303]\n",
      "[Epoch 1/200] [Batch 34/169] [D loss: 0.691810] [G loss: 0.694498]\n",
      "[Epoch 1/200] [Batch 35/169] [D loss: 0.691827] [G loss: 0.694605]\n",
      "[Epoch 1/200] [Batch 36/169] [D loss: 0.691786] [G loss: 0.694612]\n",
      "[Epoch 1/200] [Batch 37/169] [D loss: 0.691857] [G loss: 0.694466]\n",
      "[Epoch 1/200] [Batch 38/169] [D loss: 0.691789] [G loss: 0.694605]\n",
      "[Epoch 1/200] [Batch 39/169] [D loss: 0.691587] [G loss: 0.694898]\n",
      "[Epoch 1/200] [Batch 40/169] [D loss: 0.691643] [G loss: 0.694649]\n",
      "[Epoch 1/200] [Batch 41/169] [D loss: 0.691421] [G loss: 0.694732]\n",
      "[Epoch 1/200] [Batch 42/169] [D loss: 0.691592] [G loss: 0.694851]\n",
      "[Epoch 1/200] [Batch 43/169] [D loss: 0.691687] [G loss: 0.694999]\n",
      "[Epoch 1/200] [Batch 44/169] [D loss: 0.691336] [G loss: 0.694889]\n",
      "[Epoch 1/200] [Batch 45/169] [D loss: 0.691312] [G loss: 0.695010]\n",
      "[Epoch 1/200] [Batch 46/169] [D loss: 0.691199] [G loss: 0.694998]\n",
      "[Epoch 1/200] [Batch 47/169] [D loss: 0.690978] [G loss: 0.695065]\n",
      "[Epoch 1/200] [Batch 48/169] [D loss: 0.691150] [G loss: 0.695209]\n",
      "[Epoch 1/200] [Batch 49/169] [D loss: 0.690670] [G loss: 0.695214]\n",
      "[Epoch 1/200] [Batch 50/169] [D loss: 0.690943] [G loss: 0.695473]\n",
      "[Epoch 1/200] [Batch 51/169] [D loss: 0.690620] [G loss: 0.695409]\n",
      "[Epoch 1/200] [Batch 52/169] [D loss: 0.690704] [G loss: 0.695739]\n",
      "[Epoch 1/200] [Batch 53/169] [D loss: 0.690605] [G loss: 0.695685]\n",
      "[Epoch 1/200] [Batch 54/169] [D loss: 0.690486] [G loss: 0.695594]\n",
      "[Epoch 1/200] [Batch 55/169] [D loss: 0.690474] [G loss: 0.695801]\n",
      "[Epoch 1/200] [Batch 56/169] [D loss: 0.690390] [G loss: 0.695905]\n",
      "[Epoch 1/200] [Batch 57/169] [D loss: 0.690689] [G loss: 0.695893]\n",
      "[Epoch 1/200] [Batch 58/169] [D loss: 0.690329] [G loss: 0.696085]\n",
      "[Epoch 1/200] [Batch 59/169] [D loss: 0.690089] [G loss: 0.695582]\n",
      "[Epoch 1/200] [Batch 60/169] [D loss: 0.689671] [G loss: 0.696254]\n",
      "[Epoch 1/200] [Batch 61/169] [D loss: 0.689776] [G loss: 0.696209]\n",
      "[Epoch 1/200] [Batch 62/169] [D loss: 0.689289] [G loss: 0.696455]\n",
      "[Epoch 1/200] [Batch 63/169] [D loss: 0.689012] [G loss: 0.696141]\n",
      "[Epoch 1/200] [Batch 64/169] [D loss: 0.688946] [G loss: 0.696329]\n",
      "[Epoch 1/200] [Batch 65/169] [D loss: 0.688983] [G loss: 0.696479]\n",
      "[Epoch 1/200] [Batch 66/169] [D loss: 0.689080] [G loss: 0.697060]\n",
      "[Epoch 1/200] [Batch 67/169] [D loss: 0.688361] [G loss: 0.697261]\n",
      "[Epoch 1/200] [Batch 68/169] [D loss: 0.688306] [G loss: 0.697399]\n",
      "[Epoch 1/200] [Batch 69/169] [D loss: 0.688444] [G loss: 0.697497]\n",
      "[Epoch 1/200] [Batch 70/169] [D loss: 0.687932] [G loss: 0.697726]\n",
      "[Epoch 1/200] [Batch 71/169] [D loss: 0.687228] [G loss: 0.697956]\n",
      "[Epoch 1/200] [Batch 72/169] [D loss: 0.688150] [G loss: 0.698278]\n",
      "[Epoch 1/200] [Batch 73/169] [D loss: 0.686907] [G loss: 0.697868]\n",
      "[Epoch 1/200] [Batch 74/169] [D loss: 0.687288] [G loss: 0.698205]\n",
      "[Epoch 1/200] [Batch 75/169] [D loss: 0.686866] [G loss: 0.698294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 76/169] [D loss: 0.687716] [G loss: 0.698347]\n",
      "[Epoch 1/200] [Batch 77/169] [D loss: 0.686916] [G loss: 0.698352]\n",
      "[Epoch 1/200] [Batch 78/169] [D loss: 0.687199] [G loss: 0.698841]\n",
      "[Epoch 1/200] [Batch 79/169] [D loss: 0.686373] [G loss: 0.698204]\n",
      "[Epoch 1/200] [Batch 80/169] [D loss: 0.685269] [G loss: 0.698634]\n",
      "[Epoch 1/200] [Batch 81/169] [D loss: 0.685939] [G loss: 0.697981]\n",
      "[Epoch 1/200] [Batch 82/169] [D loss: 0.685343] [G loss: 0.698018]\n",
      "[Epoch 1/200] [Batch 83/169] [D loss: 0.684441] [G loss: 0.698559]\n",
      "[Epoch 1/200] [Batch 84/169] [D loss: 0.685113] [G loss: 0.697916]\n",
      "[Epoch 1/200] [Batch 85/169] [D loss: 0.686255] [G loss: 0.697587]\n",
      "[Epoch 1/200] [Batch 86/169] [D loss: 0.684866] [G loss: 0.697293]\n",
      "[Epoch 1/200] [Batch 87/169] [D loss: 0.686034] [G loss: 0.696733]\n",
      "[Epoch 1/200] [Batch 88/169] [D loss: 0.686051] [G loss: 0.696276]\n",
      "[Epoch 1/200] [Batch 89/169] [D loss: 0.687464] [G loss: 0.693556]\n",
      "[Epoch 1/200] [Batch 90/169] [D loss: 0.687267] [G loss: 0.692798]\n",
      "[Epoch 1/200] [Batch 91/169] [D loss: 0.687347] [G loss: 0.690057]\n",
      "[Epoch 1/200] [Batch 92/169] [D loss: 0.690157] [G loss: 0.688191]\n",
      "[Epoch 1/200] [Batch 93/169] [D loss: 0.690903] [G loss: 0.691255]\n",
      "[Epoch 1/200] [Batch 94/169] [D loss: 0.690285] [G loss: 0.690266]\n",
      "[Epoch 1/200] [Batch 95/169] [D loss: 0.691788] [G loss: 0.690101]\n",
      "[Epoch 1/200] [Batch 96/169] [D loss: 0.692166] [G loss: 0.690717]\n",
      "[Epoch 1/200] [Batch 97/169] [D loss: 0.692426] [G loss: 0.690083]\n",
      "[Epoch 1/200] [Batch 98/169] [D loss: 0.694140] [G loss: 0.687791]\n",
      "[Epoch 1/200] [Batch 99/169] [D loss: 0.693730] [G loss: 0.689867]\n",
      "[Epoch 1/200] [Batch 100/169] [D loss: 0.695300] [G loss: 0.686242]\n",
      "[Epoch 1/200] [Batch 101/169] [D loss: 0.695123] [G loss: 0.686363]\n",
      "[Epoch 1/200] [Batch 102/169] [D loss: 0.696030] [G loss: 0.686846]\n",
      "[Epoch 1/200] [Batch 103/169] [D loss: 0.696992] [G loss: 0.684725]\n",
      "[Epoch 1/200] [Batch 104/169] [D loss: 0.697873] [G loss: 0.690211]\n",
      "[Epoch 1/200] [Batch 105/169] [D loss: 0.696744] [G loss: 0.688992]\n",
      "[Epoch 1/200] [Batch 106/169] [D loss: 0.696822] [G loss: 0.692394]\n",
      "[Epoch 1/200] [Batch 107/169] [D loss: 0.698109] [G loss: 0.692791]\n",
      "[Epoch 1/200] [Batch 108/169] [D loss: 0.697873] [G loss: 0.690931]\n",
      "[Epoch 1/200] [Batch 109/169] [D loss: 0.696577] [G loss: 0.692479]\n",
      "[Epoch 1/200] [Batch 110/169] [D loss: 0.695377] [G loss: 0.692684]\n",
      "[Epoch 1/200] [Batch 111/169] [D loss: 0.695621] [G loss: 0.692752]\n",
      "[Epoch 1/200] [Batch 112/169] [D loss: 0.696123] [G loss: 0.692842]\n",
      "[Epoch 1/200] [Batch 113/169] [D loss: 0.694911] [G loss: 0.694821]\n",
      "[Epoch 1/200] [Batch 114/169] [D loss: 0.696285] [G loss: 0.694272]\n",
      "[Epoch 1/200] [Batch 115/169] [D loss: 0.692947] [G loss: 0.692085]\n",
      "[Epoch 1/200] [Batch 116/169] [D loss: 0.694625] [G loss: 0.692845]\n",
      "[Epoch 1/200] [Batch 117/169] [D loss: 0.696025] [G loss: 0.695318]\n",
      "[Epoch 1/200] [Batch 118/169] [D loss: 0.695740] [G loss: 0.693547]\n",
      "[Epoch 1/200] [Batch 119/169] [D loss: 0.694436] [G loss: 0.692585]\n",
      "[Epoch 1/200] [Batch 120/169] [D loss: 0.693785] [G loss: 0.694635]\n",
      "[Epoch 1/200] [Batch 121/169] [D loss: 0.693932] [G loss: 0.697095]\n",
      "[Epoch 1/200] [Batch 122/169] [D loss: 0.695000] [G loss: 0.693942]\n",
      "[Epoch 1/200] [Batch 123/169] [D loss: 0.694844] [G loss: 0.696481]\n",
      "[Epoch 1/200] [Batch 124/169] [D loss: 0.694319] [G loss: 0.694464]\n",
      "[Epoch 1/200] [Batch 125/169] [D loss: 0.694852] [G loss: 0.695530]\n",
      "[Epoch 1/200] [Batch 126/169] [D loss: 0.693927] [G loss: 0.695409]\n",
      "[Epoch 1/200] [Batch 127/169] [D loss: 0.693223] [G loss: 0.694225]\n",
      "[Epoch 1/200] [Batch 128/169] [D loss: 0.693897] [G loss: 0.695990]\n",
      "[Epoch 1/200] [Batch 129/169] [D loss: 0.693015] [G loss: 0.695020]\n",
      "[Epoch 1/200] [Batch 130/169] [D loss: 0.693796] [G loss: 0.694268]\n",
      "[Epoch 1/200] [Batch 131/169] [D loss: 0.693399] [G loss: 0.694790]\n",
      "[Epoch 1/200] [Batch 132/169] [D loss: 0.692809] [G loss: 0.695880]\n",
      "[Epoch 1/200] [Batch 133/169] [D loss: 0.692392] [G loss: 0.694765]\n",
      "[Epoch 1/200] [Batch 134/169] [D loss: 0.693077] [G loss: 0.694193]\n",
      "[Epoch 1/200] [Batch 135/169] [D loss: 0.693305] [G loss: 0.693412]\n",
      "[Epoch 1/200] [Batch 136/169] [D loss: 0.693389] [G loss: 0.693295]\n",
      "[Epoch 1/200] [Batch 137/169] [D loss: 0.692394] [G loss: 0.696631]\n",
      "[Epoch 1/200] [Batch 138/169] [D loss: 0.692817] [G loss: 0.696329]\n",
      "[Epoch 1/200] [Batch 139/169] [D loss: 0.692571] [G loss: 0.694811]\n",
      "[Epoch 1/200] [Batch 140/169] [D loss: 0.693464] [G loss: 0.694641]\n",
      "[Epoch 1/200] [Batch 141/169] [D loss: 0.692431] [G loss: 0.696302]\n",
      "[Epoch 1/200] [Batch 142/169] [D loss: 0.693504] [G loss: 0.695125]\n",
      "[Epoch 1/200] [Batch 143/169] [D loss: 0.692080] [G loss: 0.695303]\n",
      "[Epoch 1/200] [Batch 144/169] [D loss: 0.694192] [G loss: 0.695063]\n",
      "[Epoch 1/200] [Batch 145/169] [D loss: 0.692065] [G loss: 0.695766]\n",
      "[Epoch 1/200] [Batch 146/169] [D loss: 0.692013] [G loss: 0.696232]\n",
      "[Epoch 1/200] [Batch 147/169] [D loss: 0.690194] [G loss: 0.696956]\n",
      "[Epoch 1/200] [Batch 148/169] [D loss: 0.690704] [G loss: 0.697193]\n",
      "[Epoch 1/200] [Batch 149/169] [D loss: 0.692362] [G loss: 0.694431]\n",
      "[Epoch 1/200] [Batch 150/169] [D loss: 0.692624] [G loss: 0.692781]\n",
      "[Epoch 1/200] [Batch 151/169] [D loss: 0.692286] [G loss: 0.695186]\n",
      "[Epoch 1/200] [Batch 152/169] [D loss: 0.691404] [G loss: 0.698088]\n",
      "[Epoch 1/200] [Batch 153/169] [D loss: 0.692702] [G loss: 0.695258]\n",
      "[Epoch 1/200] [Batch 154/169] [D loss: 0.691853] [G loss: 0.695336]\n",
      "[Epoch 1/200] [Batch 155/169] [D loss: 0.691572] [G loss: 0.696932]\n",
      "[Epoch 1/200] [Batch 156/169] [D loss: 0.693190] [G loss: 0.693826]\n",
      "[Epoch 1/200] [Batch 157/169] [D loss: 0.692241] [G loss: 0.694387]\n",
      "[Epoch 1/200] [Batch 158/169] [D loss: 0.694285] [G loss: 0.692616]\n",
      "[Epoch 1/200] [Batch 159/169] [D loss: 0.694187] [G loss: 0.693917]\n",
      "[Epoch 1/200] [Batch 160/169] [D loss: 0.691282] [G loss: 0.693962]\n",
      "[Epoch 1/200] [Batch 161/169] [D loss: 0.693595] [G loss: 0.693003]\n",
      "[Epoch 1/200] [Batch 162/169] [D loss: 0.692649] [G loss: 0.695826]\n",
      "[Epoch 1/200] [Batch 163/169] [D loss: 0.691906] [G loss: 0.693949]\n",
      "[Epoch 1/200] [Batch 164/169] [D loss: 0.693376] [G loss: 0.694816]\n",
      "[Epoch 1/200] [Batch 165/169] [D loss: 0.692381] [G loss: 0.693523]\n",
      "[Epoch 1/200] [Batch 166/169] [D loss: 0.693709] [G loss: 0.691849]\n",
      "[Epoch 1/200] [Batch 167/169] [D loss: 0.693622] [G loss: 0.692503]\n",
      "[Epoch 1/200] [Batch 168/169] [D loss: 0.694451] [G loss: 0.693468]\n",
      "[Epoch 2/200] [Batch 0/169] [D loss: 0.692654] [G loss: 0.694590]\n",
      "[Epoch 2/200] [Batch 1/169] [D loss: 0.694517] [G loss: 0.692947]\n",
      "[Epoch 2/200] [Batch 2/169] [D loss: 0.695191] [G loss: 0.694804]\n",
      "[Epoch 2/200] [Batch 3/169] [D loss: 0.694836] [G loss: 0.693512]\n",
      "[Epoch 2/200] [Batch 4/169] [D loss: 0.695199] [G loss: 0.691781]\n",
      "[Epoch 2/200] [Batch 5/169] [D loss: 0.694224] [G loss: 0.695107]\n",
      "[Epoch 2/200] [Batch 6/169] [D loss: 0.694555] [G loss: 0.692632]\n",
      "[Epoch 2/200] [Batch 7/169] [D loss: 0.694170] [G loss: 0.693004]\n",
      "[Epoch 2/200] [Batch 8/169] [D loss: 0.694671] [G loss: 0.690287]\n",
      "[Epoch 2/200] [Batch 9/169] [D loss: 0.694946] [G loss: 0.692408]\n",
      "[Epoch 2/200] [Batch 10/169] [D loss: 0.694625] [G loss: 0.692986]\n",
      "[Epoch 2/200] [Batch 11/169] [D loss: 0.695322] [G loss: 0.691920]\n",
      "[Epoch 2/200] [Batch 12/169] [D loss: 0.694597] [G loss: 0.692284]\n",
      "[Epoch 2/200] [Batch 13/169] [D loss: 0.694792] [G loss: 0.692487]\n",
      "[Epoch 2/200] [Batch 14/169] [D loss: 0.694733] [G loss: 0.693582]\n",
      "[Epoch 2/200] [Batch 15/169] [D loss: 0.695766] [G loss: 0.692197]\n",
      "[Epoch 2/200] [Batch 16/169] [D loss: 0.694280] [G loss: 0.691767]\n",
      "[Epoch 2/200] [Batch 17/169] [D loss: 0.694452] [G loss: 0.693326]\n",
      "[Epoch 2/200] [Batch 18/169] [D loss: 0.696270] [G loss: 0.692408]\n",
      "[Epoch 2/200] [Batch 19/169] [D loss: 0.694282] [G loss: 0.693743]\n",
      "[Epoch 2/200] [Batch 20/169] [D loss: 0.694780] [G loss: 0.691983]\n",
      "[Epoch 2/200] [Batch 21/169] [D loss: 0.693609] [G loss: 0.691896]\n",
      "[Epoch 2/200] [Batch 22/169] [D loss: 0.694009] [G loss: 0.695466]\n",
      "[Epoch 2/200] [Batch 23/169] [D loss: 0.693053] [G loss: 0.692571]\n",
      "[Epoch 2/200] [Batch 24/169] [D loss: 0.693403] [G loss: 0.694352]\n",
      "[Epoch 2/200] [Batch 25/169] [D loss: 0.694283] [G loss: 0.692066]\n",
      "[Epoch 2/200] [Batch 26/169] [D loss: 0.694927] [G loss: 0.691893]\n",
      "[Epoch 2/200] [Batch 27/169] [D loss: 0.694366] [G loss: 0.693586]\n",
      "[Epoch 2/200] [Batch 28/169] [D loss: 0.693569] [G loss: 0.692620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 29/169] [D loss: 0.693726] [G loss: 0.693003]\n",
      "[Epoch 2/200] [Batch 30/169] [D loss: 0.694519] [G loss: 0.691839]\n",
      "[Epoch 2/200] [Batch 31/169] [D loss: 0.693902] [G loss: 0.691711]\n",
      "[Epoch 2/200] [Batch 32/169] [D loss: 0.694306] [G loss: 0.693285]\n",
      "[Epoch 2/200] [Batch 33/169] [D loss: 0.693704] [G loss: 0.692324]\n",
      "[Epoch 2/200] [Batch 34/169] [D loss: 0.693808] [G loss: 0.694530]\n",
      "[Epoch 2/200] [Batch 35/169] [D loss: 0.694040] [G loss: 0.692327]\n",
      "[Epoch 2/200] [Batch 36/169] [D loss: 0.693778] [G loss: 0.693142]\n",
      "[Epoch 2/200] [Batch 37/169] [D loss: 0.694486] [G loss: 0.693603]\n",
      "[Epoch 2/200] [Batch 38/169] [D loss: 0.693289] [G loss: 0.692713]\n",
      "[Epoch 2/200] [Batch 39/169] [D loss: 0.693959] [G loss: 0.694144]\n",
      "[Epoch 2/200] [Batch 40/169] [D loss: 0.693266] [G loss: 0.693675]\n",
      "[Epoch 2/200] [Batch 41/169] [D loss: 0.694029] [G loss: 0.691742]\n",
      "[Epoch 2/200] [Batch 42/169] [D loss: 0.694470] [G loss: 0.692846]\n",
      "[Epoch 2/200] [Batch 43/169] [D loss: 0.694209] [G loss: 0.692544]\n",
      "[Epoch 2/200] [Batch 44/169] [D loss: 0.693128] [G loss: 0.692680]\n",
      "[Epoch 2/200] [Batch 45/169] [D loss: 0.693410] [G loss: 0.693156]\n",
      "[Epoch 2/200] [Batch 46/169] [D loss: 0.693519] [G loss: 0.693877]\n",
      "[Epoch 2/200] [Batch 47/169] [D loss: 0.693988] [G loss: 0.692865]\n",
      "[Epoch 2/200] [Batch 48/169] [D loss: 0.692682] [G loss: 0.693947]\n",
      "[Epoch 2/200] [Batch 49/169] [D loss: 0.692702] [G loss: 0.694291]\n",
      "[Epoch 2/200] [Batch 50/169] [D loss: 0.693813] [G loss: 0.694036]\n",
      "[Epoch 2/200] [Batch 51/169] [D loss: 0.692839] [G loss: 0.692591]\n",
      "[Epoch 2/200] [Batch 52/169] [D loss: 0.692865] [G loss: 0.694188]\n",
      "[Epoch 2/200] [Batch 53/169] [D loss: 0.692959] [G loss: 0.693855]\n",
      "[Epoch 2/200] [Batch 54/169] [D loss: 0.693017] [G loss: 0.693518]\n",
      "[Epoch 2/200] [Batch 55/169] [D loss: 0.692653] [G loss: 0.694692]\n",
      "[Epoch 2/200] [Batch 56/169] [D loss: 0.693194] [G loss: 0.693841]\n",
      "[Epoch 2/200] [Batch 57/169] [D loss: 0.692342] [G loss: 0.694270]\n",
      "[Epoch 2/200] [Batch 58/169] [D loss: 0.692754] [G loss: 0.693698]\n",
      "[Epoch 2/200] [Batch 59/169] [D loss: 0.693340] [G loss: 0.693734]\n",
      "[Epoch 2/200] [Batch 60/169] [D loss: 0.692394] [G loss: 0.694091]\n",
      "[Epoch 2/200] [Batch 61/169] [D loss: 0.692600] [G loss: 0.693250]\n",
      "[Epoch 2/200] [Batch 62/169] [D loss: 0.692530] [G loss: 0.694718]\n",
      "[Epoch 2/200] [Batch 63/169] [D loss: 0.692371] [G loss: 0.693945]\n",
      "[Epoch 2/200] [Batch 64/169] [D loss: 0.692146] [G loss: 0.694026]\n",
      "[Epoch 2/200] [Batch 65/169] [D loss: 0.693347] [G loss: 0.693939]\n",
      "[Epoch 2/200] [Batch 66/169] [D loss: 0.692290] [G loss: 0.694083]\n",
      "[Epoch 2/200] [Batch 67/169] [D loss: 0.692388] [G loss: 0.695151]\n",
      "[Epoch 2/200] [Batch 68/169] [D loss: 0.691717] [G loss: 0.694111]\n",
      "[Epoch 2/200] [Batch 69/169] [D loss: 0.692518] [G loss: 0.694089]\n",
      "[Epoch 2/200] [Batch 70/169] [D loss: 0.693029] [G loss: 0.694905]\n",
      "[Epoch 2/200] [Batch 71/169] [D loss: 0.691947] [G loss: 0.694434]\n",
      "[Epoch 2/200] [Batch 72/169] [D loss: 0.692074] [G loss: 0.695008]\n",
      "[Epoch 2/200] [Batch 73/169] [D loss: 0.692560] [G loss: 0.694487]\n",
      "[Epoch 2/200] [Batch 74/169] [D loss: 0.691843] [G loss: 0.694506]\n",
      "[Epoch 2/200] [Batch 75/169] [D loss: 0.691793] [G loss: 0.695447]\n",
      "[Epoch 2/200] [Batch 76/169] [D loss: 0.692496] [G loss: 0.693857]\n",
      "[Epoch 2/200] [Batch 77/169] [D loss: 0.691673] [G loss: 0.695231]\n",
      "[Epoch 2/200] [Batch 78/169] [D loss: 0.692009] [G loss: 0.694833]\n",
      "[Epoch 2/200] [Batch 79/169] [D loss: 0.691525] [G loss: 0.695394]\n",
      "[Epoch 2/200] [Batch 80/169] [D loss: 0.691930] [G loss: 0.694689]\n",
      "[Epoch 2/200] [Batch 81/169] [D loss: 0.691755] [G loss: 0.694663]\n",
      "[Epoch 2/200] [Batch 82/169] [D loss: 0.691713] [G loss: 0.695404]\n",
      "[Epoch 2/200] [Batch 83/169] [D loss: 0.691910] [G loss: 0.695133]\n",
      "[Epoch 2/200] [Batch 84/169] [D loss: 0.691361] [G loss: 0.694826]\n",
      "[Epoch 2/200] [Batch 85/169] [D loss: 0.691548] [G loss: 0.695122]\n",
      "[Epoch 2/200] [Batch 86/169] [D loss: 0.691322] [G loss: 0.695716]\n",
      "[Epoch 2/200] [Batch 87/169] [D loss: 0.691192] [G loss: 0.694803]\n",
      "[Epoch 2/200] [Batch 88/169] [D loss: 0.691866] [G loss: 0.695180]\n",
      "[Epoch 2/200] [Batch 89/169] [D loss: 0.691726] [G loss: 0.694895]\n",
      "[Epoch 2/200] [Batch 90/169] [D loss: 0.691604] [G loss: 0.695412]\n",
      "[Epoch 2/200] [Batch 91/169] [D loss: 0.691772] [G loss: 0.694994]\n",
      "[Epoch 2/200] [Batch 92/169] [D loss: 0.690887] [G loss: 0.696496]\n",
      "[Epoch 2/200] [Batch 93/169] [D loss: 0.691027] [G loss: 0.694572]\n",
      "[Epoch 2/200] [Batch 94/169] [D loss: 0.691165] [G loss: 0.695316]\n",
      "[Epoch 2/200] [Batch 95/169] [D loss: 0.691278] [G loss: 0.695255]\n",
      "[Epoch 2/200] [Batch 96/169] [D loss: 0.690686] [G loss: 0.695844]\n",
      "[Epoch 2/200] [Batch 97/169] [D loss: 0.690938] [G loss: 0.696279]\n",
      "[Epoch 2/200] [Batch 98/169] [D loss: 0.690690] [G loss: 0.695626]\n",
      "[Epoch 2/200] [Batch 99/169] [D loss: 0.690686] [G loss: 0.696181]\n",
      "[Epoch 2/200] [Batch 100/169] [D loss: 0.690595] [G loss: 0.695810]\n",
      "[Epoch 2/200] [Batch 101/169] [D loss: 0.690971] [G loss: 0.695357]\n",
      "[Epoch 2/200] [Batch 102/169] [D loss: 0.690498] [G loss: 0.695838]\n",
      "[Epoch 2/200] [Batch 103/169] [D loss: 0.690739] [G loss: 0.695992]\n",
      "[Epoch 2/200] [Batch 104/169] [D loss: 0.690320] [G loss: 0.695299]\n",
      "[Epoch 2/200] [Batch 105/169] [D loss: 0.690247] [G loss: 0.696005]\n",
      "[Epoch 2/200] [Batch 106/169] [D loss: 0.690696] [G loss: 0.696248]\n",
      "[Epoch 2/200] [Batch 107/169] [D loss: 0.690503] [G loss: 0.695117]\n",
      "[Epoch 2/200] [Batch 108/169] [D loss: 0.691253] [G loss: 0.696897]\n",
      "[Epoch 2/200] [Batch 109/169] [D loss: 0.689761] [G loss: 0.696521]\n",
      "[Epoch 2/200] [Batch 110/169] [D loss: 0.690102] [G loss: 0.696261]\n",
      "[Epoch 2/200] [Batch 111/169] [D loss: 0.690173] [G loss: 0.695937]\n",
      "[Epoch 2/200] [Batch 112/169] [D loss: 0.689342] [G loss: 0.696313]\n",
      "[Epoch 2/200] [Batch 113/169] [D loss: 0.690128] [G loss: 0.696083]\n",
      "[Epoch 2/200] [Batch 114/169] [D loss: 0.689281] [G loss: 0.696315]\n",
      "[Epoch 2/200] [Batch 115/169] [D loss: 0.689456] [G loss: 0.697558]\n",
      "[Epoch 2/200] [Batch 116/169] [D loss: 0.690542] [G loss: 0.695970]\n",
      "[Epoch 2/200] [Batch 117/169] [D loss: 0.690079] [G loss: 0.696485]\n",
      "[Epoch 2/200] [Batch 118/169] [D loss: 0.690053] [G loss: 0.696448]\n",
      "[Epoch 2/200] [Batch 119/169] [D loss: 0.689588] [G loss: 0.696547]\n",
      "[Epoch 2/200] [Batch 120/169] [D loss: 0.689674] [G loss: 0.698532]\n",
      "[Epoch 2/200] [Batch 121/169] [D loss: 0.690399] [G loss: 0.695575]\n",
      "[Epoch 2/200] [Batch 122/169] [D loss: 0.689805] [G loss: 0.696491]\n",
      "[Epoch 2/200] [Batch 123/169] [D loss: 0.689276] [G loss: 0.697023]\n",
      "[Epoch 2/200] [Batch 124/169] [D loss: 0.689616] [G loss: 0.697303]\n",
      "[Epoch 2/200] [Batch 125/169] [D loss: 0.690017] [G loss: 0.696759]\n",
      "[Epoch 2/200] [Batch 126/169] [D loss: 0.690002] [G loss: 0.697616]\n",
      "[Epoch 2/200] [Batch 127/169] [D loss: 0.689176] [G loss: 0.697518]\n",
      "[Epoch 2/200] [Batch 128/169] [D loss: 0.690026] [G loss: 0.696876]\n",
      "[Epoch 2/200] [Batch 129/169] [D loss: 0.690201] [G loss: 0.697163]\n",
      "[Epoch 2/200] [Batch 130/169] [D loss: 0.689689] [G loss: 0.697480]\n",
      "[Epoch 2/200] [Batch 131/169] [D loss: 0.689671] [G loss: 0.696641]\n",
      "[Epoch 2/200] [Batch 132/169] [D loss: 0.689530] [G loss: 0.697399]\n",
      "[Epoch 2/200] [Batch 133/169] [D loss: 0.689721] [G loss: 0.695903]\n",
      "[Epoch 2/200] [Batch 134/169] [D loss: 0.689645] [G loss: 0.696460]\n",
      "[Epoch 2/200] [Batch 135/169] [D loss: 0.689797] [G loss: 0.696828]\n",
      "[Epoch 2/200] [Batch 136/169] [D loss: 0.690047] [G loss: 0.696126]\n",
      "[Epoch 2/200] [Batch 137/169] [D loss: 0.689193] [G loss: 0.697517]\n",
      "[Epoch 2/200] [Batch 138/169] [D loss: 0.688614] [G loss: 0.698938]\n",
      "[Epoch 2/200] [Batch 139/169] [D loss: 0.690291] [G loss: 0.696051]\n",
      "[Epoch 2/200] [Batch 140/169] [D loss: 0.690118] [G loss: 0.695674]\n",
      "[Epoch 2/200] [Batch 141/169] [D loss: 0.691233] [G loss: 0.695395]\n",
      "[Epoch 2/200] [Batch 142/169] [D loss: 0.689157] [G loss: 0.697764]\n",
      "[Epoch 2/200] [Batch 143/169] [D loss: 0.689642] [G loss: 0.695813]\n",
      "[Epoch 2/200] [Batch 144/169] [D loss: 0.690487] [G loss: 0.697052]\n",
      "[Epoch 2/200] [Batch 145/169] [D loss: 0.690072] [G loss: 0.696159]\n",
      "[Epoch 2/200] [Batch 146/169] [D loss: 0.691501] [G loss: 0.695147]\n",
      "[Epoch 2/200] [Batch 147/169] [D loss: 0.690533] [G loss: 0.694834]\n",
      "[Epoch 2/200] [Batch 148/169] [D loss: 0.691273] [G loss: 0.695776]\n",
      "[Epoch 2/200] [Batch 149/169] [D loss: 0.691395] [G loss: 0.696313]\n",
      "[Epoch 2/200] [Batch 150/169] [D loss: 0.691259] [G loss: 0.697036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 151/169] [D loss: 0.690402] [G loss: 0.697214]\n",
      "[Epoch 2/200] [Batch 152/169] [D loss: 0.692549] [G loss: 0.694758]\n",
      "[Epoch 2/200] [Batch 153/169] [D loss: 0.689865] [G loss: 0.698196]\n",
      "[Epoch 2/200] [Batch 154/169] [D loss: 0.690405] [G loss: 0.696801]\n",
      "[Epoch 2/200] [Batch 155/169] [D loss: 0.691985] [G loss: 0.697546]\n",
      "[Epoch 2/200] [Batch 156/169] [D loss: 0.691442] [G loss: 0.696258]\n",
      "[Epoch 2/200] [Batch 157/169] [D loss: 0.691139] [G loss: 0.693629]\n",
      "[Epoch 2/200] [Batch 158/169] [D loss: 0.690310] [G loss: 0.695185]\n",
      "[Epoch 2/200] [Batch 159/169] [D loss: 0.691779] [G loss: 0.695297]\n",
      "[Epoch 2/200] [Batch 160/169] [D loss: 0.691127] [G loss: 0.693646]\n",
      "[Epoch 2/200] [Batch 161/169] [D loss: 0.692064] [G loss: 0.695326]\n",
      "[Epoch 2/200] [Batch 162/169] [D loss: 0.690730] [G loss: 0.696195]\n",
      "[Epoch 2/200] [Batch 163/169] [D loss: 0.692322] [G loss: 0.695357]\n",
      "[Epoch 2/200] [Batch 164/169] [D loss: 0.692323] [G loss: 0.697687]\n",
      "[Epoch 2/200] [Batch 165/169] [D loss: 0.690464] [G loss: 0.697346]\n",
      "[Epoch 2/200] [Batch 166/169] [D loss: 0.691461] [G loss: 0.696715]\n",
      "[Epoch 2/200] [Batch 167/169] [D loss: 0.691600] [G loss: 0.696672]\n",
      "[Epoch 2/200] [Batch 168/169] [D loss: 0.696028] [G loss: 0.691911]\n",
      "[Epoch 3/200] [Batch 0/169] [D loss: 0.692980] [G loss: 0.693394]\n",
      "[Epoch 3/200] [Batch 1/169] [D loss: 0.692102] [G loss: 0.693160]\n",
      "[Epoch 3/200] [Batch 2/169] [D loss: 0.692409] [G loss: 0.693610]\n",
      "[Epoch 3/200] [Batch 3/169] [D loss: 0.691305] [G loss: 0.695142]\n",
      "[Epoch 3/200] [Batch 4/169] [D loss: 0.690761] [G loss: 0.694529]\n",
      "[Epoch 3/200] [Batch 5/169] [D loss: 0.692372] [G loss: 0.694072]\n",
      "[Epoch 3/200] [Batch 6/169] [D loss: 0.693205] [G loss: 0.695395]\n",
      "[Epoch 3/200] [Batch 7/169] [D loss: 0.691915] [G loss: 0.693397]\n",
      "[Epoch 3/200] [Batch 8/169] [D loss: 0.690696] [G loss: 0.693304]\n",
      "[Epoch 3/200] [Batch 9/169] [D loss: 0.693592] [G loss: 0.693692]\n",
      "[Epoch 3/200] [Batch 10/169] [D loss: 0.692669] [G loss: 0.692487]\n",
      "[Epoch 3/200] [Batch 11/169] [D loss: 0.692714] [G loss: 0.694837]\n",
      "[Epoch 3/200] [Batch 12/169] [D loss: 0.691516] [G loss: 0.693545]\n",
      "[Epoch 3/200] [Batch 13/169] [D loss: 0.692636] [G loss: 0.694045]\n",
      "[Epoch 3/200] [Batch 14/169] [D loss: 0.692881] [G loss: 0.692848]\n",
      "[Epoch 3/200] [Batch 15/169] [D loss: 0.692586] [G loss: 0.692137]\n",
      "[Epoch 3/200] [Batch 16/169] [D loss: 0.693075] [G loss: 0.695006]\n",
      "[Epoch 3/200] [Batch 17/169] [D loss: 0.694777] [G loss: 0.688349]\n",
      "[Epoch 3/200] [Batch 18/169] [D loss: 0.694441] [G loss: 0.692410]\n",
      "[Epoch 3/200] [Batch 19/169] [D loss: 0.693704] [G loss: 0.691063]\n",
      "[Epoch 3/200] [Batch 20/169] [D loss: 0.695366] [G loss: 0.694171]\n",
      "[Epoch 3/200] [Batch 21/169] [D loss: 0.693265] [G loss: 0.692992]\n",
      "[Epoch 3/200] [Batch 22/169] [D loss: 0.694087] [G loss: 0.691980]\n",
      "[Epoch 3/200] [Batch 23/169] [D loss: 0.694892] [G loss: 0.694188]\n",
      "[Epoch 3/200] [Batch 24/169] [D loss: 0.696182] [G loss: 0.692262]\n",
      "[Epoch 3/200] [Batch 25/169] [D loss: 0.694709] [G loss: 0.690877]\n",
      "[Epoch 3/200] [Batch 26/169] [D loss: 0.695139] [G loss: 0.690839]\n",
      "[Epoch 3/200] [Batch 27/169] [D loss: 0.694619] [G loss: 0.691915]\n",
      "[Epoch 3/200] [Batch 28/169] [D loss: 0.694057] [G loss: 0.692063]\n",
      "[Epoch 3/200] [Batch 29/169] [D loss: 0.696749] [G loss: 0.690705]\n",
      "[Epoch 3/200] [Batch 30/169] [D loss: 0.697728] [G loss: 0.690161]\n",
      "[Epoch 3/200] [Batch 31/169] [D loss: 0.696257] [G loss: 0.692475]\n",
      "[Epoch 3/200] [Batch 32/169] [D loss: 0.695331] [G loss: 0.690422]\n",
      "[Epoch 3/200] [Batch 33/169] [D loss: 0.697088] [G loss: 0.690833]\n",
      "[Epoch 3/200] [Batch 34/169] [D loss: 0.696727] [G loss: 0.690497]\n",
      "[Epoch 3/200] [Batch 35/169] [D loss: 0.696622] [G loss: 0.687284]\n",
      "[Epoch 3/200] [Batch 36/169] [D loss: 0.696969] [G loss: 0.688463]\n",
      "[Epoch 3/200] [Batch 37/169] [D loss: 0.696964] [G loss: 0.690364]\n",
      "[Epoch 3/200] [Batch 38/169] [D loss: 0.696702] [G loss: 0.691500]\n",
      "[Epoch 3/200] [Batch 39/169] [D loss: 0.696882] [G loss: 0.692744]\n",
      "[Epoch 3/200] [Batch 40/169] [D loss: 0.696190] [G loss: 0.688918]\n",
      "[Epoch 3/200] [Batch 41/169] [D loss: 0.695084] [G loss: 0.690683]\n",
      "[Epoch 3/200] [Batch 42/169] [D loss: 0.696962] [G loss: 0.689167]\n",
      "[Epoch 3/200] [Batch 43/169] [D loss: 0.695742] [G loss: 0.691181]\n",
      "[Epoch 3/200] [Batch 44/169] [D loss: 0.695511] [G loss: 0.689479]\n",
      "[Epoch 3/200] [Batch 45/169] [D loss: 0.695366] [G loss: 0.689391]\n",
      "[Epoch 3/200] [Batch 46/169] [D loss: 0.697007] [G loss: 0.689151]\n",
      "[Epoch 3/200] [Batch 47/169] [D loss: 0.697209] [G loss: 0.689817]\n",
      "[Epoch 3/200] [Batch 48/169] [D loss: 0.696699] [G loss: 0.689507]\n",
      "[Epoch 3/200] [Batch 49/169] [D loss: 0.697834] [G loss: 0.689727]\n",
      "[Epoch 3/200] [Batch 50/169] [D loss: 0.696333] [G loss: 0.691012]\n",
      "[Epoch 3/200] [Batch 51/169] [D loss: 0.696290] [G loss: 0.691844]\n",
      "[Epoch 3/200] [Batch 52/169] [D loss: 0.696944] [G loss: 0.692546]\n",
      "[Epoch 3/200] [Batch 53/169] [D loss: 0.696380] [G loss: 0.692249]\n",
      "[Epoch 3/200] [Batch 54/169] [D loss: 0.695756] [G loss: 0.691936]\n",
      "[Epoch 3/200] [Batch 55/169] [D loss: 0.694295] [G loss: 0.691150]\n",
      "[Epoch 3/200] [Batch 56/169] [D loss: 0.695414] [G loss: 0.692037]\n",
      "[Epoch 3/200] [Batch 57/169] [D loss: 0.695942] [G loss: 0.691466]\n",
      "[Epoch 3/200] [Batch 58/169] [D loss: 0.695981] [G loss: 0.692529]\n",
      "[Epoch 3/200] [Batch 59/169] [D loss: 0.695816] [G loss: 0.691641]\n",
      "[Epoch 3/200] [Batch 60/169] [D loss: 0.694439] [G loss: 0.693929]\n",
      "[Epoch 3/200] [Batch 61/169] [D loss: 0.695671] [G loss: 0.692203]\n",
      "[Epoch 3/200] [Batch 62/169] [D loss: 0.695661] [G loss: 0.692821]\n",
      "[Epoch 3/200] [Batch 63/169] [D loss: 0.694658] [G loss: 0.692480]\n",
      "[Epoch 3/200] [Batch 64/169] [D loss: 0.694755] [G loss: 0.691588]\n",
      "[Epoch 3/200] [Batch 65/169] [D loss: 0.694876] [G loss: 0.691924]\n",
      "[Epoch 3/200] [Batch 66/169] [D loss: 0.695761] [G loss: 0.691081]\n",
      "[Epoch 3/200] [Batch 67/169] [D loss: 0.694666] [G loss: 0.694161]\n",
      "[Epoch 3/200] [Batch 68/169] [D loss: 0.695810] [G loss: 0.692749]\n",
      "[Epoch 3/200] [Batch 69/169] [D loss: 0.694410] [G loss: 0.691751]\n",
      "[Epoch 3/200] [Batch 70/169] [D loss: 0.695167] [G loss: 0.692835]\n",
      "[Epoch 3/200] [Batch 71/169] [D loss: 0.693578] [G loss: 0.693031]\n",
      "[Epoch 3/200] [Batch 72/169] [D loss: 0.694470] [G loss: 0.691137]\n",
      "[Epoch 3/200] [Batch 73/169] [D loss: 0.694942] [G loss: 0.692841]\n",
      "[Epoch 3/200] [Batch 74/169] [D loss: 0.694196] [G loss: 0.692765]\n",
      "[Epoch 3/200] [Batch 75/169] [D loss: 0.694609] [G loss: 0.693294]\n",
      "[Epoch 3/200] [Batch 76/169] [D loss: 0.693912] [G loss: 0.692463]\n",
      "[Epoch 3/200] [Batch 77/169] [D loss: 0.693883] [G loss: 0.691258]\n",
      "[Epoch 3/200] [Batch 78/169] [D loss: 0.694150] [G loss: 0.692214]\n",
      "[Epoch 3/200] [Batch 79/169] [D loss: 0.694705] [G loss: 0.692066]\n",
      "[Epoch 3/200] [Batch 80/169] [D loss: 0.693781] [G loss: 0.692582]\n",
      "[Epoch 3/200] [Batch 81/169] [D loss: 0.694714] [G loss: 0.691616]\n",
      "[Epoch 3/200] [Batch 82/169] [D loss: 0.693834] [G loss: 0.692268]\n",
      "[Epoch 3/200] [Batch 83/169] [D loss: 0.694095] [G loss: 0.693141]\n",
      "[Epoch 3/200] [Batch 84/169] [D loss: 0.694099] [G loss: 0.693180]\n",
      "[Epoch 3/200] [Batch 85/169] [D loss: 0.693515] [G loss: 0.692369]\n",
      "[Epoch 3/200] [Batch 86/169] [D loss: 0.693883] [G loss: 0.692413]\n",
      "[Epoch 3/200] [Batch 87/169] [D loss: 0.694392] [G loss: 0.692184]\n",
      "[Epoch 3/200] [Batch 88/169] [D loss: 0.693981] [G loss: 0.692595]\n",
      "[Epoch 3/200] [Batch 89/169] [D loss: 0.694239] [G loss: 0.692717]\n",
      "[Epoch 3/200] [Batch 90/169] [D loss: 0.693585] [G loss: 0.692307]\n",
      "[Epoch 3/200] [Batch 91/169] [D loss: 0.693614] [G loss: 0.692836]\n",
      "[Epoch 3/200] [Batch 92/169] [D loss: 0.694780] [G loss: 0.692892]\n",
      "[Epoch 3/200] [Batch 93/169] [D loss: 0.693839] [G loss: 0.692614]\n",
      "[Epoch 3/200] [Batch 94/169] [D loss: 0.693582] [G loss: 0.693391]\n",
      "[Epoch 3/200] [Batch 95/169] [D loss: 0.693341] [G loss: 0.693320]\n",
      "[Epoch 3/200] [Batch 96/169] [D loss: 0.694112] [G loss: 0.693495]\n",
      "[Epoch 3/200] [Batch 97/169] [D loss: 0.694314] [G loss: 0.693412]\n",
      "[Epoch 3/200] [Batch 98/169] [D loss: 0.693586] [G loss: 0.693072]\n",
      "[Epoch 3/200] [Batch 99/169] [D loss: 0.693607] [G loss: 0.692167]\n",
      "[Epoch 3/200] [Batch 100/169] [D loss: 0.693212] [G loss: 0.693717]\n",
      "[Epoch 3/200] [Batch 101/169] [D loss: 0.693755] [G loss: 0.693872]\n",
      "[Epoch 3/200] [Batch 102/169] [D loss: 0.693364] [G loss: 0.693076]\n",
      "[Epoch 3/200] [Batch 103/169] [D loss: 0.693476] [G loss: 0.693441]\n",
      "[Epoch 3/200] [Batch 104/169] [D loss: 0.693379] [G loss: 0.693074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 105/169] [D loss: 0.693433] [G loss: 0.693470]\n",
      "[Epoch 3/200] [Batch 106/169] [D loss: 0.692779] [G loss: 0.693878]\n",
      "[Epoch 3/200] [Batch 107/169] [D loss: 0.693356] [G loss: 0.693087]\n",
      "[Epoch 3/200] [Batch 108/169] [D loss: 0.693162] [G loss: 0.693377]\n",
      "[Epoch 3/200] [Batch 109/169] [D loss: 0.693338] [G loss: 0.692855]\n",
      "[Epoch 3/200] [Batch 110/169] [D loss: 0.693502] [G loss: 0.693131]\n",
      "[Epoch 3/200] [Batch 111/169] [D loss: 0.693704] [G loss: 0.693735]\n",
      "[Epoch 3/200] [Batch 112/169] [D loss: 0.693957] [G loss: 0.692453]\n",
      "[Epoch 3/200] [Batch 113/169] [D loss: 0.693327] [G loss: 0.693747]\n",
      "[Epoch 3/200] [Batch 114/169] [D loss: 0.693426] [G loss: 0.693938]\n",
      "[Epoch 3/200] [Batch 115/169] [D loss: 0.693571] [G loss: 0.693299]\n",
      "[Epoch 3/200] [Batch 116/169] [D loss: 0.693932] [G loss: 0.692714]\n",
      "[Epoch 3/200] [Batch 117/169] [D loss: 0.693222] [G loss: 0.694004]\n",
      "[Epoch 3/200] [Batch 118/169] [D loss: 0.693277] [G loss: 0.693845]\n",
      "[Epoch 3/200] [Batch 119/169] [D loss: 0.693447] [G loss: 0.693230]\n",
      "[Epoch 3/200] [Batch 120/169] [D loss: 0.693053] [G loss: 0.693690]\n",
      "[Epoch 3/200] [Batch 121/169] [D loss: 0.693081] [G loss: 0.692972]\n",
      "[Epoch 3/200] [Batch 122/169] [D loss: 0.692975] [G loss: 0.692713]\n",
      "[Epoch 3/200] [Batch 123/169] [D loss: 0.693098] [G loss: 0.692904]\n",
      "[Epoch 3/200] [Batch 124/169] [D loss: 0.693445] [G loss: 0.693426]\n",
      "[Epoch 3/200] [Batch 125/169] [D loss: 0.693358] [G loss: 0.692994]\n",
      "[Epoch 3/200] [Batch 126/169] [D loss: 0.693230] [G loss: 0.692575]\n",
      "[Epoch 3/200] [Batch 127/169] [D loss: 0.693458] [G loss: 0.692853]\n",
      "[Epoch 3/200] [Batch 128/169] [D loss: 0.693336] [G loss: 0.693866]\n",
      "[Epoch 3/200] [Batch 129/169] [D loss: 0.692681] [G loss: 0.693238]\n",
      "[Epoch 3/200] [Batch 130/169] [D loss: 0.693351] [G loss: 0.693044]\n",
      "[Epoch 3/200] [Batch 131/169] [D loss: 0.692785] [G loss: 0.693811]\n",
      "[Epoch 3/200] [Batch 132/169] [D loss: 0.693201] [G loss: 0.694165]\n",
      "[Epoch 3/200] [Batch 133/169] [D loss: 0.693146] [G loss: 0.693036]\n",
      "[Epoch 3/200] [Batch 134/169] [D loss: 0.693392] [G loss: 0.693444]\n",
      "[Epoch 3/200] [Batch 135/169] [D loss: 0.692611] [G loss: 0.693047]\n",
      "[Epoch 3/200] [Batch 136/169] [D loss: 0.693253] [G loss: 0.693526]\n",
      "[Epoch 3/200] [Batch 137/169] [D loss: 0.693216] [G loss: 0.693809]\n",
      "[Epoch 3/200] [Batch 138/169] [D loss: 0.693489] [G loss: 0.693256]\n",
      "[Epoch 3/200] [Batch 139/169] [D loss: 0.693104] [G loss: 0.693617]\n",
      "[Epoch 3/200] [Batch 140/169] [D loss: 0.692763] [G loss: 0.693747]\n",
      "[Epoch 3/200] [Batch 141/169] [D loss: 0.692913] [G loss: 0.693227]\n",
      "[Epoch 3/200] [Batch 142/169] [D loss: 0.692506] [G loss: 0.693242]\n",
      "[Epoch 3/200] [Batch 143/169] [D loss: 0.692852] [G loss: 0.693092]\n",
      "[Epoch 3/200] [Batch 144/169] [D loss: 0.692684] [G loss: 0.693751]\n",
      "[Epoch 3/200] [Batch 145/169] [D loss: 0.693110] [G loss: 0.693527]\n",
      "[Epoch 3/200] [Batch 146/169] [D loss: 0.693022] [G loss: 0.693672]\n",
      "[Epoch 3/200] [Batch 147/169] [D loss: 0.693185] [G loss: 0.693734]\n",
      "[Epoch 3/200] [Batch 148/169] [D loss: 0.692388] [G loss: 0.693098]\n",
      "[Epoch 3/200] [Batch 149/169] [D loss: 0.693406] [G loss: 0.692664]\n",
      "[Epoch 3/200] [Batch 150/169] [D loss: 0.692877] [G loss: 0.693675]\n",
      "[Epoch 3/200] [Batch 151/169] [D loss: 0.693124] [G loss: 0.693524]\n",
      "[Epoch 3/200] [Batch 152/169] [D loss: 0.693166] [G loss: 0.693778]\n",
      "[Epoch 3/200] [Batch 153/169] [D loss: 0.692921] [G loss: 0.693953]\n",
      "[Epoch 3/200] [Batch 154/169] [D loss: 0.693021] [G loss: 0.693302]\n",
      "[Epoch 3/200] [Batch 155/169] [D loss: 0.692603] [G loss: 0.693768]\n",
      "[Epoch 3/200] [Batch 156/169] [D loss: 0.692652] [G loss: 0.693851]\n",
      "[Epoch 3/200] [Batch 157/169] [D loss: 0.693015] [G loss: 0.693446]\n",
      "[Epoch 3/200] [Batch 158/169] [D loss: 0.693071] [G loss: 0.693898]\n",
      "[Epoch 3/200] [Batch 159/169] [D loss: 0.692652] [G loss: 0.693326]\n",
      "[Epoch 3/200] [Batch 160/169] [D loss: 0.693103] [G loss: 0.694599]\n",
      "[Epoch 3/200] [Batch 161/169] [D loss: 0.693076] [G loss: 0.693526]\n",
      "[Epoch 3/200] [Batch 162/169] [D loss: 0.692848] [G loss: 0.693907]\n",
      "[Epoch 3/200] [Batch 163/169] [D loss: 0.692535] [G loss: 0.693342]\n",
      "[Epoch 3/200] [Batch 164/169] [D loss: 0.692299] [G loss: 0.693764]\n",
      "[Epoch 3/200] [Batch 165/169] [D loss: 0.692503] [G loss: 0.694129]\n",
      "[Epoch 3/200] [Batch 166/169] [D loss: 0.693091] [G loss: 0.692836]\n",
      "[Epoch 3/200] [Batch 167/169] [D loss: 0.692293] [G loss: 0.693365]\n",
      "[Epoch 3/200] [Batch 168/169] [D loss: 0.692954] [G loss: 0.694060]\n",
      "[Epoch 4/200] [Batch 0/169] [D loss: 0.692969] [G loss: 0.694324]\n",
      "[Epoch 4/200] [Batch 1/169] [D loss: 0.692736] [G loss: 0.692510]\n",
      "[Epoch 4/200] [Batch 2/169] [D loss: 0.692413] [G loss: 0.694282]\n",
      "[Epoch 4/200] [Batch 3/169] [D loss: 0.692299] [G loss: 0.693326]\n",
      "[Epoch 4/200] [Batch 4/169] [D loss: 0.693638] [G loss: 0.694045]\n",
      "[Epoch 4/200] [Batch 5/169] [D loss: 0.692547] [G loss: 0.693919]\n",
      "[Epoch 4/200] [Batch 6/169] [D loss: 0.692540] [G loss: 0.693704]\n",
      "[Epoch 4/200] [Batch 7/169] [D loss: 0.693102] [G loss: 0.693159]\n",
      "[Epoch 4/200] [Batch 8/169] [D loss: 0.692959] [G loss: 0.693414]\n",
      "[Epoch 4/200] [Batch 9/169] [D loss: 0.692917] [G loss: 0.693792]\n",
      "[Epoch 4/200] [Batch 10/169] [D loss: 0.692846] [G loss: 0.694594]\n",
      "[Epoch 4/200] [Batch 11/169] [D loss: 0.692752] [G loss: 0.694519]\n",
      "[Epoch 4/200] [Batch 12/169] [D loss: 0.692852] [G loss: 0.693972]\n",
      "[Epoch 4/200] [Batch 13/169] [D loss: 0.692623] [G loss: 0.693139]\n",
      "[Epoch 4/200] [Batch 14/169] [D loss: 0.692584] [G loss: 0.693544]\n",
      "[Epoch 4/200] [Batch 15/169] [D loss: 0.692124] [G loss: 0.694550]\n",
      "[Epoch 4/200] [Batch 16/169] [D loss: 0.692529] [G loss: 0.693842]\n",
      "[Epoch 4/200] [Batch 17/169] [D loss: 0.692338] [G loss: 0.693700]\n",
      "[Epoch 4/200] [Batch 18/169] [D loss: 0.692344] [G loss: 0.693992]\n",
      "[Epoch 4/200] [Batch 19/169] [D loss: 0.692144] [G loss: 0.693630]\n",
      "[Epoch 4/200] [Batch 20/169] [D loss: 0.692731] [G loss: 0.693595]\n",
      "[Epoch 4/200] [Batch 21/169] [D loss: 0.692168] [G loss: 0.693793]\n",
      "[Epoch 4/200] [Batch 22/169] [D loss: 0.692035] [G loss: 0.694036]\n",
      "[Epoch 4/200] [Batch 23/169] [D loss: 0.692772] [G loss: 0.693887]\n",
      "[Epoch 4/200] [Batch 24/169] [D loss: 0.692417] [G loss: 0.693971]\n",
      "[Epoch 4/200] [Batch 25/169] [D loss: 0.692809] [G loss: 0.694611]\n",
      "[Epoch 4/200] [Batch 26/169] [D loss: 0.692803] [G loss: 0.693796]\n",
      "[Epoch 4/200] [Batch 27/169] [D loss: 0.692046] [G loss: 0.694383]\n",
      "[Epoch 4/200] [Batch 28/169] [D loss: 0.692187] [G loss: 0.694598]\n",
      "[Epoch 4/200] [Batch 29/169] [D loss: 0.692232] [G loss: 0.694159]\n",
      "[Epoch 4/200] [Batch 30/169] [D loss: 0.692258] [G loss: 0.694718]\n",
      "[Epoch 4/200] [Batch 31/169] [D loss: 0.692772] [G loss: 0.694507]\n",
      "[Epoch 4/200] [Batch 32/169] [D loss: 0.692191] [G loss: 0.693978]\n",
      "[Epoch 4/200] [Batch 33/169] [D loss: 0.692251] [G loss: 0.694577]\n",
      "[Epoch 4/200] [Batch 34/169] [D loss: 0.693087] [G loss: 0.693980]\n",
      "[Epoch 4/200] [Batch 35/169] [D loss: 0.692969] [G loss: 0.694536]\n",
      "[Epoch 4/200] [Batch 36/169] [D loss: 0.692765] [G loss: 0.693893]\n",
      "[Epoch 4/200] [Batch 37/169] [D loss: 0.692166] [G loss: 0.693430]\n",
      "[Epoch 4/200] [Batch 38/169] [D loss: 0.692087] [G loss: 0.693515]\n",
      "[Epoch 4/200] [Batch 39/169] [D loss: 0.692338] [G loss: 0.694335]\n",
      "[Epoch 4/200] [Batch 40/169] [D loss: 0.692213] [G loss: 0.694595]\n",
      "[Epoch 4/200] [Batch 41/169] [D loss: 0.692543] [G loss: 0.693700]\n",
      "[Epoch 4/200] [Batch 42/169] [D loss: 0.691975] [G loss: 0.693318]\n",
      "[Epoch 4/200] [Batch 43/169] [D loss: 0.691999] [G loss: 0.694317]\n",
      "[Epoch 4/200] [Batch 44/169] [D loss: 0.693297] [G loss: 0.694243]\n",
      "[Epoch 4/200] [Batch 45/169] [D loss: 0.692145] [G loss: 0.694340]\n",
      "[Epoch 4/200] [Batch 46/169] [D loss: 0.692690] [G loss: 0.694882]\n",
      "[Epoch 4/200] [Batch 47/169] [D loss: 0.691892] [G loss: 0.694649]\n",
      "[Epoch 4/200] [Batch 48/169] [D loss: 0.692235] [G loss: 0.694377]\n",
      "[Epoch 4/200] [Batch 49/169] [D loss: 0.692959] [G loss: 0.694905]\n",
      "[Epoch 4/200] [Batch 50/169] [D loss: 0.692023] [G loss: 0.693609]\n",
      "[Epoch 4/200] [Batch 51/169] [D loss: 0.692813] [G loss: 0.694871]\n",
      "[Epoch 4/200] [Batch 52/169] [D loss: 0.692784] [G loss: 0.694153]\n",
      "[Epoch 4/200] [Batch 53/169] [D loss: 0.692018] [G loss: 0.694569]\n",
      "[Epoch 4/200] [Batch 54/169] [D loss: 0.692057] [G loss: 0.694404]\n",
      "[Epoch 4/200] [Batch 55/169] [D loss: 0.692949] [G loss: 0.694908]\n",
      "[Epoch 4/200] [Batch 56/169] [D loss: 0.692428] [G loss: 0.694267]\n",
      "[Epoch 4/200] [Batch 57/169] [D loss: 0.691632] [G loss: 0.694656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 58/169] [D loss: 0.692293] [G loss: 0.694338]\n",
      "[Epoch 4/200] [Batch 59/169] [D loss: 0.692076] [G loss: 0.694906]\n",
      "[Epoch 4/200] [Batch 60/169] [D loss: 0.692084] [G loss: 0.694533]\n",
      "[Epoch 4/200] [Batch 61/169] [D loss: 0.692393] [G loss: 0.694574]\n",
      "[Epoch 4/200] [Batch 62/169] [D loss: 0.691646] [G loss: 0.694521]\n",
      "[Epoch 4/200] [Batch 63/169] [D loss: 0.692316] [G loss: 0.694034]\n",
      "[Epoch 4/200] [Batch 64/169] [D loss: 0.692424] [G loss: 0.694635]\n",
      "[Epoch 4/200] [Batch 65/169] [D loss: 0.691503] [G loss: 0.694356]\n",
      "[Epoch 4/200] [Batch 66/169] [D loss: 0.691432] [G loss: 0.693909]\n",
      "[Epoch 4/200] [Batch 67/169] [D loss: 0.691868] [G loss: 0.694102]\n",
      "[Epoch 4/200] [Batch 68/169] [D loss: 0.691686] [G loss: 0.695216]\n",
      "[Epoch 4/200] [Batch 69/169] [D loss: 0.692456] [G loss: 0.694623]\n",
      "[Epoch 4/200] [Batch 70/169] [D loss: 0.691820] [G loss: 0.694719]\n",
      "[Epoch 4/200] [Batch 71/169] [D loss: 0.691666] [G loss: 0.694792]\n",
      "[Epoch 4/200] [Batch 72/169] [D loss: 0.692689] [G loss: 0.694263]\n",
      "[Epoch 4/200] [Batch 73/169] [D loss: 0.691767] [G loss: 0.694193]\n",
      "[Epoch 4/200] [Batch 74/169] [D loss: 0.692104] [G loss: 0.694111]\n",
      "[Epoch 4/200] [Batch 75/169] [D loss: 0.691953] [G loss: 0.694357]\n",
      "[Epoch 4/200] [Batch 76/169] [D loss: 0.691938] [G loss: 0.694001]\n",
      "[Epoch 4/200] [Batch 77/169] [D loss: 0.691752] [G loss: 0.694771]\n",
      "[Epoch 4/200] [Batch 78/169] [D loss: 0.691362] [G loss: 0.696406]\n",
      "[Epoch 4/200] [Batch 79/169] [D loss: 0.691545] [G loss: 0.694875]\n",
      "[Epoch 4/200] [Batch 80/169] [D loss: 0.691196] [G loss: 0.694245]\n",
      "[Epoch 4/200] [Batch 81/169] [D loss: 0.691661] [G loss: 0.694235]\n",
      "[Epoch 4/200] [Batch 82/169] [D loss: 0.691136] [G loss: 0.694660]\n",
      "[Epoch 4/200] [Batch 83/169] [D loss: 0.691742] [G loss: 0.694814]\n",
      "[Epoch 4/200] [Batch 84/169] [D loss: 0.692011] [G loss: 0.694342]\n",
      "[Epoch 4/200] [Batch 85/169] [D loss: 0.692066] [G loss: 0.694993]\n",
      "[Epoch 4/200] [Batch 86/169] [D loss: 0.691683] [G loss: 0.694487]\n",
      "[Epoch 4/200] [Batch 87/169] [D loss: 0.691921] [G loss: 0.694604]\n",
      "[Epoch 4/200] [Batch 88/169] [D loss: 0.692305] [G loss: 0.694920]\n",
      "[Epoch 4/200] [Batch 89/169] [D loss: 0.691467] [G loss: 0.695311]\n",
      "[Epoch 4/200] [Batch 90/169] [D loss: 0.691043] [G loss: 0.695501]\n",
      "[Epoch 4/200] [Batch 91/169] [D loss: 0.691342] [G loss: 0.694528]\n",
      "[Epoch 4/200] [Batch 92/169] [D loss: 0.691448] [G loss: 0.694811]\n",
      "[Epoch 4/200] [Batch 93/169] [D loss: 0.691240] [G loss: 0.694888]\n",
      "[Epoch 4/200] [Batch 94/169] [D loss: 0.691485] [G loss: 0.695545]\n",
      "[Epoch 4/200] [Batch 95/169] [D loss: 0.691909] [G loss: 0.695735]\n",
      "[Epoch 4/200] [Batch 96/169] [D loss: 0.692009] [G loss: 0.695982]\n",
      "[Epoch 4/200] [Batch 97/169] [D loss: 0.691719] [G loss: 0.695277]\n",
      "[Epoch 4/200] [Batch 98/169] [D loss: 0.691621] [G loss: 0.694885]\n",
      "[Epoch 4/200] [Batch 99/169] [D loss: 0.691378] [G loss: 0.695376]\n",
      "[Epoch 4/200] [Batch 100/169] [D loss: 0.691471] [G loss: 0.695948]\n",
      "[Epoch 4/200] [Batch 101/169] [D loss: 0.691212] [G loss: 0.695724]\n",
      "[Epoch 4/200] [Batch 102/169] [D loss: 0.691742] [G loss: 0.695994]\n",
      "[Epoch 4/200] [Batch 103/169] [D loss: 0.690847] [G loss: 0.695677]\n",
      "[Epoch 4/200] [Batch 104/169] [D loss: 0.691684] [G loss: 0.694378]\n",
      "[Epoch 4/200] [Batch 105/169] [D loss: 0.691723] [G loss: 0.694058]\n",
      "[Epoch 4/200] [Batch 106/169] [D loss: 0.691631] [G loss: 0.694701]\n",
      "[Epoch 4/200] [Batch 107/169] [D loss: 0.691868] [G loss: 0.694495]\n",
      "[Epoch 4/200] [Batch 108/169] [D loss: 0.691685] [G loss: 0.695650]\n",
      "[Epoch 4/200] [Batch 109/169] [D loss: 0.691239] [G loss: 0.694853]\n",
      "[Epoch 4/200] [Batch 110/169] [D loss: 0.691191] [G loss: 0.694520]\n",
      "[Epoch 4/200] [Batch 111/169] [D loss: 0.691161] [G loss: 0.695770]\n",
      "[Epoch 4/200] [Batch 112/169] [D loss: 0.690837] [G loss: 0.695526]\n",
      "[Epoch 4/200] [Batch 113/169] [D loss: 0.692063] [G loss: 0.695154]\n",
      "[Epoch 4/200] [Batch 114/169] [D loss: 0.691654] [G loss: 0.695118]\n",
      "[Epoch 4/200] [Batch 115/169] [D loss: 0.691670] [G loss: 0.694518]\n",
      "[Epoch 4/200] [Batch 116/169] [D loss: 0.691884] [G loss: 0.694088]\n",
      "[Epoch 4/200] [Batch 117/169] [D loss: 0.691478] [G loss: 0.694428]\n",
      "[Epoch 4/200] [Batch 118/169] [D loss: 0.691681] [G loss: 0.694257]\n",
      "[Epoch 4/200] [Batch 119/169] [D loss: 0.691913] [G loss: 0.693644]\n",
      "[Epoch 4/200] [Batch 120/169] [D loss: 0.692386] [G loss: 0.694291]\n",
      "[Epoch 4/200] [Batch 121/169] [D loss: 0.692314] [G loss: 0.695020]\n",
      "[Epoch 4/200] [Batch 122/169] [D loss: 0.692947] [G loss: 0.694196]\n",
      "[Epoch 4/200] [Batch 123/169] [D loss: 0.692094] [G loss: 0.695961]\n",
      "[Epoch 4/200] [Batch 124/169] [D loss: 0.692296] [G loss: 0.694416]\n",
      "[Epoch 4/200] [Batch 125/169] [D loss: 0.692566] [G loss: 0.694697]\n",
      "[Epoch 4/200] [Batch 126/169] [D loss: 0.692977] [G loss: 0.693441]\n",
      "[Epoch 4/200] [Batch 127/169] [D loss: 0.692407] [G loss: 0.693757]\n",
      "[Epoch 4/200] [Batch 128/169] [D loss: 0.693144] [G loss: 0.693467]\n",
      "[Epoch 4/200] [Batch 129/169] [D loss: 0.692286] [G loss: 0.694938]\n",
      "[Epoch 4/200] [Batch 130/169] [D loss: 0.693659] [G loss: 0.692803]\n",
      "[Epoch 4/200] [Batch 131/169] [D loss: 0.692919] [G loss: 0.694024]\n",
      "[Epoch 4/200] [Batch 132/169] [D loss: 0.692506] [G loss: 0.694572]\n",
      "[Epoch 4/200] [Batch 133/169] [D loss: 0.693573] [G loss: 0.693665]\n",
      "[Epoch 4/200] [Batch 134/169] [D loss: 0.692825] [G loss: 0.693715]\n",
      "[Epoch 4/200] [Batch 135/169] [D loss: 0.694323] [G loss: 0.693418]\n",
      "[Epoch 4/200] [Batch 136/169] [D loss: 0.693076] [G loss: 0.692619]\n",
      "[Epoch 4/200] [Batch 137/169] [D loss: 0.692987] [G loss: 0.693929]\n",
      "[Epoch 4/200] [Batch 138/169] [D loss: 0.693263] [G loss: 0.693701]\n",
      "[Epoch 4/200] [Batch 139/169] [D loss: 0.692789] [G loss: 0.694874]\n",
      "[Epoch 4/200] [Batch 140/169] [D loss: 0.692937] [G loss: 0.694780]\n",
      "[Epoch 4/200] [Batch 141/169] [D loss: 0.693291] [G loss: 0.695296]\n",
      "[Epoch 4/200] [Batch 142/169] [D loss: 0.693603] [G loss: 0.693765]\n",
      "[Epoch 4/200] [Batch 143/169] [D loss: 0.692655] [G loss: 0.694063]\n",
      "[Epoch 4/200] [Batch 144/169] [D loss: 0.693202] [G loss: 0.693659]\n",
      "[Epoch 4/200] [Batch 145/169] [D loss: 0.693058] [G loss: 0.693435]\n",
      "[Epoch 4/200] [Batch 146/169] [D loss: 0.693252] [G loss: 0.694683]\n",
      "[Epoch 4/200] [Batch 147/169] [D loss: 0.693278] [G loss: 0.693949]\n",
      "[Epoch 4/200] [Batch 148/169] [D loss: 0.693638] [G loss: 0.694002]\n",
      "[Epoch 4/200] [Batch 149/169] [D loss: 0.692522] [G loss: 0.694196]\n",
      "[Epoch 4/200] [Batch 150/169] [D loss: 0.692385] [G loss: 0.694734]\n",
      "[Epoch 4/200] [Batch 151/169] [D loss: 0.693210] [G loss: 0.695101]\n",
      "[Epoch 4/200] [Batch 152/169] [D loss: 0.692722] [G loss: 0.694692]\n",
      "[Epoch 4/200] [Batch 153/169] [D loss: 0.693112] [G loss: 0.696347]\n",
      "[Epoch 4/200] [Batch 154/169] [D loss: 0.692495] [G loss: 0.694283]\n",
      "[Epoch 4/200] [Batch 155/169] [D loss: 0.692417] [G loss: 0.696290]\n",
      "[Epoch 4/200] [Batch 156/169] [D loss: 0.691130] [G loss: 0.695436]\n",
      "[Epoch 4/200] [Batch 157/169] [D loss: 0.691566] [G loss: 0.695468]\n",
      "[Epoch 4/200] [Batch 158/169] [D loss: 0.692072] [G loss: 0.695443]\n",
      "[Epoch 4/200] [Batch 159/169] [D loss: 0.690795] [G loss: 0.696796]\n",
      "[Epoch 4/200] [Batch 160/169] [D loss: 0.691890] [G loss: 0.695778]\n",
      "[Epoch 4/200] [Batch 161/169] [D loss: 0.692104] [G loss: 0.695734]\n",
      "[Epoch 4/200] [Batch 162/169] [D loss: 0.691162] [G loss: 0.694874]\n",
      "[Epoch 4/200] [Batch 163/169] [D loss: 0.691496] [G loss: 0.695859]\n",
      "[Epoch 4/200] [Batch 164/169] [D loss: 0.691356] [G loss: 0.696050]\n",
      "[Epoch 4/200] [Batch 165/169] [D loss: 0.690779] [G loss: 0.697848]\n",
      "[Epoch 4/200] [Batch 166/169] [D loss: 0.690955] [G loss: 0.696161]\n",
      "[Epoch 4/200] [Batch 167/169] [D loss: 0.691177] [G loss: 0.696666]\n",
      "[Epoch 4/200] [Batch 168/169] [D loss: 0.688080] [G loss: 0.698251]\n",
      "[Epoch 5/200] [Batch 0/169] [D loss: 0.690620] [G loss: 0.696073]\n",
      "[Epoch 5/200] [Batch 1/169] [D loss: 0.689325] [G loss: 0.697890]\n",
      "[Epoch 5/200] [Batch 2/169] [D loss: 0.690332] [G loss: 0.696938]\n",
      "[Epoch 5/200] [Batch 3/169] [D loss: 0.690250] [G loss: 0.696752]\n",
      "[Epoch 5/200] [Batch 4/169] [D loss: 0.691209] [G loss: 0.694736]\n",
      "[Epoch 5/200] [Batch 5/169] [D loss: 0.690489] [G loss: 0.697227]\n",
      "[Epoch 5/200] [Batch 6/169] [D loss: 0.692166] [G loss: 0.694898]\n",
      "[Epoch 5/200] [Batch 7/169] [D loss: 0.690079] [G loss: 0.694867]\n",
      "[Epoch 5/200] [Batch 8/169] [D loss: 0.690610] [G loss: 0.698300]\n",
      "[Epoch 5/200] [Batch 9/169] [D loss: 0.690565] [G loss: 0.697860]\n",
      "[Epoch 5/200] [Batch 10/169] [D loss: 0.690185] [G loss: 0.698890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 11/169] [D loss: 0.690912] [G loss: 0.695207]\n",
      "[Epoch 5/200] [Batch 12/169] [D loss: 0.690040] [G loss: 0.697892]\n",
      "[Epoch 5/200] [Batch 13/169] [D loss: 0.690493] [G loss: 0.696357]\n",
      "[Epoch 5/200] [Batch 14/169] [D loss: 0.691357] [G loss: 0.696810]\n",
      "[Epoch 5/200] [Batch 15/169] [D loss: 0.690068] [G loss: 0.695879]\n",
      "[Epoch 5/200] [Batch 16/169] [D loss: 0.690474] [G loss: 0.699055]\n",
      "[Epoch 5/200] [Batch 17/169] [D loss: 0.690725] [G loss: 0.694205]\n",
      "[Epoch 5/200] [Batch 18/169] [D loss: 0.694037] [G loss: 0.693043]\n",
      "[Epoch 5/200] [Batch 19/169] [D loss: 0.691126] [G loss: 0.695753]\n",
      "[Epoch 5/200] [Batch 20/169] [D loss: 0.691743] [G loss: 0.693590]\n",
      "[Epoch 5/200] [Batch 21/169] [D loss: 0.690984] [G loss: 0.694673]\n",
      "[Epoch 5/200] [Batch 22/169] [D loss: 0.691409] [G loss: 0.696253]\n",
      "[Epoch 5/200] [Batch 23/169] [D loss: 0.693265] [G loss: 0.692598]\n",
      "[Epoch 5/200] [Batch 24/169] [D loss: 0.689885] [G loss: 0.696101]\n",
      "[Epoch 5/200] [Batch 25/169] [D loss: 0.694706] [G loss: 0.691611]\n",
      "[Epoch 5/200] [Batch 26/169] [D loss: 0.693305] [G loss: 0.690677]\n",
      "[Epoch 5/200] [Batch 27/169] [D loss: 0.692269] [G loss: 0.695886]\n",
      "[Epoch 5/200] [Batch 28/169] [D loss: 0.692638] [G loss: 0.693841]\n",
      "[Epoch 5/200] [Batch 29/169] [D loss: 0.691327] [G loss: 0.694265]\n",
      "[Epoch 5/200] [Batch 30/169] [D loss: 0.691753] [G loss: 0.693620]\n",
      "[Epoch 5/200] [Batch 31/169] [D loss: 0.693650] [G loss: 0.692546]\n",
      "[Epoch 5/200] [Batch 32/169] [D loss: 0.693787] [G loss: 0.695814]\n",
      "[Epoch 5/200] [Batch 33/169] [D loss: 0.693606] [G loss: 0.693567]\n",
      "[Epoch 5/200] [Batch 34/169] [D loss: 0.692218] [G loss: 0.694179]\n",
      "[Epoch 5/200] [Batch 35/169] [D loss: 0.693406] [G loss: 0.691903]\n",
      "[Epoch 5/200] [Batch 36/169] [D loss: 0.694849] [G loss: 0.691776]\n",
      "[Epoch 5/200] [Batch 37/169] [D loss: 0.694563] [G loss: 0.692855]\n",
      "[Epoch 5/200] [Batch 38/169] [D loss: 0.693442] [G loss: 0.692933]\n",
      "[Epoch 5/200] [Batch 39/169] [D loss: 0.694554] [G loss: 0.694180]\n",
      "[Epoch 5/200] [Batch 40/169] [D loss: 0.694173] [G loss: 0.692129]\n",
      "[Epoch 5/200] [Batch 41/169] [D loss: 0.695013] [G loss: 0.692254]\n",
      "[Epoch 5/200] [Batch 42/169] [D loss: 0.695012] [G loss: 0.689050]\n",
      "[Epoch 5/200] [Batch 43/169] [D loss: 0.694494] [G loss: 0.692822]\n",
      "[Epoch 5/200] [Batch 44/169] [D loss: 0.693360] [G loss: 0.694058]\n",
      "[Epoch 5/200] [Batch 45/169] [D loss: 0.694204] [G loss: 0.693475]\n",
      "[Epoch 5/200] [Batch 46/169] [D loss: 0.695294] [G loss: 0.690838]\n",
      "[Epoch 5/200] [Batch 47/169] [D loss: 0.695742] [G loss: 0.690217]\n",
      "[Epoch 5/200] [Batch 48/169] [D loss: 0.693750] [G loss: 0.690095]\n",
      "[Epoch 5/200] [Batch 49/169] [D loss: 0.694165] [G loss: 0.690683]\n",
      "[Epoch 5/200] [Batch 50/169] [D loss: 0.695304] [G loss: 0.690203]\n",
      "[Epoch 5/200] [Batch 51/169] [D loss: 0.695357] [G loss: 0.691840]\n",
      "[Epoch 5/200] [Batch 52/169] [D loss: 0.694249] [G loss: 0.690750]\n",
      "[Epoch 5/200] [Batch 53/169] [D loss: 0.694202] [G loss: 0.691528]\n",
      "[Epoch 5/200] [Batch 54/169] [D loss: 0.694917] [G loss: 0.691955]\n",
      "[Epoch 5/200] [Batch 55/169] [D loss: 0.695539] [G loss: 0.691376]\n",
      "[Epoch 5/200] [Batch 56/169] [D loss: 0.694512] [G loss: 0.692794]\n",
      "[Epoch 5/200] [Batch 57/169] [D loss: 0.694817] [G loss: 0.691954]\n",
      "[Epoch 5/200] [Batch 58/169] [D loss: 0.695014] [G loss: 0.691671]\n",
      "[Epoch 5/200] [Batch 59/169] [D loss: 0.694959] [G loss: 0.691273]\n",
      "[Epoch 5/200] [Batch 60/169] [D loss: 0.693693] [G loss: 0.692410]\n",
      "[Epoch 5/200] [Batch 61/169] [D loss: 0.695207] [G loss: 0.690425]\n",
      "[Epoch 5/200] [Batch 62/169] [D loss: 0.695186] [G loss: 0.691271]\n",
      "[Epoch 5/200] [Batch 63/169] [D loss: 0.695022] [G loss: 0.690748]\n",
      "[Epoch 5/200] [Batch 64/169] [D loss: 0.695410] [G loss: 0.692859]\n",
      "[Epoch 5/200] [Batch 65/169] [D loss: 0.695189] [G loss: 0.692977]\n",
      "[Epoch 5/200] [Batch 66/169] [D loss: 0.693806] [G loss: 0.692177]\n",
      "[Epoch 5/200] [Batch 67/169] [D loss: 0.694664] [G loss: 0.691663]\n",
      "[Epoch 5/200] [Batch 68/169] [D loss: 0.693441] [G loss: 0.692976]\n",
      "[Epoch 5/200] [Batch 69/169] [D loss: 0.693814] [G loss: 0.692020]\n",
      "[Epoch 5/200] [Batch 70/169] [D loss: 0.694785] [G loss: 0.691595]\n",
      "[Epoch 5/200] [Batch 71/169] [D loss: 0.693074] [G loss: 0.691611]\n",
      "[Epoch 5/200] [Batch 72/169] [D loss: 0.693944] [G loss: 0.692084]\n",
      "[Epoch 5/200] [Batch 73/169] [D loss: 0.694146] [G loss: 0.694641]\n",
      "[Epoch 5/200] [Batch 74/169] [D loss: 0.693845] [G loss: 0.691146]\n",
      "[Epoch 5/200] [Batch 75/169] [D loss: 0.693501] [G loss: 0.692133]\n",
      "[Epoch 5/200] [Batch 76/169] [D loss: 0.693585] [G loss: 0.693549]\n",
      "[Epoch 5/200] [Batch 77/169] [D loss: 0.693685] [G loss: 0.692542]\n",
      "[Epoch 5/200] [Batch 78/169] [D loss: 0.694690] [G loss: 0.692132]\n",
      "[Epoch 5/200] [Batch 79/169] [D loss: 0.694374] [G loss: 0.691749]\n",
      "[Epoch 5/200] [Batch 80/169] [D loss: 0.693094] [G loss: 0.692540]\n",
      "[Epoch 5/200] [Batch 81/169] [D loss: 0.693702] [G loss: 0.693950]\n",
      "[Epoch 5/200] [Batch 82/169] [D loss: 0.692236] [G loss: 0.693149]\n",
      "[Epoch 5/200] [Batch 83/169] [D loss: 0.693593] [G loss: 0.693217]\n",
      "[Epoch 5/200] [Batch 84/169] [D loss: 0.691954] [G loss: 0.693159]\n",
      "[Epoch 5/200] [Batch 85/169] [D loss: 0.692491] [G loss: 0.692009]\n",
      "[Epoch 5/200] [Batch 86/169] [D loss: 0.692539] [G loss: 0.694550]\n",
      "[Epoch 5/200] [Batch 87/169] [D loss: 0.692908] [G loss: 0.693126]\n",
      "[Epoch 5/200] [Batch 88/169] [D loss: 0.693039] [G loss: 0.693006]\n",
      "[Epoch 5/200] [Batch 89/169] [D loss: 0.693021] [G loss: 0.692615]\n",
      "[Epoch 5/200] [Batch 90/169] [D loss: 0.692951] [G loss: 0.693576]\n",
      "[Epoch 5/200] [Batch 91/169] [D loss: 0.693277] [G loss: 0.693076]\n",
      "[Epoch 5/200] [Batch 92/169] [D loss: 0.692604] [G loss: 0.694636]\n",
      "[Epoch 5/200] [Batch 93/169] [D loss: 0.692603] [G loss: 0.693881]\n",
      "[Epoch 5/200] [Batch 94/169] [D loss: 0.692505] [G loss: 0.695026]\n",
      "[Epoch 5/200] [Batch 95/169] [D loss: 0.692417] [G loss: 0.693578]\n",
      "[Epoch 5/200] [Batch 96/169] [D loss: 0.691635] [G loss: 0.694070]\n",
      "[Epoch 5/200] [Batch 97/169] [D loss: 0.693524] [G loss: 0.694916]\n",
      "[Epoch 5/200] [Batch 98/169] [D loss: 0.691782] [G loss: 0.693453]\n",
      "[Epoch 5/200] [Batch 99/169] [D loss: 0.692510] [G loss: 0.693264]\n",
      "[Epoch 5/200] [Batch 100/169] [D loss: 0.692067] [G loss: 0.693722]\n",
      "[Epoch 5/200] [Batch 101/169] [D loss: 0.692480] [G loss: 0.694660]\n",
      "[Epoch 5/200] [Batch 102/169] [D loss: 0.692276] [G loss: 0.695414]\n",
      "[Epoch 5/200] [Batch 103/169] [D loss: 0.691630] [G loss: 0.693979]\n",
      "[Epoch 5/200] [Batch 104/169] [D loss: 0.692338] [G loss: 0.694452]\n",
      "[Epoch 5/200] [Batch 105/169] [D loss: 0.693039] [G loss: 0.695438]\n",
      "[Epoch 5/200] [Batch 106/169] [D loss: 0.691253] [G loss: 0.693409]\n",
      "[Epoch 5/200] [Batch 107/169] [D loss: 0.693162] [G loss: 0.693824]\n",
      "[Epoch 5/200] [Batch 108/169] [D loss: 0.691729] [G loss: 0.694113]\n",
      "[Epoch 5/200] [Batch 109/169] [D loss: 0.692042] [G loss: 0.694100]\n",
      "[Epoch 5/200] [Batch 110/169] [D loss: 0.692226] [G loss: 0.693155]\n",
      "[Epoch 5/200] [Batch 111/169] [D loss: 0.691616] [G loss: 0.693603]\n",
      "[Epoch 5/200] [Batch 112/169] [D loss: 0.692043] [G loss: 0.695014]\n",
      "[Epoch 5/200] [Batch 113/169] [D loss: 0.691350] [G loss: 0.695304]\n",
      "[Epoch 5/200] [Batch 114/169] [D loss: 0.691593] [G loss: 0.695638]\n",
      "[Epoch 5/200] [Batch 115/169] [D loss: 0.692405] [G loss: 0.694639]\n",
      "[Epoch 5/200] [Batch 116/169] [D loss: 0.692359] [G loss: 0.692659]\n",
      "[Epoch 5/200] [Batch 117/169] [D loss: 0.691794] [G loss: 0.694515]\n",
      "[Epoch 5/200] [Batch 118/169] [D loss: 0.691641] [G loss: 0.693371]\n",
      "[Epoch 5/200] [Batch 119/169] [D loss: 0.691473] [G loss: 0.694540]\n",
      "[Epoch 5/200] [Batch 120/169] [D loss: 0.691472] [G loss: 0.696311]\n",
      "[Epoch 5/200] [Batch 121/169] [D loss: 0.691162] [G loss: 0.694288]\n",
      "[Epoch 5/200] [Batch 122/169] [D loss: 0.691828] [G loss: 0.694225]\n",
      "[Epoch 5/200] [Batch 123/169] [D loss: 0.692067] [G loss: 0.695356]\n",
      "[Epoch 5/200] [Batch 124/169] [D loss: 0.692021] [G loss: 0.693803]\n",
      "[Epoch 5/200] [Batch 125/169] [D loss: 0.691844] [G loss: 0.694512]\n",
      "[Epoch 5/200] [Batch 126/169] [D loss: 0.691398] [G loss: 0.693990]\n",
      "[Epoch 5/200] [Batch 127/169] [D loss: 0.691348] [G loss: 0.693965]\n",
      "[Epoch 5/200] [Batch 128/169] [D loss: 0.691379] [G loss: 0.694205]\n",
      "[Epoch 5/200] [Batch 129/169] [D loss: 0.690564] [G loss: 0.695874]\n",
      "[Epoch 5/200] [Batch 130/169] [D loss: 0.690762] [G loss: 0.695375]\n",
      "[Epoch 5/200] [Batch 131/169] [D loss: 0.692239] [G loss: 0.693699]\n",
      "[Epoch 5/200] [Batch 132/169] [D loss: 0.692022] [G loss: 0.695947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 133/169] [D loss: 0.691316] [G loss: 0.694032]\n",
      "[Epoch 5/200] [Batch 134/169] [D loss: 0.691100] [G loss: 0.693908]\n",
      "[Epoch 5/200] [Batch 135/169] [D loss: 0.691569] [G loss: 0.695557]\n",
      "[Epoch 5/200] [Batch 136/169] [D loss: 0.690890] [G loss: 0.694526]\n",
      "[Epoch 5/200] [Batch 137/169] [D loss: 0.691027] [G loss: 0.696056]\n",
      "[Epoch 5/200] [Batch 138/169] [D loss: 0.691340] [G loss: 0.695330]\n",
      "[Epoch 5/200] [Batch 139/169] [D loss: 0.691669] [G loss: 0.695270]\n",
      "[Epoch 5/200] [Batch 140/169] [D loss: 0.690757] [G loss: 0.694943]\n",
      "[Epoch 5/200] [Batch 141/169] [D loss: 0.690154] [G loss: 0.694978]\n",
      "[Epoch 5/200] [Batch 142/169] [D loss: 0.691330] [G loss: 0.695257]\n",
      "[Epoch 5/200] [Batch 143/169] [D loss: 0.690912] [G loss: 0.693727]\n",
      "[Epoch 5/200] [Batch 144/169] [D loss: 0.691217] [G loss: 0.693519]\n",
      "[Epoch 5/200] [Batch 145/169] [D loss: 0.690424] [G loss: 0.695739]\n",
      "[Epoch 5/200] [Batch 146/169] [D loss: 0.691258] [G loss: 0.693495]\n",
      "[Epoch 5/200] [Batch 147/169] [D loss: 0.692096] [G loss: 0.693963]\n",
      "[Epoch 5/200] [Batch 148/169] [D loss: 0.689814] [G loss: 0.694818]\n",
      "[Epoch 5/200] [Batch 149/169] [D loss: 0.689790] [G loss: 0.696400]\n",
      "[Epoch 5/200] [Batch 150/169] [D loss: 0.692665] [G loss: 0.695454]\n",
      "[Epoch 5/200] [Batch 151/169] [D loss: 0.693459] [G loss: 0.693477]\n",
      "[Epoch 5/200] [Batch 152/169] [D loss: 0.692009] [G loss: 0.693271]\n",
      "[Epoch 5/200] [Batch 153/169] [D loss: 0.690545] [G loss: 0.693219]\n",
      "[Epoch 5/200] [Batch 154/169] [D loss: 0.691319] [G loss: 0.692469]\n",
      "[Epoch 5/200] [Batch 155/169] [D loss: 0.694110] [G loss: 0.693975]\n",
      "[Epoch 5/200] [Batch 156/169] [D loss: 0.693825] [G loss: 0.695940]\n",
      "[Epoch 5/200] [Batch 157/169] [D loss: 0.693567] [G loss: 0.694312]\n",
      "[Epoch 5/200] [Batch 158/169] [D loss: 0.694351] [G loss: 0.692854]\n",
      "[Epoch 5/200] [Batch 159/169] [D loss: 0.693056] [G loss: 0.693076]\n",
      "[Epoch 5/200] [Batch 160/169] [D loss: 0.692977] [G loss: 0.693540]\n",
      "[Epoch 5/200] [Batch 161/169] [D loss: 0.693920] [G loss: 0.693604]\n",
      "[Epoch 5/200] [Batch 162/169] [D loss: 0.695437] [G loss: 0.692625]\n",
      "[Epoch 5/200] [Batch 163/169] [D loss: 0.694543] [G loss: 0.692172]\n",
      "[Epoch 5/200] [Batch 164/169] [D loss: 0.695366] [G loss: 0.690515]\n",
      "[Epoch 5/200] [Batch 165/169] [D loss: 0.695391] [G loss: 0.689829]\n",
      "[Epoch 5/200] [Batch 166/169] [D loss: 0.695800] [G loss: 0.689456]\n",
      "[Epoch 5/200] [Batch 167/169] [D loss: 0.696600] [G loss: 0.690028]\n",
      "[Epoch 5/200] [Batch 168/169] [D loss: 0.697974] [G loss: 0.690122]\n",
      "[Epoch 6/200] [Batch 0/169] [D loss: 0.697335] [G loss: 0.692747]\n",
      "[Epoch 6/200] [Batch 1/169] [D loss: 0.698243] [G loss: 0.691302]\n",
      "[Epoch 6/200] [Batch 2/169] [D loss: 0.697460] [G loss: 0.693630]\n",
      "[Epoch 6/200] [Batch 3/169] [D loss: 0.697380] [G loss: 0.692187]\n",
      "[Epoch 6/200] [Batch 4/169] [D loss: 0.696858] [G loss: 0.691918]\n",
      "[Epoch 6/200] [Batch 5/169] [D loss: 0.696934] [G loss: 0.693048]\n",
      "[Epoch 6/200] [Batch 6/169] [D loss: 0.697211] [G loss: 0.690913]\n",
      "[Epoch 6/200] [Batch 7/169] [D loss: 0.695064] [G loss: 0.691616]\n",
      "[Epoch 6/200] [Batch 8/169] [D loss: 0.694724] [G loss: 0.692436]\n",
      "[Epoch 6/200] [Batch 9/169] [D loss: 0.695849] [G loss: 0.693356]\n",
      "[Epoch 6/200] [Batch 10/169] [D loss: 0.694678] [G loss: 0.694183]\n",
      "[Epoch 6/200] [Batch 11/169] [D loss: 0.695477] [G loss: 0.693461]\n",
      "[Epoch 6/200] [Batch 12/169] [D loss: 0.696491] [G loss: 0.691721]\n",
      "[Epoch 6/200] [Batch 13/169] [D loss: 0.695902] [G loss: 0.692024]\n",
      "[Epoch 6/200] [Batch 14/169] [D loss: 0.695843] [G loss: 0.694922]\n",
      "[Epoch 6/200] [Batch 15/169] [D loss: 0.693955] [G loss: 0.692533]\n",
      "[Epoch 6/200] [Batch 16/169] [D loss: 0.695619] [G loss: 0.691285]\n",
      "[Epoch 6/200] [Batch 17/169] [D loss: 0.695562] [G loss: 0.690698]\n",
      "[Epoch 6/200] [Batch 18/169] [D loss: 0.694574] [G loss: 0.693303]\n",
      "[Epoch 6/200] [Batch 19/169] [D loss: 0.694622] [G loss: 0.693007]\n",
      "[Epoch 6/200] [Batch 20/169] [D loss: 0.693827] [G loss: 0.692870]\n",
      "[Epoch 6/200] [Batch 21/169] [D loss: 0.693132] [G loss: 0.692611]\n",
      "[Epoch 6/200] [Batch 22/169] [D loss: 0.693898] [G loss: 0.693008]\n",
      "[Epoch 6/200] [Batch 23/169] [D loss: 0.693148] [G loss: 0.691769]\n",
      "[Epoch 6/200] [Batch 24/169] [D loss: 0.693374] [G loss: 0.693342]\n",
      "[Epoch 6/200] [Batch 25/169] [D loss: 0.693441] [G loss: 0.693337]\n",
      "[Epoch 6/200] [Batch 26/169] [D loss: 0.693796] [G loss: 0.693489]\n",
      "[Epoch 6/200] [Batch 27/169] [D loss: 0.693010] [G loss: 0.693938]\n",
      "[Epoch 6/200] [Batch 28/169] [D loss: 0.693351] [G loss: 0.694362]\n",
      "[Epoch 6/200] [Batch 29/169] [D loss: 0.692640] [G loss: 0.694503]\n",
      "[Epoch 6/200] [Batch 30/169] [D loss: 0.693395] [G loss: 0.694003]\n",
      "[Epoch 6/200] [Batch 31/169] [D loss: 0.691919] [G loss: 0.696410]\n",
      "[Epoch 6/200] [Batch 32/169] [D loss: 0.692352] [G loss: 0.694537]\n",
      "[Epoch 6/200] [Batch 33/169] [D loss: 0.693139] [G loss: 0.695904]\n",
      "[Epoch 6/200] [Batch 34/169] [D loss: 0.692145] [G loss: 0.697131]\n",
      "[Epoch 6/200] [Batch 35/169] [D loss: 0.691227] [G loss: 0.696585]\n",
      "[Epoch 6/200] [Batch 36/169] [D loss: 0.691200] [G loss: 0.697572]\n",
      "[Epoch 6/200] [Batch 37/169] [D loss: 0.691621] [G loss: 0.697229]\n",
      "[Epoch 6/200] [Batch 38/169] [D loss: 0.690549] [G loss: 0.696294]\n",
      "[Epoch 6/200] [Batch 39/169] [D loss: 0.690746] [G loss: 0.698060]\n",
      "[Epoch 6/200] [Batch 40/169] [D loss: 0.690012] [G loss: 0.697029]\n",
      "[Epoch 6/200] [Batch 41/169] [D loss: 0.691383] [G loss: 0.698052]\n",
      "[Epoch 6/200] [Batch 42/169] [D loss: 0.690956] [G loss: 0.699239]\n",
      "[Epoch 6/200] [Batch 43/169] [D loss: 0.689679] [G loss: 0.697922]\n",
      "[Epoch 6/200] [Batch 44/169] [D loss: 0.690566] [G loss: 0.697346]\n",
      "[Epoch 6/200] [Batch 45/169] [D loss: 0.688275] [G loss: 0.697680]\n",
      "[Epoch 6/200] [Batch 46/169] [D loss: 0.690370] [G loss: 0.698419]\n",
      "[Epoch 6/200] [Batch 47/169] [D loss: 0.689733] [G loss: 0.697724]\n",
      "[Epoch 6/200] [Batch 48/169] [D loss: 0.689506] [G loss: 0.696561]\n",
      "[Epoch 6/200] [Batch 49/169] [D loss: 0.688808] [G loss: 0.698307]\n",
      "[Epoch 6/200] [Batch 50/169] [D loss: 0.690013] [G loss: 0.698421]\n",
      "[Epoch 6/200] [Batch 51/169] [D loss: 0.690863] [G loss: 0.696629]\n",
      "[Epoch 6/200] [Batch 52/169] [D loss: 0.689716] [G loss: 0.697175]\n",
      "[Epoch 6/200] [Batch 53/169] [D loss: 0.688603] [G loss: 0.697219]\n",
      "[Epoch 6/200] [Batch 54/169] [D loss: 0.689017] [G loss: 0.698303]\n",
      "[Epoch 6/200] [Batch 55/169] [D loss: 0.688606] [G loss: 0.697361]\n",
      "[Epoch 6/200] [Batch 56/169] [D loss: 0.690127] [G loss: 0.697791]\n",
      "[Epoch 6/200] [Batch 57/169] [D loss: 0.689036] [G loss: 0.696634]\n",
      "[Epoch 6/200] [Batch 58/169] [D loss: 0.690626] [G loss: 0.696325]\n",
      "[Epoch 6/200] [Batch 59/169] [D loss: 0.690433] [G loss: 0.696786]\n",
      "[Epoch 6/200] [Batch 60/169] [D loss: 0.690429] [G loss: 0.696512]\n",
      "[Epoch 6/200] [Batch 61/169] [D loss: 0.689669] [G loss: 0.696542]\n",
      "[Epoch 6/200] [Batch 62/169] [D loss: 0.691340] [G loss: 0.696647]\n",
      "[Epoch 6/200] [Batch 63/169] [D loss: 0.691056] [G loss: 0.696831]\n",
      "[Epoch 6/200] [Batch 64/169] [D loss: 0.691499] [G loss: 0.697477]\n",
      "[Epoch 6/200] [Batch 65/169] [D loss: 0.691736] [G loss: 0.694079]\n",
      "[Epoch 6/200] [Batch 66/169] [D loss: 0.692078] [G loss: 0.693582]\n",
      "[Epoch 6/200] [Batch 67/169] [D loss: 0.692825] [G loss: 0.693432]\n",
      "[Epoch 6/200] [Batch 68/169] [D loss: 0.691240] [G loss: 0.692550]\n",
      "[Epoch 6/200] [Batch 69/169] [D loss: 0.691351] [G loss: 0.694805]\n",
      "[Epoch 6/200] [Batch 70/169] [D loss: 0.691591] [G loss: 0.692075]\n",
      "[Epoch 6/200] [Batch 71/169] [D loss: 0.692135] [G loss: 0.694016]\n",
      "[Epoch 6/200] [Batch 72/169] [D loss: 0.692139] [G loss: 0.691725]\n",
      "[Epoch 6/200] [Batch 73/169] [D loss: 0.692415] [G loss: 0.692613]\n",
      "[Epoch 6/200] [Batch 74/169] [D loss: 0.692059] [G loss: 0.693370]\n",
      "[Epoch 6/200] [Batch 75/169] [D loss: 0.692414] [G loss: 0.693730]\n",
      "[Epoch 6/200] [Batch 76/169] [D loss: 0.693361] [G loss: 0.691641]\n",
      "[Epoch 6/200] [Batch 77/169] [D loss: 0.692141] [G loss: 0.693714]\n",
      "[Epoch 6/200] [Batch 78/169] [D loss: 0.693346] [G loss: 0.691343]\n",
      "[Epoch 6/200] [Batch 79/169] [D loss: 0.693375] [G loss: 0.691787]\n",
      "[Epoch 6/200] [Batch 80/169] [D loss: 0.694521] [G loss: 0.691386]\n",
      "[Epoch 6/200] [Batch 81/169] [D loss: 0.693858] [G loss: 0.691271]\n",
      "[Epoch 6/200] [Batch 82/169] [D loss: 0.694642] [G loss: 0.691941]\n",
      "[Epoch 6/200] [Batch 83/169] [D loss: 0.694967] [G loss: 0.690153]\n",
      "[Epoch 6/200] [Batch 84/169] [D loss: 0.695232] [G loss: 0.690951]\n",
      "[Epoch 6/200] [Batch 85/169] [D loss: 0.694634] [G loss: 0.690235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 86/169] [D loss: 0.694878] [G loss: 0.689113]\n",
      "[Epoch 6/200] [Batch 87/169] [D loss: 0.695615] [G loss: 0.690919]\n",
      "[Epoch 6/200] [Batch 88/169] [D loss: 0.693871] [G loss: 0.689496]\n",
      "[Epoch 6/200] [Batch 89/169] [D loss: 0.695709] [G loss: 0.692148]\n",
      "[Epoch 6/200] [Batch 90/169] [D loss: 0.694797] [G loss: 0.689353]\n",
      "[Epoch 6/200] [Batch 91/169] [D loss: 0.695553] [G loss: 0.691671]\n",
      "[Epoch 6/200] [Batch 92/169] [D loss: 0.694081] [G loss: 0.691841]\n",
      "[Epoch 6/200] [Batch 93/169] [D loss: 0.694026] [G loss: 0.691797]\n",
      "[Epoch 6/200] [Batch 94/169] [D loss: 0.695107] [G loss: 0.691628]\n",
      "[Epoch 6/200] [Batch 95/169] [D loss: 0.695567] [G loss: 0.689445]\n",
      "[Epoch 6/200] [Batch 96/169] [D loss: 0.694751] [G loss: 0.691510]\n",
      "[Epoch 6/200] [Batch 97/169] [D loss: 0.693441] [G loss: 0.691189]\n",
      "[Epoch 6/200] [Batch 98/169] [D loss: 0.694962] [G loss: 0.691885]\n",
      "[Epoch 6/200] [Batch 99/169] [D loss: 0.694153] [G loss: 0.690406]\n",
      "[Epoch 6/200] [Batch 100/169] [D loss: 0.694471] [G loss: 0.690924]\n",
      "[Epoch 6/200] [Batch 101/169] [D loss: 0.694366] [G loss: 0.692387]\n",
      "[Epoch 6/200] [Batch 102/169] [D loss: 0.694179] [G loss: 0.693194]\n",
      "[Epoch 6/200] [Batch 103/169] [D loss: 0.693513] [G loss: 0.691727]\n",
      "[Epoch 6/200] [Batch 104/169] [D loss: 0.694447] [G loss: 0.690490]\n",
      "[Epoch 6/200] [Batch 105/169] [D loss: 0.693400] [G loss: 0.693245]\n",
      "[Epoch 6/200] [Batch 106/169] [D loss: 0.693610] [G loss: 0.695434]\n",
      "[Epoch 6/200] [Batch 107/169] [D loss: 0.694149] [G loss: 0.693111]\n",
      "[Epoch 6/200] [Batch 108/169] [D loss: 0.693804] [G loss: 0.692201]\n",
      "[Epoch 6/200] [Batch 109/169] [D loss: 0.693427] [G loss: 0.693653]\n",
      "[Epoch 6/200] [Batch 110/169] [D loss: 0.692815] [G loss: 0.694698]\n",
      "[Epoch 6/200] [Batch 111/169] [D loss: 0.692293] [G loss: 0.695113]\n",
      "[Epoch 6/200] [Batch 112/169] [D loss: 0.693092] [G loss: 0.693961]\n",
      "[Epoch 6/200] [Batch 113/169] [D loss: 0.692652] [G loss: 0.695397]\n",
      "[Epoch 6/200] [Batch 114/169] [D loss: 0.692268] [G loss: 0.694271]\n",
      "[Epoch 6/200] [Batch 115/169] [D loss: 0.691581] [G loss: 0.696735]\n",
      "[Epoch 6/200] [Batch 116/169] [D loss: 0.690410] [G loss: 0.695572]\n",
      "[Epoch 6/200] [Batch 117/169] [D loss: 0.691636] [G loss: 0.696243]\n",
      "[Epoch 6/200] [Batch 118/169] [D loss: 0.690356] [G loss: 0.695702]\n",
      "[Epoch 6/200] [Batch 119/169] [D loss: 0.689915] [G loss: 0.695459]\n",
      "[Epoch 6/200] [Batch 120/169] [D loss: 0.690303] [G loss: 0.697680]\n",
      "[Epoch 6/200] [Batch 121/169] [D loss: 0.690983] [G loss: 0.696282]\n",
      "[Epoch 6/200] [Batch 122/169] [D loss: 0.689696] [G loss: 0.696495]\n",
      "[Epoch 6/200] [Batch 123/169] [D loss: 0.690640] [G loss: 0.696711]\n",
      "[Epoch 6/200] [Batch 124/169] [D loss: 0.689164] [G loss: 0.697529]\n",
      "[Epoch 6/200] [Batch 125/169] [D loss: 0.689012] [G loss: 0.696949]\n",
      "[Epoch 6/200] [Batch 126/169] [D loss: 0.689474] [G loss: 0.697319]\n",
      "[Epoch 6/200] [Batch 127/169] [D loss: 0.689135] [G loss: 0.696819]\n",
      "[Epoch 6/200] [Batch 128/169] [D loss: 0.687914] [G loss: 0.699555]\n",
      "[Epoch 6/200] [Batch 129/169] [D loss: 0.689682] [G loss: 0.698535]\n",
      "[Epoch 6/200] [Batch 130/169] [D loss: 0.689588] [G loss: 0.696563]\n",
      "[Epoch 6/200] [Batch 131/169] [D loss: 0.689633] [G loss: 0.696445]\n",
      "[Epoch 6/200] [Batch 132/169] [D loss: 0.689135] [G loss: 0.694559]\n",
      "[Epoch 6/200] [Batch 133/169] [D loss: 0.691064] [G loss: 0.692357]\n",
      "[Epoch 6/200] [Batch 134/169] [D loss: 0.688817] [G loss: 0.698013]\n",
      "[Epoch 6/200] [Batch 135/169] [D loss: 0.690020] [G loss: 0.696654]\n",
      "[Epoch 6/200] [Batch 136/169] [D loss: 0.690186] [G loss: 0.693293]\n",
      "[Epoch 6/200] [Batch 137/169] [D loss: 0.692378] [G loss: 0.692571]\n",
      "[Epoch 6/200] [Batch 138/169] [D loss: 0.692748] [G loss: 0.692433]\n",
      "[Epoch 6/200] [Batch 139/169] [D loss: 0.694193] [G loss: 0.693059]\n",
      "[Epoch 6/200] [Batch 140/169] [D loss: 0.693987] [G loss: 0.692671]\n",
      "[Epoch 6/200] [Batch 141/169] [D loss: 0.693660] [G loss: 0.691805]\n",
      "[Epoch 6/200] [Batch 142/169] [D loss: 0.692924] [G loss: 0.695444]\n",
      "[Epoch 6/200] [Batch 143/169] [D loss: 0.693923] [G loss: 0.691381]\n",
      "[Epoch 6/200] [Batch 144/169] [D loss: 0.694896] [G loss: 0.689788]\n",
      "[Epoch 6/200] [Batch 145/169] [D loss: 0.694656] [G loss: 0.690853]\n",
      "[Epoch 6/200] [Batch 146/169] [D loss: 0.695622] [G loss: 0.690282]\n",
      "[Epoch 6/200] [Batch 147/169] [D loss: 0.696281] [G loss: 0.686620]\n",
      "[Epoch 6/200] [Batch 148/169] [D loss: 0.696291] [G loss: 0.689832]\n",
      "[Epoch 6/200] [Batch 149/169] [D loss: 0.694989] [G loss: 0.691048]\n",
      "[Epoch 6/200] [Batch 150/169] [D loss: 0.695304] [G loss: 0.687440]\n",
      "[Epoch 6/200] [Batch 151/169] [D loss: 0.696378] [G loss: 0.685572]\n",
      "[Epoch 6/200] [Batch 152/169] [D loss: 0.695976] [G loss: 0.689462]\n",
      "[Epoch 6/200] [Batch 153/169] [D loss: 0.696703] [G loss: 0.690368]\n",
      "[Epoch 6/200] [Batch 154/169] [D loss: 0.695640] [G loss: 0.691784]\n",
      "[Epoch 6/200] [Batch 155/169] [D loss: 0.695021] [G loss: 0.692233]\n",
      "[Epoch 6/200] [Batch 156/169] [D loss: 0.695679] [G loss: 0.691064]\n",
      "[Epoch 6/200] [Batch 157/169] [D loss: 0.696830] [G loss: 0.692445]\n",
      "[Epoch 6/200] [Batch 158/169] [D loss: 0.695619] [G loss: 0.690665]\n",
      "[Epoch 6/200] [Batch 159/169] [D loss: 0.697817] [G loss: 0.689250]\n",
      "[Epoch 6/200] [Batch 160/169] [D loss: 0.697243] [G loss: 0.690065]\n",
      "[Epoch 6/200] [Batch 161/169] [D loss: 0.695421] [G loss: 0.689773]\n",
      "[Epoch 6/200] [Batch 162/169] [D loss: 0.696157] [G loss: 0.690364]\n",
      "[Epoch 6/200] [Batch 163/169] [D loss: 0.695534] [G loss: 0.690961]\n",
      "[Epoch 6/200] [Batch 164/169] [D loss: 0.696081] [G loss: 0.690740]\n",
      "[Epoch 6/200] [Batch 165/169] [D loss: 0.696488] [G loss: 0.690543]\n",
      "[Epoch 6/200] [Batch 166/169] [D loss: 0.696375] [G loss: 0.691884]\n",
      "[Epoch 6/200] [Batch 167/169] [D loss: 0.694718] [G loss: 0.691574]\n",
      "[Epoch 6/200] [Batch 168/169] [D loss: 0.695075] [G loss: 0.693613]\n",
      "[Epoch 7/200] [Batch 0/169] [D loss: 0.695692] [G loss: 0.691127]\n",
      "[Epoch 7/200] [Batch 1/169] [D loss: 0.695167] [G loss: 0.692617]\n",
      "[Epoch 7/200] [Batch 2/169] [D loss: 0.695362] [G loss: 0.690795]\n",
      "[Epoch 7/200] [Batch 3/169] [D loss: 0.695235] [G loss: 0.691762]\n",
      "[Epoch 7/200] [Batch 4/169] [D loss: 0.695279] [G loss: 0.692130]\n",
      "[Epoch 7/200] [Batch 5/169] [D loss: 0.695148] [G loss: 0.691615]\n",
      "[Epoch 7/200] [Batch 6/169] [D loss: 0.695255] [G loss: 0.691958]\n",
      "[Epoch 7/200] [Batch 7/169] [D loss: 0.694543] [G loss: 0.691982]\n",
      "[Epoch 7/200] [Batch 8/169] [D loss: 0.694622] [G loss: 0.692241]\n",
      "[Epoch 7/200] [Batch 9/169] [D loss: 0.693997] [G loss: 0.691409]\n",
      "[Epoch 7/200] [Batch 10/169] [D loss: 0.694638] [G loss: 0.693138]\n",
      "[Epoch 7/200] [Batch 11/169] [D loss: 0.694974] [G loss: 0.692444]\n",
      "[Epoch 7/200] [Batch 12/169] [D loss: 0.694568] [G loss: 0.693972]\n",
      "[Epoch 7/200] [Batch 13/169] [D loss: 0.694528] [G loss: 0.693268]\n",
      "[Epoch 7/200] [Batch 14/169] [D loss: 0.693175] [G loss: 0.693633]\n",
      "[Epoch 7/200] [Batch 15/169] [D loss: 0.694104] [G loss: 0.693174]\n",
      "[Epoch 7/200] [Batch 16/169] [D loss: 0.694160] [G loss: 0.692578]\n",
      "[Epoch 7/200] [Batch 17/169] [D loss: 0.693759] [G loss: 0.693714]\n",
      "[Epoch 7/200] [Batch 18/169] [D loss: 0.693298] [G loss: 0.695319]\n",
      "[Epoch 7/200] [Batch 19/169] [D loss: 0.693050] [G loss: 0.695622]\n",
      "[Epoch 7/200] [Batch 20/169] [D loss: 0.692014] [G loss: 0.695521]\n",
      "[Epoch 7/200] [Batch 21/169] [D loss: 0.692968] [G loss: 0.694491]\n",
      "[Epoch 7/200] [Batch 22/169] [D loss: 0.692304] [G loss: 0.694860]\n",
      "[Epoch 7/200] [Batch 23/169] [D loss: 0.692673] [G loss: 0.695205]\n",
      "[Epoch 7/200] [Batch 24/169] [D loss: 0.691712] [G loss: 0.695711]\n",
      "[Epoch 7/200] [Batch 25/169] [D loss: 0.691251] [G loss: 0.695906]\n",
      "[Epoch 7/200] [Batch 26/169] [D loss: 0.691433] [G loss: 0.694945]\n",
      "[Epoch 7/200] [Batch 27/169] [D loss: 0.691666] [G loss: 0.695374]\n",
      "[Epoch 7/200] [Batch 28/169] [D loss: 0.691730] [G loss: 0.695401]\n",
      "[Epoch 7/200] [Batch 29/169] [D loss: 0.690721] [G loss: 0.697534]\n",
      "[Epoch 7/200] [Batch 30/169] [D loss: 0.689937] [G loss: 0.698087]\n",
      "[Epoch 7/200] [Batch 31/169] [D loss: 0.690445] [G loss: 0.696199]\n",
      "[Epoch 7/200] [Batch 32/169] [D loss: 0.689848] [G loss: 0.697432]\n",
      "[Epoch 7/200] [Batch 33/169] [D loss: 0.690122] [G loss: 0.696483]\n",
      "[Epoch 7/200] [Batch 34/169] [D loss: 0.689318] [G loss: 0.698826]\n",
      "[Epoch 7/200] [Batch 35/169] [D loss: 0.690353] [G loss: 0.697915]\n",
      "[Epoch 7/200] [Batch 36/169] [D loss: 0.690653] [G loss: 0.697358]\n",
      "[Epoch 7/200] [Batch 37/169] [D loss: 0.689991] [G loss: 0.700512]\n",
      "[Epoch 7/200] [Batch 38/169] [D loss: 0.690756] [G loss: 0.696624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 39/169] [D loss: 0.691235] [G loss: 0.695270]\n",
      "[Epoch 7/200] [Batch 40/169] [D loss: 0.690552] [G loss: 0.694833]\n",
      "[Epoch 7/200] [Batch 41/169] [D loss: 0.690042] [G loss: 0.695591]\n",
      "[Epoch 7/200] [Batch 42/169] [D loss: 0.692122] [G loss: 0.693733]\n",
      "[Epoch 7/200] [Batch 43/169] [D loss: 0.692772] [G loss: 0.693077]\n",
      "[Epoch 7/200] [Batch 44/169] [D loss: 0.692297] [G loss: 0.694190]\n",
      "[Epoch 7/200] [Batch 45/169] [D loss: 0.695027] [G loss: 0.692070]\n",
      "[Epoch 7/200] [Batch 46/169] [D loss: 0.693502] [G loss: 0.691865]\n",
      "[Epoch 7/200] [Batch 47/169] [D loss: 0.693602] [G loss: 0.690113]\n",
      "[Epoch 7/200] [Batch 48/169] [D loss: 0.693453] [G loss: 0.689627]\n",
      "[Epoch 7/200] [Batch 49/169] [D loss: 0.695671] [G loss: 0.692079]\n",
      "[Epoch 7/200] [Batch 50/169] [D loss: 0.694668] [G loss: 0.689991]\n",
      "[Epoch 7/200] [Batch 51/169] [D loss: 0.695708] [G loss: 0.690759]\n",
      "[Epoch 7/200] [Batch 52/169] [D loss: 0.694167] [G loss: 0.690820]\n",
      "[Epoch 7/200] [Batch 53/169] [D loss: 0.696422] [G loss: 0.688099]\n",
      "[Epoch 7/200] [Batch 54/169] [D loss: 0.695856] [G loss: 0.689794]\n",
      "[Epoch 7/200] [Batch 55/169] [D loss: 0.695397] [G loss: 0.691215]\n",
      "[Epoch 7/200] [Batch 56/169] [D loss: 0.695731] [G loss: 0.690137]\n",
      "[Epoch 7/200] [Batch 57/169] [D loss: 0.695760] [G loss: 0.690988]\n",
      "[Epoch 7/200] [Batch 58/169] [D loss: 0.696947] [G loss: 0.688757]\n",
      "[Epoch 7/200] [Batch 59/169] [D loss: 0.695730] [G loss: 0.689110]\n",
      "[Epoch 7/200] [Batch 60/169] [D loss: 0.695643] [G loss: 0.688939]\n",
      "[Epoch 7/200] [Batch 61/169] [D loss: 0.694982] [G loss: 0.690845]\n",
      "[Epoch 7/200] [Batch 62/169] [D loss: 0.695492] [G loss: 0.690529]\n",
      "[Epoch 7/200] [Batch 63/169] [D loss: 0.694667] [G loss: 0.690990]\n",
      "[Epoch 7/200] [Batch 64/169] [D loss: 0.694806] [G loss: 0.691568]\n",
      "[Epoch 7/200] [Batch 65/169] [D loss: 0.695712] [G loss: 0.690661]\n",
      "[Epoch 7/200] [Batch 66/169] [D loss: 0.694842] [G loss: 0.691245]\n",
      "[Epoch 7/200] [Batch 67/169] [D loss: 0.694939] [G loss: 0.692009]\n",
      "[Epoch 7/200] [Batch 68/169] [D loss: 0.694957] [G loss: 0.692735]\n",
      "[Epoch 7/200] [Batch 69/169] [D loss: 0.694173] [G loss: 0.692092]\n",
      "[Epoch 7/200] [Batch 70/169] [D loss: 0.694263] [G loss: 0.692661]\n",
      "[Epoch 7/200] [Batch 71/169] [D loss: 0.694156] [G loss: 0.692660]\n",
      "[Epoch 7/200] [Batch 72/169] [D loss: 0.693860] [G loss: 0.692113]\n",
      "[Epoch 7/200] [Batch 73/169] [D loss: 0.693266] [G loss: 0.692493]\n",
      "[Epoch 7/200] [Batch 74/169] [D loss: 0.693838] [G loss: 0.692423]\n",
      "[Epoch 7/200] [Batch 75/169] [D loss: 0.693618] [G loss: 0.693918]\n",
      "[Epoch 7/200] [Batch 76/169] [D loss: 0.693400] [G loss: 0.692218]\n",
      "[Epoch 7/200] [Batch 77/169] [D loss: 0.693054] [G loss: 0.693409]\n",
      "[Epoch 7/200] [Batch 78/169] [D loss: 0.692915] [G loss: 0.693589]\n",
      "[Epoch 7/200] [Batch 79/169] [D loss: 0.692546] [G loss: 0.692906]\n",
      "[Epoch 7/200] [Batch 80/169] [D loss: 0.693426] [G loss: 0.692922]\n",
      "[Epoch 7/200] [Batch 81/169] [D loss: 0.692742] [G loss: 0.692907]\n",
      "[Epoch 7/200] [Batch 82/169] [D loss: 0.693130] [G loss: 0.692989]\n",
      "[Epoch 7/200] [Batch 83/169] [D loss: 0.691827] [G loss: 0.693814]\n",
      "[Epoch 7/200] [Batch 84/169] [D loss: 0.692730] [G loss: 0.693286]\n",
      "[Epoch 7/200] [Batch 85/169] [D loss: 0.692320] [G loss: 0.693826]\n",
      "[Epoch 7/200] [Batch 86/169] [D loss: 0.692522] [G loss: 0.693540]\n",
      "[Epoch 7/200] [Batch 87/169] [D loss: 0.692276] [G loss: 0.694008]\n",
      "[Epoch 7/200] [Batch 88/169] [D loss: 0.692050] [G loss: 0.693431]\n",
      "[Epoch 7/200] [Batch 89/169] [D loss: 0.692223] [G loss: 0.692977]\n",
      "[Epoch 7/200] [Batch 90/169] [D loss: 0.691534] [G loss: 0.694637]\n",
      "[Epoch 7/200] [Batch 91/169] [D loss: 0.692745] [G loss: 0.694068]\n",
      "[Epoch 7/200] [Batch 92/169] [D loss: 0.691324] [G loss: 0.693503]\n",
      "[Epoch 7/200] [Batch 93/169] [D loss: 0.692513] [G loss: 0.694105]\n",
      "[Epoch 7/200] [Batch 94/169] [D loss: 0.691869] [G loss: 0.695628]\n",
      "[Epoch 7/200] [Batch 95/169] [D loss: 0.692021] [G loss: 0.695304]\n",
      "[Epoch 7/200] [Batch 96/169] [D loss: 0.692272] [G loss: 0.694891]\n",
      "[Epoch 7/200] [Batch 97/169] [D loss: 0.691922] [G loss: 0.694296]\n",
      "[Epoch 7/200] [Batch 98/169] [D loss: 0.691792] [G loss: 0.693996]\n",
      "[Epoch 7/200] [Batch 99/169] [D loss: 0.691390] [G loss: 0.695409]\n",
      "[Epoch 7/200] [Batch 100/169] [D loss: 0.690808] [G loss: 0.695302]\n",
      "[Epoch 7/200] [Batch 101/169] [D loss: 0.691688] [G loss: 0.694657]\n",
      "[Epoch 7/200] [Batch 102/169] [D loss: 0.691085] [G loss: 0.695034]\n",
      "[Epoch 7/200] [Batch 103/169] [D loss: 0.691420] [G loss: 0.694416]\n",
      "[Epoch 7/200] [Batch 104/169] [D loss: 0.692253] [G loss: 0.694256]\n",
      "[Epoch 7/200] [Batch 105/169] [D loss: 0.691403] [G loss: 0.694220]\n",
      "[Epoch 7/200] [Batch 106/169] [D loss: 0.691689] [G loss: 0.694371]\n",
      "[Epoch 7/200] [Batch 107/169] [D loss: 0.691973] [G loss: 0.694494]\n",
      "[Epoch 7/200] [Batch 108/169] [D loss: 0.691347] [G loss: 0.694560]\n",
      "[Epoch 7/200] [Batch 109/169] [D loss: 0.690454] [G loss: 0.696953]\n",
      "[Epoch 7/200] [Batch 110/169] [D loss: 0.691566] [G loss: 0.696378]\n",
      "[Epoch 7/200] [Batch 111/169] [D loss: 0.691863] [G loss: 0.693385]\n",
      "[Epoch 7/200] [Batch 112/169] [D loss: 0.690317] [G loss: 0.694046]\n",
      "[Epoch 7/200] [Batch 113/169] [D loss: 0.690205] [G loss: 0.695491]\n",
      "[Epoch 7/200] [Batch 114/169] [D loss: 0.692351] [G loss: 0.694832]\n",
      "[Epoch 7/200] [Batch 115/169] [D loss: 0.690534] [G loss: 0.694468]\n",
      "[Epoch 7/200] [Batch 116/169] [D loss: 0.692309] [G loss: 0.694708]\n",
      "[Epoch 7/200] [Batch 117/169] [D loss: 0.690892] [G loss: 0.695256]\n",
      "[Epoch 7/200] [Batch 118/169] [D loss: 0.692222] [G loss: 0.694454]\n",
      "[Epoch 7/200] [Batch 119/169] [D loss: 0.691683] [G loss: 0.694591]\n",
      "[Epoch 7/200] [Batch 120/169] [D loss: 0.691778] [G loss: 0.696017]\n",
      "[Epoch 7/200] [Batch 121/169] [D loss: 0.691080] [G loss: 0.695920]\n",
      "[Epoch 7/200] [Batch 122/169] [D loss: 0.691766] [G loss: 0.696028]\n",
      "[Epoch 7/200] [Batch 123/169] [D loss: 0.693494] [G loss: 0.693651]\n",
      "[Epoch 7/200] [Batch 124/169] [D loss: 0.692046] [G loss: 0.695657]\n",
      "[Epoch 7/200] [Batch 125/169] [D loss: 0.692179] [G loss: 0.694573]\n",
      "[Epoch 7/200] [Batch 126/169] [D loss: 0.691582] [G loss: 0.693702]\n",
      "[Epoch 7/200] [Batch 127/169] [D loss: 0.692392] [G loss: 0.691712]\n",
      "[Epoch 7/200] [Batch 128/169] [D loss: 0.692522] [G loss: 0.693522]\n",
      "[Epoch 7/200] [Batch 129/169] [D loss: 0.695456] [G loss: 0.693228]\n",
      "[Epoch 7/200] [Batch 130/169] [D loss: 0.695177] [G loss: 0.692408]\n",
      "[Epoch 7/200] [Batch 131/169] [D loss: 0.693439] [G loss: 0.693011]\n",
      "[Epoch 7/200] [Batch 132/169] [D loss: 0.694409] [G loss: 0.690867]\n",
      "[Epoch 7/200] [Batch 133/169] [D loss: 0.694614] [G loss: 0.690805]\n",
      "[Epoch 7/200] [Batch 134/169] [D loss: 0.694511] [G loss: 0.690723]\n",
      "[Epoch 7/200] [Batch 135/169] [D loss: 0.693794] [G loss: 0.692263]\n",
      "[Epoch 7/200] [Batch 136/169] [D loss: 0.694298] [G loss: 0.691738]\n",
      "[Epoch 7/200] [Batch 137/169] [D loss: 0.695239] [G loss: 0.690325]\n",
      "[Epoch 7/200] [Batch 138/169] [D loss: 0.694781] [G loss: 0.690601]\n",
      "[Epoch 7/200] [Batch 139/169] [D loss: 0.694621] [G loss: 0.692621]\n",
      "[Epoch 7/200] [Batch 140/169] [D loss: 0.694535] [G loss: 0.691774]\n",
      "[Epoch 7/200] [Batch 141/169] [D loss: 0.696557] [G loss: 0.691418]\n",
      "[Epoch 7/200] [Batch 142/169] [D loss: 0.695360] [G loss: 0.692922]\n",
      "[Epoch 7/200] [Batch 143/169] [D loss: 0.695420] [G loss: 0.692590]\n",
      "[Epoch 7/200] [Batch 144/169] [D loss: 0.695391] [G loss: 0.692229]\n",
      "[Epoch 7/200] [Batch 145/169] [D loss: 0.693858] [G loss: 0.692508]\n",
      "[Epoch 7/200] [Batch 146/169] [D loss: 0.694772] [G loss: 0.692242]\n",
      "[Epoch 7/200] [Batch 147/169] [D loss: 0.694802] [G loss: 0.691903]\n",
      "[Epoch 7/200] [Batch 148/169] [D loss: 0.694414] [G loss: 0.692799]\n",
      "[Epoch 7/200] [Batch 149/169] [D loss: 0.693634] [G loss: 0.693224]\n",
      "[Epoch 7/200] [Batch 150/169] [D loss: 0.693899] [G loss: 0.693298]\n",
      "[Epoch 7/200] [Batch 151/169] [D loss: 0.694025] [G loss: 0.693839]\n",
      "[Epoch 7/200] [Batch 152/169] [D loss: 0.693719] [G loss: 0.693876]\n",
      "[Epoch 7/200] [Batch 153/169] [D loss: 0.693735] [G loss: 0.693766]\n",
      "[Epoch 7/200] [Batch 154/169] [D loss: 0.693349] [G loss: 0.693064]\n",
      "[Epoch 7/200] [Batch 155/169] [D loss: 0.693618] [G loss: 0.694014]\n",
      "[Epoch 7/200] [Batch 156/169] [D loss: 0.693312] [G loss: 0.693742]\n",
      "[Epoch 7/200] [Batch 157/169] [D loss: 0.693437] [G loss: 0.693846]\n",
      "[Epoch 7/200] [Batch 158/169] [D loss: 0.693682] [G loss: 0.693494]\n",
      "[Epoch 7/200] [Batch 159/169] [D loss: 0.693300] [G loss: 0.693403]\n",
      "[Epoch 7/200] [Batch 160/169] [D loss: 0.693177] [G loss: 0.694748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 161/169] [D loss: 0.692696] [G loss: 0.693265]\n",
      "[Epoch 7/200] [Batch 162/169] [D loss: 0.692213] [G loss: 0.693658]\n",
      "[Epoch 7/200] [Batch 163/169] [D loss: 0.692798] [G loss: 0.693244]\n",
      "[Epoch 7/200] [Batch 164/169] [D loss: 0.692014] [G loss: 0.694733]\n",
      "[Epoch 7/200] [Batch 165/169] [D loss: 0.692639] [G loss: 0.693919]\n",
      "[Epoch 7/200] [Batch 166/169] [D loss: 0.692284] [G loss: 0.695526]\n",
      "[Epoch 7/200] [Batch 167/169] [D loss: 0.692128] [G loss: 0.694412]\n",
      "[Epoch 7/200] [Batch 168/169] [D loss: 0.692654] [G loss: 0.694759]\n",
      "[Epoch 8/200] [Batch 0/169] [D loss: 0.691927] [G loss: 0.694557]\n",
      "[Epoch 8/200] [Batch 1/169] [D loss: 0.692535] [G loss: 0.693339]\n",
      "[Epoch 8/200] [Batch 2/169] [D loss: 0.692806] [G loss: 0.694353]\n",
      "[Epoch 8/200] [Batch 3/169] [D loss: 0.692451] [G loss: 0.695025]\n",
      "[Epoch 8/200] [Batch 4/169] [D loss: 0.692240] [G loss: 0.694567]\n",
      "[Epoch 8/200] [Batch 5/169] [D loss: 0.692305] [G loss: 0.695027]\n",
      "[Epoch 8/200] [Batch 6/169] [D loss: 0.692335] [G loss: 0.694520]\n",
      "[Epoch 8/200] [Batch 7/169] [D loss: 0.691786] [G loss: 0.694465]\n",
      "[Epoch 8/200] [Batch 8/169] [D loss: 0.691932] [G loss: 0.694620]\n",
      "[Epoch 8/200] [Batch 9/169] [D loss: 0.691608] [G loss: 0.695559]\n",
      "[Epoch 8/200] [Batch 10/169] [D loss: 0.692235] [G loss: 0.695264]\n",
      "[Epoch 8/200] [Batch 11/169] [D loss: 0.692326] [G loss: 0.695896]\n",
      "[Epoch 8/200] [Batch 12/169] [D loss: 0.692911] [G loss: 0.696027]\n",
      "[Epoch 8/200] [Batch 13/169] [D loss: 0.692488] [G loss: 0.693079]\n",
      "[Epoch 8/200] [Batch 14/169] [D loss: 0.692824] [G loss: 0.693690]\n",
      "[Epoch 8/200] [Batch 15/169] [D loss: 0.692421] [G loss: 0.694650]\n",
      "[Epoch 8/200] [Batch 16/169] [D loss: 0.691289] [G loss: 0.694539]\n",
      "[Epoch 8/200] [Batch 17/169] [D loss: 0.691702] [G loss: 0.694971]\n",
      "[Epoch 8/200] [Batch 18/169] [D loss: 0.693012] [G loss: 0.693973]\n",
      "[Epoch 8/200] [Batch 19/169] [D loss: 0.692024] [G loss: 0.694618]\n",
      "[Epoch 8/200] [Batch 20/169] [D loss: 0.692317] [G loss: 0.694794]\n",
      "[Epoch 8/200] [Batch 21/169] [D loss: 0.693007] [G loss: 0.692555]\n",
      "[Epoch 8/200] [Batch 22/169] [D loss: 0.693036] [G loss: 0.694389]\n",
      "[Epoch 8/200] [Batch 23/169] [D loss: 0.692577] [G loss: 0.693366]\n",
      "[Epoch 8/200] [Batch 24/169] [D loss: 0.693136] [G loss: 0.693955]\n",
      "[Epoch 8/200] [Batch 25/169] [D loss: 0.692666] [G loss: 0.692928]\n",
      "[Epoch 8/200] [Batch 26/169] [D loss: 0.692669] [G loss: 0.692625]\n",
      "[Epoch 8/200] [Batch 27/169] [D loss: 0.692748] [G loss: 0.693430]\n",
      "[Epoch 8/200] [Batch 28/169] [D loss: 0.692327] [G loss: 0.693851]\n",
      "[Epoch 8/200] [Batch 29/169] [D loss: 0.693466] [G loss: 0.692937]\n",
      "[Epoch 8/200] [Batch 30/169] [D loss: 0.692073] [G loss: 0.692333]\n",
      "[Epoch 8/200] [Batch 31/169] [D loss: 0.692549] [G loss: 0.693760]\n",
      "[Epoch 8/200] [Batch 32/169] [D loss: 0.692848] [G loss: 0.694734]\n",
      "[Epoch 8/200] [Batch 33/169] [D loss: 0.693932] [G loss: 0.693811]\n",
      "[Epoch 8/200] [Batch 34/169] [D loss: 0.692514] [G loss: 0.693503]\n",
      "[Epoch 8/200] [Batch 35/169] [D loss: 0.693708] [G loss: 0.692547]\n",
      "[Epoch 8/200] [Batch 36/169] [D loss: 0.692914] [G loss: 0.692093]\n",
      "[Epoch 8/200] [Batch 37/169] [D loss: 0.694263] [G loss: 0.692451]\n",
      "[Epoch 8/200] [Batch 38/169] [D loss: 0.693425] [G loss: 0.693514]\n",
      "[Epoch 8/200] [Batch 39/169] [D loss: 0.693555] [G loss: 0.692554]\n",
      "[Epoch 8/200] [Batch 40/169] [D loss: 0.693494] [G loss: 0.692440]\n",
      "[Epoch 8/200] [Batch 41/169] [D loss: 0.693842] [G loss: 0.692295]\n",
      "[Epoch 8/200] [Batch 42/169] [D loss: 0.694393] [G loss: 0.692579]\n",
      "[Epoch 8/200] [Batch 43/169] [D loss: 0.693399] [G loss: 0.691977]\n",
      "[Epoch 8/200] [Batch 44/169] [D loss: 0.694559] [G loss: 0.690856]\n",
      "[Epoch 8/200] [Batch 45/169] [D loss: 0.694907] [G loss: 0.691622]\n",
      "[Epoch 8/200] [Batch 46/169] [D loss: 0.693902] [G loss: 0.692204]\n",
      "[Epoch 8/200] [Batch 47/169] [D loss: 0.694893] [G loss: 0.692271]\n",
      "[Epoch 8/200] [Batch 48/169] [D loss: 0.694177] [G loss: 0.691836]\n",
      "[Epoch 8/200] [Batch 49/169] [D loss: 0.694235] [G loss: 0.691900]\n",
      "[Epoch 8/200] [Batch 50/169] [D loss: 0.694000] [G loss: 0.691506]\n",
      "[Epoch 8/200] [Batch 51/169] [D loss: 0.693354] [G loss: 0.692815]\n",
      "[Epoch 8/200] [Batch 52/169] [D loss: 0.693983] [G loss: 0.693321]\n",
      "[Epoch 8/200] [Batch 53/169] [D loss: 0.693644] [G loss: 0.692794]\n",
      "[Epoch 8/200] [Batch 54/169] [D loss: 0.692860] [G loss: 0.692127]\n",
      "[Epoch 8/200] [Batch 55/169] [D loss: 0.692866] [G loss: 0.693933]\n",
      "[Epoch 8/200] [Batch 56/169] [D loss: 0.692806] [G loss: 0.694086]\n",
      "[Epoch 8/200] [Batch 57/169] [D loss: 0.692569] [G loss: 0.693998]\n",
      "[Epoch 8/200] [Batch 58/169] [D loss: 0.692432] [G loss: 0.693264]\n",
      "[Epoch 8/200] [Batch 59/169] [D loss: 0.692142] [G loss: 0.692815]\n",
      "[Epoch 8/200] [Batch 60/169] [D loss: 0.692276] [G loss: 0.693354]\n",
      "[Epoch 8/200] [Batch 61/169] [D loss: 0.692094] [G loss: 0.692938]\n",
      "[Epoch 8/200] [Batch 62/169] [D loss: 0.692498] [G loss: 0.693671]\n",
      "[Epoch 8/200] [Batch 63/169] [D loss: 0.692002] [G loss: 0.694542]\n",
      "[Epoch 8/200] [Batch 64/169] [D loss: 0.691584] [G loss: 0.694282]\n",
      "[Epoch 8/200] [Batch 65/169] [D loss: 0.691290] [G loss: 0.693964]\n",
      "[Epoch 8/200] [Batch 66/169] [D loss: 0.692085] [G loss: 0.693974]\n",
      "[Epoch 8/200] [Batch 67/169] [D loss: 0.691868] [G loss: 0.694349]\n",
      "[Epoch 8/200] [Batch 68/169] [D loss: 0.691045] [G loss: 0.694788]\n",
      "[Epoch 8/200] [Batch 69/169] [D loss: 0.691408] [G loss: 0.693825]\n",
      "[Epoch 8/200] [Batch 70/169] [D loss: 0.691337] [G loss: 0.695516]\n",
      "[Epoch 8/200] [Batch 71/169] [D loss: 0.689688] [G loss: 0.695073]\n",
      "[Epoch 8/200] [Batch 72/169] [D loss: 0.690641] [G loss: 0.694731]\n",
      "[Epoch 8/200] [Batch 73/169] [D loss: 0.692254] [G loss: 0.695374]\n",
      "[Epoch 8/200] [Batch 74/169] [D loss: 0.691054] [G loss: 0.693508]\n",
      "[Epoch 8/200] [Batch 75/169] [D loss: 0.691206] [G loss: 0.694432]\n",
      "[Epoch 8/200] [Batch 76/169] [D loss: 0.692318] [G loss: 0.695305]\n",
      "[Epoch 8/200] [Batch 77/169] [D loss: 0.692746] [G loss: 0.693550]\n",
      "[Epoch 8/200] [Batch 78/169] [D loss: 0.691938] [G loss: 0.694467]\n",
      "[Epoch 8/200] [Batch 79/169] [D loss: 0.692440] [G loss: 0.693510]\n",
      "[Epoch 8/200] [Batch 80/169] [D loss: 0.691690] [G loss: 0.695599]\n",
      "[Epoch 8/200] [Batch 81/169] [D loss: 0.693370] [G loss: 0.692997]\n",
      "[Epoch 8/200] [Batch 82/169] [D loss: 0.692108] [G loss: 0.693804]\n",
      "[Epoch 8/200] [Batch 83/169] [D loss: 0.691703] [G loss: 0.693366]\n",
      "[Epoch 8/200] [Batch 84/169] [D loss: 0.692139] [G loss: 0.692801]\n",
      "[Epoch 8/200] [Batch 85/169] [D loss: 0.693987] [G loss: 0.692166]\n",
      "[Epoch 8/200] [Batch 86/169] [D loss: 0.693486] [G loss: 0.694409]\n",
      "[Epoch 8/200] [Batch 87/169] [D loss: 0.693450] [G loss: 0.693502]\n",
      "[Epoch 8/200] [Batch 88/169] [D loss: 0.693497] [G loss: 0.693972]\n",
      "[Epoch 8/200] [Batch 89/169] [D loss: 0.693353] [G loss: 0.694413]\n",
      "[Epoch 8/200] [Batch 90/169] [D loss: 0.693106] [G loss: 0.691045]\n",
      "[Epoch 8/200] [Batch 91/169] [D loss: 0.693827] [G loss: 0.694020]\n",
      "[Epoch 8/200] [Batch 92/169] [D loss: 0.693104] [G loss: 0.694900]\n",
      "[Epoch 8/200] [Batch 93/169] [D loss: 0.693850] [G loss: 0.693420]\n",
      "[Epoch 8/200] [Batch 94/169] [D loss: 0.694159] [G loss: 0.693564]\n",
      "[Epoch 8/200] [Batch 95/169] [D loss: 0.693195] [G loss: 0.692216]\n",
      "[Epoch 8/200] [Batch 96/169] [D loss: 0.694258] [G loss: 0.692854]\n",
      "[Epoch 8/200] [Batch 97/169] [D loss: 0.693820] [G loss: 0.695502]\n",
      "[Epoch 8/200] [Batch 98/169] [D loss: 0.693460] [G loss: 0.691497]\n",
      "[Epoch 8/200] [Batch 99/169] [D loss: 0.694530] [G loss: 0.694901]\n",
      "[Epoch 8/200] [Batch 100/169] [D loss: 0.693509] [G loss: 0.694630]\n",
      "[Epoch 8/200] [Batch 101/169] [D loss: 0.692937] [G loss: 0.695005]\n",
      "[Epoch 8/200] [Batch 102/169] [D loss: 0.693498] [G loss: 0.693513]\n",
      "[Epoch 8/200] [Batch 103/169] [D loss: 0.693080] [G loss: 0.693054]\n",
      "[Epoch 8/200] [Batch 104/169] [D loss: 0.693157] [G loss: 0.693546]\n",
      "[Epoch 8/200] [Batch 105/169] [D loss: 0.693036] [G loss: 0.694317]\n",
      "[Epoch 8/200] [Batch 106/169] [D loss: 0.693379] [G loss: 0.694509]\n",
      "[Epoch 8/200] [Batch 107/169] [D loss: 0.693651] [G loss: 0.696266]\n",
      "[Epoch 8/200] [Batch 108/169] [D loss: 0.693313] [G loss: 0.693383]\n",
      "[Epoch 8/200] [Batch 109/169] [D loss: 0.693081] [G loss: 0.695352]\n",
      "[Epoch 8/200] [Batch 110/169] [D loss: 0.692830] [G loss: 0.693280]\n",
      "[Epoch 8/200] [Batch 111/169] [D loss: 0.693000] [G loss: 0.695304]\n",
      "[Epoch 8/200] [Batch 112/169] [D loss: 0.693625] [G loss: 0.693772]\n",
      "[Epoch 8/200] [Batch 113/169] [D loss: 0.692054] [G loss: 0.694057]\n",
      "[Epoch 8/200] [Batch 114/169] [D loss: 0.692702] [G loss: 0.695336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 115/169] [D loss: 0.692587] [G loss: 0.694933]\n",
      "[Epoch 8/200] [Batch 116/169] [D loss: 0.692521] [G loss: 0.695189]\n",
      "[Epoch 8/200] [Batch 117/169] [D loss: 0.692510] [G loss: 0.694777]\n",
      "[Epoch 8/200] [Batch 118/169] [D loss: 0.692177] [G loss: 0.695858]\n",
      "[Epoch 8/200] [Batch 119/169] [D loss: 0.691837] [G loss: 0.695078]\n",
      "[Epoch 8/200] [Batch 120/169] [D loss: 0.692571] [G loss: 0.695943]\n",
      "[Epoch 8/200] [Batch 121/169] [D loss: 0.691007] [G loss: 0.695717]\n",
      "[Epoch 8/200] [Batch 122/169] [D loss: 0.692205] [G loss: 0.694842]\n",
      "[Epoch 8/200] [Batch 123/169] [D loss: 0.692328] [G loss: 0.696200]\n",
      "[Epoch 8/200] [Batch 124/169] [D loss: 0.691409] [G loss: 0.695059]\n",
      "[Epoch 8/200] [Batch 125/169] [D loss: 0.690444] [G loss: 0.695113]\n",
      "[Epoch 8/200] [Batch 126/169] [D loss: 0.690496] [G loss: 0.696669]\n",
      "[Epoch 8/200] [Batch 127/169] [D loss: 0.690683] [G loss: 0.695282]\n",
      "[Epoch 8/200] [Batch 128/169] [D loss: 0.691061] [G loss: 0.695819]\n",
      "[Epoch 8/200] [Batch 129/169] [D loss: 0.690305] [G loss: 0.695969]\n",
      "[Epoch 8/200] [Batch 130/169] [D loss: 0.689290] [G loss: 0.698231]\n",
      "[Epoch 8/200] [Batch 131/169] [D loss: 0.690253] [G loss: 0.694684]\n",
      "[Epoch 8/200] [Batch 132/169] [D loss: 0.691641] [G loss: 0.694278]\n",
      "[Epoch 8/200] [Batch 133/169] [D loss: 0.690633] [G loss: 0.696805]\n",
      "[Epoch 8/200] [Batch 134/169] [D loss: 0.689891] [G loss: 0.699365]\n",
      "[Epoch 8/200] [Batch 135/169] [D loss: 0.690791] [G loss: 0.695612]\n",
      "[Epoch 8/200] [Batch 136/169] [D loss: 0.692247] [G loss: 0.692229]\n",
      "[Epoch 8/200] [Batch 137/169] [D loss: 0.690704] [G loss: 0.695502]\n",
      "[Epoch 8/200] [Batch 138/169] [D loss: 0.691464] [G loss: 0.695295]\n",
      "[Epoch 8/200] [Batch 139/169] [D loss: 0.691260] [G loss: 0.693757]\n",
      "[Epoch 8/200] [Batch 140/169] [D loss: 0.692305] [G loss: 0.693118]\n",
      "[Epoch 8/200] [Batch 141/169] [D loss: 0.691655] [G loss: 0.692018]\n",
      "[Epoch 8/200] [Batch 142/169] [D loss: 0.692571] [G loss: 0.692302]\n",
      "[Epoch 8/200] [Batch 143/169] [D loss: 0.692868] [G loss: 0.693509]\n",
      "[Epoch 8/200] [Batch 144/169] [D loss: 0.692958] [G loss: 0.691429]\n",
      "[Epoch 8/200] [Batch 145/169] [D loss: 0.692469] [G loss: 0.693653]\n",
      "[Epoch 8/200] [Batch 146/169] [D loss: 0.695085] [G loss: 0.691714]\n",
      "[Epoch 8/200] [Batch 147/169] [D loss: 0.694700] [G loss: 0.690288]\n",
      "[Epoch 8/200] [Batch 148/169] [D loss: 0.694879] [G loss: 0.689204]\n",
      "[Epoch 8/200] [Batch 149/169] [D loss: 0.693077] [G loss: 0.694323]\n",
      "[Epoch 8/200] [Batch 150/169] [D loss: 0.692967] [G loss: 0.692789]\n",
      "[Epoch 8/200] [Batch 151/169] [D loss: 0.693702] [G loss: 0.692017]\n",
      "[Epoch 8/200] [Batch 152/169] [D loss: 0.693496] [G loss: 0.692174]\n",
      "[Epoch 8/200] [Batch 153/169] [D loss: 0.693714] [G loss: 0.692397]\n",
      "[Epoch 8/200] [Batch 154/169] [D loss: 0.692163] [G loss: 0.693705]\n",
      "[Epoch 8/200] [Batch 155/169] [D loss: 0.693092] [G loss: 0.694688]\n",
      "[Epoch 8/200] [Batch 156/169] [D loss: 0.691830] [G loss: 0.694123]\n",
      "[Epoch 8/200] [Batch 157/169] [D loss: 0.692538] [G loss: 0.694793]\n",
      "[Epoch 8/200] [Batch 158/169] [D loss: 0.691617] [G loss: 0.694426]\n",
      "[Epoch 8/200] [Batch 159/169] [D loss: 0.692330] [G loss: 0.693976]\n",
      "[Epoch 8/200] [Batch 160/169] [D loss: 0.691788] [G loss: 0.696622]\n",
      "[Epoch 8/200] [Batch 161/169] [D loss: 0.691048] [G loss: 0.697433]\n",
      "[Epoch 8/200] [Batch 162/169] [D loss: 0.690379] [G loss: 0.696878]\n",
      "[Epoch 8/200] [Batch 163/169] [D loss: 0.691692] [G loss: 0.693680]\n",
      "[Epoch 8/200] [Batch 164/169] [D loss: 0.690230] [G loss: 0.697351]\n",
      "[Epoch 8/200] [Batch 165/169] [D loss: 0.692470] [G loss: 0.694828]\n",
      "[Epoch 8/200] [Batch 166/169] [D loss: 0.690264] [G loss: 0.695691]\n",
      "[Epoch 8/200] [Batch 167/169] [D loss: 0.691345] [G loss: 0.696042]\n",
      "[Epoch 8/200] [Batch 168/169] [D loss: 0.689365] [G loss: 0.696685]\n",
      "[Epoch 9/200] [Batch 0/169] [D loss: 0.691334] [G loss: 0.695527]\n",
      "[Epoch 9/200] [Batch 1/169] [D loss: 0.691491] [G loss: 0.692276]\n",
      "[Epoch 9/200] [Batch 2/169] [D loss: 0.693221] [G loss: 0.692467]\n",
      "[Epoch 9/200] [Batch 3/169] [D loss: 0.692467] [G loss: 0.693027]\n",
      "[Epoch 9/200] [Batch 4/169] [D loss: 0.692748] [G loss: 0.692126]\n",
      "[Epoch 9/200] [Batch 5/169] [D loss: 0.694097] [G loss: 0.691707]\n",
      "[Epoch 9/200] [Batch 6/169] [D loss: 0.692774] [G loss: 0.693667]\n",
      "[Epoch 9/200] [Batch 7/169] [D loss: 0.695627] [G loss: 0.690296]\n",
      "[Epoch 9/200] [Batch 8/169] [D loss: 0.693758] [G loss: 0.693946]\n",
      "[Epoch 9/200] [Batch 9/169] [D loss: 0.694507] [G loss: 0.692097]\n",
      "[Epoch 9/200] [Batch 10/169] [D loss: 0.695105] [G loss: 0.692978]\n",
      "[Epoch 9/200] [Batch 11/169] [D loss: 0.695551] [G loss: 0.693590]\n",
      "[Epoch 9/200] [Batch 12/169] [D loss: 0.694202] [G loss: 0.693007]\n",
      "[Epoch 9/200] [Batch 13/169] [D loss: 0.694566] [G loss: 0.693555]\n",
      "[Epoch 9/200] [Batch 14/169] [D loss: 0.693723] [G loss: 0.693693]\n",
      "[Epoch 9/200] [Batch 15/169] [D loss: 0.694951] [G loss: 0.693847]\n",
      "[Epoch 9/200] [Batch 16/169] [D loss: 0.693166] [G loss: 0.692923]\n",
      "[Epoch 9/200] [Batch 17/169] [D loss: 0.692787] [G loss: 0.693300]\n",
      "[Epoch 9/200] [Batch 18/169] [D loss: 0.692445] [G loss: 0.693741]\n",
      "[Epoch 9/200] [Batch 19/169] [D loss: 0.692624] [G loss: 0.693912]\n",
      "[Epoch 9/200] [Batch 20/169] [D loss: 0.692342] [G loss: 0.693259]\n",
      "[Epoch 9/200] [Batch 21/169] [D loss: 0.692269] [G loss: 0.696001]\n",
      "[Epoch 9/200] [Batch 22/169] [D loss: 0.692441] [G loss: 0.696105]\n",
      "[Epoch 9/200] [Batch 23/169] [D loss: 0.692257] [G loss: 0.694805]\n",
      "[Epoch 9/200] [Batch 24/169] [D loss: 0.692325] [G loss: 0.692696]\n",
      "[Epoch 9/200] [Batch 25/169] [D loss: 0.693001] [G loss: 0.693551]\n",
      "[Epoch 9/200] [Batch 26/169] [D loss: 0.692927] [G loss: 0.694860]\n",
      "[Epoch 9/200] [Batch 27/169] [D loss: 0.692199] [G loss: 0.693804]\n",
      "[Epoch 9/200] [Batch 28/169] [D loss: 0.692729] [G loss: 0.693792]\n",
      "[Epoch 9/200] [Batch 29/169] [D loss: 0.692447] [G loss: 0.694678]\n",
      "[Epoch 9/200] [Batch 30/169] [D loss: 0.694065] [G loss: 0.691630]\n",
      "[Epoch 9/200] [Batch 31/169] [D loss: 0.694020] [G loss: 0.694058]\n",
      "[Epoch 9/200] [Batch 32/169] [D loss: 0.693446] [G loss: 0.690737]\n",
      "[Epoch 9/200] [Batch 33/169] [D loss: 0.693763] [G loss: 0.690434]\n",
      "[Epoch 9/200] [Batch 34/169] [D loss: 0.694379] [G loss: 0.692553]\n",
      "[Epoch 9/200] [Batch 35/169] [D loss: 0.693507] [G loss: 0.690793]\n",
      "[Epoch 9/200] [Batch 36/169] [D loss: 0.694016] [G loss: 0.693057]\n",
      "[Epoch 9/200] [Batch 37/169] [D loss: 0.693101] [G loss: 0.692574]\n",
      "[Epoch 9/200] [Batch 38/169] [D loss: 0.693528] [G loss: 0.689857]\n",
      "[Epoch 9/200] [Batch 39/169] [D loss: 0.693945] [G loss: 0.691179]\n",
      "[Epoch 9/200] [Batch 40/169] [D loss: 0.693584] [G loss: 0.692416]\n",
      "[Epoch 9/200] [Batch 41/169] [D loss: 0.692726] [G loss: 0.692865]\n",
      "[Epoch 9/200] [Batch 42/169] [D loss: 0.692976] [G loss: 0.693006]\n",
      "[Epoch 9/200] [Batch 43/169] [D loss: 0.693384] [G loss: 0.693268]\n",
      "[Epoch 9/200] [Batch 44/169] [D loss: 0.692478] [G loss: 0.694156]\n",
      "[Epoch 9/200] [Batch 45/169] [D loss: 0.692234] [G loss: 0.693141]\n",
      "[Epoch 9/200] [Batch 46/169] [D loss: 0.692987] [G loss: 0.693817]\n",
      "[Epoch 9/200] [Batch 47/169] [D loss: 0.692119] [G loss: 0.693673]\n",
      "[Epoch 9/200] [Batch 48/169] [D loss: 0.692502] [G loss: 0.693477]\n",
      "[Epoch 9/200] [Batch 49/169] [D loss: 0.692193] [G loss: 0.693977]\n",
      "[Epoch 9/200] [Batch 50/169] [D loss: 0.692250] [G loss: 0.694596]\n",
      "[Epoch 9/200] [Batch 51/169] [D loss: 0.692123] [G loss: 0.694066]\n",
      "[Epoch 9/200] [Batch 52/169] [D loss: 0.692333] [G loss: 0.693705]\n",
      "[Epoch 9/200] [Batch 53/169] [D loss: 0.692069] [G loss: 0.694007]\n",
      "[Epoch 9/200] [Batch 54/169] [D loss: 0.692411] [G loss: 0.695197]\n",
      "[Epoch 9/200] [Batch 55/169] [D loss: 0.692958] [G loss: 0.692759]\n",
      "[Epoch 9/200] [Batch 56/169] [D loss: 0.692448] [G loss: 0.693458]\n",
      "[Epoch 9/200] [Batch 57/169] [D loss: 0.692541] [G loss: 0.694725]\n",
      "[Epoch 9/200] [Batch 58/169] [D loss: 0.691930] [G loss: 0.694989]\n",
      "[Epoch 9/200] [Batch 59/169] [D loss: 0.692942] [G loss: 0.693706]\n",
      "[Epoch 9/200] [Batch 60/169] [D loss: 0.693577] [G loss: 0.693926]\n",
      "[Epoch 9/200] [Batch 61/169] [D loss: 0.694203] [G loss: 0.693044]\n",
      "[Epoch 9/200] [Batch 62/169] [D loss: 0.692925] [G loss: 0.692870]\n",
      "[Epoch 9/200] [Batch 63/169] [D loss: 0.693481] [G loss: 0.693661]\n",
      "[Epoch 9/200] [Batch 64/169] [D loss: 0.693769] [G loss: 0.694128]\n",
      "[Epoch 9/200] [Batch 65/169] [D loss: 0.693603] [G loss: 0.693709]\n",
      "[Epoch 9/200] [Batch 66/169] [D loss: 0.692239] [G loss: 0.695326]\n",
      "[Epoch 9/200] [Batch 67/169] [D loss: 0.693254] [G loss: 0.692441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 68/169] [D loss: 0.692836] [G loss: 0.693167]\n",
      "[Epoch 9/200] [Batch 69/169] [D loss: 0.692997] [G loss: 0.693633]\n",
      "[Epoch 9/200] [Batch 70/169] [D loss: 0.693185] [G loss: 0.694754]\n",
      "[Epoch 9/200] [Batch 71/169] [D loss: 0.693711] [G loss: 0.693984]\n",
      "[Epoch 9/200] [Batch 72/169] [D loss: 0.692741] [G loss: 0.694519]\n",
      "[Epoch 9/200] [Batch 73/169] [D loss: 0.692324] [G loss: 0.695331]\n",
      "[Epoch 9/200] [Batch 74/169] [D loss: 0.692351] [G loss: 0.694250]\n",
      "[Epoch 9/200] [Batch 75/169] [D loss: 0.691580] [G loss: 0.696133]\n",
      "[Epoch 9/200] [Batch 76/169] [D loss: 0.692803] [G loss: 0.694388]\n",
      "[Epoch 9/200] [Batch 77/169] [D loss: 0.691110] [G loss: 0.695896]\n",
      "[Epoch 9/200] [Batch 78/169] [D loss: 0.691657] [G loss: 0.696686]\n",
      "[Epoch 9/200] [Batch 79/169] [D loss: 0.692160] [G loss: 0.694918]\n",
      "[Epoch 9/200] [Batch 80/169] [D loss: 0.691595] [G loss: 0.696220]\n",
      "[Epoch 9/200] [Batch 81/169] [D loss: 0.691744] [G loss: 0.693335]\n",
      "[Epoch 9/200] [Batch 82/169] [D loss: 0.692434] [G loss: 0.693452]\n",
      "[Epoch 9/200] [Batch 83/169] [D loss: 0.692153] [G loss: 0.694047]\n",
      "[Epoch 9/200] [Batch 84/169] [D loss: 0.692338] [G loss: 0.693257]\n",
      "[Epoch 9/200] [Batch 85/169] [D loss: 0.693031] [G loss: 0.693003]\n",
      "[Epoch 9/200] [Batch 86/169] [D loss: 0.692993] [G loss: 0.692901]\n",
      "[Epoch 9/200] [Batch 87/169] [D loss: 0.693951] [G loss: 0.693339]\n",
      "[Epoch 9/200] [Batch 88/169] [D loss: 0.692968] [G loss: 0.692673]\n",
      "[Epoch 9/200] [Batch 89/169] [D loss: 0.693150] [G loss: 0.691924]\n",
      "[Epoch 9/200] [Batch 90/169] [D loss: 0.693276] [G loss: 0.692263]\n",
      "[Epoch 9/200] [Batch 91/169] [D loss: 0.693008] [G loss: 0.690510]\n",
      "[Epoch 9/200] [Batch 92/169] [D loss: 0.693867] [G loss: 0.689927]\n",
      "[Epoch 9/200] [Batch 93/169] [D loss: 0.692723] [G loss: 0.692398]\n",
      "[Epoch 9/200] [Batch 94/169] [D loss: 0.693048] [G loss: 0.693445]\n",
      "[Epoch 9/200] [Batch 95/169] [D loss: 0.692908] [G loss: 0.694553]\n",
      "[Epoch 9/200] [Batch 96/169] [D loss: 0.693565] [G loss: 0.694261]\n",
      "[Epoch 9/200] [Batch 97/169] [D loss: 0.692112] [G loss: 0.695264]\n",
      "[Epoch 9/200] [Batch 98/169] [D loss: 0.692733] [G loss: 0.694470]\n",
      "[Epoch 9/200] [Batch 99/169] [D loss: 0.692910] [G loss: 0.696095]\n",
      "[Epoch 9/200] [Batch 100/169] [D loss: 0.692459] [G loss: 0.693365]\n",
      "[Epoch 9/200] [Batch 101/169] [D loss: 0.691853] [G loss: 0.694581]\n",
      "[Epoch 9/200] [Batch 102/169] [D loss: 0.692128] [G loss: 0.693619]\n",
      "[Epoch 9/200] [Batch 103/169] [D loss: 0.692238] [G loss: 0.696404]\n",
      "[Epoch 9/200] [Batch 104/169] [D loss: 0.692810] [G loss: 0.694907]\n",
      "[Epoch 9/200] [Batch 105/169] [D loss: 0.692711] [G loss: 0.692617]\n",
      "[Epoch 9/200] [Batch 106/169] [D loss: 0.693064] [G loss: 0.694300]\n",
      "[Epoch 9/200] [Batch 107/169] [D loss: 0.693589] [G loss: 0.691445]\n",
      "[Epoch 9/200] [Batch 108/169] [D loss: 0.692855] [G loss: 0.693494]\n",
      "[Epoch 9/200] [Batch 109/169] [D loss: 0.694649] [G loss: 0.693303]\n",
      "[Epoch 9/200] [Batch 110/169] [D loss: 0.693577] [G loss: 0.693533]\n",
      "[Epoch 9/200] [Batch 111/169] [D loss: 0.693365] [G loss: 0.692493]\n",
      "[Epoch 9/200] [Batch 112/169] [D loss: 0.692977] [G loss: 0.693942]\n",
      "[Epoch 9/200] [Batch 113/169] [D loss: 0.694324] [G loss: 0.693284]\n",
      "[Epoch 9/200] [Batch 114/169] [D loss: 0.693412] [G loss: 0.692351]\n",
      "[Epoch 9/200] [Batch 115/169] [D loss: 0.694545] [G loss: 0.693584]\n",
      "[Epoch 9/200] [Batch 116/169] [D loss: 0.694348] [G loss: 0.693614]\n",
      "[Epoch 9/200] [Batch 117/169] [D loss: 0.694669] [G loss: 0.693411]\n",
      "[Epoch 9/200] [Batch 118/169] [D loss: 0.694525] [G loss: 0.691605]\n",
      "[Epoch 9/200] [Batch 119/169] [D loss: 0.693284] [G loss: 0.692711]\n",
      "[Epoch 9/200] [Batch 120/169] [D loss: 0.693036] [G loss: 0.693324]\n",
      "[Epoch 9/200] [Batch 121/169] [D loss: 0.693072] [G loss: 0.693658]\n",
      "[Epoch 9/200] [Batch 122/169] [D loss: 0.692609] [G loss: 0.694201]\n",
      "[Epoch 9/200] [Batch 123/169] [D loss: 0.693128] [G loss: 0.695105]\n",
      "[Epoch 9/200] [Batch 124/169] [D loss: 0.692447] [G loss: 0.694197]\n",
      "[Epoch 9/200] [Batch 125/169] [D loss: 0.691834] [G loss: 0.693578]\n",
      "[Epoch 9/200] [Batch 126/169] [D loss: 0.692221] [G loss: 0.694167]\n",
      "[Epoch 9/200] [Batch 127/169] [D loss: 0.692392] [G loss: 0.691943]\n",
      "[Epoch 9/200] [Batch 128/169] [D loss: 0.691644] [G loss: 0.693170]\n",
      "[Epoch 9/200] [Batch 129/169] [D loss: 0.690943] [G loss: 0.694776]\n",
      "[Epoch 9/200] [Batch 130/169] [D loss: 0.691572] [G loss: 0.695517]\n",
      "[Epoch 9/200] [Batch 131/169] [D loss: 0.691537] [G loss: 0.693863]\n",
      "[Epoch 9/200] [Batch 132/169] [D loss: 0.691546] [G loss: 0.692900]\n",
      "[Epoch 9/200] [Batch 133/169] [D loss: 0.692160] [G loss: 0.694900]\n",
      "[Epoch 9/200] [Batch 134/169] [D loss: 0.691912] [G loss: 0.692623]\n",
      "[Epoch 9/200] [Batch 135/169] [D loss: 0.691562] [G loss: 0.692817]\n",
      "[Epoch 9/200] [Batch 136/169] [D loss: 0.692905] [G loss: 0.692682]\n",
      "[Epoch 9/200] [Batch 137/169] [D loss: 0.692003] [G loss: 0.694231]\n",
      "[Epoch 9/200] [Batch 138/169] [D loss: 0.693581] [G loss: 0.694846]\n",
      "[Epoch 9/200] [Batch 139/169] [D loss: 0.692913] [G loss: 0.695428]\n",
      "[Epoch 9/200] [Batch 140/169] [D loss: 0.692561] [G loss: 0.693795]\n",
      "[Epoch 9/200] [Batch 141/169] [D loss: 0.692052] [G loss: 0.693641]\n",
      "[Epoch 9/200] [Batch 142/169] [D loss: 0.692641] [G loss: 0.693466]\n",
      "[Epoch 9/200] [Batch 143/169] [D loss: 0.691695] [G loss: 0.694556]\n",
      "[Epoch 9/200] [Batch 144/169] [D loss: 0.692605] [G loss: 0.692865]\n",
      "[Epoch 9/200] [Batch 145/169] [D loss: 0.693096] [G loss: 0.695113]\n",
      "[Epoch 9/200] [Batch 146/169] [D loss: 0.692845] [G loss: 0.694452]\n",
      "[Epoch 9/200] [Batch 147/169] [D loss: 0.691996] [G loss: 0.694792]\n",
      "[Epoch 9/200] [Batch 148/169] [D loss: 0.691798] [G loss: 0.696393]\n",
      "[Epoch 9/200] [Batch 149/169] [D loss: 0.691374] [G loss: 0.693361]\n",
      "[Epoch 9/200] [Batch 150/169] [D loss: 0.692530] [G loss: 0.695327]\n",
      "[Epoch 9/200] [Batch 151/169] [D loss: 0.690808] [G loss: 0.695095]\n",
      "[Epoch 9/200] [Batch 152/169] [D loss: 0.690708] [G loss: 0.695462]\n",
      "[Epoch 9/200] [Batch 153/169] [D loss: 0.690098] [G loss: 0.697018]\n",
      "[Epoch 9/200] [Batch 154/169] [D loss: 0.690296] [G loss: 0.695428]\n",
      "[Epoch 9/200] [Batch 155/169] [D loss: 0.690250] [G loss: 0.697727]\n",
      "[Epoch 9/200] [Batch 156/169] [D loss: 0.689448] [G loss: 0.696063]\n",
      "[Epoch 9/200] [Batch 157/169] [D loss: 0.690610] [G loss: 0.694469]\n",
      "[Epoch 9/200] [Batch 158/169] [D loss: 0.690420] [G loss: 0.696297]\n",
      "[Epoch 9/200] [Batch 159/169] [D loss: 0.690682] [G loss: 0.696502]\n",
      "[Epoch 9/200] [Batch 160/169] [D loss: 0.692222] [G loss: 0.695499]\n",
      "[Epoch 9/200] [Batch 161/169] [D loss: 0.691766] [G loss: 0.694315]\n",
      "[Epoch 9/200] [Batch 162/169] [D loss: 0.693483] [G loss: 0.691791]\n",
      "[Epoch 9/200] [Batch 163/169] [D loss: 0.692614] [G loss: 0.691874]\n",
      "[Epoch 9/200] [Batch 164/169] [D loss: 0.694109] [G loss: 0.689547]\n",
      "[Epoch 9/200] [Batch 165/169] [D loss: 0.694673] [G loss: 0.689915]\n",
      "[Epoch 9/200] [Batch 166/169] [D loss: 0.695343] [G loss: 0.688982]\n",
      "[Epoch 9/200] [Batch 167/169] [D loss: 0.695209] [G loss: 0.690452]\n",
      "[Epoch 9/200] [Batch 168/169] [D loss: 0.695851] [G loss: 0.690922]\n",
      "[Epoch 10/200] [Batch 0/169] [D loss: 0.694564] [G loss: 0.693851]\n",
      "[Epoch 10/200] [Batch 1/169] [D loss: 0.694572] [G loss: 0.693839]\n",
      "[Epoch 10/200] [Batch 2/169] [D loss: 0.693482] [G loss: 0.693564]\n",
      "[Epoch 10/200] [Batch 3/169] [D loss: 0.693049] [G loss: 0.694856]\n",
      "[Epoch 10/200] [Batch 4/169] [D loss: 0.693293] [G loss: 0.693514]\n",
      "[Epoch 10/200] [Batch 5/169] [D loss: 0.693577] [G loss: 0.693891]\n",
      "[Epoch 10/200] [Batch 6/169] [D loss: 0.691732] [G loss: 0.695293]\n",
      "[Epoch 10/200] [Batch 7/169] [D loss: 0.692143] [G loss: 0.695564]\n",
      "[Epoch 10/200] [Batch 8/169] [D loss: 0.691753] [G loss: 0.694650]\n",
      "[Epoch 10/200] [Batch 9/169] [D loss: 0.690482] [G loss: 0.697283]\n",
      "[Epoch 10/200] [Batch 10/169] [D loss: 0.691470] [G loss: 0.695157]\n",
      "[Epoch 10/200] [Batch 11/169] [D loss: 0.690885] [G loss: 0.695476]\n",
      "[Epoch 10/200] [Batch 12/169] [D loss: 0.691854] [G loss: 0.693613]\n",
      "[Epoch 10/200] [Batch 13/169] [D loss: 0.692423] [G loss: 0.693543]\n",
      "[Epoch 10/200] [Batch 14/169] [D loss: 0.691192] [G loss: 0.692753]\n",
      "[Epoch 10/200] [Batch 15/169] [D loss: 0.692629] [G loss: 0.692055]\n",
      "[Epoch 10/200] [Batch 16/169] [D loss: 0.694259] [G loss: 0.691697]\n",
      "[Epoch 10/200] [Batch 17/169] [D loss: 0.694594] [G loss: 0.692494]\n",
      "[Epoch 10/200] [Batch 18/169] [D loss: 0.694917] [G loss: 0.691761]\n",
      "[Epoch 10/200] [Batch 19/169] [D loss: 0.694880] [G loss: 0.690792]\n",
      "[Epoch 10/200] [Batch 20/169] [D loss: 0.694936] [G loss: 0.690677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 21/169] [D loss: 0.695112] [G loss: 0.691143]\n",
      "[Epoch 10/200] [Batch 22/169] [D loss: 0.695758] [G loss: 0.690912]\n",
      "[Epoch 10/200] [Batch 23/169] [D loss: 0.695093] [G loss: 0.691667]\n",
      "[Epoch 10/200] [Batch 24/169] [D loss: 0.693932] [G loss: 0.694798]\n",
      "[Epoch 10/200] [Batch 25/169] [D loss: 0.693580] [G loss: 0.693805]\n",
      "[Epoch 10/200] [Batch 26/169] [D loss: 0.693389] [G loss: 0.694026]\n",
      "[Epoch 10/200] [Batch 27/169] [D loss: 0.693531] [G loss: 0.692661]\n",
      "[Epoch 10/200] [Batch 28/169] [D loss: 0.693546] [G loss: 0.693783]\n",
      "[Epoch 10/200] [Batch 29/169] [D loss: 0.692769] [G loss: 0.695017]\n",
      "[Epoch 10/200] [Batch 30/169] [D loss: 0.691879] [G loss: 0.695374]\n",
      "[Epoch 10/200] [Batch 31/169] [D loss: 0.692376] [G loss: 0.695277]\n",
      "[Epoch 10/200] [Batch 32/169] [D loss: 0.691715] [G loss: 0.696242]\n",
      "[Epoch 10/200] [Batch 33/169] [D loss: 0.691045] [G loss: 0.695577]\n",
      "[Epoch 10/200] [Batch 34/169] [D loss: 0.691398] [G loss: 0.694483]\n",
      "[Epoch 10/200] [Batch 35/169] [D loss: 0.692002] [G loss: 0.695431]\n",
      "[Epoch 10/200] [Batch 36/169] [D loss: 0.691203] [G loss: 0.693818]\n",
      "[Epoch 10/200] [Batch 37/169] [D loss: 0.691662] [G loss: 0.692917]\n",
      "[Epoch 10/200] [Batch 38/169] [D loss: 0.693345] [G loss: 0.693097]\n",
      "[Epoch 10/200] [Batch 39/169] [D loss: 0.692470] [G loss: 0.693951]\n",
      "[Epoch 10/200] [Batch 40/169] [D loss: 0.693559] [G loss: 0.693477]\n",
      "[Epoch 10/200] [Batch 41/169] [D loss: 0.693585] [G loss: 0.691817]\n",
      "[Epoch 10/200] [Batch 42/169] [D loss: 0.693230] [G loss: 0.693472]\n",
      "[Epoch 10/200] [Batch 43/169] [D loss: 0.694439] [G loss: 0.692770]\n",
      "[Epoch 10/200] [Batch 44/169] [D loss: 0.694002] [G loss: 0.691290]\n",
      "[Epoch 10/200] [Batch 45/169] [D loss: 0.695121] [G loss: 0.693129]\n",
      "[Epoch 10/200] [Batch 46/169] [D loss: 0.693993] [G loss: 0.692989]\n",
      "[Epoch 10/200] [Batch 47/169] [D loss: 0.694308] [G loss: 0.693877]\n",
      "[Epoch 10/200] [Batch 48/169] [D loss: 0.694329] [G loss: 0.692928]\n",
      "[Epoch 10/200] [Batch 49/169] [D loss: 0.693605] [G loss: 0.694970]\n",
      "[Epoch 10/200] [Batch 50/169] [D loss: 0.693736] [G loss: 0.694137]\n",
      "[Epoch 10/200] [Batch 51/169] [D loss: 0.693581] [G loss: 0.693485]\n",
      "[Epoch 10/200] [Batch 52/169] [D loss: 0.693587] [G loss: 0.693434]\n",
      "[Epoch 10/200] [Batch 53/169] [D loss: 0.693640] [G loss: 0.694501]\n",
      "[Epoch 10/200] [Batch 54/169] [D loss: 0.692527] [G loss: 0.693860]\n",
      "[Epoch 10/200] [Batch 55/169] [D loss: 0.691896] [G loss: 0.694031]\n",
      "[Epoch 10/200] [Batch 56/169] [D loss: 0.692828] [G loss: 0.694336]\n",
      "[Epoch 10/200] [Batch 57/169] [D loss: 0.692568] [G loss: 0.695701]\n",
      "[Epoch 10/200] [Batch 58/169] [D loss: 0.692085] [G loss: 0.695431]\n",
      "[Epoch 10/200] [Batch 59/169] [D loss: 0.691995] [G loss: 0.694879]\n",
      "[Epoch 10/200] [Batch 60/169] [D loss: 0.691716] [G loss: 0.694548]\n",
      "[Epoch 10/200] [Batch 61/169] [D loss: 0.692222] [G loss: 0.694341]\n",
      "[Epoch 10/200] [Batch 62/169] [D loss: 0.692258] [G loss: 0.695653]\n",
      "[Epoch 10/200] [Batch 63/169] [D loss: 0.691886] [G loss: 0.695222]\n",
      "[Epoch 10/200] [Batch 64/169] [D loss: 0.690878] [G loss: 0.693989]\n",
      "[Epoch 10/200] [Batch 65/169] [D loss: 0.692581] [G loss: 0.693951]\n",
      "[Epoch 10/200] [Batch 66/169] [D loss: 0.692294] [G loss: 0.693602]\n",
      "[Epoch 10/200] [Batch 67/169] [D loss: 0.693447] [G loss: 0.693407]\n",
      "[Epoch 10/200] [Batch 68/169] [D loss: 0.693031] [G loss: 0.692340]\n",
      "[Epoch 10/200] [Batch 69/169] [D loss: 0.692770] [G loss: 0.694939]\n",
      "[Epoch 10/200] [Batch 70/169] [D loss: 0.694223] [G loss: 0.692051]\n",
      "[Epoch 10/200] [Batch 71/169] [D loss: 0.691900] [G loss: 0.691125]\n",
      "[Epoch 10/200] [Batch 72/169] [D loss: 0.694647] [G loss: 0.692077]\n",
      "[Epoch 10/200] [Batch 73/169] [D loss: 0.694590] [G loss: 0.692793]\n",
      "[Epoch 10/200] [Batch 74/169] [D loss: 0.694158] [G loss: 0.693324]\n",
      "[Epoch 10/200] [Batch 75/169] [D loss: 0.693119] [G loss: 0.691935]\n",
      "[Epoch 10/200] [Batch 76/169] [D loss: 0.694970] [G loss: 0.693033]\n",
      "[Epoch 10/200] [Batch 77/169] [D loss: 0.694763] [G loss: 0.692180]\n",
      "[Epoch 10/200] [Batch 78/169] [D loss: 0.694552] [G loss: 0.692008]\n",
      "[Epoch 10/200] [Batch 79/169] [D loss: 0.694334] [G loss: 0.692215]\n",
      "[Epoch 10/200] [Batch 80/169] [D loss: 0.693818] [G loss: 0.694053]\n",
      "[Epoch 10/200] [Batch 81/169] [D loss: 0.693227] [G loss: 0.693922]\n",
      "[Epoch 10/200] [Batch 82/169] [D loss: 0.692919] [G loss: 0.693214]\n",
      "[Epoch 10/200] [Batch 83/169] [D loss: 0.692899] [G loss: 0.693032]\n",
      "[Epoch 10/200] [Batch 84/169] [D loss: 0.693486] [G loss: 0.693299]\n",
      "[Epoch 10/200] [Batch 85/169] [D loss: 0.693107] [G loss: 0.692643]\n",
      "[Epoch 10/200] [Batch 86/169] [D loss: 0.693822] [G loss: 0.693264]\n",
      "[Epoch 10/200] [Batch 87/169] [D loss: 0.693142] [G loss: 0.693267]\n",
      "[Epoch 10/200] [Batch 88/169] [D loss: 0.693747] [G loss: 0.693929]\n",
      "[Epoch 10/200] [Batch 89/169] [D loss: 0.693085] [G loss: 0.693703]\n",
      "[Epoch 10/200] [Batch 90/169] [D loss: 0.693273] [G loss: 0.694061]\n",
      "[Epoch 10/200] [Batch 91/169] [D loss: 0.693729] [G loss: 0.694883]\n",
      "[Epoch 10/200] [Batch 92/169] [D loss: 0.693268] [G loss: 0.693682]\n",
      "[Epoch 10/200] [Batch 93/169] [D loss: 0.694157] [G loss: 0.694136]\n",
      "[Epoch 10/200] [Batch 94/169] [D loss: 0.693644] [G loss: 0.692158]\n",
      "[Epoch 10/200] [Batch 95/169] [D loss: 0.692740] [G loss: 0.692777]\n",
      "[Epoch 10/200] [Batch 96/169] [D loss: 0.693365] [G loss: 0.694627]\n",
      "[Epoch 10/200] [Batch 97/169] [D loss: 0.693304] [G loss: 0.693796]\n",
      "[Epoch 10/200] [Batch 98/169] [D loss: 0.693305] [G loss: 0.695195]\n",
      "[Epoch 10/200] [Batch 99/169] [D loss: 0.692390] [G loss: 0.695384]\n",
      "[Epoch 10/200] [Batch 100/169] [D loss: 0.692365] [G loss: 0.694502]\n",
      "[Epoch 10/200] [Batch 101/169] [D loss: 0.692948] [G loss: 0.693715]\n",
      "[Epoch 10/200] [Batch 102/169] [D loss: 0.692636] [G loss: 0.693545]\n",
      "[Epoch 10/200] [Batch 103/169] [D loss: 0.692633] [G loss: 0.695479]\n",
      "[Epoch 10/200] [Batch 104/169] [D loss: 0.691904] [G loss: 0.694996]\n",
      "[Epoch 10/200] [Batch 105/169] [D loss: 0.691185] [G loss: 0.694254]\n",
      "[Epoch 10/200] [Batch 106/169] [D loss: 0.691059] [G loss: 0.695289]\n",
      "[Epoch 10/200] [Batch 107/169] [D loss: 0.692012] [G loss: 0.694346]\n",
      "[Epoch 10/200] [Batch 108/169] [D loss: 0.691692] [G loss: 0.694915]\n",
      "[Epoch 10/200] [Batch 109/169] [D loss: 0.692481] [G loss: 0.695717]\n",
      "[Epoch 10/200] [Batch 110/169] [D loss: 0.691809] [G loss: 0.695644]\n",
      "[Epoch 10/200] [Batch 111/169] [D loss: 0.692594] [G loss: 0.694674]\n",
      "[Epoch 10/200] [Batch 112/169] [D loss: 0.693113] [G loss: 0.693881]\n",
      "[Epoch 10/200] [Batch 113/169] [D loss: 0.692242] [G loss: 0.694231]\n",
      "[Epoch 10/200] [Batch 114/169] [D loss: 0.691960] [G loss: 0.694615]\n",
      "[Epoch 10/200] [Batch 115/169] [D loss: 0.691964] [G loss: 0.693807]\n",
      "[Epoch 10/200] [Batch 116/169] [D loss: 0.692106] [G loss: 0.693203]\n",
      "[Epoch 10/200] [Batch 117/169] [D loss: 0.692156] [G loss: 0.694051]\n",
      "[Epoch 10/200] [Batch 118/169] [D loss: 0.692450] [G loss: 0.694965]\n",
      "[Epoch 10/200] [Batch 119/169] [D loss: 0.692324] [G loss: 0.694013]\n",
      "[Epoch 10/200] [Batch 120/169] [D loss: 0.692062] [G loss: 0.692807]\n",
      "[Epoch 10/200] [Batch 121/169] [D loss: 0.693113] [G loss: 0.690825]\n",
      "[Epoch 10/200] [Batch 122/169] [D loss: 0.692530] [G loss: 0.693468]\n",
      "[Epoch 10/200] [Batch 123/169] [D loss: 0.692551] [G loss: 0.693679]\n",
      "[Epoch 10/200] [Batch 124/169] [D loss: 0.692208] [G loss: 0.694564]\n",
      "[Epoch 10/200] [Batch 125/169] [D loss: 0.691631] [G loss: 0.695968]\n",
      "[Epoch 10/200] [Batch 126/169] [D loss: 0.691544] [G loss: 0.694379]\n",
      "[Epoch 10/200] [Batch 127/169] [D loss: 0.691153] [G loss: 0.695609]\n",
      "[Epoch 10/200] [Batch 128/169] [D loss: 0.691890] [G loss: 0.695400]\n",
      "[Epoch 10/200] [Batch 129/169] [D loss: 0.690851] [G loss: 0.695082]\n",
      "[Epoch 10/200] [Batch 130/169] [D loss: 0.691199] [G loss: 0.694935]\n",
      "[Epoch 10/200] [Batch 131/169] [D loss: 0.691134] [G loss: 0.693156]\n",
      "[Epoch 10/200] [Batch 132/169] [D loss: 0.690819] [G loss: 0.694830]\n",
      "[Epoch 10/200] [Batch 133/169] [D loss: 0.690852] [G loss: 0.697278]\n",
      "[Epoch 10/200] [Batch 134/169] [D loss: 0.691644] [G loss: 0.694961]\n",
      "[Epoch 10/200] [Batch 135/169] [D loss: 0.691553] [G loss: 0.694795]\n",
      "[Epoch 10/200] [Batch 136/169] [D loss: 0.691906] [G loss: 0.692919]\n",
      "[Epoch 10/200] [Batch 137/169] [D loss: 0.692310] [G loss: 0.695011]\n",
      "[Epoch 10/200] [Batch 138/169] [D loss: 0.692550] [G loss: 0.693705]\n",
      "[Epoch 10/200] [Batch 139/169] [D loss: 0.691798] [G loss: 0.696036]\n",
      "[Epoch 10/200] [Batch 140/169] [D loss: 0.692622] [G loss: 0.693777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 141/169] [D loss: 0.693535] [G loss: 0.694640]\n",
      "[Epoch 10/200] [Batch 142/169] [D loss: 0.691987] [G loss: 0.695449]\n",
      "[Epoch 10/200] [Batch 143/169] [D loss: 0.692098] [G loss: 0.694933]\n",
      "[Epoch 10/200] [Batch 144/169] [D loss: 0.691489] [G loss: 0.693084]\n",
      "[Epoch 10/200] [Batch 145/169] [D loss: 0.691737] [G loss: 0.695930]\n",
      "[Epoch 10/200] [Batch 146/169] [D loss: 0.692311] [G loss: 0.695810]\n",
      "[Epoch 10/200] [Batch 147/169] [D loss: 0.691916] [G loss: 0.696301]\n",
      "[Epoch 10/200] [Batch 148/169] [D loss: 0.691881] [G loss: 0.693556]\n",
      "[Epoch 10/200] [Batch 149/169] [D loss: 0.691818] [G loss: 0.695393]\n",
      "[Epoch 10/200] [Batch 150/169] [D loss: 0.691487] [G loss: 0.696443]\n",
      "[Epoch 10/200] [Batch 151/169] [D loss: 0.692060] [G loss: 0.695147]\n",
      "[Epoch 10/200] [Batch 152/169] [D loss: 0.691728] [G loss: 0.694027]\n",
      "[Epoch 10/200] [Batch 153/169] [D loss: 0.693008] [G loss: 0.694110]\n",
      "[Epoch 10/200] [Batch 154/169] [D loss: 0.691898] [G loss: 0.694100]\n",
      "[Epoch 10/200] [Batch 155/169] [D loss: 0.692939] [G loss: 0.693337]\n",
      "[Epoch 10/200] [Batch 156/169] [D loss: 0.692057] [G loss: 0.693922]\n",
      "[Epoch 10/200] [Batch 157/169] [D loss: 0.692657] [G loss: 0.694086]\n",
      "[Epoch 10/200] [Batch 158/169] [D loss: 0.692095] [G loss: 0.693304]\n",
      "[Epoch 10/200] [Batch 159/169] [D loss: 0.693076] [G loss: 0.692153]\n",
      "[Epoch 10/200] [Batch 160/169] [D loss: 0.692250] [G loss: 0.693563]\n",
      "[Epoch 10/200] [Batch 161/169] [D loss: 0.692827] [G loss: 0.692694]\n",
      "[Epoch 10/200] [Batch 162/169] [D loss: 0.693521] [G loss: 0.693272]\n",
      "[Epoch 10/200] [Batch 163/169] [D loss: 0.693948] [G loss: 0.693118]\n",
      "[Epoch 10/200] [Batch 164/169] [D loss: 0.693493] [G loss: 0.693047]\n",
      "[Epoch 10/200] [Batch 165/169] [D loss: 0.693914] [G loss: 0.694694]\n",
      "[Epoch 10/200] [Batch 166/169] [D loss: 0.692916] [G loss: 0.691788]\n",
      "[Epoch 10/200] [Batch 167/169] [D loss: 0.693346] [G loss: 0.693138]\n",
      "[Epoch 10/200] [Batch 168/169] [D loss: 0.694348] [G loss: 0.691127]\n",
      "[Epoch 11/200] [Batch 0/169] [D loss: 0.693710] [G loss: 0.692672]\n",
      "[Epoch 11/200] [Batch 1/169] [D loss: 0.693370] [G loss: 0.694536]\n",
      "[Epoch 11/200] [Batch 2/169] [D loss: 0.694177] [G loss: 0.692185]\n",
      "[Epoch 11/200] [Batch 3/169] [D loss: 0.693761] [G loss: 0.692246]\n",
      "[Epoch 11/200] [Batch 4/169] [D loss: 0.692960] [G loss: 0.692616]\n",
      "[Epoch 11/200] [Batch 5/169] [D loss: 0.694162] [G loss: 0.691771]\n",
      "[Epoch 11/200] [Batch 6/169] [D loss: 0.693019] [G loss: 0.692811]\n",
      "[Epoch 11/200] [Batch 7/169] [D loss: 0.693292] [G loss: 0.692801]\n",
      "[Epoch 11/200] [Batch 8/169] [D loss: 0.692258] [G loss: 0.693626]\n",
      "[Epoch 11/200] [Batch 9/169] [D loss: 0.692252] [G loss: 0.693501]\n",
      "[Epoch 11/200] [Batch 10/169] [D loss: 0.693648] [G loss: 0.694350]\n",
      "[Epoch 11/200] [Batch 11/169] [D loss: 0.693025] [G loss: 0.693826]\n",
      "[Epoch 11/200] [Batch 12/169] [D loss: 0.692304] [G loss: 0.693424]\n",
      "[Epoch 11/200] [Batch 13/169] [D loss: 0.692214] [G loss: 0.694176]\n",
      "[Epoch 11/200] [Batch 14/169] [D loss: 0.691737] [G loss: 0.693958]\n",
      "[Epoch 11/200] [Batch 15/169] [D loss: 0.692077] [G loss: 0.693381]\n",
      "[Epoch 11/200] [Batch 16/169] [D loss: 0.691785] [G loss: 0.693863]\n",
      "[Epoch 11/200] [Batch 17/169] [D loss: 0.691403] [G loss: 0.694884]\n",
      "[Epoch 11/200] [Batch 18/169] [D loss: 0.690925] [G loss: 0.693278]\n",
      "[Epoch 11/200] [Batch 19/169] [D loss: 0.691471] [G loss: 0.694703]\n",
      "[Epoch 11/200] [Batch 20/169] [D loss: 0.692292] [G loss: 0.694943]\n",
      "[Epoch 11/200] [Batch 21/169] [D loss: 0.690964] [G loss: 0.694885]\n",
      "[Epoch 11/200] [Batch 22/169] [D loss: 0.691322] [G loss: 0.694090]\n",
      "[Epoch 11/200] [Batch 23/169] [D loss: 0.691392] [G loss: 0.695641]\n",
      "[Epoch 11/200] [Batch 24/169] [D loss: 0.690959] [G loss: 0.695238]\n",
      "[Epoch 11/200] [Batch 25/169] [D loss: 0.691585] [G loss: 0.694072]\n",
      "[Epoch 11/200] [Batch 26/169] [D loss: 0.690288] [G loss: 0.694576]\n",
      "[Epoch 11/200] [Batch 27/169] [D loss: 0.692395] [G loss: 0.694291]\n",
      "[Epoch 11/200] [Batch 28/169] [D loss: 0.690423] [G loss: 0.695558]\n",
      "[Epoch 11/200] [Batch 29/169] [D loss: 0.690956] [G loss: 0.694208]\n",
      "[Epoch 11/200] [Batch 30/169] [D loss: 0.690630] [G loss: 0.696021]\n",
      "[Epoch 11/200] [Batch 31/169] [D loss: 0.690524] [G loss: 0.696011]\n",
      "[Epoch 11/200] [Batch 32/169] [D loss: 0.689859] [G loss: 0.695707]\n",
      "[Epoch 11/200] [Batch 33/169] [D loss: 0.689947] [G loss: 0.698178]\n",
      "[Epoch 11/200] [Batch 34/169] [D loss: 0.690647] [G loss: 0.696505]\n",
      "[Epoch 11/200] [Batch 35/169] [D loss: 0.690804] [G loss: 0.696077]\n",
      "[Epoch 11/200] [Batch 36/169] [D loss: 0.690323] [G loss: 0.696345]\n",
      "[Epoch 11/200] [Batch 37/169] [D loss: 0.689342] [G loss: 0.697638]\n",
      "[Epoch 11/200] [Batch 38/169] [D loss: 0.690146] [G loss: 0.694546]\n",
      "[Epoch 11/200] [Batch 39/169] [D loss: 0.690993] [G loss: 0.695316]\n",
      "[Epoch 11/200] [Batch 40/169] [D loss: 0.690014] [G loss: 0.695961]\n",
      "[Epoch 11/200] [Batch 41/169] [D loss: 0.690255] [G loss: 0.695882]\n",
      "[Epoch 11/200] [Batch 42/169] [D loss: 0.692074] [G loss: 0.696021]\n",
      "[Epoch 11/200] [Batch 43/169] [D loss: 0.690373] [G loss: 0.695153]\n",
      "[Epoch 11/200] [Batch 44/169] [D loss: 0.691575] [G loss: 0.695177]\n",
      "[Epoch 11/200] [Batch 45/169] [D loss: 0.691638] [G loss: 0.693822]\n",
      "[Epoch 11/200] [Batch 46/169] [D loss: 0.692715] [G loss: 0.695865]\n",
      "[Epoch 11/200] [Batch 47/169] [D loss: 0.691906] [G loss: 0.694613]\n",
      "[Epoch 11/200] [Batch 48/169] [D loss: 0.693679] [G loss: 0.695286]\n",
      "[Epoch 11/200] [Batch 49/169] [D loss: 0.694108] [G loss: 0.693542]\n",
      "[Epoch 11/200] [Batch 50/169] [D loss: 0.694494] [G loss: 0.691537]\n",
      "[Epoch 11/200] [Batch 51/169] [D loss: 0.693233] [G loss: 0.690690]\n",
      "[Epoch 11/200] [Batch 52/169] [D loss: 0.693998] [G loss: 0.690581]\n",
      "[Epoch 11/200] [Batch 53/169] [D loss: 0.694379] [G loss: 0.692068]\n",
      "[Epoch 11/200] [Batch 54/169] [D loss: 0.695126] [G loss: 0.691793]\n",
      "[Epoch 11/200] [Batch 55/169] [D loss: 0.693857] [G loss: 0.690443]\n",
      "[Epoch 11/200] [Batch 56/169] [D loss: 0.693616] [G loss: 0.692682]\n",
      "[Epoch 11/200] [Batch 57/169] [D loss: 0.694385] [G loss: 0.693125]\n",
      "[Epoch 11/200] [Batch 58/169] [D loss: 0.692445] [G loss: 0.692249]\n",
      "[Epoch 11/200] [Batch 59/169] [D loss: 0.693071] [G loss: 0.694351]\n",
      "[Epoch 11/200] [Batch 60/169] [D loss: 0.691216] [G loss: 0.695125]\n",
      "[Epoch 11/200] [Batch 61/169] [D loss: 0.691398] [G loss: 0.695568]\n",
      "[Epoch 11/200] [Batch 62/169] [D loss: 0.691084] [G loss: 0.696139]\n",
      "[Epoch 11/200] [Batch 63/169] [D loss: 0.690352] [G loss: 0.696247]\n",
      "[Epoch 11/200] [Batch 64/169] [D loss: 0.689306] [G loss: 0.697332]\n",
      "[Epoch 11/200] [Batch 65/169] [D loss: 0.689471] [G loss: 0.697324]\n",
      "[Epoch 11/200] [Batch 66/169] [D loss: 0.689889] [G loss: 0.697198]\n",
      "[Epoch 11/200] [Batch 67/169] [D loss: 0.687698] [G loss: 0.698000]\n",
      "[Epoch 11/200] [Batch 68/169] [D loss: 0.688457] [G loss: 0.698776]\n",
      "[Epoch 11/200] [Batch 69/169] [D loss: 0.687719] [G loss: 0.699303]\n",
      "[Epoch 11/200] [Batch 70/169] [D loss: 0.688739] [G loss: 0.698206]\n",
      "[Epoch 11/200] [Batch 71/169] [D loss: 0.687551] [G loss: 0.697463]\n",
      "[Epoch 11/200] [Batch 72/169] [D loss: 0.686843] [G loss: 0.698340]\n",
      "[Epoch 11/200] [Batch 73/169] [D loss: 0.688071] [G loss: 0.699459]\n",
      "[Epoch 11/200] [Batch 74/169] [D loss: 0.687795] [G loss: 0.696765]\n",
      "[Epoch 11/200] [Batch 75/169] [D loss: 0.687033] [G loss: 0.698724]\n",
      "[Epoch 11/200] [Batch 76/169] [D loss: 0.690345] [G loss: 0.697974]\n",
      "[Epoch 11/200] [Batch 77/169] [D loss: 0.690666] [G loss: 0.699590]\n",
      "[Epoch 11/200] [Batch 78/169] [D loss: 0.689049] [G loss: 0.698831]\n",
      "[Epoch 11/200] [Batch 79/169] [D loss: 0.691170] [G loss: 0.700107]\n",
      "[Epoch 11/200] [Batch 80/169] [D loss: 0.689362] [G loss: 0.701916]\n",
      "[Epoch 11/200] [Batch 81/169] [D loss: 0.689737] [G loss: 0.696865]\n",
      "[Epoch 11/200] [Batch 82/169] [D loss: 0.687489] [G loss: 0.701365]\n",
      "[Epoch 11/200] [Batch 83/169] [D loss: 0.690325] [G loss: 0.694377]\n",
      "[Epoch 11/200] [Batch 84/169] [D loss: 0.692383] [G loss: 0.694249]\n",
      "[Epoch 11/200] [Batch 85/169] [D loss: 0.691408] [G loss: 0.692021]\n",
      "[Epoch 11/200] [Batch 86/169] [D loss: 0.690285] [G loss: 0.695401]\n",
      "[Epoch 11/200] [Batch 87/169] [D loss: 0.695383] [G loss: 0.689084]\n",
      "[Epoch 11/200] [Batch 88/169] [D loss: 0.695483] [G loss: 0.691160]\n",
      "[Epoch 11/200] [Batch 89/169] [D loss: 0.693310] [G loss: 0.693050]\n",
      "[Epoch 11/200] [Batch 90/169] [D loss: 0.691768] [G loss: 0.695242]\n",
      "[Epoch 11/200] [Batch 91/169] [D loss: 0.688649] [G loss: 0.698737]\n",
      "[Epoch 11/200] [Batch 92/169] [D loss: 0.687344] [G loss: 0.699253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 93/169] [D loss: 0.685737] [G loss: 0.700460]\n",
      "[Epoch 11/200] [Batch 94/169] [D loss: 0.687107] [G loss: 0.698370]\n",
      "[Epoch 11/200] [Batch 95/169] [D loss: 0.685528] [G loss: 0.698033]\n",
      "[Epoch 11/200] [Batch 96/169] [D loss: 0.692579] [G loss: 0.688831]\n",
      "[Epoch 11/200] [Batch 97/169] [D loss: 0.694090] [G loss: 0.686197]\n",
      "[Epoch 11/200] [Batch 98/169] [D loss: 0.696082] [G loss: 0.685728]\n",
      "[Epoch 11/200] [Batch 99/169] [D loss: 0.696088] [G loss: 0.688002]\n",
      "[Epoch 11/200] [Batch 100/169] [D loss: 0.696697] [G loss: 0.688907]\n",
      "[Epoch 11/200] [Batch 101/169] [D loss: 0.697364] [G loss: 0.692187]\n",
      "[Epoch 11/200] [Batch 102/169] [D loss: 0.694859] [G loss: 0.696548]\n",
      "[Epoch 11/200] [Batch 103/169] [D loss: 0.695955] [G loss: 0.699103]\n",
      "[Epoch 11/200] [Batch 104/169] [D loss: 0.693246] [G loss: 0.701653]\n",
      "[Epoch 11/200] [Batch 105/169] [D loss: 0.690297] [G loss: 0.702272]\n",
      "[Epoch 11/200] [Batch 106/169] [D loss: 0.687785] [G loss: 0.704755]\n",
      "[Epoch 11/200] [Batch 107/169] [D loss: 0.688540] [G loss: 0.699963]\n",
      "[Epoch 11/200] [Batch 108/169] [D loss: 0.690626] [G loss: 0.696603]\n",
      "[Epoch 11/200] [Batch 109/169] [D loss: 0.690554] [G loss: 0.696907]\n",
      "[Epoch 11/200] [Batch 110/169] [D loss: 0.689918] [G loss: 0.694463]\n",
      "[Epoch 11/200] [Batch 111/169] [D loss: 0.691938] [G loss: 0.692022]\n",
      "[Epoch 11/200] [Batch 112/169] [D loss: 0.692237] [G loss: 0.689152]\n",
      "[Epoch 11/200] [Batch 113/169] [D loss: 0.692926] [G loss: 0.690675]\n",
      "[Epoch 11/200] [Batch 114/169] [D loss: 0.690577] [G loss: 0.692946]\n",
      "[Epoch 11/200] [Batch 115/169] [D loss: 0.688027] [G loss: 0.696708]\n",
      "[Epoch 11/200] [Batch 116/169] [D loss: 0.687058] [G loss: 0.697929]\n",
      "[Epoch 11/200] [Batch 117/169] [D loss: 0.686475] [G loss: 0.703402]\n",
      "[Epoch 11/200] [Batch 118/169] [D loss: 0.681682] [G loss: 0.706120]\n",
      "[Epoch 11/200] [Batch 119/169] [D loss: 0.682424] [G loss: 0.706715]\n",
      "[Epoch 11/200] [Batch 120/169] [D loss: 0.679120] [G loss: 0.706010]\n",
      "[Epoch 11/200] [Batch 121/169] [D loss: 0.679293] [G loss: 0.707376]\n",
      "[Epoch 11/200] [Batch 122/169] [D loss: 0.677087] [G loss: 0.708606]\n",
      "[Epoch 11/200] [Batch 123/169] [D loss: 0.676838] [G loss: 0.709190]\n",
      "[Epoch 11/200] [Batch 124/169] [D loss: 0.677790] [G loss: 0.708250]\n",
      "[Epoch 11/200] [Batch 125/169] [D loss: 0.684164] [G loss: 0.700370]\n",
      "[Epoch 11/200] [Batch 126/169] [D loss: 0.685621] [G loss: 0.695109]\n",
      "[Epoch 11/200] [Batch 127/169] [D loss: 0.690839] [G loss: 0.683603]\n",
      "[Epoch 11/200] [Batch 128/169] [D loss: 0.695420] [G loss: 0.686434]\n",
      "[Epoch 11/200] [Batch 129/169] [D loss: 0.694927] [G loss: 0.690380]\n",
      "[Epoch 11/200] [Batch 130/169] [D loss: 0.692903] [G loss: 0.699641]\n",
      "[Epoch 11/200] [Batch 131/169] [D loss: 0.692414] [G loss: 0.701171]\n",
      "[Epoch 11/200] [Batch 132/169] [D loss: 0.685364] [G loss: 0.715224]\n",
      "[Epoch 11/200] [Batch 133/169] [D loss: 0.681549] [G loss: 0.720605]\n",
      "[Epoch 11/200] [Batch 134/169] [D loss: 0.680132] [G loss: 0.719690]\n",
      "[Epoch 11/200] [Batch 135/169] [D loss: 0.690589] [G loss: 0.695781]\n",
      "[Epoch 11/200] [Batch 136/169] [D loss: 0.704830] [G loss: 0.662884]\n",
      "[Epoch 11/200] [Batch 137/169] [D loss: 0.707501] [G loss: 0.656597]\n",
      "[Epoch 11/200] [Batch 138/169] [D loss: 0.714429] [G loss: 0.655614]\n",
      "[Epoch 11/200] [Batch 139/169] [D loss: 0.712322] [G loss: 0.668555]\n",
      "[Epoch 11/200] [Batch 140/169] [D loss: 0.701033] [G loss: 0.696190]\n",
      "[Epoch 11/200] [Batch 141/169] [D loss: 0.694888] [G loss: 0.702804]\n",
      "[Epoch 11/200] [Batch 142/169] [D loss: 0.684113] [G loss: 0.709680]\n",
      "[Epoch 11/200] [Batch 143/169] [D loss: 0.677069] [G loss: 0.717246]\n",
      "[Epoch 11/200] [Batch 144/169] [D loss: 0.672849] [G loss: 0.719135]\n",
      "[Epoch 11/200] [Batch 145/169] [D loss: 0.670157] [G loss: 0.721606]\n",
      "[Epoch 11/200] [Batch 146/169] [D loss: 0.664634] [G loss: 0.727093]\n",
      "[Epoch 11/200] [Batch 147/169] [D loss: 0.661358] [G loss: 0.723292]\n",
      "[Epoch 11/200] [Batch 148/169] [D loss: 0.658053] [G loss: 0.728263]\n",
      "[Epoch 11/200] [Batch 149/169] [D loss: 0.653670] [G loss: 0.732098]\n",
      "[Epoch 11/200] [Batch 150/169] [D loss: 0.653920] [G loss: 0.739161]\n",
      "[Epoch 11/200] [Batch 151/169] [D loss: 0.657457] [G loss: 0.728497]\n",
      "[Epoch 11/200] [Batch 152/169] [D loss: 0.666648] [G loss: 0.701596]\n",
      "[Epoch 11/200] [Batch 153/169] [D loss: 0.697028] [G loss: 0.650559]\n",
      "[Epoch 11/200] [Batch 154/169] [D loss: 0.724621] [G loss: 0.621837]\n",
      "[Epoch 11/200] [Batch 155/169] [D loss: 0.739405] [G loss: 0.619920]\n",
      "[Epoch 11/200] [Batch 156/169] [D loss: 0.732305] [G loss: 0.654178]\n",
      "[Epoch 11/200] [Batch 157/169] [D loss: 0.722656] [G loss: 0.690278]\n",
      "[Epoch 11/200] [Batch 158/169] [D loss: 0.714237] [G loss: 0.707452]\n",
      "[Epoch 11/200] [Batch 159/169] [D loss: 0.704200] [G loss: 0.722744]\n",
      "[Epoch 11/200] [Batch 160/169] [D loss: 0.693009] [G loss: 0.729755]\n",
      "[Epoch 11/200] [Batch 161/169] [D loss: 0.685405] [G loss: 0.733778]\n",
      "[Epoch 11/200] [Batch 162/169] [D loss: 0.678531] [G loss: 0.737001]\n",
      "[Epoch 11/200] [Batch 163/169] [D loss: 0.672685] [G loss: 0.736689]\n",
      "[Epoch 11/200] [Batch 164/169] [D loss: 0.668879] [G loss: 0.745606]\n",
      "[Epoch 11/200] [Batch 165/169] [D loss: 0.657742] [G loss: 0.739606]\n",
      "[Epoch 11/200] [Batch 166/169] [D loss: 0.657087] [G loss: 0.737703]\n",
      "[Epoch 11/200] [Batch 167/169] [D loss: 0.654765] [G loss: 0.745076]\n",
      "[Epoch 11/200] [Batch 168/169] [D loss: 0.639481] [G loss: 0.760594]\n",
      "[Epoch 12/200] [Batch 0/169] [D loss: 0.635071] [G loss: 0.760882]\n",
      "[Epoch 12/200] [Batch 1/169] [D loss: 0.640466] [G loss: 0.779291]\n",
      "[Epoch 12/200] [Batch 2/169] [D loss: 0.628663] [G loss: 0.784448]\n",
      "[Epoch 12/200] [Batch 3/169] [D loss: 0.649917] [G loss: 0.754147]\n",
      "[Epoch 12/200] [Batch 4/169] [D loss: 0.648074] [G loss: 0.749313]\n",
      "[Epoch 12/200] [Batch 5/169] [D loss: 0.675750] [G loss: 0.693362]\n",
      "[Epoch 12/200] [Batch 6/169] [D loss: 0.722597] [G loss: 0.637415]\n",
      "[Epoch 12/200] [Batch 7/169] [D loss: 0.732222] [G loss: 0.634357]\n",
      "[Epoch 12/200] [Batch 8/169] [D loss: 0.751162] [G loss: 0.632301]\n",
      "[Epoch 12/200] [Batch 9/169] [D loss: 0.722080] [G loss: 0.689500]\n",
      "[Epoch 12/200] [Batch 10/169] [D loss: 0.696245] [G loss: 0.751196]\n",
      "[Epoch 12/200] [Batch 11/169] [D loss: 0.674170] [G loss: 0.777312]\n",
      "[Epoch 12/200] [Batch 12/169] [D loss: 0.659363] [G loss: 0.787326]\n",
      "[Epoch 12/200] [Batch 13/169] [D loss: 0.644426] [G loss: 0.799633]\n",
      "[Epoch 12/200] [Batch 14/169] [D loss: 0.652934] [G loss: 0.774275]\n",
      "[Epoch 12/200] [Batch 15/169] [D loss: 0.649105] [G loss: 0.786627]\n",
      "[Epoch 12/200] [Batch 16/169] [D loss: 0.641295] [G loss: 0.764000]\n",
      "[Epoch 12/200] [Batch 17/169] [D loss: 0.650955] [G loss: 0.727829]\n",
      "[Epoch 12/200] [Batch 18/169] [D loss: 0.664634] [G loss: 0.716700]\n",
      "[Epoch 12/200] [Batch 19/169] [D loss: 0.684132] [G loss: 0.673547]\n",
      "[Epoch 12/200] [Batch 20/169] [D loss: 0.715408] [G loss: 0.612805]\n",
      "[Epoch 12/200] [Batch 21/169] [D loss: 0.732357] [G loss: 0.579587]\n",
      "[Epoch 12/200] [Batch 22/169] [D loss: 0.742893] [G loss: 0.541318]\n",
      "[Epoch 12/200] [Batch 23/169] [D loss: 0.744566] [G loss: 0.590022]\n",
      "[Epoch 12/200] [Batch 24/169] [D loss: 0.741082] [G loss: 0.625006]\n",
      "[Epoch 12/200] [Batch 25/169] [D loss: 0.719396] [G loss: 0.690375]\n",
      "[Epoch 12/200] [Batch 26/169] [D loss: 0.693492] [G loss: 0.758275]\n",
      "[Epoch 12/200] [Batch 27/169] [D loss: 0.685499] [G loss: 0.781192]\n",
      "[Epoch 12/200] [Batch 28/169] [D loss: 0.689400] [G loss: 0.772122]\n",
      "[Epoch 12/200] [Batch 29/169] [D loss: 0.702437] [G loss: 0.723024]\n",
      "[Epoch 12/200] [Batch 30/169] [D loss: 0.732526] [G loss: 0.665006]\n",
      "[Epoch 12/200] [Batch 31/169] [D loss: 0.739856] [G loss: 0.637650]\n",
      "[Epoch 12/200] [Batch 32/169] [D loss: 0.719857] [G loss: 0.666575]\n",
      "[Epoch 12/200] [Batch 33/169] [D loss: 0.693400] [G loss: 0.702436]\n",
      "[Epoch 12/200] [Batch 34/169] [D loss: 0.670346] [G loss: 0.754013]\n",
      "[Epoch 12/200] [Batch 35/169] [D loss: 0.651440] [G loss: 0.762014]\n",
      "[Epoch 12/200] [Batch 36/169] [D loss: 0.644032] [G loss: 0.787411]\n",
      "[Epoch 12/200] [Batch 37/169] [D loss: 0.620229] [G loss: 0.803348]\n",
      "[Epoch 12/200] [Batch 38/169] [D loss: 0.595931] [G loss: 0.840182]\n",
      "[Epoch 12/200] [Batch 39/169] [D loss: 0.577363] [G loss: 0.873695]\n",
      "[Epoch 12/200] [Batch 40/169] [D loss: 0.549868] [G loss: 0.895970]\n",
      "[Epoch 12/200] [Batch 41/169] [D loss: 0.521290] [G loss: 0.971665]\n",
      "[Epoch 12/200] [Batch 42/169] [D loss: 0.461366] [G loss: 1.037330]\n",
      "[Epoch 12/200] [Batch 43/169] [D loss: 0.412465] [G loss: 1.186048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 44/169] [D loss: 0.388193] [G loss: 1.169810]\n",
      "[Epoch 12/200] [Batch 45/169] [D loss: 0.852707] [G loss: 0.366672]\n",
      "[Epoch 12/200] [Batch 46/169] [D loss: 0.855808] [G loss: 0.390061]\n",
      "[Epoch 12/200] [Batch 47/169] [D loss: 0.787436] [G loss: 0.491808]\n",
      "[Epoch 12/200] [Batch 48/169] [D loss: 0.811099] [G loss: 0.559990]\n",
      "[Epoch 12/200] [Batch 49/169] [D loss: 0.797110] [G loss: 0.642600]\n",
      "[Epoch 12/200] [Batch 50/169] [D loss: 0.755729] [G loss: 0.732860]\n",
      "[Epoch 12/200] [Batch 51/169] [D loss: 0.743958] [G loss: 0.795514]\n",
      "[Epoch 12/200] [Batch 52/169] [D loss: 0.728859] [G loss: 0.793767]\n",
      "[Epoch 12/200] [Batch 53/169] [D loss: 0.707146] [G loss: 0.823205]\n",
      "[Epoch 12/200] [Batch 54/169] [D loss: 0.706345] [G loss: 0.789498]\n",
      "[Epoch 12/200] [Batch 55/169] [D loss: 0.699113] [G loss: 0.779096]\n",
      "[Epoch 12/200] [Batch 56/169] [D loss: 0.718723] [G loss: 0.751413]\n",
      "[Epoch 12/200] [Batch 57/169] [D loss: 0.704055] [G loss: 0.700093]\n",
      "[Epoch 12/200] [Batch 58/169] [D loss: 0.705920] [G loss: 0.682510]\n",
      "[Epoch 12/200] [Batch 59/169] [D loss: 0.715518] [G loss: 0.709714]\n",
      "[Epoch 12/200] [Batch 60/169] [D loss: 0.733820] [G loss: 0.658148]\n",
      "[Epoch 12/200] [Batch 61/169] [D loss: 0.755531] [G loss: 0.631233]\n",
      "[Epoch 12/200] [Batch 62/169] [D loss: 0.751141] [G loss: 0.621769]\n",
      "[Epoch 12/200] [Batch 63/169] [D loss: 0.744336] [G loss: 0.643170]\n",
      "[Epoch 12/200] [Batch 64/169] [D loss: 0.731935] [G loss: 0.667400]\n",
      "[Epoch 12/200] [Batch 65/169] [D loss: 0.714424] [G loss: 0.696300]\n",
      "[Epoch 12/200] [Batch 66/169] [D loss: 0.699147] [G loss: 0.714195]\n",
      "[Epoch 12/200] [Batch 67/169] [D loss: 0.700948] [G loss: 0.726174]\n",
      "[Epoch 12/200] [Batch 68/169] [D loss: 0.695298] [G loss: 0.736678]\n",
      "[Epoch 12/200] [Batch 69/169] [D loss: 0.687265] [G loss: 0.752058]\n",
      "[Epoch 12/200] [Batch 70/169] [D loss: 0.682654] [G loss: 0.758225]\n",
      "[Epoch 12/200] [Batch 71/169] [D loss: 0.674743] [G loss: 0.778477]\n",
      "[Epoch 12/200] [Batch 72/169] [D loss: 0.666191] [G loss: 0.806935]\n",
      "[Epoch 12/200] [Batch 73/169] [D loss: 0.660172] [G loss: 0.822650]\n",
      "[Epoch 12/200] [Batch 74/169] [D loss: 0.643375] [G loss: 0.839365]\n",
      "[Epoch 12/200] [Batch 75/169] [D loss: 0.643814] [G loss: 0.839892]\n",
      "[Epoch 12/200] [Batch 76/169] [D loss: 0.645472] [G loss: 0.832872]\n",
      "[Epoch 12/200] [Batch 77/169] [D loss: 0.651998] [G loss: 0.813043]\n",
      "[Epoch 12/200] [Batch 78/169] [D loss: 0.652496] [G loss: 0.781287]\n",
      "[Epoch 12/200] [Batch 79/169] [D loss: 0.656929] [G loss: 0.756018]\n",
      "[Epoch 12/200] [Batch 80/169] [D loss: 0.668799] [G loss: 0.732347]\n",
      "[Epoch 12/200] [Batch 81/169] [D loss: 0.707782] [G loss: 0.683564]\n",
      "[Epoch 12/200] [Batch 82/169] [D loss: 0.772669] [G loss: 0.570509]\n",
      "[Epoch 12/200] [Batch 83/169] [D loss: 0.796902] [G loss: 0.518618]\n",
      "[Epoch 12/200] [Batch 84/169] [D loss: 0.765918] [G loss: 0.538804]\n",
      "[Epoch 12/200] [Batch 85/169] [D loss: 0.736790] [G loss: 0.580379]\n",
      "[Epoch 12/200] [Batch 86/169] [D loss: 0.725741] [G loss: 0.614753]\n",
      "[Epoch 12/200] [Batch 87/169] [D loss: 0.710458] [G loss: 0.650173]\n",
      "[Epoch 12/200] [Batch 88/169] [D loss: 0.714219] [G loss: 0.647585]\n",
      "[Epoch 12/200] [Batch 89/169] [D loss: 0.709444] [G loss: 0.679967]\n",
      "[Epoch 12/200] [Batch 90/169] [D loss: 0.701065] [G loss: 0.698611]\n",
      "[Epoch 12/200] [Batch 91/169] [D loss: 0.692958] [G loss: 0.713193]\n",
      "[Epoch 12/200] [Batch 92/169] [D loss: 0.692111] [G loss: 0.739057]\n",
      "[Epoch 12/200] [Batch 93/169] [D loss: 0.671338] [G loss: 0.754189]\n",
      "[Epoch 12/200] [Batch 94/169] [D loss: 0.665844] [G loss: 0.777673]\n",
      "[Epoch 12/200] [Batch 95/169] [D loss: 0.644241] [G loss: 0.802811]\n",
      "[Epoch 12/200] [Batch 96/169] [D loss: 0.636616] [G loss: 0.829999]\n",
      "[Epoch 12/200] [Batch 97/169] [D loss: 0.627814] [G loss: 0.823522]\n",
      "[Epoch 12/200] [Batch 98/169] [D loss: 0.614961] [G loss: 0.845129]\n",
      "[Epoch 12/200] [Batch 99/169] [D loss: 0.622619] [G loss: 0.804849]\n",
      "[Epoch 12/200] [Batch 100/169] [D loss: 0.624881] [G loss: 0.768733]\n",
      "[Epoch 12/200] [Batch 101/169] [D loss: 0.652058] [G loss: 0.718025]\n",
      "[Epoch 12/200] [Batch 102/169] [D loss: 0.683616] [G loss: 0.640155]\n",
      "[Epoch 12/200] [Batch 103/169] [D loss: 0.704140] [G loss: 0.621948]\n",
      "[Epoch 12/200] [Batch 104/169] [D loss: 0.711755] [G loss: 0.610311]\n",
      "[Epoch 12/200] [Batch 105/169] [D loss: 0.715276] [G loss: 0.613333]\n",
      "[Epoch 12/200] [Batch 106/169] [D loss: 0.722224] [G loss: 0.619480]\n",
      "[Epoch 12/200] [Batch 107/169] [D loss: 0.717092] [G loss: 0.638193]\n",
      "[Epoch 12/200] [Batch 108/169] [D loss: 0.717777] [G loss: 0.652201]\n",
      "[Epoch 12/200] [Batch 109/169] [D loss: 0.713405] [G loss: 0.666945]\n",
      "[Epoch 12/200] [Batch 110/169] [D loss: 0.715682] [G loss: 0.672281]\n",
      "[Epoch 12/200] [Batch 111/169] [D loss: 0.707628] [G loss: 0.687330]\n",
      "[Epoch 12/200] [Batch 112/169] [D loss: 0.706939] [G loss: 0.693111]\n",
      "[Epoch 12/200] [Batch 113/169] [D loss: 0.709148] [G loss: 0.694410]\n",
      "[Epoch 12/200] [Batch 114/169] [D loss: 0.717671] [G loss: 0.702254]\n",
      "[Epoch 12/200] [Batch 115/169] [D loss: 0.713227] [G loss: 0.707508]\n",
      "[Epoch 12/200] [Batch 116/169] [D loss: 0.702781] [G loss: 0.701057]\n",
      "[Epoch 12/200] [Batch 117/169] [D loss: 0.703372] [G loss: 0.709989]\n",
      "[Epoch 12/200] [Batch 118/169] [D loss: 0.699736] [G loss: 0.710842]\n",
      "[Epoch 12/200] [Batch 119/169] [D loss: 0.699693] [G loss: 0.714827]\n",
      "[Epoch 12/200] [Batch 120/169] [D loss: 0.693622] [G loss: 0.725659]\n",
      "[Epoch 12/200] [Batch 121/169] [D loss: 0.689616] [G loss: 0.733264]\n",
      "[Epoch 12/200] [Batch 122/169] [D loss: 0.690550] [G loss: 0.737472]\n",
      "[Epoch 12/200] [Batch 123/169] [D loss: 0.686074] [G loss: 0.735723]\n",
      "[Epoch 12/200] [Batch 124/169] [D loss: 0.687025] [G loss: 0.743910]\n",
      "[Epoch 12/200] [Batch 125/169] [D loss: 0.692426] [G loss: 0.748000]\n",
      "[Epoch 12/200] [Batch 126/169] [D loss: 0.685606] [G loss: 0.745109]\n",
      "[Epoch 12/200] [Batch 127/169] [D loss: 0.677534] [G loss: 0.750971]\n",
      "[Epoch 12/200] [Batch 128/169] [D loss: 0.684688] [G loss: 0.747033]\n",
      "[Epoch 12/200] [Batch 129/169] [D loss: 0.679660] [G loss: 0.741473]\n",
      "[Epoch 12/200] [Batch 130/169] [D loss: 0.679209] [G loss: 0.745094]\n",
      "[Epoch 12/200] [Batch 131/169] [D loss: 0.674180] [G loss: 0.744085]\n",
      "[Epoch 12/200] [Batch 132/169] [D loss: 0.679728] [G loss: 0.739509]\n",
      "[Epoch 12/200] [Batch 133/169] [D loss: 0.681098] [G loss: 0.724436]\n",
      "[Epoch 12/200] [Batch 134/169] [D loss: 0.680661] [G loss: 0.720463]\n",
      "[Epoch 12/200] [Batch 135/169] [D loss: 0.679765] [G loss: 0.720793]\n",
      "[Epoch 12/200] [Batch 136/169] [D loss: 0.688633] [G loss: 0.711819]\n",
      "[Epoch 12/200] [Batch 137/169] [D loss: 0.690332] [G loss: 0.700011]\n",
      "[Epoch 12/200] [Batch 138/169] [D loss: 0.693141] [G loss: 0.695217]\n",
      "[Epoch 12/200] [Batch 139/169] [D loss: 0.701623] [G loss: 0.686114]\n",
      "[Epoch 12/200] [Batch 140/169] [D loss: 0.699368] [G loss: 0.670230]\n",
      "[Epoch 12/200] [Batch 141/169] [D loss: 0.707450] [G loss: 0.656335]\n",
      "[Epoch 12/200] [Batch 142/169] [D loss: 0.700345] [G loss: 0.653543]\n",
      "[Epoch 12/200] [Batch 143/169] [D loss: 0.691793] [G loss: 0.665705]\n",
      "[Epoch 12/200] [Batch 144/169] [D loss: 0.684001] [G loss: 0.679621]\n",
      "[Epoch 12/200] [Batch 145/169] [D loss: 0.673478] [G loss: 0.693874]\n",
      "[Epoch 12/200] [Batch 146/169] [D loss: 0.675282] [G loss: 0.695004]\n",
      "[Epoch 12/200] [Batch 147/169] [D loss: 0.676680] [G loss: 0.693918]\n",
      "[Epoch 12/200] [Batch 148/169] [D loss: 0.673180] [G loss: 0.700464]\n",
      "[Epoch 12/200] [Batch 149/169] [D loss: 0.682717] [G loss: 0.697679]\n",
      "[Epoch 12/200] [Batch 150/169] [D loss: 0.686229] [G loss: 0.698717]\n",
      "[Epoch 12/200] [Batch 151/169] [D loss: 0.683035] [G loss: 0.691838]\n",
      "[Epoch 12/200] [Batch 152/169] [D loss: 0.689499] [G loss: 0.693399]\n",
      "[Epoch 12/200] [Batch 153/169] [D loss: 0.692557] [G loss: 0.684795]\n",
      "[Epoch 12/200] [Batch 154/169] [D loss: 0.695392] [G loss: 0.679948]\n",
      "[Epoch 12/200] [Batch 155/169] [D loss: 0.695609] [G loss: 0.688351]\n",
      "[Epoch 12/200] [Batch 156/169] [D loss: 0.705878] [G loss: 0.691665]\n",
      "[Epoch 12/200] [Batch 157/169] [D loss: 0.706005] [G loss: 0.693174]\n",
      "[Epoch 12/200] [Batch 158/169] [D loss: 0.693374] [G loss: 0.692195]\n",
      "[Epoch 12/200] [Batch 159/169] [D loss: 0.694047] [G loss: 0.713576]\n",
      "[Epoch 12/200] [Batch 160/169] [D loss: 0.694014] [G loss: 0.714034]\n",
      "[Epoch 12/200] [Batch 161/169] [D loss: 0.698595] [G loss: 0.719109]\n",
      "[Epoch 12/200] [Batch 162/169] [D loss: 0.687070] [G loss: 0.714716]\n",
      "[Epoch 12/200] [Batch 163/169] [D loss: 0.686215] [G loss: 0.735028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 164/169] [D loss: 0.678058] [G loss: 0.735606]\n",
      "[Epoch 12/200] [Batch 165/169] [D loss: 0.682075] [G loss: 0.747234]\n",
      "[Epoch 12/200] [Batch 166/169] [D loss: 0.682807] [G loss: 0.741847]\n",
      "[Epoch 12/200] [Batch 167/169] [D loss: 0.682534] [G loss: 0.735866]\n",
      "[Epoch 12/200] [Batch 168/169] [D loss: 0.687185] [G loss: 0.737246]\n",
      "[Epoch 13/200] [Batch 0/169] [D loss: 0.687849] [G loss: 0.714859]\n",
      "[Epoch 13/200] [Batch 1/169] [D loss: 0.687411] [G loss: 0.708536]\n",
      "[Epoch 13/200] [Batch 2/169] [D loss: 0.692808] [G loss: 0.693819]\n",
      "[Epoch 13/200] [Batch 3/169] [D loss: 0.685929] [G loss: 0.688053]\n",
      "[Epoch 13/200] [Batch 4/169] [D loss: 0.691684] [G loss: 0.681901]\n",
      "[Epoch 13/200] [Batch 5/169] [D loss: 0.689788] [G loss: 0.679919]\n",
      "[Epoch 13/200] [Batch 6/169] [D loss: 0.694480] [G loss: 0.687711]\n",
      "[Epoch 13/200] [Batch 7/169] [D loss: 0.690549] [G loss: 0.682948]\n",
      "[Epoch 13/200] [Batch 8/169] [D loss: 0.691697] [G loss: 0.686706]\n",
      "[Epoch 13/200] [Batch 9/169] [D loss: 0.693914] [G loss: 0.687659]\n",
      "[Epoch 13/200] [Batch 10/169] [D loss: 0.688349] [G loss: 0.699350]\n",
      "[Epoch 13/200] [Batch 11/169] [D loss: 0.688605] [G loss: 0.698736]\n",
      "[Epoch 13/200] [Batch 12/169] [D loss: 0.692215] [G loss: 0.701921]\n",
      "[Epoch 13/200] [Batch 13/169] [D loss: 0.687934] [G loss: 0.709276]\n",
      "[Epoch 13/200] [Batch 14/169] [D loss: 0.690749] [G loss: 0.707373]\n",
      "[Epoch 13/200] [Batch 15/169] [D loss: 0.690447] [G loss: 0.710349]\n",
      "[Epoch 13/200] [Batch 16/169] [D loss: 0.686213] [G loss: 0.714280]\n",
      "[Epoch 13/200] [Batch 17/169] [D loss: 0.685292] [G loss: 0.720415]\n",
      "[Epoch 13/200] [Batch 18/169] [D loss: 0.683617] [G loss: 0.725978]\n",
      "[Epoch 13/200] [Batch 19/169] [D loss: 0.680155] [G loss: 0.727205]\n",
      "[Epoch 13/200] [Batch 20/169] [D loss: 0.678977] [G loss: 0.738382]\n",
      "[Epoch 13/200] [Batch 21/169] [D loss: 0.679445] [G loss: 0.736815]\n",
      "[Epoch 13/200] [Batch 22/169] [D loss: 0.672126] [G loss: 0.744711]\n",
      "[Epoch 13/200] [Batch 23/169] [D loss: 0.672990] [G loss: 0.760778]\n",
      "[Epoch 13/200] [Batch 24/169] [D loss: 0.670913] [G loss: 0.738219]\n",
      "[Epoch 13/200] [Batch 25/169] [D loss: 0.675214] [G loss: 0.725254]\n",
      "[Epoch 13/200] [Batch 26/169] [D loss: 0.684459] [G loss: 0.714338]\n",
      "[Epoch 13/200] [Batch 27/169] [D loss: 0.684141] [G loss: 0.694108]\n",
      "[Epoch 13/200] [Batch 28/169] [D loss: 0.681630] [G loss: 0.692161]\n",
      "[Epoch 13/200] [Batch 29/169] [D loss: 0.681103] [G loss: 0.691492]\n",
      "[Epoch 13/200] [Batch 30/169] [D loss: 0.671422] [G loss: 0.695154]\n",
      "[Epoch 13/200] [Batch 31/169] [D loss: 0.671582] [G loss: 0.693127]\n",
      "[Epoch 13/200] [Batch 32/169] [D loss: 0.667341] [G loss: 0.690821]\n",
      "[Epoch 13/200] [Batch 33/169] [D loss: 0.678333] [G loss: 0.674896]\n",
      "[Epoch 13/200] [Batch 34/169] [D loss: 0.685169] [G loss: 0.668616]\n",
      "[Epoch 13/200] [Batch 35/169] [D loss: 0.678719] [G loss: 0.673053]\n",
      "[Epoch 13/200] [Batch 36/169] [D loss: 0.686468] [G loss: 0.676884]\n",
      "[Epoch 13/200] [Batch 37/169] [D loss: 0.689442] [G loss: 0.683999]\n",
      "[Epoch 13/200] [Batch 38/169] [D loss: 0.683740] [G loss: 0.679264]\n",
      "[Epoch 13/200] [Batch 39/169] [D loss: 0.687287] [G loss: 0.687933]\n",
      "[Epoch 13/200] [Batch 40/169] [D loss: 0.685269] [G loss: 0.712498]\n",
      "[Epoch 13/200] [Batch 41/169] [D loss: 0.677202] [G loss: 0.727444]\n",
      "[Epoch 13/200] [Batch 42/169] [D loss: 0.670574] [G loss: 0.738597]\n",
      "[Epoch 13/200] [Batch 43/169] [D loss: 0.668655] [G loss: 0.757319]\n",
      "[Epoch 13/200] [Batch 44/169] [D loss: 0.660278] [G loss: 0.771460]\n",
      "[Epoch 13/200] [Batch 45/169] [D loss: 0.657344] [G loss: 0.771200]\n",
      "[Epoch 13/200] [Batch 46/169] [D loss: 0.658125] [G loss: 0.768987]\n",
      "[Epoch 13/200] [Batch 47/169] [D loss: 0.674310] [G loss: 0.750165]\n",
      "[Epoch 13/200] [Batch 48/169] [D loss: 0.670294] [G loss: 0.726711]\n",
      "[Epoch 13/200] [Batch 49/169] [D loss: 0.681094] [G loss: 0.699396]\n",
      "[Epoch 13/200] [Batch 50/169] [D loss: 0.692458] [G loss: 0.690943]\n",
      "[Epoch 13/200] [Batch 51/169] [D loss: 0.683944] [G loss: 0.690530]\n",
      "[Epoch 13/200] [Batch 52/169] [D loss: 0.671802] [G loss: 0.708449]\n",
      "[Epoch 13/200] [Batch 53/169] [D loss: 0.666035] [G loss: 0.710384]\n",
      "[Epoch 13/200] [Batch 54/169] [D loss: 0.669638] [G loss: 0.713682]\n",
      "[Epoch 13/200] [Batch 55/169] [D loss: 0.667647] [G loss: 0.707680]\n",
      "[Epoch 13/200] [Batch 56/169] [D loss: 0.670677] [G loss: 0.702149]\n",
      "[Epoch 13/200] [Batch 57/169] [D loss: 0.687446] [G loss: 0.693891]\n",
      "[Epoch 13/200] [Batch 58/169] [D loss: 0.690698] [G loss: 0.674882]\n",
      "[Epoch 13/200] [Batch 59/169] [D loss: 0.697932] [G loss: 0.667641]\n",
      "[Epoch 13/200] [Batch 60/169] [D loss: 0.706288] [G loss: 0.672083]\n",
      "[Epoch 13/200] [Batch 61/169] [D loss: 0.705187] [G loss: 0.681731]\n",
      "[Epoch 13/200] [Batch 62/169] [D loss: 0.698793] [G loss: 0.677503]\n",
      "[Epoch 13/200] [Batch 63/169] [D loss: 0.695022] [G loss: 0.715331]\n",
      "[Epoch 13/200] [Batch 64/169] [D loss: 0.671760] [G loss: 0.766769]\n",
      "[Epoch 13/200] [Batch 65/169] [D loss: 0.672175] [G loss: 0.774703]\n",
      "[Epoch 13/200] [Batch 66/169] [D loss: 0.667588] [G loss: 0.792603]\n",
      "[Epoch 13/200] [Batch 67/169] [D loss: 0.675267] [G loss: 0.775815]\n",
      "[Epoch 13/200] [Batch 68/169] [D loss: 0.690999] [G loss: 0.716177]\n",
      "[Epoch 13/200] [Batch 69/169] [D loss: 0.700677] [G loss: 0.684039]\n",
      "[Epoch 13/200] [Batch 70/169] [D loss: 0.711864] [G loss: 0.664438]\n",
      "[Epoch 13/200] [Batch 71/169] [D loss: 0.710280] [G loss: 0.663456]\n",
      "[Epoch 13/200] [Batch 72/169] [D loss: 0.695203] [G loss: 0.684657]\n",
      "[Epoch 13/200] [Batch 73/169] [D loss: 0.691219] [G loss: 0.674188]\n",
      "[Epoch 13/200] [Batch 74/169] [D loss: 0.689147] [G loss: 0.672058]\n",
      "[Epoch 13/200] [Batch 75/169] [D loss: 0.699043] [G loss: 0.676312]\n",
      "[Epoch 13/200] [Batch 76/169] [D loss: 0.693390] [G loss: 0.674096]\n",
      "[Epoch 13/200] [Batch 77/169] [D loss: 0.697400] [G loss: 0.660555]\n",
      "[Epoch 13/200] [Batch 78/169] [D loss: 0.708919] [G loss: 0.677977]\n",
      "[Epoch 13/200] [Batch 79/169] [D loss: 0.703082] [G loss: 0.679819]\n",
      "[Epoch 13/200] [Batch 80/169] [D loss: 0.710995] [G loss: 0.669420]\n",
      "[Epoch 13/200] [Batch 81/169] [D loss: 0.712301] [G loss: 0.671171]\n",
      "[Epoch 13/200] [Batch 82/169] [D loss: 0.710023] [G loss: 0.675662]\n",
      "[Epoch 13/200] [Batch 83/169] [D loss: 0.717967] [G loss: 0.682708]\n",
      "[Epoch 13/200] [Batch 84/169] [D loss: 0.715456] [G loss: 0.680191]\n",
      "[Epoch 13/200] [Batch 85/169] [D loss: 0.712317] [G loss: 0.692833]\n",
      "[Epoch 13/200] [Batch 86/169] [D loss: 0.720494] [G loss: 0.679055]\n",
      "[Epoch 13/200] [Batch 87/169] [D loss: 0.716263] [G loss: 0.683363]\n",
      "[Epoch 13/200] [Batch 88/169] [D loss: 0.724639] [G loss: 0.678671]\n",
      "[Epoch 13/200] [Batch 89/169] [D loss: 0.718402] [G loss: 0.681888]\n",
      "[Epoch 13/200] [Batch 90/169] [D loss: 0.722289] [G loss: 0.671205]\n",
      "[Epoch 13/200] [Batch 91/169] [D loss: 0.724715] [G loss: 0.663127]\n",
      "[Epoch 13/200] [Batch 92/169] [D loss: 0.723357] [G loss: 0.667935]\n",
      "[Epoch 13/200] [Batch 93/169] [D loss: 0.719230] [G loss: 0.671852]\n",
      "[Epoch 13/200] [Batch 94/169] [D loss: 0.720081] [G loss: 0.666362]\n",
      "[Epoch 13/200] [Batch 95/169] [D loss: 0.714181] [G loss: 0.673471]\n",
      "[Epoch 13/200] [Batch 96/169] [D loss: 0.711205] [G loss: 0.672271]\n",
      "[Epoch 13/200] [Batch 97/169] [D loss: 0.713053] [G loss: 0.674923]\n",
      "[Epoch 13/200] [Batch 98/169] [D loss: 0.709305] [G loss: 0.675581]\n",
      "[Epoch 13/200] [Batch 99/169] [D loss: 0.707518] [G loss: 0.676193]\n",
      "[Epoch 13/200] [Batch 100/169] [D loss: 0.707889] [G loss: 0.672439]\n",
      "[Epoch 13/200] [Batch 101/169] [D loss: 0.702236] [G loss: 0.682442]\n",
      "[Epoch 13/200] [Batch 102/169] [D loss: 0.704600] [G loss: 0.682887]\n",
      "[Epoch 13/200] [Batch 103/169] [D loss: 0.700389] [G loss: 0.686340]\n",
      "[Epoch 13/200] [Batch 104/169] [D loss: 0.704563] [G loss: 0.685599]\n",
      "[Epoch 13/200] [Batch 105/169] [D loss: 0.704923] [G loss: 0.685391]\n",
      "[Epoch 13/200] [Batch 106/169] [D loss: 0.701371] [G loss: 0.689685]\n",
      "[Epoch 13/200] [Batch 107/169] [D loss: 0.700181] [G loss: 0.690042]\n",
      "[Epoch 13/200] [Batch 108/169] [D loss: 0.700033] [G loss: 0.687389]\n",
      "[Epoch 13/200] [Batch 109/169] [D loss: 0.696506] [G loss: 0.690700]\n",
      "[Epoch 13/200] [Batch 110/169] [D loss: 0.695699] [G loss: 0.694137]\n",
      "[Epoch 13/200] [Batch 111/169] [D loss: 0.697778] [G loss: 0.686404]\n",
      "[Epoch 13/200] [Batch 112/169] [D loss: 0.697479] [G loss: 0.686608]\n",
      "[Epoch 13/200] [Batch 113/169] [D loss: 0.697758] [G loss: 0.689950]\n",
      "[Epoch 13/200] [Batch 114/169] [D loss: 0.698898] [G loss: 0.690383]\n",
      "[Epoch 13/200] [Batch 115/169] [D loss: 0.696154] [G loss: 0.686967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 116/169] [D loss: 0.699443] [G loss: 0.690140]\n",
      "[Epoch 13/200] [Batch 117/169] [D loss: 0.693867] [G loss: 0.692286]\n",
      "[Epoch 13/200] [Batch 118/169] [D loss: 0.694689] [G loss: 0.695756]\n",
      "[Epoch 13/200] [Batch 119/169] [D loss: 0.697598] [G loss: 0.688636]\n",
      "[Epoch 13/200] [Batch 120/169] [D loss: 0.696921] [G loss: 0.694827]\n",
      "[Epoch 13/200] [Batch 121/169] [D loss: 0.698488] [G loss: 0.694366]\n",
      "[Epoch 13/200] [Batch 122/169] [D loss: 0.691745] [G loss: 0.701693]\n",
      "[Epoch 13/200] [Batch 123/169] [D loss: 0.700565] [G loss: 0.693437]\n",
      "[Epoch 13/200] [Batch 124/169] [D loss: 0.694424] [G loss: 0.700994]\n",
      "[Epoch 13/200] [Batch 125/169] [D loss: 0.696111] [G loss: 0.694780]\n",
      "[Epoch 13/200] [Batch 126/169] [D loss: 0.693876] [G loss: 0.699526]\n",
      "[Epoch 13/200] [Batch 127/169] [D loss: 0.694870] [G loss: 0.700433]\n",
      "[Epoch 13/200] [Batch 128/169] [D loss: 0.694381] [G loss: 0.698647]\n",
      "[Epoch 13/200] [Batch 129/169] [D loss: 0.694902] [G loss: 0.697613]\n",
      "[Epoch 13/200] [Batch 130/169] [D loss: 0.695323] [G loss: 0.694345]\n",
      "[Epoch 13/200] [Batch 131/169] [D loss: 0.698681] [G loss: 0.697241]\n",
      "[Epoch 13/200] [Batch 132/169] [D loss: 0.696271] [G loss: 0.694159]\n",
      "[Epoch 13/200] [Batch 133/169] [D loss: 0.698981] [G loss: 0.691021]\n",
      "[Epoch 13/200] [Batch 134/169] [D loss: 0.698657] [G loss: 0.691815]\n",
      "[Epoch 13/200] [Batch 135/169] [D loss: 0.698121] [G loss: 0.692912]\n",
      "[Epoch 13/200] [Batch 136/169] [D loss: 0.697476] [G loss: 0.695514]\n",
      "[Epoch 13/200] [Batch 137/169] [D loss: 0.696454] [G loss: 0.696264]\n",
      "[Epoch 13/200] [Batch 138/169] [D loss: 0.696177] [G loss: 0.693663]\n",
      "[Epoch 13/200] [Batch 139/169] [D loss: 0.697524] [G loss: 0.692845]\n",
      "[Epoch 13/200] [Batch 140/169] [D loss: 0.698587] [G loss: 0.697784]\n",
      "[Epoch 13/200] [Batch 141/169] [D loss: 0.697267] [G loss: 0.690693]\n",
      "[Epoch 13/200] [Batch 142/169] [D loss: 0.696495] [G loss: 0.693830]\n",
      "[Epoch 13/200] [Batch 143/169] [D loss: 0.695603] [G loss: 0.694145]\n",
      "[Epoch 13/200] [Batch 144/169] [D loss: 0.695241] [G loss: 0.690141]\n",
      "[Epoch 13/200] [Batch 145/169] [D loss: 0.695885] [G loss: 0.691931]\n",
      "[Epoch 13/200] [Batch 146/169] [D loss: 0.697556] [G loss: 0.692533]\n",
      "[Epoch 13/200] [Batch 147/169] [D loss: 0.695163] [G loss: 0.693297]\n",
      "[Epoch 13/200] [Batch 148/169] [D loss: 0.695408] [G loss: 0.694257]\n",
      "[Epoch 13/200] [Batch 149/169] [D loss: 0.697562] [G loss: 0.696440]\n",
      "[Epoch 13/200] [Batch 150/169] [D loss: 0.693198] [G loss: 0.694896]\n",
      "[Epoch 13/200] [Batch 151/169] [D loss: 0.698379] [G loss: 0.690078]\n",
      "[Epoch 13/200] [Batch 152/169] [D loss: 0.696166] [G loss: 0.690921]\n",
      "[Epoch 13/200] [Batch 153/169] [D loss: 0.694864] [G loss: 0.691316]\n",
      "[Epoch 13/200] [Batch 154/169] [D loss: 0.698383] [G loss: 0.691575]\n",
      "[Epoch 13/200] [Batch 155/169] [D loss: 0.696760] [G loss: 0.692195]\n",
      "[Epoch 13/200] [Batch 156/169] [D loss: 0.697316] [G loss: 0.690015]\n",
      "[Epoch 13/200] [Batch 157/169] [D loss: 0.695432] [G loss: 0.691438]\n",
      "[Epoch 13/200] [Batch 158/169] [D loss: 0.696488] [G loss: 0.689145]\n",
      "[Epoch 13/200] [Batch 159/169] [D loss: 0.696840] [G loss: 0.691932]\n",
      "[Epoch 13/200] [Batch 160/169] [D loss: 0.698760] [G loss: 0.690800]\n",
      "[Epoch 13/200] [Batch 161/169] [D loss: 0.696206] [G loss: 0.693282]\n",
      "[Epoch 13/200] [Batch 162/169] [D loss: 0.695568] [G loss: 0.693710]\n",
      "[Epoch 13/200] [Batch 163/169] [D loss: 0.695188] [G loss: 0.692824]\n",
      "[Epoch 13/200] [Batch 164/169] [D loss: 0.694365] [G loss: 0.696292]\n",
      "[Epoch 13/200] [Batch 165/169] [D loss: 0.696231] [G loss: 0.694290]\n",
      "[Epoch 13/200] [Batch 166/169] [D loss: 0.694721] [G loss: 0.693631]\n",
      "[Epoch 13/200] [Batch 167/169] [D loss: 0.691254] [G loss: 0.695746]\n",
      "[Epoch 13/200] [Batch 168/169] [D loss: 0.694862] [G loss: 0.690575]\n",
      "[Epoch 14/200] [Batch 0/169] [D loss: 0.693517] [G loss: 0.692701]\n",
      "[Epoch 14/200] [Batch 1/169] [D loss: 0.694387] [G loss: 0.691834]\n",
      "[Epoch 14/200] [Batch 2/169] [D loss: 0.693258] [G loss: 0.692481]\n",
      "[Epoch 14/200] [Batch 3/169] [D loss: 0.696444] [G loss: 0.695284]\n",
      "[Epoch 14/200] [Batch 4/169] [D loss: 0.695878] [G loss: 0.692168]\n",
      "[Epoch 14/200] [Batch 5/169] [D loss: 0.692976] [G loss: 0.694784]\n",
      "[Epoch 14/200] [Batch 6/169] [D loss: 0.695443] [G loss: 0.692769]\n",
      "[Epoch 14/200] [Batch 7/169] [D loss: 0.693121] [G loss: 0.693463]\n",
      "[Epoch 14/200] [Batch 8/169] [D loss: 0.693464] [G loss: 0.693751]\n",
      "[Epoch 14/200] [Batch 9/169] [D loss: 0.695194] [G loss: 0.691616]\n",
      "[Epoch 14/200] [Batch 10/169] [D loss: 0.693858] [G loss: 0.691774]\n",
      "[Epoch 14/200] [Batch 11/169] [D loss: 0.693380] [G loss: 0.693503]\n",
      "[Epoch 14/200] [Batch 12/169] [D loss: 0.693801] [G loss: 0.691687]\n",
      "[Epoch 14/200] [Batch 13/169] [D loss: 0.692505] [G loss: 0.694860]\n",
      "[Epoch 14/200] [Batch 14/169] [D loss: 0.693035] [G loss: 0.694090]\n",
      "[Epoch 14/200] [Batch 15/169] [D loss: 0.694097] [G loss: 0.694904]\n",
      "[Epoch 14/200] [Batch 16/169] [D loss: 0.692478] [G loss: 0.696688]\n",
      "[Epoch 14/200] [Batch 17/169] [D loss: 0.692080] [G loss: 0.696214]\n",
      "[Epoch 14/200] [Batch 18/169] [D loss: 0.692591] [G loss: 0.696077]\n",
      "[Epoch 14/200] [Batch 19/169] [D loss: 0.691727] [G loss: 0.697688]\n",
      "[Epoch 14/200] [Batch 20/169] [D loss: 0.691099] [G loss: 0.698663]\n",
      "[Epoch 14/200] [Batch 21/169] [D loss: 0.690691] [G loss: 0.697887]\n",
      "[Epoch 14/200] [Batch 22/169] [D loss: 0.690318] [G loss: 0.698176]\n",
      "[Epoch 14/200] [Batch 23/169] [D loss: 0.690624] [G loss: 0.702527]\n",
      "[Epoch 14/200] [Batch 24/169] [D loss: 0.689773] [G loss: 0.701028]\n",
      "[Epoch 14/200] [Batch 25/169] [D loss: 0.690618] [G loss: 0.701462]\n",
      "[Epoch 14/200] [Batch 26/169] [D loss: 0.688669] [G loss: 0.702168]\n",
      "[Epoch 14/200] [Batch 27/169] [D loss: 0.689132] [G loss: 0.700442]\n",
      "[Epoch 14/200] [Batch 28/169] [D loss: 0.691501] [G loss: 0.699203]\n",
      "[Epoch 14/200] [Batch 29/169] [D loss: 0.690157] [G loss: 0.694274]\n",
      "[Epoch 14/200] [Batch 30/169] [D loss: 0.694463] [G loss: 0.691569]\n",
      "[Epoch 14/200] [Batch 31/169] [D loss: 0.695254] [G loss: 0.690165]\n",
      "[Epoch 14/200] [Batch 32/169] [D loss: 0.693837] [G loss: 0.688889]\n",
      "[Epoch 14/200] [Batch 33/169] [D loss: 0.694243] [G loss: 0.688691]\n",
      "[Epoch 14/200] [Batch 34/169] [D loss: 0.693647] [G loss: 0.688675]\n",
      "[Epoch 14/200] [Batch 35/169] [D loss: 0.694844] [G loss: 0.692952]\n",
      "[Epoch 14/200] [Batch 36/169] [D loss: 0.692104] [G loss: 0.693067]\n",
      "[Epoch 14/200] [Batch 37/169] [D loss: 0.690525] [G loss: 0.692632]\n",
      "[Epoch 14/200] [Batch 38/169] [D loss: 0.692108] [G loss: 0.693581]\n",
      "[Epoch 14/200] [Batch 39/169] [D loss: 0.690699] [G loss: 0.694424]\n",
      "[Epoch 14/200] [Batch 40/169] [D loss: 0.690966] [G loss: 0.695041]\n",
      "[Epoch 14/200] [Batch 41/169] [D loss: 0.688095] [G loss: 0.696650]\n",
      "[Epoch 14/200] [Batch 42/169] [D loss: 0.690134] [G loss: 0.695668]\n",
      "[Epoch 14/200] [Batch 43/169] [D loss: 0.690013] [G loss: 0.698849]\n",
      "[Epoch 14/200] [Batch 44/169] [D loss: 0.690102] [G loss: 0.697120]\n",
      "[Epoch 14/200] [Batch 45/169] [D loss: 0.689018] [G loss: 0.698196]\n",
      "[Epoch 14/200] [Batch 46/169] [D loss: 0.690917] [G loss: 0.697540]\n",
      "[Epoch 14/200] [Batch 47/169] [D loss: 0.690431] [G loss: 0.699300]\n",
      "[Epoch 14/200] [Batch 48/169] [D loss: 0.687477] [G loss: 0.695794]\n",
      "[Epoch 14/200] [Batch 49/169] [D loss: 0.688992] [G loss: 0.695616]\n",
      "[Epoch 14/200] [Batch 50/169] [D loss: 0.690593] [G loss: 0.697390]\n",
      "[Epoch 14/200] [Batch 51/169] [D loss: 0.688345] [G loss: 0.700170]\n",
      "[Epoch 14/200] [Batch 52/169] [D loss: 0.691099] [G loss: 0.698217]\n",
      "[Epoch 14/200] [Batch 53/169] [D loss: 0.690511] [G loss: 0.695374]\n",
      "[Epoch 14/200] [Batch 54/169] [D loss: 0.690997] [G loss: 0.698249]\n",
      "[Epoch 14/200] [Batch 55/169] [D loss: 0.691174] [G loss: 0.699385]\n",
      "[Epoch 14/200] [Batch 56/169] [D loss: 0.689843] [G loss: 0.695485]\n",
      "[Epoch 14/200] [Batch 57/169] [D loss: 0.692244] [G loss: 0.695306]\n",
      "[Epoch 14/200] [Batch 58/169] [D loss: 0.690149] [G loss: 0.696650]\n",
      "[Epoch 14/200] [Batch 59/169] [D loss: 0.692065] [G loss: 0.694505]\n",
      "[Epoch 14/200] [Batch 60/169] [D loss: 0.692116] [G loss: 0.698289]\n",
      "[Epoch 14/200] [Batch 61/169] [D loss: 0.689591] [G loss: 0.696229]\n",
      "[Epoch 14/200] [Batch 62/169] [D loss: 0.692040] [G loss: 0.697459]\n",
      "[Epoch 14/200] [Batch 63/169] [D loss: 0.691659] [G loss: 0.699014]\n",
      "[Epoch 14/200] [Batch 64/169] [D loss: 0.691147] [G loss: 0.693431]\n",
      "[Epoch 14/200] [Batch 65/169] [D loss: 0.692678] [G loss: 0.692076]\n",
      "[Epoch 14/200] [Batch 66/169] [D loss: 0.691805] [G loss: 0.698104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 67/169] [D loss: 0.692558] [G loss: 0.693581]\n",
      "[Epoch 14/200] [Batch 68/169] [D loss: 0.693279] [G loss: 0.693121]\n",
      "[Epoch 14/200] [Batch 69/169] [D loss: 0.693349] [G loss: 0.692978]\n",
      "[Epoch 14/200] [Batch 70/169] [D loss: 0.693735] [G loss: 0.694188]\n",
      "[Epoch 14/200] [Batch 71/169] [D loss: 0.693736] [G loss: 0.691161]\n",
      "[Epoch 14/200] [Batch 72/169] [D loss: 0.692953] [G loss: 0.693566]\n",
      "[Epoch 14/200] [Batch 73/169] [D loss: 0.692899] [G loss: 0.694901]\n",
      "[Epoch 14/200] [Batch 74/169] [D loss: 0.691971] [G loss: 0.693188]\n",
      "[Epoch 14/200] [Batch 75/169] [D loss: 0.695581] [G loss: 0.689862]\n",
      "[Epoch 14/200] [Batch 76/169] [D loss: 0.693820] [G loss: 0.689822]\n",
      "[Epoch 14/200] [Batch 77/169] [D loss: 0.692291] [G loss: 0.694169]\n",
      "[Epoch 14/200] [Batch 78/169] [D loss: 0.695765] [G loss: 0.690760]\n",
      "[Epoch 14/200] [Batch 79/169] [D loss: 0.691853] [G loss: 0.693262]\n",
      "[Epoch 14/200] [Batch 80/169] [D loss: 0.693571] [G loss: 0.693428]\n",
      "[Epoch 14/200] [Batch 81/169] [D loss: 0.692409] [G loss: 0.693909]\n",
      "[Epoch 14/200] [Batch 82/169] [D loss: 0.689689] [G loss: 0.696645]\n",
      "[Epoch 14/200] [Batch 83/169] [D loss: 0.693047] [G loss: 0.695580]\n",
      "[Epoch 14/200] [Batch 84/169] [D loss: 0.692033] [G loss: 0.696067]\n",
      "[Epoch 14/200] [Batch 85/169] [D loss: 0.693137] [G loss: 0.696428]\n",
      "[Epoch 14/200] [Batch 86/169] [D loss: 0.690942] [G loss: 0.698062]\n",
      "[Epoch 14/200] [Batch 87/169] [D loss: 0.691743] [G loss: 0.698277]\n",
      "[Epoch 14/200] [Batch 88/169] [D loss: 0.690901] [G loss: 0.695807]\n",
      "[Epoch 14/200] [Batch 89/169] [D loss: 0.691284] [G loss: 0.695231]\n",
      "[Epoch 14/200] [Batch 90/169] [D loss: 0.691197] [G loss: 0.694810]\n",
      "[Epoch 14/200] [Batch 91/169] [D loss: 0.691396] [G loss: 0.696504]\n",
      "[Epoch 14/200] [Batch 92/169] [D loss: 0.690155] [G loss: 0.694055]\n",
      "[Epoch 14/200] [Batch 93/169] [D loss: 0.691585] [G loss: 0.697184]\n",
      "[Epoch 14/200] [Batch 94/169] [D loss: 0.689882] [G loss: 0.694323]\n",
      "[Epoch 14/200] [Batch 95/169] [D loss: 0.691111] [G loss: 0.697908]\n",
      "[Epoch 14/200] [Batch 96/169] [D loss: 0.689320] [G loss: 0.696369]\n",
      "[Epoch 14/200] [Batch 97/169] [D loss: 0.691295] [G loss: 0.698221]\n",
      "[Epoch 14/200] [Batch 98/169] [D loss: 0.689705] [G loss: 0.695125]\n",
      "[Epoch 14/200] [Batch 99/169] [D loss: 0.691531] [G loss: 0.694474]\n",
      "[Epoch 14/200] [Batch 100/169] [D loss: 0.693081] [G loss: 0.693869]\n",
      "[Epoch 14/200] [Batch 101/169] [D loss: 0.691245] [G loss: 0.691328]\n",
      "[Epoch 14/200] [Batch 102/169] [D loss: 0.690054] [G loss: 0.695776]\n",
      "[Epoch 14/200] [Batch 103/169] [D loss: 0.693965] [G loss: 0.692698]\n",
      "[Epoch 14/200] [Batch 104/169] [D loss: 0.693723] [G loss: 0.693901]\n",
      "[Epoch 14/200] [Batch 105/169] [D loss: 0.691597] [G loss: 0.694830]\n",
      "[Epoch 14/200] [Batch 106/169] [D loss: 0.693358] [G loss: 0.693253]\n",
      "[Epoch 14/200] [Batch 107/169] [D loss: 0.692325] [G loss: 0.691429]\n",
      "[Epoch 14/200] [Batch 108/169] [D loss: 0.694270] [G loss: 0.692960]\n",
      "[Epoch 14/200] [Batch 109/169] [D loss: 0.694766] [G loss: 0.695186]\n",
      "[Epoch 14/200] [Batch 110/169] [D loss: 0.695001] [G loss: 0.691528]\n",
      "[Epoch 14/200] [Batch 111/169] [D loss: 0.692654] [G loss: 0.694935]\n",
      "[Epoch 14/200] [Batch 112/169] [D loss: 0.691987] [G loss: 0.696304]\n",
      "[Epoch 14/200] [Batch 113/169] [D loss: 0.692046] [G loss: 0.693467]\n",
      "[Epoch 14/200] [Batch 114/169] [D loss: 0.692094] [G loss: 0.695737]\n",
      "[Epoch 14/200] [Batch 115/169] [D loss: 0.693933] [G loss: 0.693743]\n",
      "[Epoch 14/200] [Batch 116/169] [D loss: 0.692074] [G loss: 0.697620]\n",
      "[Epoch 14/200] [Batch 117/169] [D loss: 0.693064] [G loss: 0.697558]\n",
      "[Epoch 14/200] [Batch 118/169] [D loss: 0.690633] [G loss: 0.701081]\n",
      "[Epoch 14/200] [Batch 119/169] [D loss: 0.692248] [G loss: 0.704048]\n",
      "[Epoch 14/200] [Batch 120/169] [D loss: 0.691868] [G loss: 0.705930]\n",
      "[Epoch 14/200] [Batch 121/169] [D loss: 0.688944] [G loss: 0.704047]\n",
      "[Epoch 14/200] [Batch 122/169] [D loss: 0.689335] [G loss: 0.705452]\n",
      "[Epoch 14/200] [Batch 123/169] [D loss: 0.688589] [G loss: 0.707675]\n",
      "[Epoch 14/200] [Batch 124/169] [D loss: 0.688053] [G loss: 0.708710]\n",
      "[Epoch 14/200] [Batch 125/169] [D loss: 0.687271] [G loss: 0.711180]\n",
      "[Epoch 14/200] [Batch 126/169] [D loss: 0.688007] [G loss: 0.704468]\n",
      "[Epoch 14/200] [Batch 127/169] [D loss: 0.695583] [G loss: 0.701538]\n",
      "[Epoch 14/200] [Batch 128/169] [D loss: 0.695495] [G loss: 0.693075]\n",
      "[Epoch 14/200] [Batch 129/169] [D loss: 0.695059] [G loss: 0.685426]\n",
      "[Epoch 14/200] [Batch 130/169] [D loss: 0.697905] [G loss: 0.677657]\n",
      "[Epoch 14/200] [Batch 131/169] [D loss: 0.698375] [G loss: 0.675145]\n",
      "[Epoch 14/200] [Batch 132/169] [D loss: 0.695973] [G loss: 0.674432]\n",
      "[Epoch 14/200] [Batch 133/169] [D loss: 0.694046] [G loss: 0.672030]\n",
      "[Epoch 14/200] [Batch 134/169] [D loss: 0.693299] [G loss: 0.676176]\n",
      "[Epoch 14/200] [Batch 135/169] [D loss: 0.695347] [G loss: 0.678463]\n",
      "[Epoch 14/200] [Batch 136/169] [D loss: 0.692699] [G loss: 0.681765]\n",
      "[Epoch 14/200] [Batch 137/169] [D loss: 0.694177] [G loss: 0.682751]\n",
      "[Epoch 14/200] [Batch 138/169] [D loss: 0.694189] [G loss: 0.682248]\n",
      "[Epoch 14/200] [Batch 139/169] [D loss: 0.691321] [G loss: 0.686455]\n",
      "[Epoch 14/200] [Batch 140/169] [D loss: 0.690495] [G loss: 0.691259]\n",
      "[Epoch 14/200] [Batch 141/169] [D loss: 0.691619] [G loss: 0.692540]\n",
      "[Epoch 14/200] [Batch 142/169] [D loss: 0.689120] [G loss: 0.688313]\n",
      "[Epoch 14/200] [Batch 143/169] [D loss: 0.694858] [G loss: 0.690555]\n",
      "[Epoch 14/200] [Batch 144/169] [D loss: 0.694212] [G loss: 0.689767]\n",
      "[Epoch 14/200] [Batch 145/169] [D loss: 0.693468] [G loss: 0.692893]\n",
      "[Epoch 14/200] [Batch 146/169] [D loss: 0.697515] [G loss: 0.686103]\n",
      "[Epoch 14/200] [Batch 147/169] [D loss: 0.697974] [G loss: 0.691800]\n",
      "[Epoch 14/200] [Batch 148/169] [D loss: 0.696392] [G loss: 0.690610]\n",
      "[Epoch 14/200] [Batch 149/169] [D loss: 0.694512] [G loss: 0.690764]\n",
      "[Epoch 14/200] [Batch 150/169] [D loss: 0.697681] [G loss: 0.688373]\n",
      "[Epoch 14/200] [Batch 151/169] [D loss: 0.698444] [G loss: 0.689996]\n",
      "[Epoch 14/200] [Batch 152/169] [D loss: 0.698410] [G loss: 0.691863]\n",
      "[Epoch 14/200] [Batch 153/169] [D loss: 0.698632] [G loss: 0.690098]\n",
      "[Epoch 14/200] [Batch 154/169] [D loss: 0.699187] [G loss: 0.686482]\n",
      "[Epoch 14/200] [Batch 155/169] [D loss: 0.698325] [G loss: 0.688689]\n",
      "[Epoch 14/200] [Batch 156/169] [D loss: 0.696582] [G loss: 0.690539]\n",
      "[Epoch 14/200] [Batch 157/169] [D loss: 0.698274] [G loss: 0.692296]\n",
      "[Epoch 14/200] [Batch 158/169] [D loss: 0.696231] [G loss: 0.689860]\n",
      "[Epoch 14/200] [Batch 159/169] [D loss: 0.694423] [G loss: 0.691603]\n",
      "[Epoch 14/200] [Batch 160/169] [D loss: 0.695482] [G loss: 0.691106]\n",
      "[Epoch 14/200] [Batch 161/169] [D loss: 0.696291] [G loss: 0.694124]\n",
      "[Epoch 14/200] [Batch 162/169] [D loss: 0.694493] [G loss: 0.693742]\n",
      "[Epoch 14/200] [Batch 163/169] [D loss: 0.693177] [G loss: 0.696801]\n",
      "[Epoch 14/200] [Batch 164/169] [D loss: 0.692892] [G loss: 0.697862]\n",
      "[Epoch 14/200] [Batch 165/169] [D loss: 0.692811] [G loss: 0.701975]\n",
      "[Epoch 14/200] [Batch 166/169] [D loss: 0.693206] [G loss: 0.700004]\n",
      "[Epoch 14/200] [Batch 167/169] [D loss: 0.692465] [G loss: 0.700546]\n",
      "[Epoch 14/200] [Batch 168/169] [D loss: 0.691208] [G loss: 0.696677]\n",
      "[Epoch 15/200] [Batch 0/169] [D loss: 0.689733] [G loss: 0.705161]\n",
      "[Epoch 15/200] [Batch 1/169] [D loss: 0.691421] [G loss: 0.707652]\n",
      "[Epoch 15/200] [Batch 2/169] [D loss: 0.691274] [G loss: 0.704421]\n",
      "[Epoch 15/200] [Batch 3/169] [D loss: 0.690328] [G loss: 0.702375]\n",
      "[Epoch 15/200] [Batch 4/169] [D loss: 0.694567] [G loss: 0.700493]\n",
      "[Epoch 15/200] [Batch 5/169] [D loss: 0.695566] [G loss: 0.697515]\n",
      "[Epoch 15/200] [Batch 6/169] [D loss: 0.694807] [G loss: 0.692023]\n",
      "[Epoch 15/200] [Batch 7/169] [D loss: 0.698083] [G loss: 0.687864]\n",
      "[Epoch 15/200] [Batch 8/169] [D loss: 0.698821] [G loss: 0.682866]\n",
      "[Epoch 15/200] [Batch 9/169] [D loss: 0.697605] [G loss: 0.684253]\n",
      "[Epoch 15/200] [Batch 10/169] [D loss: 0.699040] [G loss: 0.677975]\n",
      "[Epoch 15/200] [Batch 11/169] [D loss: 0.696593] [G loss: 0.682781]\n",
      "[Epoch 15/200] [Batch 12/169] [D loss: 0.693418] [G loss: 0.685486]\n",
      "[Epoch 15/200] [Batch 13/169] [D loss: 0.694422] [G loss: 0.684317]\n",
      "[Epoch 15/200] [Batch 14/169] [D loss: 0.694432] [G loss: 0.687753]\n",
      "[Epoch 15/200] [Batch 15/169] [D loss: 0.693501] [G loss: 0.689592]\n",
      "[Epoch 15/200] [Batch 16/169] [D loss: 0.694926] [G loss: 0.690331]\n",
      "[Epoch 15/200] [Batch 17/169] [D loss: 0.694565] [G loss: 0.690420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 18/169] [D loss: 0.694703] [G loss: 0.689142]\n",
      "[Epoch 15/200] [Batch 19/169] [D loss: 0.694440] [G loss: 0.693085]\n",
      "[Epoch 15/200] [Batch 20/169] [D loss: 0.696244] [G loss: 0.688499]\n",
      "[Epoch 15/200] [Batch 21/169] [D loss: 0.697138] [G loss: 0.688313]\n",
      "[Epoch 15/200] [Batch 22/169] [D loss: 0.697311] [G loss: 0.688655]\n",
      "[Epoch 15/200] [Batch 23/169] [D loss: 0.698380] [G loss: 0.688200]\n",
      "[Epoch 15/200] [Batch 24/169] [D loss: 0.696820] [G loss: 0.689402]\n",
      "[Epoch 15/200] [Batch 25/169] [D loss: 0.696640] [G loss: 0.690170]\n",
      "[Epoch 15/200] [Batch 26/169] [D loss: 0.695823] [G loss: 0.692385]\n",
      "[Epoch 15/200] [Batch 27/169] [D loss: 0.697560] [G loss: 0.690275]\n",
      "[Epoch 15/200] [Batch 28/169] [D loss: 0.696818] [G loss: 0.691553]\n",
      "[Epoch 15/200] [Batch 29/169] [D loss: 0.696507] [G loss: 0.690437]\n",
      "[Epoch 15/200] [Batch 30/169] [D loss: 0.694614] [G loss: 0.692291]\n",
      "[Epoch 15/200] [Batch 31/169] [D loss: 0.693098] [G loss: 0.691817]\n",
      "[Epoch 15/200] [Batch 32/169] [D loss: 0.693602] [G loss: 0.694917]\n",
      "[Epoch 15/200] [Batch 33/169] [D loss: 0.692228] [G loss: 0.695707]\n",
      "[Epoch 15/200] [Batch 34/169] [D loss: 0.692740] [G loss: 0.693802]\n",
      "[Epoch 15/200] [Batch 35/169] [D loss: 0.691875] [G loss: 0.696201]\n",
      "[Epoch 15/200] [Batch 36/169] [D loss: 0.692158] [G loss: 0.697783]\n",
      "[Epoch 15/200] [Batch 37/169] [D loss: 0.692998] [G loss: 0.698582]\n",
      "[Epoch 15/200] [Batch 38/169] [D loss: 0.691344] [G loss: 0.697312]\n",
      "[Epoch 15/200] [Batch 39/169] [D loss: 0.692599] [G loss: 0.698345]\n",
      "[Epoch 15/200] [Batch 40/169] [D loss: 0.692881] [G loss: 0.699841]\n",
      "[Epoch 15/200] [Batch 41/169] [D loss: 0.691696] [G loss: 0.700166]\n",
      "[Epoch 15/200] [Batch 42/169] [D loss: 0.689001] [G loss: 0.700572]\n",
      "[Epoch 15/200] [Batch 43/169] [D loss: 0.688918] [G loss: 0.701053]\n",
      "[Epoch 15/200] [Batch 44/169] [D loss: 0.691284] [G loss: 0.703388]\n",
      "[Epoch 15/200] [Batch 45/169] [D loss: 0.689678] [G loss: 0.700983]\n",
      "[Epoch 15/200] [Batch 46/169] [D loss: 0.689569] [G loss: 0.698039]\n",
      "[Epoch 15/200] [Batch 47/169] [D loss: 0.690557] [G loss: 0.698978]\n",
      "[Epoch 15/200] [Batch 48/169] [D loss: 0.688114] [G loss: 0.702194]\n",
      "[Epoch 15/200] [Batch 49/169] [D loss: 0.689380] [G loss: 0.702725]\n",
      "[Epoch 15/200] [Batch 50/169] [D loss: 0.690860] [G loss: 0.702688]\n",
      "[Epoch 15/200] [Batch 51/169] [D loss: 0.689237] [G loss: 0.702019]\n",
      "[Epoch 15/200] [Batch 52/169] [D loss: 0.689304] [G loss: 0.700668]\n",
      "[Epoch 15/200] [Batch 53/169] [D loss: 0.690894] [G loss: 0.700735]\n",
      "[Epoch 15/200] [Batch 54/169] [D loss: 0.689535] [G loss: 0.703226]\n",
      "[Epoch 15/200] [Batch 55/169] [D loss: 0.689739] [G loss: 0.702674]\n",
      "[Epoch 15/200] [Batch 56/169] [D loss: 0.692086] [G loss: 0.699936]\n",
      "[Epoch 15/200] [Batch 57/169] [D loss: 0.692954] [G loss: 0.699125]\n",
      "[Epoch 15/200] [Batch 58/169] [D loss: 0.695830] [G loss: 0.695946]\n",
      "[Epoch 15/200] [Batch 59/169] [D loss: 0.694441] [G loss: 0.694904]\n",
      "[Epoch 15/200] [Batch 60/169] [D loss: 0.694363] [G loss: 0.687195]\n",
      "[Epoch 15/200] [Batch 61/169] [D loss: 0.699899] [G loss: 0.682674]\n",
      "[Epoch 15/200] [Batch 62/169] [D loss: 0.696977] [G loss: 0.684318]\n",
      "[Epoch 15/200] [Batch 63/169] [D loss: 0.695609] [G loss: 0.684139]\n",
      "[Epoch 15/200] [Batch 64/169] [D loss: 0.695939] [G loss: 0.685648]\n",
      "[Epoch 15/200] [Batch 65/169] [D loss: 0.692162] [G loss: 0.689089]\n",
      "[Epoch 15/200] [Batch 66/169] [D loss: 0.691588] [G loss: 0.691534]\n",
      "[Epoch 15/200] [Batch 67/169] [D loss: 0.690886] [G loss: 0.693985]\n",
      "[Epoch 15/200] [Batch 68/169] [D loss: 0.690903] [G loss: 0.694698]\n",
      "[Epoch 15/200] [Batch 69/169] [D loss: 0.687118] [G loss: 0.699330]\n",
      "[Epoch 15/200] [Batch 70/169] [D loss: 0.687128] [G loss: 0.697661]\n",
      "[Epoch 15/200] [Batch 71/169] [D loss: 0.685746] [G loss: 0.701529]\n",
      "[Epoch 15/200] [Batch 72/169] [D loss: 0.688540] [G loss: 0.698311]\n",
      "[Epoch 15/200] [Batch 73/169] [D loss: 0.688163] [G loss: 0.699141]\n",
      "[Epoch 15/200] [Batch 74/169] [D loss: 0.687749] [G loss: 0.701582]\n",
      "[Epoch 15/200] [Batch 75/169] [D loss: 0.686875] [G loss: 0.696910]\n",
      "[Epoch 15/200] [Batch 76/169] [D loss: 0.690597] [G loss: 0.697018]\n",
      "[Epoch 15/200] [Batch 77/169] [D loss: 0.689934] [G loss: 0.694681]\n",
      "[Epoch 15/200] [Batch 78/169] [D loss: 0.688380] [G loss: 0.692205]\n",
      "[Epoch 15/200] [Batch 79/169] [D loss: 0.691198] [G loss: 0.692567]\n",
      "[Epoch 15/200] [Batch 80/169] [D loss: 0.687623] [G loss: 0.689792]\n",
      "[Epoch 15/200] [Batch 81/169] [D loss: 0.689738] [G loss: 0.689071]\n",
      "[Epoch 15/200] [Batch 82/169] [D loss: 0.692239] [G loss: 0.689552]\n",
      "[Epoch 15/200] [Batch 83/169] [D loss: 0.693988] [G loss: 0.689000]\n",
      "[Epoch 15/200] [Batch 84/169] [D loss: 0.695185] [G loss: 0.685346]\n",
      "[Epoch 15/200] [Batch 85/169] [D loss: 0.699035] [G loss: 0.682716]\n",
      "[Epoch 15/200] [Batch 86/169] [D loss: 0.699816] [G loss: 0.685996]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9f82e494839d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msavepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'image_linear_GD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-acd13e2ff54d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# 创建ground truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m    150\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load2 = torch.load('net_state_dict.pth')\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "\n",
    "\n",
    "generator.load_state_dict(load2['generator'])\n",
    "generator.apply(weights_init_normal)             ### 初始化模型，保留线性\n",
    "discriminator.load_state_dict(load2['discriminator'])\n",
    "discriminator.apply(weights_init_normal)   \n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "optimizer_G.load_state_dict(load2['optimizer_G'])\n",
    "optimizer_D.load_state_dict(load2['optimizer_D'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "savepath = 'image_linear_GD'\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8f435b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/169] [D loss: 0.692512] [G loss: 0.682857]\n",
      "[Epoch 0/200] [Batch 1/169] [D loss: 0.692431] [G loss: 0.683333]\n",
      "[Epoch 0/200] [Batch 2/169] [D loss: 0.692656] [G loss: 0.682603]\n",
      "[Epoch 0/200] [Batch 3/169] [D loss: 0.693506] [G loss: 0.682779]\n",
      "[Epoch 0/200] [Batch 4/169] [D loss: 0.693073] [G loss: 0.682504]\n",
      "[Epoch 0/200] [Batch 5/169] [D loss: 0.694072] [G loss: 0.681734]\n",
      "[Epoch 0/200] [Batch 6/169] [D loss: 0.693388] [G loss: 0.682588]\n",
      "[Epoch 0/200] [Batch 7/169] [D loss: 0.693154] [G loss: 0.683092]\n",
      "[Epoch 0/200] [Batch 8/169] [D loss: 0.692975] [G loss: 0.683220]\n",
      "[Epoch 0/200] [Batch 9/169] [D loss: 0.693567] [G loss: 0.682560]\n",
      "[Epoch 0/200] [Batch 10/169] [D loss: 0.693407] [G loss: 0.683284]\n",
      "[Epoch 0/200] [Batch 11/169] [D loss: 0.693736] [G loss: 0.683485]\n",
      "[Epoch 0/200] [Batch 12/169] [D loss: 0.693730] [G loss: 0.683889]\n",
      "[Epoch 0/200] [Batch 13/169] [D loss: 0.692843] [G loss: 0.684062]\n",
      "[Epoch 0/200] [Batch 14/169] [D loss: 0.693574] [G loss: 0.684952]\n",
      "[Epoch 0/200] [Batch 15/169] [D loss: 0.692543] [G loss: 0.685560]\n",
      "[Epoch 0/200] [Batch 16/169] [D loss: 0.692886] [G loss: 0.683289]\n",
      "[Epoch 0/200] [Batch 17/169] [D loss: 0.692760] [G loss: 0.685899]\n",
      "[Epoch 0/200] [Batch 18/169] [D loss: 0.693033] [G loss: 0.684349]\n",
      "[Epoch 0/200] [Batch 19/169] [D loss: 0.693186] [G loss: 0.685039]\n",
      "[Epoch 0/200] [Batch 20/169] [D loss: 0.693229] [G loss: 0.684321]\n",
      "[Epoch 0/200] [Batch 21/169] [D loss: 0.693848] [G loss: 0.683987]\n",
      "[Epoch 0/200] [Batch 22/169] [D loss: 0.693959] [G loss: 0.684305]\n",
      "[Epoch 0/200] [Batch 23/169] [D loss: 0.693134] [G loss: 0.684706]\n",
      "[Epoch 0/200] [Batch 24/169] [D loss: 0.692754] [G loss: 0.684909]\n",
      "[Epoch 0/200] [Batch 25/169] [D loss: 0.693496] [G loss: 0.685818]\n",
      "[Epoch 0/200] [Batch 26/169] [D loss: 0.693719] [G loss: 0.685663]\n",
      "[Epoch 0/200] [Batch 27/169] [D loss: 0.692866] [G loss: 0.685946]\n",
      "[Epoch 0/200] [Batch 28/169] [D loss: 0.692717] [G loss: 0.685955]\n",
      "[Epoch 0/200] [Batch 29/169] [D loss: 0.693395] [G loss: 0.686763]\n",
      "[Epoch 0/200] [Batch 30/169] [D loss: 0.693241] [G loss: 0.685434]\n",
      "[Epoch 0/200] [Batch 31/169] [D loss: 0.693814] [G loss: 0.684959]\n",
      "[Epoch 0/200] [Batch 32/169] [D loss: 0.693595] [G loss: 0.686331]\n",
      "[Epoch 0/200] [Batch 33/169] [D loss: 0.693000] [G loss: 0.686695]\n",
      "[Epoch 0/200] [Batch 34/169] [D loss: 0.692996] [G loss: 0.686027]\n",
      "[Epoch 0/200] [Batch 35/169] [D loss: 0.693454] [G loss: 0.687284]\n",
      "[Epoch 0/200] [Batch 36/169] [D loss: 0.692658] [G loss: 0.687558]\n",
      "[Epoch 0/200] [Batch 37/169] [D loss: 0.693305] [G loss: 0.686522]\n",
      "[Epoch 0/200] [Batch 38/169] [D loss: 0.693428] [G loss: 0.687848]\n",
      "[Epoch 0/200] [Batch 39/169] [D loss: 0.692337] [G loss: 0.687670]\n",
      "[Epoch 0/200] [Batch 40/169] [D loss: 0.692456] [G loss: 0.687010]\n",
      "[Epoch 0/200] [Batch 41/169] [D loss: 0.692954] [G loss: 0.687689]\n",
      "[Epoch 0/200] [Batch 42/169] [D loss: 0.693526] [G loss: 0.686853]\n",
      "[Epoch 0/200] [Batch 43/169] [D loss: 0.693344] [G loss: 0.687795]\n",
      "[Epoch 0/200] [Batch 44/169] [D loss: 0.692714] [G loss: 0.687494]\n",
      "[Epoch 0/200] [Batch 45/169] [D loss: 0.693469] [G loss: 0.688051]\n",
      "[Epoch 0/200] [Batch 46/169] [D loss: 0.693095] [G loss: 0.689400]\n",
      "[Epoch 0/200] [Batch 47/169] [D loss: 0.692857] [G loss: 0.689410]\n",
      "[Epoch 0/200] [Batch 48/169] [D loss: 0.693696] [G loss: 0.688797]\n",
      "[Epoch 0/200] [Batch 49/169] [D loss: 0.693090] [G loss: 0.688191]\n",
      "[Epoch 0/200] [Batch 50/169] [D loss: 0.693643] [G loss: 0.689112]\n",
      "[Epoch 0/200] [Batch 51/169] [D loss: 0.693295] [G loss: 0.689619]\n",
      "[Epoch 0/200] [Batch 52/169] [D loss: 0.692461] [G loss: 0.689265]\n",
      "[Epoch 0/200] [Batch 53/169] [D loss: 0.693614] [G loss: 0.689146]\n",
      "[Epoch 0/200] [Batch 54/169] [D loss: 0.693084] [G loss: 0.690005]\n",
      "[Epoch 0/200] [Batch 55/169] [D loss: 0.692766] [G loss: 0.690678]\n",
      "[Epoch 0/200] [Batch 56/169] [D loss: 0.693110] [G loss: 0.689540]\n",
      "[Epoch 0/200] [Batch 57/169] [D loss: 0.692636] [G loss: 0.690781]\n",
      "[Epoch 0/200] [Batch 58/169] [D loss: 0.692878] [G loss: 0.689500]\n",
      "[Epoch 0/200] [Batch 59/169] [D loss: 0.692787] [G loss: 0.690735]\n",
      "[Epoch 0/200] [Batch 60/169] [D loss: 0.692726] [G loss: 0.690446]\n",
      "[Epoch 0/200] [Batch 61/169] [D loss: 0.693074] [G loss: 0.688570]\n",
      "[Epoch 0/200] [Batch 62/169] [D loss: 0.692965] [G loss: 0.690618]\n",
      "[Epoch 0/200] [Batch 63/169] [D loss: 0.693586] [G loss: 0.691543]\n",
      "[Epoch 0/200] [Batch 64/169] [D loss: 0.692514] [G loss: 0.690283]\n",
      "[Epoch 0/200] [Batch 65/169] [D loss: 0.692500] [G loss: 0.691558]\n",
      "[Epoch 0/200] [Batch 66/169] [D loss: 0.693140] [G loss: 0.690308]\n",
      "[Epoch 0/200] [Batch 67/169] [D loss: 0.693365] [G loss: 0.689086]\n",
      "[Epoch 0/200] [Batch 68/169] [D loss: 0.693853] [G loss: 0.691067]\n",
      "[Epoch 0/200] [Batch 69/169] [D loss: 0.692815] [G loss: 0.692185]\n",
      "[Epoch 0/200] [Batch 70/169] [D loss: 0.693174] [G loss: 0.691783]\n",
      "[Epoch 0/200] [Batch 71/169] [D loss: 0.693410] [G loss: 0.691583]\n",
      "[Epoch 0/200] [Batch 72/169] [D loss: 0.693744] [G loss: 0.689540]\n",
      "[Epoch 0/200] [Batch 73/169] [D loss: 0.693037] [G loss: 0.692497]\n",
      "[Epoch 0/200] [Batch 74/169] [D loss: 0.693729] [G loss: 0.692734]\n",
      "[Epoch 0/200] [Batch 75/169] [D loss: 0.692120] [G loss: 0.692044]\n",
      "[Epoch 0/200] [Batch 76/169] [D loss: 0.693467] [G loss: 0.691463]\n",
      "[Epoch 0/200] [Batch 77/169] [D loss: 0.693053] [G loss: 0.693099]\n",
      "[Epoch 0/200] [Batch 78/169] [D loss: 0.692928] [G loss: 0.693358]\n",
      "[Epoch 0/200] [Batch 79/169] [D loss: 0.693682] [G loss: 0.691351]\n",
      "[Epoch 0/200] [Batch 80/169] [D loss: 0.693676] [G loss: 0.692179]\n",
      "[Epoch 0/200] [Batch 81/169] [D loss: 0.692771] [G loss: 0.692351]\n",
      "[Epoch 0/200] [Batch 82/169] [D loss: 0.693098] [G loss: 0.692597]\n",
      "[Epoch 0/200] [Batch 83/169] [D loss: 0.691973] [G loss: 0.693252]\n",
      "[Epoch 0/200] [Batch 84/169] [D loss: 0.693091] [G loss: 0.692811]\n",
      "[Epoch 0/200] [Batch 85/169] [D loss: 0.693365] [G loss: 0.693847]\n",
      "[Epoch 0/200] [Batch 86/169] [D loss: 0.693655] [G loss: 0.692745]\n",
      "[Epoch 0/200] [Batch 87/169] [D loss: 0.693390] [G loss: 0.693818]\n",
      "[Epoch 0/200] [Batch 88/169] [D loss: 0.692697] [G loss: 0.693656]\n",
      "[Epoch 0/200] [Batch 89/169] [D loss: 0.693000] [G loss: 0.693952]\n",
      "[Epoch 0/200] [Batch 90/169] [D loss: 0.693008] [G loss: 0.694183]\n",
      "[Epoch 0/200] [Batch 91/169] [D loss: 0.692063] [G loss: 0.695399]\n",
      "[Epoch 0/200] [Batch 92/169] [D loss: 0.692031] [G loss: 0.694024]\n",
      "[Epoch 0/200] [Batch 93/169] [D loss: 0.692723] [G loss: 0.694223]\n",
      "[Epoch 0/200] [Batch 94/169] [D loss: 0.694156] [G loss: 0.694198]\n",
      "[Epoch 0/200] [Batch 95/169] [D loss: 0.692646] [G loss: 0.693985]\n",
      "[Epoch 0/200] [Batch 96/169] [D loss: 0.692747] [G loss: 0.695535]\n",
      "[Epoch 0/200] [Batch 97/169] [D loss: 0.692339] [G loss: 0.694378]\n",
      "[Epoch 0/200] [Batch 98/169] [D loss: 0.692846] [G loss: 0.695154]\n",
      "[Epoch 0/200] [Batch 99/169] [D loss: 0.692141] [G loss: 0.695558]\n",
      "[Epoch 0/200] [Batch 100/169] [D loss: 0.693360] [G loss: 0.694686]\n",
      "[Epoch 0/200] [Batch 101/169] [D loss: 0.692801] [G loss: 0.695522]\n",
      "[Epoch 0/200] [Batch 102/169] [D loss: 0.692645] [G loss: 0.695772]\n",
      "[Epoch 0/200] [Batch 103/169] [D loss: 0.693156] [G loss: 0.694936]\n",
      "[Epoch 0/200] [Batch 104/169] [D loss: 0.693535] [G loss: 0.694518]\n",
      "[Epoch 0/200] [Batch 105/169] [D loss: 0.692483] [G loss: 0.695462]\n",
      "[Epoch 0/200] [Batch 106/169] [D loss: 0.692782] [G loss: 0.696158]\n",
      "[Epoch 0/200] [Batch 107/169] [D loss: 0.693027] [G loss: 0.694936]\n",
      "[Epoch 0/200] [Batch 108/169] [D loss: 0.692640] [G loss: 0.694406]\n",
      "[Epoch 0/200] [Batch 109/169] [D loss: 0.692455] [G loss: 0.695579]\n",
      "[Epoch 0/200] [Batch 110/169] [D loss: 0.692988] [G loss: 0.695506]\n",
      "[Epoch 0/200] [Batch 111/169] [D loss: 0.693471] [G loss: 0.696149]\n",
      "[Epoch 0/200] [Batch 112/169] [D loss: 0.693385] [G loss: 0.694944]\n",
      "[Epoch 0/200] [Batch 113/169] [D loss: 0.692481] [G loss: 0.695481]\n",
      "[Epoch 0/200] [Batch 114/169] [D loss: 0.692907] [G loss: 0.697497]\n",
      "[Epoch 0/200] [Batch 115/169] [D loss: 0.691898] [G loss: 0.697193]\n",
      "[Epoch 0/200] [Batch 116/169] [D loss: 0.692839] [G loss: 0.697373]\n",
      "[Epoch 0/200] [Batch 117/169] [D loss: 0.693153] [G loss: 0.697247]\n",
      "[Epoch 0/200] [Batch 118/169] [D loss: 0.692386] [G loss: 0.696368]\n",
      "[Epoch 0/200] [Batch 119/169] [D loss: 0.693232] [G loss: 0.696414]\n",
      "[Epoch 0/200] [Batch 120/169] [D loss: 0.693288] [G loss: 0.696109]\n",
      "[Epoch 0/200] [Batch 121/169] [D loss: 0.693288] [G loss: 0.696434]\n",
      "[Epoch 0/200] [Batch 122/169] [D loss: 0.692044] [G loss: 0.698513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 123/169] [D loss: 0.692743] [G loss: 0.699577]\n",
      "[Epoch 0/200] [Batch 124/169] [D loss: 0.692764] [G loss: 0.697885]\n",
      "[Epoch 0/200] [Batch 125/169] [D loss: 0.693035] [G loss: 0.698193]\n",
      "[Epoch 0/200] [Batch 126/169] [D loss: 0.692616] [G loss: 0.697360]\n",
      "[Epoch 0/200] [Batch 127/169] [D loss: 0.692638] [G loss: 0.697404]\n",
      "[Epoch 0/200] [Batch 128/169] [D loss: 0.693417] [G loss: 0.697038]\n",
      "[Epoch 0/200] [Batch 129/169] [D loss: 0.692650] [G loss: 0.697150]\n",
      "[Epoch 0/200] [Batch 130/169] [D loss: 0.691896] [G loss: 0.698274]\n",
      "[Epoch 0/200] [Batch 131/169] [D loss: 0.692437] [G loss: 0.697702]\n",
      "[Epoch 0/200] [Batch 132/169] [D loss: 0.691961] [G loss: 0.698116]\n",
      "[Epoch 0/200] [Batch 133/169] [D loss: 0.692671] [G loss: 0.698920]\n",
      "[Epoch 0/200] [Batch 134/169] [D loss: 0.691995] [G loss: 0.697885]\n",
      "[Epoch 0/200] [Batch 135/169] [D loss: 0.692054] [G loss: 0.697918]\n",
      "[Epoch 0/200] [Batch 136/169] [D loss: 0.692631] [G loss: 0.697976]\n",
      "[Epoch 0/200] [Batch 137/169] [D loss: 0.692989] [G loss: 0.695858]\n",
      "[Epoch 0/200] [Batch 138/169] [D loss: 0.693210] [G loss: 0.697189]\n",
      "[Epoch 0/200] [Batch 139/169] [D loss: 0.692487] [G loss: 0.697480]\n",
      "[Epoch 0/200] [Batch 140/169] [D loss: 0.692318] [G loss: 0.697748]\n",
      "[Epoch 0/200] [Batch 141/169] [D loss: 0.692801] [G loss: 0.697693]\n",
      "[Epoch 0/200] [Batch 142/169] [D loss: 0.694018] [G loss: 0.697171]\n",
      "[Epoch 0/200] [Batch 143/169] [D loss: 0.692404] [G loss: 0.697723]\n",
      "[Epoch 0/200] [Batch 144/169] [D loss: 0.691944] [G loss: 0.698125]\n",
      "[Epoch 0/200] [Batch 145/169] [D loss: 0.691950] [G loss: 0.697297]\n",
      "[Epoch 0/200] [Batch 146/169] [D loss: 0.692448] [G loss: 0.697721]\n",
      "[Epoch 0/200] [Batch 147/169] [D loss: 0.692027] [G loss: 0.697048]\n",
      "[Epoch 0/200] [Batch 148/169] [D loss: 0.692028] [G loss: 0.698079]\n",
      "[Epoch 0/200] [Batch 149/169] [D loss: 0.692870] [G loss: 0.696192]\n",
      "[Epoch 0/200] [Batch 150/169] [D loss: 0.692359] [G loss: 0.695077]\n",
      "[Epoch 0/200] [Batch 151/169] [D loss: 0.691737] [G loss: 0.696302]\n",
      "[Epoch 0/200] [Batch 152/169] [D loss: 0.692228] [G loss: 0.695769]\n",
      "[Epoch 0/200] [Batch 153/169] [D loss: 0.691651] [G loss: 0.696888]\n",
      "[Epoch 0/200] [Batch 154/169] [D loss: 0.691048] [G loss: 0.697876]\n",
      "[Epoch 0/200] [Batch 155/169] [D loss: 0.691247] [G loss: 0.696078]\n",
      "[Epoch 0/200] [Batch 156/169] [D loss: 0.691603] [G loss: 0.696998]\n",
      "[Epoch 0/200] [Batch 157/169] [D loss: 0.693601] [G loss: 0.696590]\n",
      "[Epoch 0/200] [Batch 158/169] [D loss: 0.693434] [G loss: 0.697617]\n",
      "[Epoch 0/200] [Batch 159/169] [D loss: 0.692248] [G loss: 0.695367]\n",
      "[Epoch 0/200] [Batch 160/169] [D loss: 0.692120] [G loss: 0.695849]\n",
      "[Epoch 0/200] [Batch 161/169] [D loss: 0.693028] [G loss: 0.695648]\n",
      "[Epoch 0/200] [Batch 162/169] [D loss: 0.692849] [G loss: 0.695151]\n",
      "[Epoch 0/200] [Batch 163/169] [D loss: 0.692503] [G loss: 0.693636]\n",
      "[Epoch 0/200] [Batch 164/169] [D loss: 0.692404] [G loss: 0.696644]\n",
      "[Epoch 0/200] [Batch 165/169] [D loss: 0.693813] [G loss: 0.694856]\n",
      "[Epoch 0/200] [Batch 166/169] [D loss: 0.691968] [G loss: 0.695306]\n",
      "[Epoch 0/200] [Batch 167/169] [D loss: 0.691838] [G loss: 0.696266]\n",
      "[Epoch 0/200] [Batch 168/169] [D loss: 0.693733] [G loss: 0.696076]\n",
      "[Epoch 1/200] [Batch 0/169] [D loss: 0.693395] [G loss: 0.695344]\n",
      "[Epoch 1/200] [Batch 1/169] [D loss: 0.692762] [G loss: 0.694308]\n",
      "[Epoch 1/200] [Batch 2/169] [D loss: 0.692350] [G loss: 0.695129]\n",
      "[Epoch 1/200] [Batch 3/169] [D loss: 0.692314] [G loss: 0.694363]\n",
      "[Epoch 1/200] [Batch 4/169] [D loss: 0.693589] [G loss: 0.694834]\n",
      "[Epoch 1/200] [Batch 5/169] [D loss: 0.691786] [G loss: 0.695663]\n",
      "[Epoch 1/200] [Batch 6/169] [D loss: 0.692581] [G loss: 0.693986]\n",
      "[Epoch 1/200] [Batch 7/169] [D loss: 0.693206] [G loss: 0.694451]\n",
      "[Epoch 1/200] [Batch 8/169] [D loss: 0.692553] [G loss: 0.694457]\n",
      "[Epoch 1/200] [Batch 9/169] [D loss: 0.693158] [G loss: 0.693251]\n",
      "[Epoch 1/200] [Batch 10/169] [D loss: 0.693007] [G loss: 0.693271]\n",
      "[Epoch 1/200] [Batch 11/169] [D loss: 0.693176] [G loss: 0.693051]\n",
      "[Epoch 1/200] [Batch 12/169] [D loss: 0.692805] [G loss: 0.693923]\n",
      "[Epoch 1/200] [Batch 13/169] [D loss: 0.692198] [G loss: 0.692382]\n",
      "[Epoch 1/200] [Batch 14/169] [D loss: 0.692633] [G loss: 0.693418]\n",
      "[Epoch 1/200] [Batch 15/169] [D loss: 0.693305] [G loss: 0.693790]\n",
      "[Epoch 1/200] [Batch 16/169] [D loss: 0.692424] [G loss: 0.693263]\n",
      "[Epoch 1/200] [Batch 17/169] [D loss: 0.692875] [G loss: 0.692666]\n",
      "[Epoch 1/200] [Batch 18/169] [D loss: 0.692822] [G loss: 0.691902]\n",
      "[Epoch 1/200] [Batch 19/169] [D loss: 0.693348] [G loss: 0.692115]\n",
      "[Epoch 1/200] [Batch 20/169] [D loss: 0.693178] [G loss: 0.692244]\n",
      "[Epoch 1/200] [Batch 21/169] [D loss: 0.692952] [G loss: 0.690918]\n",
      "[Epoch 1/200] [Batch 22/169] [D loss: 0.692527] [G loss: 0.693123]\n",
      "[Epoch 1/200] [Batch 23/169] [D loss: 0.692803] [G loss: 0.693430]\n",
      "[Epoch 1/200] [Batch 24/169] [D loss: 0.693388] [G loss: 0.691453]\n",
      "[Epoch 1/200] [Batch 25/169] [D loss: 0.693276] [G loss: 0.690577]\n",
      "[Epoch 1/200] [Batch 26/169] [D loss: 0.692761] [G loss: 0.693050]\n",
      "[Epoch 1/200] [Batch 27/169] [D loss: 0.692271] [G loss: 0.690268]\n",
      "[Epoch 1/200] [Batch 28/169] [D loss: 0.692251] [G loss: 0.690821]\n",
      "[Epoch 1/200] [Batch 29/169] [D loss: 0.692704] [G loss: 0.691631]\n",
      "[Epoch 1/200] [Batch 30/169] [D loss: 0.693385] [G loss: 0.689598]\n",
      "[Epoch 1/200] [Batch 31/169] [D loss: 0.692080] [G loss: 0.690832]\n",
      "[Epoch 1/200] [Batch 32/169] [D loss: 0.692906] [G loss: 0.690192]\n",
      "[Epoch 1/200] [Batch 33/169] [D loss: 0.692292] [G loss: 0.690964]\n",
      "[Epoch 1/200] [Batch 34/169] [D loss: 0.693494] [G loss: 0.690705]\n",
      "[Epoch 1/200] [Batch 35/169] [D loss: 0.691325] [G loss: 0.691702]\n",
      "[Epoch 1/200] [Batch 36/169] [D loss: 0.693759] [G loss: 0.689749]\n",
      "[Epoch 1/200] [Batch 37/169] [D loss: 0.692078] [G loss: 0.690757]\n",
      "[Epoch 1/200] [Batch 38/169] [D loss: 0.692985] [G loss: 0.690261]\n",
      "[Epoch 1/200] [Batch 39/169] [D loss: 0.692951] [G loss: 0.690001]\n",
      "[Epoch 1/200] [Batch 40/169] [D loss: 0.692646] [G loss: 0.691108]\n",
      "[Epoch 1/200] [Batch 41/169] [D loss: 0.692684] [G loss: 0.689588]\n",
      "[Epoch 1/200] [Batch 42/169] [D loss: 0.691768] [G loss: 0.691700]\n",
      "[Epoch 1/200] [Batch 43/169] [D loss: 0.693835] [G loss: 0.690157]\n",
      "[Epoch 1/200] [Batch 44/169] [D loss: 0.694202] [G loss: 0.690040]\n",
      "[Epoch 1/200] [Batch 45/169] [D loss: 0.693174] [G loss: 0.689712]\n",
      "[Epoch 1/200] [Batch 46/169] [D loss: 0.691760] [G loss: 0.691033]\n",
      "[Epoch 1/200] [Batch 47/169] [D loss: 0.693050] [G loss: 0.690616]\n",
      "[Epoch 1/200] [Batch 48/169] [D loss: 0.692497] [G loss: 0.689120]\n",
      "[Epoch 1/200] [Batch 49/169] [D loss: 0.693264] [G loss: 0.691213]\n",
      "[Epoch 1/200] [Batch 50/169] [D loss: 0.692976] [G loss: 0.690798]\n",
      "[Epoch 1/200] [Batch 51/169] [D loss: 0.692071] [G loss: 0.691188]\n",
      "[Epoch 1/200] [Batch 52/169] [D loss: 0.693274] [G loss: 0.691247]\n",
      "[Epoch 1/200] [Batch 53/169] [D loss: 0.693558] [G loss: 0.691172]\n",
      "[Epoch 1/200] [Batch 54/169] [D loss: 0.693267] [G loss: 0.690172]\n",
      "[Epoch 1/200] [Batch 55/169] [D loss: 0.692711] [G loss: 0.691210]\n",
      "[Epoch 1/200] [Batch 56/169] [D loss: 0.693235] [G loss: 0.691621]\n",
      "[Epoch 1/200] [Batch 57/169] [D loss: 0.691932] [G loss: 0.689481]\n",
      "[Epoch 1/200] [Batch 58/169] [D loss: 0.692490] [G loss: 0.690043]\n",
      "[Epoch 1/200] [Batch 59/169] [D loss: 0.691921] [G loss: 0.690195]\n",
      "[Epoch 1/200] [Batch 60/169] [D loss: 0.692619] [G loss: 0.690727]\n",
      "[Epoch 1/200] [Batch 61/169] [D loss: 0.692387] [G loss: 0.690782]\n",
      "[Epoch 1/200] [Batch 62/169] [D loss: 0.692420] [G loss: 0.691162]\n",
      "[Epoch 1/200] [Batch 63/169] [D loss: 0.692050] [G loss: 0.690670]\n",
      "[Epoch 1/200] [Batch 64/169] [D loss: 0.691981] [G loss: 0.689836]\n",
      "[Epoch 1/200] [Batch 65/169] [D loss: 0.693311] [G loss: 0.689639]\n",
      "[Epoch 1/200] [Batch 66/169] [D loss: 0.691922] [G loss: 0.689936]\n",
      "[Epoch 1/200] [Batch 67/169] [D loss: 0.694050] [G loss: 0.690907]\n",
      "[Epoch 1/200] [Batch 68/169] [D loss: 0.693554] [G loss: 0.692087]\n",
      "[Epoch 1/200] [Batch 69/169] [D loss: 0.693512] [G loss: 0.692000]\n",
      "[Epoch 1/200] [Batch 70/169] [D loss: 0.692977] [G loss: 0.693056]\n",
      "[Epoch 1/200] [Batch 71/169] [D loss: 0.692508] [G loss: 0.691359]\n",
      "[Epoch 1/200] [Batch 72/169] [D loss: 0.691788] [G loss: 0.692722]\n",
      "[Epoch 1/200] [Batch 73/169] [D loss: 0.692976] [G loss: 0.691627]\n",
      "[Epoch 1/200] [Batch 74/169] [D loss: 0.692322] [G loss: 0.693644]\n",
      "[Epoch 1/200] [Batch 75/169] [D loss: 0.692723] [G loss: 0.691951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 76/169] [D loss: 0.692703] [G loss: 0.692367]\n",
      "[Epoch 1/200] [Batch 77/169] [D loss: 0.692449] [G loss: 0.692619]\n",
      "[Epoch 1/200] [Batch 78/169] [D loss: 0.693151] [G loss: 0.692229]\n",
      "[Epoch 1/200] [Batch 79/169] [D loss: 0.693705] [G loss: 0.691779]\n",
      "[Epoch 1/200] [Batch 80/169] [D loss: 0.693197] [G loss: 0.692767]\n",
      "[Epoch 1/200] [Batch 81/169] [D loss: 0.692585] [G loss: 0.692321]\n",
      "[Epoch 1/200] [Batch 82/169] [D loss: 0.692226] [G loss: 0.692408]\n",
      "[Epoch 1/200] [Batch 83/169] [D loss: 0.692911] [G loss: 0.692577]\n",
      "[Epoch 1/200] [Batch 84/169] [D loss: 0.693412] [G loss: 0.694025]\n",
      "[Epoch 1/200] [Batch 85/169] [D loss: 0.693132] [G loss: 0.693209]\n",
      "[Epoch 1/200] [Batch 86/169] [D loss: 0.693029] [G loss: 0.693251]\n",
      "[Epoch 1/200] [Batch 87/169] [D loss: 0.692907] [G loss: 0.692698]\n",
      "[Epoch 1/200] [Batch 88/169] [D loss: 0.691985] [G loss: 0.694293]\n",
      "[Epoch 1/200] [Batch 89/169] [D loss: 0.692346] [G loss: 0.695067]\n",
      "[Epoch 1/200] [Batch 90/169] [D loss: 0.692014] [G loss: 0.693555]\n",
      "[Epoch 1/200] [Batch 91/169] [D loss: 0.691975] [G loss: 0.693864]\n",
      "[Epoch 1/200] [Batch 92/169] [D loss: 0.692747] [G loss: 0.693139]\n",
      "[Epoch 1/200] [Batch 93/169] [D loss: 0.692905] [G loss: 0.694886]\n",
      "[Epoch 1/200] [Batch 94/169] [D loss: 0.692541] [G loss: 0.695877]\n",
      "[Epoch 1/200] [Batch 95/169] [D loss: 0.692917] [G loss: 0.694603]\n",
      "[Epoch 1/200] [Batch 96/169] [D loss: 0.692702] [G loss: 0.694814]\n",
      "[Epoch 1/200] [Batch 97/169] [D loss: 0.693093] [G loss: 0.695236]\n",
      "[Epoch 1/200] [Batch 98/169] [D loss: 0.692514] [G loss: 0.695368]\n",
      "[Epoch 1/200] [Batch 99/169] [D loss: 0.692977] [G loss: 0.694862]\n",
      "[Epoch 1/200] [Batch 100/169] [D loss: 0.692126] [G loss: 0.693891]\n",
      "[Epoch 1/200] [Batch 101/169] [D loss: 0.692135] [G loss: 0.695325]\n",
      "[Epoch 1/200] [Batch 102/169] [D loss: 0.692241] [G loss: 0.693405]\n",
      "[Epoch 1/200] [Batch 103/169] [D loss: 0.692891] [G loss: 0.695302]\n",
      "[Epoch 1/200] [Batch 104/169] [D loss: 0.692223] [G loss: 0.694278]\n",
      "[Epoch 1/200] [Batch 105/169] [D loss: 0.692198] [G loss: 0.695007]\n",
      "[Epoch 1/200] [Batch 106/169] [D loss: 0.692024] [G loss: 0.695464]\n",
      "[Epoch 1/200] [Batch 107/169] [D loss: 0.692498] [G loss: 0.696879]\n",
      "[Epoch 1/200] [Batch 108/169] [D loss: 0.692529] [G loss: 0.694268]\n",
      "[Epoch 1/200] [Batch 109/169] [D loss: 0.692701] [G loss: 0.694266]\n",
      "[Epoch 1/200] [Batch 110/169] [D loss: 0.692229] [G loss: 0.696399]\n",
      "[Epoch 1/200] [Batch 111/169] [D loss: 0.692481] [G loss: 0.695941]\n",
      "[Epoch 1/200] [Batch 112/169] [D loss: 0.692954] [G loss: 0.695454]\n",
      "[Epoch 1/200] [Batch 113/169] [D loss: 0.692170] [G loss: 0.695855]\n",
      "[Epoch 1/200] [Batch 114/169] [D loss: 0.691996] [G loss: 0.695096]\n",
      "[Epoch 1/200] [Batch 115/169] [D loss: 0.692018] [G loss: 0.696402]\n",
      "[Epoch 1/200] [Batch 116/169] [D loss: 0.692439] [G loss: 0.696582]\n",
      "[Epoch 1/200] [Batch 117/169] [D loss: 0.691562] [G loss: 0.696422]\n",
      "[Epoch 1/200] [Batch 118/169] [D loss: 0.691393] [G loss: 0.697168]\n",
      "[Epoch 1/200] [Batch 119/169] [D loss: 0.691936] [G loss: 0.697477]\n",
      "[Epoch 1/200] [Batch 120/169] [D loss: 0.691598] [G loss: 0.696489]\n",
      "[Epoch 1/200] [Batch 121/169] [D loss: 0.692690] [G loss: 0.696860]\n",
      "[Epoch 1/200] [Batch 122/169] [D loss: 0.691807] [G loss: 0.697010]\n",
      "[Epoch 1/200] [Batch 123/169] [D loss: 0.691786] [G loss: 0.697658]\n",
      "[Epoch 1/200] [Batch 124/169] [D loss: 0.692403] [G loss: 0.698332]\n",
      "[Epoch 1/200] [Batch 125/169] [D loss: 0.692118] [G loss: 0.697468]\n",
      "[Epoch 1/200] [Batch 126/169] [D loss: 0.691292] [G loss: 0.697833]\n",
      "[Epoch 1/200] [Batch 127/169] [D loss: 0.692183] [G loss: 0.696375]\n",
      "[Epoch 1/200] [Batch 128/169] [D loss: 0.691519] [G loss: 0.697447]\n",
      "[Epoch 1/200] [Batch 129/169] [D loss: 0.691833] [G loss: 0.697274]\n",
      "[Epoch 1/200] [Batch 130/169] [D loss: 0.692027] [G loss: 0.697916]\n",
      "[Epoch 1/200] [Batch 131/169] [D loss: 0.692077] [G loss: 0.697508]\n",
      "[Epoch 1/200] [Batch 132/169] [D loss: 0.692966] [G loss: 0.696014]\n",
      "[Epoch 1/200] [Batch 133/169] [D loss: 0.691649] [G loss: 0.695905]\n",
      "[Epoch 1/200] [Batch 134/169] [D loss: 0.692475] [G loss: 0.698177]\n",
      "[Epoch 1/200] [Batch 135/169] [D loss: 0.692387] [G loss: 0.697589]\n",
      "[Epoch 1/200] [Batch 136/169] [D loss: 0.692005] [G loss: 0.697195]\n",
      "[Epoch 1/200] [Batch 137/169] [D loss: 0.691761] [G loss: 0.696067]\n",
      "[Epoch 1/200] [Batch 138/169] [D loss: 0.692497] [G loss: 0.695694]\n",
      "[Epoch 1/200] [Batch 139/169] [D loss: 0.690996] [G loss: 0.696613]\n",
      "[Epoch 1/200] [Batch 140/169] [D loss: 0.692575] [G loss: 0.695296]\n",
      "[Epoch 1/200] [Batch 141/169] [D loss: 0.691900] [G loss: 0.696360]\n",
      "[Epoch 1/200] [Batch 142/169] [D loss: 0.692316] [G loss: 0.697387]\n",
      "[Epoch 1/200] [Batch 143/169] [D loss: 0.691822] [G loss: 0.697104]\n",
      "[Epoch 1/200] [Batch 144/169] [D loss: 0.691899] [G loss: 0.696535]\n",
      "[Epoch 1/200] [Batch 145/169] [D loss: 0.692030] [G loss: 0.695869]\n",
      "[Epoch 1/200] [Batch 146/169] [D loss: 0.692367] [G loss: 0.696903]\n",
      "[Epoch 1/200] [Batch 147/169] [D loss: 0.691735] [G loss: 0.696986]\n",
      "[Epoch 1/200] [Batch 148/169] [D loss: 0.691781] [G loss: 0.697137]\n",
      "[Epoch 1/200] [Batch 149/169] [D loss: 0.692413] [G loss: 0.696165]\n",
      "[Epoch 1/200] [Batch 150/169] [D loss: 0.691890] [G loss: 0.697277]\n",
      "[Epoch 1/200] [Batch 151/169] [D loss: 0.691964] [G loss: 0.696136]\n",
      "[Epoch 1/200] [Batch 152/169] [D loss: 0.691908] [G loss: 0.696550]\n",
      "[Epoch 1/200] [Batch 153/169] [D loss: 0.692130] [G loss: 0.698059]\n",
      "[Epoch 1/200] [Batch 154/169] [D loss: 0.691857] [G loss: 0.698841]\n",
      "[Epoch 1/200] [Batch 155/169] [D loss: 0.693672] [G loss: 0.696685]\n",
      "[Epoch 1/200] [Batch 156/169] [D loss: 0.693153] [G loss: 0.697071]\n",
      "[Epoch 1/200] [Batch 157/169] [D loss: 0.692141] [G loss: 0.697972]\n",
      "[Epoch 1/200] [Batch 158/169] [D loss: 0.692354] [G loss: 0.697674]\n",
      "[Epoch 1/200] [Batch 159/169] [D loss: 0.692203] [G loss: 0.698487]\n",
      "[Epoch 1/200] [Batch 160/169] [D loss: 0.692034] [G loss: 0.697824]\n",
      "[Epoch 1/200] [Batch 161/169] [D loss: 0.691401] [G loss: 0.697850]\n",
      "[Epoch 1/200] [Batch 162/169] [D loss: 0.693526] [G loss: 0.697303]\n",
      "[Epoch 1/200] [Batch 163/169] [D loss: 0.691344] [G loss: 0.697399]\n",
      "[Epoch 1/200] [Batch 164/169] [D loss: 0.693772] [G loss: 0.695253]\n",
      "[Epoch 1/200] [Batch 165/169] [D loss: 0.691825] [G loss: 0.697667]\n",
      "[Epoch 1/200] [Batch 166/169] [D loss: 0.691880] [G loss: 0.696995]\n",
      "[Epoch 1/200] [Batch 167/169] [D loss: 0.693272] [G loss: 0.696993]\n",
      "[Epoch 1/200] [Batch 168/169] [D loss: 0.692714] [G loss: 0.693832]\n",
      "[Epoch 2/200] [Batch 0/169] [D loss: 0.693247] [G loss: 0.697072]\n",
      "[Epoch 2/200] [Batch 1/169] [D loss: 0.693067] [G loss: 0.696825]\n",
      "[Epoch 2/200] [Batch 2/169] [D loss: 0.693085] [G loss: 0.696448]\n",
      "[Epoch 2/200] [Batch 3/169] [D loss: 0.693239] [G loss: 0.694874]\n",
      "[Epoch 2/200] [Batch 4/169] [D loss: 0.692272] [G loss: 0.695575]\n",
      "[Epoch 2/200] [Batch 5/169] [D loss: 0.693415] [G loss: 0.697319]\n",
      "[Epoch 2/200] [Batch 6/169] [D loss: 0.692041] [G loss: 0.695537]\n",
      "[Epoch 2/200] [Batch 7/169] [D loss: 0.691810] [G loss: 0.697096]\n",
      "[Epoch 2/200] [Batch 8/169] [D loss: 0.692601] [G loss: 0.696701]\n",
      "[Epoch 2/200] [Batch 9/169] [D loss: 0.692299] [G loss: 0.694811]\n",
      "[Epoch 2/200] [Batch 10/169] [D loss: 0.691438] [G loss: 0.695360]\n",
      "[Epoch 2/200] [Batch 11/169] [D loss: 0.693133] [G loss: 0.695507]\n",
      "[Epoch 2/200] [Batch 12/169] [D loss: 0.692123] [G loss: 0.695947]\n",
      "[Epoch 2/200] [Batch 13/169] [D loss: 0.692284] [G loss: 0.695596]\n",
      "[Epoch 2/200] [Batch 14/169] [D loss: 0.692646] [G loss: 0.694395]\n",
      "[Epoch 2/200] [Batch 15/169] [D loss: 0.691418] [G loss: 0.696563]\n",
      "[Epoch 2/200] [Batch 16/169] [D loss: 0.691814] [G loss: 0.693977]\n",
      "[Epoch 2/200] [Batch 17/169] [D loss: 0.693126] [G loss: 0.693613]\n",
      "[Epoch 2/200] [Batch 18/169] [D loss: 0.691736] [G loss: 0.693769]\n",
      "[Epoch 2/200] [Batch 19/169] [D loss: 0.692849] [G loss: 0.694685]\n",
      "[Epoch 2/200] [Batch 20/169] [D loss: 0.691847] [G loss: 0.696178]\n",
      "[Epoch 2/200] [Batch 21/169] [D loss: 0.691982] [G loss: 0.694980]\n",
      "[Epoch 2/200] [Batch 22/169] [D loss: 0.692323] [G loss: 0.694786]\n",
      "[Epoch 2/200] [Batch 23/169] [D loss: 0.692178] [G loss: 0.694057]\n",
      "[Epoch 2/200] [Batch 24/169] [D loss: 0.692555] [G loss: 0.692572]\n",
      "[Epoch 2/200] [Batch 25/169] [D loss: 0.692896] [G loss: 0.693289]\n",
      "[Epoch 2/200] [Batch 26/169] [D loss: 0.692926] [G loss: 0.692437]\n",
      "[Epoch 2/200] [Batch 27/169] [D loss: 0.691884] [G loss: 0.690912]\n",
      "[Epoch 2/200] [Batch 28/169] [D loss: 0.692088] [G loss: 0.690219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 29/169] [D loss: 0.693365] [G loss: 0.689994]\n",
      "[Epoch 2/200] [Batch 30/169] [D loss: 0.692846] [G loss: 0.690024]\n",
      "[Epoch 2/200] [Batch 31/169] [D loss: 0.692674] [G loss: 0.689002]\n",
      "[Epoch 2/200] [Batch 32/169] [D loss: 0.692446] [G loss: 0.688703]\n",
      "[Epoch 2/200] [Batch 33/169] [D loss: 0.693422] [G loss: 0.689340]\n",
      "[Epoch 2/200] [Batch 34/169] [D loss: 0.692982] [G loss: 0.687816]\n",
      "[Epoch 2/200] [Batch 35/169] [D loss: 0.693418] [G loss: 0.688420]\n",
      "[Epoch 2/200] [Batch 36/169] [D loss: 0.693992] [G loss: 0.688148]\n",
      "[Epoch 2/200] [Batch 37/169] [D loss: 0.693699] [G loss: 0.687382]\n",
      "[Epoch 2/200] [Batch 38/169] [D loss: 0.694040] [G loss: 0.688752]\n",
      "[Epoch 2/200] [Batch 39/169] [D loss: 0.692624] [G loss: 0.688753]\n",
      "[Epoch 2/200] [Batch 40/169] [D loss: 0.691954] [G loss: 0.690139]\n",
      "[Epoch 2/200] [Batch 41/169] [D loss: 0.691985] [G loss: 0.688200]\n",
      "[Epoch 2/200] [Batch 42/169] [D loss: 0.692918] [G loss: 0.686819]\n",
      "[Epoch 2/200] [Batch 43/169] [D loss: 0.692591] [G loss: 0.685659]\n",
      "[Epoch 2/200] [Batch 44/169] [D loss: 0.692405] [G loss: 0.687402]\n",
      "[Epoch 2/200] [Batch 45/169] [D loss: 0.691428] [G loss: 0.687994]\n",
      "[Epoch 2/200] [Batch 46/169] [D loss: 0.693885] [G loss: 0.687589]\n",
      "[Epoch 2/200] [Batch 47/169] [D loss: 0.692453] [G loss: 0.687016]\n",
      "[Epoch 2/200] [Batch 48/169] [D loss: 0.692277] [G loss: 0.685938]\n",
      "[Epoch 2/200] [Batch 49/169] [D loss: 0.691325] [G loss: 0.686473]\n",
      "[Epoch 2/200] [Batch 50/169] [D loss: 0.691764] [G loss: 0.688029]\n",
      "[Epoch 2/200] [Batch 51/169] [D loss: 0.692827] [G loss: 0.685907]\n",
      "[Epoch 2/200] [Batch 52/169] [D loss: 0.691780] [G loss: 0.686601]\n",
      "[Epoch 2/200] [Batch 53/169] [D loss: 0.691476] [G loss: 0.686514]\n",
      "[Epoch 2/200] [Batch 54/169] [D loss: 0.690997] [G loss: 0.686471]\n",
      "[Epoch 2/200] [Batch 55/169] [D loss: 0.692072] [G loss: 0.686122]\n",
      "[Epoch 2/200] [Batch 56/169] [D loss: 0.691536] [G loss: 0.684645]\n",
      "[Epoch 2/200] [Batch 57/169] [D loss: 0.692144] [G loss: 0.684946]\n",
      "[Epoch 2/200] [Batch 58/169] [D loss: 0.691732] [G loss: 0.687301]\n",
      "[Epoch 2/200] [Batch 59/169] [D loss: 0.690722] [G loss: 0.686557]\n",
      "[Epoch 2/200] [Batch 60/169] [D loss: 0.691597] [G loss: 0.685166]\n",
      "[Epoch 2/200] [Batch 61/169] [D loss: 0.691712] [G loss: 0.684975]\n",
      "[Epoch 2/200] [Batch 62/169] [D loss: 0.691313] [G loss: 0.686643]\n",
      "[Epoch 2/200] [Batch 63/169] [D loss: 0.692161] [G loss: 0.685908]\n",
      "[Epoch 2/200] [Batch 64/169] [D loss: 0.691598] [G loss: 0.684386]\n",
      "[Epoch 2/200] [Batch 65/169] [D loss: 0.691384] [G loss: 0.687341]\n",
      "[Epoch 2/200] [Batch 66/169] [D loss: 0.690463] [G loss: 0.685877]\n",
      "[Epoch 2/200] [Batch 67/169] [D loss: 0.690873] [G loss: 0.684163]\n",
      "[Epoch 2/200] [Batch 68/169] [D loss: 0.692951] [G loss: 0.684726]\n",
      "[Epoch 2/200] [Batch 69/169] [D loss: 0.691128] [G loss: 0.686531]\n",
      "[Epoch 2/200] [Batch 70/169] [D loss: 0.692521] [G loss: 0.687276]\n",
      "[Epoch 2/200] [Batch 71/169] [D loss: 0.691616] [G loss: 0.687452]\n",
      "[Epoch 2/200] [Batch 72/169] [D loss: 0.693043] [G loss: 0.684802]\n",
      "[Epoch 2/200] [Batch 73/169] [D loss: 0.692856] [G loss: 0.686619]\n",
      "[Epoch 2/200] [Batch 74/169] [D loss: 0.693139] [G loss: 0.686406]\n",
      "[Epoch 2/200] [Batch 75/169] [D loss: 0.692159] [G loss: 0.688772]\n",
      "[Epoch 2/200] [Batch 76/169] [D loss: 0.693366] [G loss: 0.687168]\n",
      "[Epoch 2/200] [Batch 77/169] [D loss: 0.693143] [G loss: 0.687955]\n",
      "[Epoch 2/200] [Batch 78/169] [D loss: 0.693872] [G loss: 0.689544]\n",
      "[Epoch 2/200] [Batch 79/169] [D loss: 0.691513] [G loss: 0.689854]\n",
      "[Epoch 2/200] [Batch 80/169] [D loss: 0.693929] [G loss: 0.689100]\n",
      "[Epoch 2/200] [Batch 81/169] [D loss: 0.694153] [G loss: 0.690199]\n",
      "[Epoch 2/200] [Batch 82/169] [D loss: 0.693935] [G loss: 0.690249]\n",
      "[Epoch 2/200] [Batch 83/169] [D loss: 0.693223] [G loss: 0.690863]\n",
      "[Epoch 2/200] [Batch 84/169] [D loss: 0.694388] [G loss: 0.690973]\n",
      "[Epoch 2/200] [Batch 85/169] [D loss: 0.693762] [G loss: 0.693310]\n",
      "[Epoch 2/200] [Batch 86/169] [D loss: 0.694259] [G loss: 0.692317]\n",
      "[Epoch 2/200] [Batch 87/169] [D loss: 0.694162] [G loss: 0.693998]\n",
      "[Epoch 2/200] [Batch 88/169] [D loss: 0.692951] [G loss: 0.693398]\n",
      "[Epoch 2/200] [Batch 89/169] [D loss: 0.693269] [G loss: 0.694570]\n",
      "[Epoch 2/200] [Batch 90/169] [D loss: 0.693745] [G loss: 0.695332]\n",
      "[Epoch 2/200] [Batch 91/169] [D loss: 0.693568] [G loss: 0.695984]\n",
      "[Epoch 2/200] [Batch 92/169] [D loss: 0.692707] [G loss: 0.697522]\n",
      "[Epoch 2/200] [Batch 93/169] [D loss: 0.691132] [G loss: 0.699482]\n",
      "[Epoch 2/200] [Batch 94/169] [D loss: 0.692196] [G loss: 0.698334]\n",
      "[Epoch 2/200] [Batch 95/169] [D loss: 0.692978] [G loss: 0.699994]\n",
      "[Epoch 2/200] [Batch 96/169] [D loss: 0.693433] [G loss: 0.700290]\n",
      "[Epoch 2/200] [Batch 97/169] [D loss: 0.691174] [G loss: 0.701820]\n",
      "[Epoch 2/200] [Batch 98/169] [D loss: 0.691370] [G loss: 0.700960]\n",
      "[Epoch 2/200] [Batch 99/169] [D loss: 0.691994] [G loss: 0.702650]\n",
      "[Epoch 2/200] [Batch 100/169] [D loss: 0.691649] [G loss: 0.703720]\n",
      "[Epoch 2/200] [Batch 101/169] [D loss: 0.689837] [G loss: 0.704768]\n",
      "[Epoch 2/200] [Batch 102/169] [D loss: 0.690997] [G loss: 0.704810]\n",
      "[Epoch 2/200] [Batch 103/169] [D loss: 0.690762] [G loss: 0.705135]\n",
      "[Epoch 2/200] [Batch 104/169] [D loss: 0.689862] [G loss: 0.708452]\n",
      "[Epoch 2/200] [Batch 105/169] [D loss: 0.689328] [G loss: 0.707789]\n",
      "[Epoch 2/200] [Batch 106/169] [D loss: 0.691599] [G loss: 0.707105]\n",
      "[Epoch 2/200] [Batch 107/169] [D loss: 0.690817] [G loss: 0.708179]\n",
      "[Epoch 2/200] [Batch 108/169] [D loss: 0.689761] [G loss: 0.709488]\n",
      "[Epoch 2/200] [Batch 109/169] [D loss: 0.690664] [G loss: 0.709596]\n",
      "[Epoch 2/200] [Batch 110/169] [D loss: 0.690802] [G loss: 0.710468]\n",
      "[Epoch 2/200] [Batch 111/169] [D loss: 0.691278] [G loss: 0.710572]\n",
      "[Epoch 2/200] [Batch 112/169] [D loss: 0.689645] [G loss: 0.708583]\n",
      "[Epoch 2/200] [Batch 113/169] [D loss: 0.689368] [G loss: 0.709582]\n",
      "[Epoch 2/200] [Batch 114/169] [D loss: 0.691885] [G loss: 0.707520]\n",
      "[Epoch 2/200] [Batch 115/169] [D loss: 0.691309] [G loss: 0.710119]\n",
      "[Epoch 2/200] [Batch 116/169] [D loss: 0.691362] [G loss: 0.709631]\n",
      "[Epoch 2/200] [Batch 117/169] [D loss: 0.691243] [G loss: 0.709293]\n",
      "[Epoch 2/200] [Batch 118/169] [D loss: 0.692136] [G loss: 0.708138]\n",
      "[Epoch 2/200] [Batch 119/169] [D loss: 0.693207] [G loss: 0.707915]\n",
      "[Epoch 2/200] [Batch 120/169] [D loss: 0.693163] [G loss: 0.707522]\n",
      "[Epoch 2/200] [Batch 121/169] [D loss: 0.691062] [G loss: 0.705366]\n",
      "[Epoch 2/200] [Batch 122/169] [D loss: 0.692895] [G loss: 0.705283]\n",
      "[Epoch 2/200] [Batch 123/169] [D loss: 0.694137] [G loss: 0.705301]\n",
      "[Epoch 2/200] [Batch 124/169] [D loss: 0.694496] [G loss: 0.702480]\n",
      "[Epoch 2/200] [Batch 125/169] [D loss: 0.694407] [G loss: 0.702680]\n",
      "[Epoch 2/200] [Batch 126/169] [D loss: 0.694368] [G loss: 0.701724]\n",
      "[Epoch 2/200] [Batch 127/169] [D loss: 0.692216] [G loss: 0.700482]\n",
      "[Epoch 2/200] [Batch 128/169] [D loss: 0.694249] [G loss: 0.700316]\n",
      "[Epoch 2/200] [Batch 129/169] [D loss: 0.694539] [G loss: 0.699248]\n",
      "[Epoch 2/200] [Batch 130/169] [D loss: 0.693453] [G loss: 0.700938]\n",
      "[Epoch 2/200] [Batch 131/169] [D loss: 0.695362] [G loss: 0.697728]\n",
      "[Epoch 2/200] [Batch 132/169] [D loss: 0.692440] [G loss: 0.701021]\n",
      "[Epoch 2/200] [Batch 133/169] [D loss: 0.694065] [G loss: 0.698722]\n",
      "[Epoch 2/200] [Batch 134/169] [D loss: 0.694961] [G loss: 0.696146]\n",
      "[Epoch 2/200] [Batch 135/169] [D loss: 0.694316] [G loss: 0.696313]\n",
      "[Epoch 2/200] [Batch 136/169] [D loss: 0.693349] [G loss: 0.695503]\n",
      "[Epoch 2/200] [Batch 137/169] [D loss: 0.693064] [G loss: 0.694495]\n",
      "[Epoch 2/200] [Batch 138/169] [D loss: 0.693325] [G loss: 0.695146]\n",
      "[Epoch 2/200] [Batch 139/169] [D loss: 0.693456] [G loss: 0.695728]\n",
      "[Epoch 2/200] [Batch 140/169] [D loss: 0.693804] [G loss: 0.691331]\n",
      "[Epoch 2/200] [Batch 141/169] [D loss: 0.692970] [G loss: 0.693965]\n",
      "[Epoch 2/200] [Batch 142/169] [D loss: 0.692018] [G loss: 0.693268]\n",
      "[Epoch 2/200] [Batch 143/169] [D loss: 0.692031] [G loss: 0.692460]\n",
      "[Epoch 2/200] [Batch 144/169] [D loss: 0.692523] [G loss: 0.691709]\n",
      "[Epoch 2/200] [Batch 145/169] [D loss: 0.691967] [G loss: 0.692588]\n",
      "[Epoch 2/200] [Batch 146/169] [D loss: 0.691835] [G loss: 0.694080]\n",
      "[Epoch 2/200] [Batch 147/169] [D loss: 0.691348] [G loss: 0.692277]\n",
      "[Epoch 2/200] [Batch 148/169] [D loss: 0.691990] [G loss: 0.693141]\n",
      "[Epoch 2/200] [Batch 149/169] [D loss: 0.690018] [G loss: 0.692434]\n",
      "[Epoch 2/200] [Batch 150/169] [D loss: 0.691399] [G loss: 0.692068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 151/169] [D loss: 0.690105] [G loss: 0.691982]\n",
      "[Epoch 2/200] [Batch 152/169] [D loss: 0.690926] [G loss: 0.689400]\n",
      "[Epoch 2/200] [Batch 153/169] [D loss: 0.691327] [G loss: 0.690474]\n",
      "[Epoch 2/200] [Batch 154/169] [D loss: 0.690439] [G loss: 0.690376]\n",
      "[Epoch 2/200] [Batch 155/169] [D loss: 0.692053] [G loss: 0.687466]\n",
      "[Epoch 2/200] [Batch 156/169] [D loss: 0.692281] [G loss: 0.688505]\n",
      "[Epoch 2/200] [Batch 157/169] [D loss: 0.692165] [G loss: 0.688828]\n",
      "[Epoch 2/200] [Batch 158/169] [D loss: 0.691128] [G loss: 0.687010]\n",
      "[Epoch 2/200] [Batch 159/169] [D loss: 0.692235] [G loss: 0.686389]\n",
      "[Epoch 2/200] [Batch 160/169] [D loss: 0.692742] [G loss: 0.683716]\n",
      "[Epoch 2/200] [Batch 161/169] [D loss: 0.692786] [G loss: 0.684880]\n",
      "[Epoch 2/200] [Batch 162/169] [D loss: 0.693803] [G loss: 0.682789]\n",
      "[Epoch 2/200] [Batch 163/169] [D loss: 0.693851] [G loss: 0.681663]\n",
      "[Epoch 2/200] [Batch 164/169] [D loss: 0.694333] [G loss: 0.681032]\n",
      "[Epoch 2/200] [Batch 165/169] [D loss: 0.694203] [G loss: 0.681298]\n",
      "[Epoch 2/200] [Batch 166/169] [D loss: 0.693799] [G loss: 0.682618]\n",
      "[Epoch 2/200] [Batch 167/169] [D loss: 0.693591] [G loss: 0.679791]\n",
      "[Epoch 2/200] [Batch 168/169] [D loss: 0.695268] [G loss: 0.678876]\n",
      "[Epoch 3/200] [Batch 0/169] [D loss: 0.695007] [G loss: 0.680013]\n",
      "[Epoch 3/200] [Batch 1/169] [D loss: 0.694426] [G loss: 0.681161]\n",
      "[Epoch 3/200] [Batch 2/169] [D loss: 0.694551] [G loss: 0.680472]\n",
      "[Epoch 3/200] [Batch 3/169] [D loss: 0.695065] [G loss: 0.682910]\n",
      "[Epoch 3/200] [Batch 4/169] [D loss: 0.693777] [G loss: 0.682353]\n",
      "[Epoch 3/200] [Batch 5/169] [D loss: 0.695680] [G loss: 0.682370]\n",
      "[Epoch 3/200] [Batch 6/169] [D loss: 0.694322] [G loss: 0.685474]\n",
      "[Epoch 3/200] [Batch 7/169] [D loss: 0.694446] [G loss: 0.683668]\n",
      "[Epoch 3/200] [Batch 8/169] [D loss: 0.693759] [G loss: 0.685548]\n",
      "[Epoch 3/200] [Batch 9/169] [D loss: 0.694060] [G loss: 0.685284]\n",
      "[Epoch 3/200] [Batch 10/169] [D loss: 0.692775] [G loss: 0.687712]\n",
      "[Epoch 3/200] [Batch 11/169] [D loss: 0.693001] [G loss: 0.688930]\n",
      "[Epoch 3/200] [Batch 12/169] [D loss: 0.693411] [G loss: 0.689412]\n",
      "[Epoch 3/200] [Batch 13/169] [D loss: 0.692676] [G loss: 0.691221]\n",
      "[Epoch 3/200] [Batch 14/169] [D loss: 0.691881] [G loss: 0.692299]\n",
      "[Epoch 3/200] [Batch 15/169] [D loss: 0.693062] [G loss: 0.692756]\n",
      "[Epoch 3/200] [Batch 16/169] [D loss: 0.691160] [G loss: 0.693651]\n",
      "[Epoch 3/200] [Batch 17/169] [D loss: 0.690347] [G loss: 0.695176]\n",
      "[Epoch 3/200] [Batch 18/169] [D loss: 0.690177] [G loss: 0.695713]\n",
      "[Epoch 3/200] [Batch 19/169] [D loss: 0.690659] [G loss: 0.694756]\n",
      "[Epoch 3/200] [Batch 20/169] [D loss: 0.690799] [G loss: 0.695429]\n",
      "[Epoch 3/200] [Batch 21/169] [D loss: 0.689828] [G loss: 0.697402]\n",
      "[Epoch 3/200] [Batch 22/169] [D loss: 0.689777] [G loss: 0.696781]\n",
      "[Epoch 3/200] [Batch 23/169] [D loss: 0.692029] [G loss: 0.696814]\n",
      "[Epoch 3/200] [Batch 24/169] [D loss: 0.688710] [G loss: 0.697981]\n",
      "[Epoch 3/200] [Batch 25/169] [D loss: 0.690550] [G loss: 0.701137]\n",
      "[Epoch 3/200] [Batch 26/169] [D loss: 0.691511] [G loss: 0.699413]\n",
      "[Epoch 3/200] [Batch 27/169] [D loss: 0.689689] [G loss: 0.700394]\n",
      "[Epoch 3/200] [Batch 28/169] [D loss: 0.689369] [G loss: 0.699375]\n",
      "[Epoch 3/200] [Batch 29/169] [D loss: 0.689726] [G loss: 0.700919]\n",
      "[Epoch 3/200] [Batch 30/169] [D loss: 0.689359] [G loss: 0.701414]\n",
      "[Epoch 3/200] [Batch 31/169] [D loss: 0.691379] [G loss: 0.699588]\n",
      "[Epoch 3/200] [Batch 32/169] [D loss: 0.690683] [G loss: 0.699353]\n",
      "[Epoch 3/200] [Batch 33/169] [D loss: 0.692224] [G loss: 0.699474]\n",
      "[Epoch 3/200] [Batch 34/169] [D loss: 0.690741] [G loss: 0.699668]\n",
      "[Epoch 3/200] [Batch 35/169] [D loss: 0.692634] [G loss: 0.699774]\n",
      "[Epoch 3/200] [Batch 36/169] [D loss: 0.691003] [G loss: 0.699021]\n",
      "[Epoch 3/200] [Batch 37/169] [D loss: 0.692412] [G loss: 0.698739]\n",
      "[Epoch 3/200] [Batch 38/169] [D loss: 0.693808] [G loss: 0.697482]\n",
      "[Epoch 3/200] [Batch 39/169] [D loss: 0.694240] [G loss: 0.696615]\n",
      "[Epoch 3/200] [Batch 40/169] [D loss: 0.693567] [G loss: 0.698455]\n",
      "[Epoch 3/200] [Batch 41/169] [D loss: 0.693832] [G loss: 0.697138]\n",
      "[Epoch 3/200] [Batch 42/169] [D loss: 0.694855] [G loss: 0.694095]\n",
      "[Epoch 3/200] [Batch 43/169] [D loss: 0.693939] [G loss: 0.695433]\n",
      "[Epoch 3/200] [Batch 44/169] [D loss: 0.694037] [G loss: 0.695372]\n",
      "[Epoch 3/200] [Batch 45/169] [D loss: 0.694442] [G loss: 0.694231]\n",
      "[Epoch 3/200] [Batch 46/169] [D loss: 0.694855] [G loss: 0.693996]\n",
      "[Epoch 3/200] [Batch 47/169] [D loss: 0.693969] [G loss: 0.694789]\n",
      "[Epoch 3/200] [Batch 48/169] [D loss: 0.693515] [G loss: 0.695436]\n",
      "[Epoch 3/200] [Batch 49/169] [D loss: 0.694554] [G loss: 0.694072]\n",
      "[Epoch 3/200] [Batch 50/169] [D loss: 0.694383] [G loss: 0.696924]\n",
      "[Epoch 3/200] [Batch 51/169] [D loss: 0.693929] [G loss: 0.695641]\n",
      "[Epoch 3/200] [Batch 52/169] [D loss: 0.694560] [G loss: 0.693634]\n",
      "[Epoch 3/200] [Batch 53/169] [D loss: 0.694184] [G loss: 0.694311]\n",
      "[Epoch 3/200] [Batch 54/169] [D loss: 0.692592] [G loss: 0.694502]\n",
      "[Epoch 3/200] [Batch 55/169] [D loss: 0.692768] [G loss: 0.694845]\n",
      "[Epoch 3/200] [Batch 56/169] [D loss: 0.693093] [G loss: 0.694943]\n",
      "[Epoch 3/200] [Batch 57/169] [D loss: 0.692809] [G loss: 0.695052]\n",
      "[Epoch 3/200] [Batch 58/169] [D loss: 0.691839] [G loss: 0.695091]\n",
      "[Epoch 3/200] [Batch 59/169] [D loss: 0.692317] [G loss: 0.695942]\n",
      "[Epoch 3/200] [Batch 60/169] [D loss: 0.691843] [G loss: 0.696034]\n",
      "[Epoch 3/200] [Batch 61/169] [D loss: 0.691158] [G loss: 0.697343]\n",
      "[Epoch 3/200] [Batch 62/169] [D loss: 0.690491] [G loss: 0.697350]\n",
      "[Epoch 3/200] [Batch 63/169] [D loss: 0.690317] [G loss: 0.694873]\n",
      "[Epoch 3/200] [Batch 64/169] [D loss: 0.689868] [G loss: 0.697719]\n",
      "[Epoch 3/200] [Batch 65/169] [D loss: 0.690520] [G loss: 0.697699]\n",
      "[Epoch 3/200] [Batch 66/169] [D loss: 0.691085] [G loss: 0.695672]\n",
      "[Epoch 3/200] [Batch 67/169] [D loss: 0.690212] [G loss: 0.698322]\n",
      "[Epoch 3/200] [Batch 68/169] [D loss: 0.689981] [G loss: 0.695583]\n",
      "[Epoch 3/200] [Batch 69/169] [D loss: 0.688970] [G loss: 0.698044]\n",
      "[Epoch 3/200] [Batch 70/169] [D loss: 0.688815] [G loss: 0.697655]\n",
      "[Epoch 3/200] [Batch 71/169] [D loss: 0.687629] [G loss: 0.700392]\n",
      "[Epoch 3/200] [Batch 72/169] [D loss: 0.689028] [G loss: 0.698270]\n",
      "[Epoch 3/200] [Batch 73/169] [D loss: 0.688752] [G loss: 0.696107]\n",
      "[Epoch 3/200] [Batch 74/169] [D loss: 0.687648] [G loss: 0.695873]\n",
      "[Epoch 3/200] [Batch 75/169] [D loss: 0.689615] [G loss: 0.695541]\n",
      "[Epoch 3/200] [Batch 76/169] [D loss: 0.689622] [G loss: 0.696108]\n",
      "[Epoch 3/200] [Batch 77/169] [D loss: 0.689231] [G loss: 0.694996]\n",
      "[Epoch 3/200] [Batch 78/169] [D loss: 0.691111] [G loss: 0.691736]\n",
      "[Epoch 3/200] [Batch 79/169] [D loss: 0.690750] [G loss: 0.690310]\n",
      "[Epoch 3/200] [Batch 80/169] [D loss: 0.690707] [G loss: 0.692407]\n",
      "[Epoch 3/200] [Batch 81/169] [D loss: 0.690967] [G loss: 0.689292]\n",
      "[Epoch 3/200] [Batch 82/169] [D loss: 0.691832] [G loss: 0.690937]\n",
      "[Epoch 3/200] [Batch 83/169] [D loss: 0.694689] [G loss: 0.687585]\n",
      "[Epoch 3/200] [Batch 84/169] [D loss: 0.695487] [G loss: 0.687551]\n",
      "[Epoch 3/200] [Batch 85/169] [D loss: 0.694545] [G loss: 0.688195]\n",
      "[Epoch 3/200] [Batch 86/169] [D loss: 0.695568] [G loss: 0.685635]\n",
      "[Epoch 3/200] [Batch 87/169] [D loss: 0.695925] [G loss: 0.683226]\n",
      "[Epoch 3/200] [Batch 88/169] [D loss: 0.695650] [G loss: 0.685254]\n",
      "[Epoch 3/200] [Batch 89/169] [D loss: 0.695673] [G loss: 0.684705]\n",
      "[Epoch 3/200] [Batch 90/169] [D loss: 0.695861] [G loss: 0.687640]\n",
      "[Epoch 3/200] [Batch 91/169] [D loss: 0.696831] [G loss: 0.685799]\n",
      "[Epoch 3/200] [Batch 92/169] [D loss: 0.695322] [G loss: 0.686750]\n",
      "[Epoch 3/200] [Batch 93/169] [D loss: 0.696759] [G loss: 0.688384]\n",
      "[Epoch 3/200] [Batch 94/169] [D loss: 0.695712] [G loss: 0.688220]\n",
      "[Epoch 3/200] [Batch 95/169] [D loss: 0.694644] [G loss: 0.691965]\n",
      "[Epoch 3/200] [Batch 96/169] [D loss: 0.694967] [G loss: 0.691735]\n",
      "[Epoch 3/200] [Batch 97/169] [D loss: 0.694750] [G loss: 0.693216]\n",
      "[Epoch 3/200] [Batch 98/169] [D loss: 0.695066] [G loss: 0.693218]\n",
      "[Epoch 3/200] [Batch 99/169] [D loss: 0.693505] [G loss: 0.696416]\n",
      "[Epoch 3/200] [Batch 100/169] [D loss: 0.693869] [G loss: 0.697327]\n",
      "[Epoch 3/200] [Batch 101/169] [D loss: 0.692596] [G loss: 0.699651]\n",
      "[Epoch 3/200] [Batch 102/169] [D loss: 0.691774] [G loss: 0.699916]\n",
      "[Epoch 3/200] [Batch 103/169] [D loss: 0.692142] [G loss: 0.701787]\n",
      "[Epoch 3/200] [Batch 104/169] [D loss: 0.690895] [G loss: 0.702716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 105/169] [D loss: 0.690912] [G loss: 0.704211]\n",
      "[Epoch 3/200] [Batch 106/169] [D loss: 0.690710] [G loss: 0.705552]\n",
      "[Epoch 3/200] [Batch 107/169] [D loss: 0.689201] [G loss: 0.708728]\n",
      "[Epoch 3/200] [Batch 108/169] [D loss: 0.688895] [G loss: 0.707200]\n",
      "[Epoch 3/200] [Batch 109/169] [D loss: 0.687701] [G loss: 0.708675]\n",
      "[Epoch 3/200] [Batch 110/169] [D loss: 0.689680] [G loss: 0.708487]\n",
      "[Epoch 3/200] [Batch 111/169] [D loss: 0.689373] [G loss: 0.707934]\n",
      "[Epoch 3/200] [Batch 112/169] [D loss: 0.687593] [G loss: 0.711048]\n",
      "[Epoch 3/200] [Batch 113/169] [D loss: 0.688614] [G loss: 0.708498]\n",
      "[Epoch 3/200] [Batch 114/169] [D loss: 0.688919] [G loss: 0.709166]\n",
      "[Epoch 3/200] [Batch 115/169] [D loss: 0.688951] [G loss: 0.708018]\n",
      "[Epoch 3/200] [Batch 116/169] [D loss: 0.688848] [G loss: 0.704571]\n",
      "[Epoch 3/200] [Batch 117/169] [D loss: 0.688965] [G loss: 0.706584]\n",
      "[Epoch 3/200] [Batch 118/169] [D loss: 0.690151] [G loss: 0.704573]\n",
      "[Epoch 3/200] [Batch 119/169] [D loss: 0.691428] [G loss: 0.702770]\n",
      "[Epoch 3/200] [Batch 120/169] [D loss: 0.692478] [G loss: 0.700865]\n",
      "[Epoch 3/200] [Batch 121/169] [D loss: 0.691571] [G loss: 0.702184]\n",
      "[Epoch 3/200] [Batch 122/169] [D loss: 0.692332] [G loss: 0.697483]\n",
      "[Epoch 3/200] [Batch 123/169] [D loss: 0.694016] [G loss: 0.693828]\n",
      "[Epoch 3/200] [Batch 124/169] [D loss: 0.695944] [G loss: 0.690699]\n",
      "[Epoch 3/200] [Batch 125/169] [D loss: 0.696524] [G loss: 0.691308]\n",
      "[Epoch 3/200] [Batch 126/169] [D loss: 0.695875] [G loss: 0.688245]\n",
      "[Epoch 3/200] [Batch 127/169] [D loss: 0.694701] [G loss: 0.688542]\n",
      "[Epoch 3/200] [Batch 128/169] [D loss: 0.694305] [G loss: 0.687190]\n",
      "[Epoch 3/200] [Batch 129/169] [D loss: 0.696739] [G loss: 0.684582]\n",
      "[Epoch 3/200] [Batch 130/169] [D loss: 0.694667] [G loss: 0.685963]\n",
      "[Epoch 3/200] [Batch 131/169] [D loss: 0.696468] [G loss: 0.682770]\n",
      "[Epoch 3/200] [Batch 132/169] [D loss: 0.697129] [G loss: 0.685322]\n",
      "[Epoch 3/200] [Batch 133/169] [D loss: 0.696495] [G loss: 0.685353]\n",
      "[Epoch 3/200] [Batch 134/169] [D loss: 0.696106] [G loss: 0.683913]\n",
      "[Epoch 3/200] [Batch 135/169] [D loss: 0.696107] [G loss: 0.683160]\n",
      "[Epoch 3/200] [Batch 136/169] [D loss: 0.693861] [G loss: 0.684258]\n",
      "[Epoch 3/200] [Batch 137/169] [D loss: 0.694616] [G loss: 0.685391]\n",
      "[Epoch 3/200] [Batch 138/169] [D loss: 0.694410] [G loss: 0.683252]\n",
      "[Epoch 3/200] [Batch 139/169] [D loss: 0.692766] [G loss: 0.685284]\n",
      "[Epoch 3/200] [Batch 140/169] [D loss: 0.692755] [G loss: 0.685098]\n",
      "[Epoch 3/200] [Batch 141/169] [D loss: 0.692775] [G loss: 0.684113]\n",
      "[Epoch 3/200] [Batch 142/169] [D loss: 0.691206] [G loss: 0.684202]\n",
      "[Epoch 3/200] [Batch 143/169] [D loss: 0.689796] [G loss: 0.687742]\n",
      "[Epoch 3/200] [Batch 144/169] [D loss: 0.691754] [G loss: 0.686124]\n",
      "[Epoch 3/200] [Batch 145/169] [D loss: 0.690173] [G loss: 0.685113]\n",
      "[Epoch 3/200] [Batch 146/169] [D loss: 0.691166] [G loss: 0.687022]\n",
      "[Epoch 3/200] [Batch 147/169] [D loss: 0.689069] [G loss: 0.686702]\n",
      "[Epoch 3/200] [Batch 148/169] [D loss: 0.689471] [G loss: 0.687450]\n",
      "[Epoch 3/200] [Batch 149/169] [D loss: 0.689695] [G loss: 0.685724]\n",
      "[Epoch 3/200] [Batch 150/169] [D loss: 0.690492] [G loss: 0.686306]\n",
      "[Epoch 3/200] [Batch 151/169] [D loss: 0.690751] [G loss: 0.683866]\n",
      "[Epoch 3/200] [Batch 152/169] [D loss: 0.690791] [G loss: 0.685931]\n",
      "[Epoch 3/200] [Batch 153/169] [D loss: 0.687980] [G loss: 0.684204]\n",
      "[Epoch 3/200] [Batch 154/169] [D loss: 0.688000] [G loss: 0.686649]\n",
      "[Epoch 3/200] [Batch 155/169] [D loss: 0.687701] [G loss: 0.684849]\n",
      "[Epoch 3/200] [Batch 156/169] [D loss: 0.691510] [G loss: 0.685237]\n",
      "[Epoch 3/200] [Batch 157/169] [D loss: 0.690224] [G loss: 0.681957]\n",
      "[Epoch 3/200] [Batch 158/169] [D loss: 0.690549] [G loss: 0.686328]\n",
      "[Epoch 3/200] [Batch 159/169] [D loss: 0.687786] [G loss: 0.682678]\n",
      "[Epoch 3/200] [Batch 160/169] [D loss: 0.690636] [G loss: 0.681091]\n",
      "[Epoch 3/200] [Batch 161/169] [D loss: 0.693933] [G loss: 0.676858]\n",
      "[Epoch 3/200] [Batch 162/169] [D loss: 0.693099] [G loss: 0.677043]\n",
      "[Epoch 3/200] [Batch 163/169] [D loss: 0.692502] [G loss: 0.677876]\n",
      "[Epoch 3/200] [Batch 164/169] [D loss: 0.693839] [G loss: 0.680970]\n",
      "[Epoch 3/200] [Batch 165/169] [D loss: 0.694951] [G loss: 0.679078]\n",
      "[Epoch 3/200] [Batch 166/169] [D loss: 0.695380] [G loss: 0.678500]\n",
      "[Epoch 3/200] [Batch 167/169] [D loss: 0.695411] [G loss: 0.679464]\n",
      "[Epoch 3/200] [Batch 168/169] [D loss: 0.696266] [G loss: 0.675233]\n",
      "[Epoch 4/200] [Batch 0/169] [D loss: 0.698694] [G loss: 0.682359]\n",
      "[Epoch 4/200] [Batch 1/169] [D loss: 0.695816] [G loss: 0.683690]\n",
      "[Epoch 4/200] [Batch 2/169] [D loss: 0.697160] [G loss: 0.682511]\n",
      "[Epoch 4/200] [Batch 3/169] [D loss: 0.696965] [G loss: 0.686828]\n",
      "[Epoch 4/200] [Batch 4/169] [D loss: 0.696509] [G loss: 0.687093]\n",
      "[Epoch 4/200] [Batch 5/169] [D loss: 0.694691] [G loss: 0.692979]\n",
      "[Epoch 4/200] [Batch 6/169] [D loss: 0.695971] [G loss: 0.691784]\n",
      "[Epoch 4/200] [Batch 7/169] [D loss: 0.695410] [G loss: 0.695812]\n",
      "[Epoch 4/200] [Batch 8/169] [D loss: 0.693595] [G loss: 0.697679]\n",
      "[Epoch 4/200] [Batch 9/169] [D loss: 0.693808] [G loss: 0.701091]\n",
      "[Epoch 4/200] [Batch 10/169] [D loss: 0.693433] [G loss: 0.700541]\n",
      "[Epoch 4/200] [Batch 11/169] [D loss: 0.692267] [G loss: 0.702204]\n",
      "[Epoch 4/200] [Batch 12/169] [D loss: 0.691407] [G loss: 0.703340]\n",
      "[Epoch 4/200] [Batch 13/169] [D loss: 0.691644] [G loss: 0.706998]\n",
      "[Epoch 4/200] [Batch 14/169] [D loss: 0.691312] [G loss: 0.708757]\n",
      "[Epoch 4/200] [Batch 15/169] [D loss: 0.690510] [G loss: 0.711486]\n",
      "[Epoch 4/200] [Batch 16/169] [D loss: 0.690312] [G loss: 0.711552]\n",
      "[Epoch 4/200] [Batch 17/169] [D loss: 0.690455] [G loss: 0.713029]\n",
      "[Epoch 4/200] [Batch 18/169] [D loss: 0.688040] [G loss: 0.715462]\n",
      "[Epoch 4/200] [Batch 19/169] [D loss: 0.691571] [G loss: 0.714624]\n",
      "[Epoch 4/200] [Batch 20/169] [D loss: 0.688131] [G loss: 0.717880]\n",
      "[Epoch 4/200] [Batch 21/169] [D loss: 0.691696] [G loss: 0.716632]\n",
      "[Epoch 4/200] [Batch 22/169] [D loss: 0.691986] [G loss: 0.719022]\n",
      "[Epoch 4/200] [Batch 23/169] [D loss: 0.691791] [G loss: 0.719358]\n",
      "[Epoch 4/200] [Batch 24/169] [D loss: 0.691414] [G loss: 0.717246]\n",
      "[Epoch 4/200] [Batch 25/169] [D loss: 0.692409] [G loss: 0.714312]\n",
      "[Epoch 4/200] [Batch 26/169] [D loss: 0.691026] [G loss: 0.718579]\n",
      "[Epoch 4/200] [Batch 27/169] [D loss: 0.691482] [G loss: 0.715766]\n",
      "[Epoch 4/200] [Batch 28/169] [D loss: 0.689892] [G loss: 0.713412]\n",
      "[Epoch 4/200] [Batch 29/169] [D loss: 0.690698] [G loss: 0.713170]\n",
      "[Epoch 4/200] [Batch 30/169] [D loss: 0.692683] [G loss: 0.709702]\n",
      "[Epoch 4/200] [Batch 31/169] [D loss: 0.695326] [G loss: 0.709936]\n",
      "[Epoch 4/200] [Batch 32/169] [D loss: 0.691682] [G loss: 0.710203]\n",
      "[Epoch 4/200] [Batch 33/169] [D loss: 0.695563] [G loss: 0.707760]\n",
      "[Epoch 4/200] [Batch 34/169] [D loss: 0.693808] [G loss: 0.706520]\n",
      "[Epoch 4/200] [Batch 35/169] [D loss: 0.695596] [G loss: 0.703819]\n",
      "[Epoch 4/200] [Batch 36/169] [D loss: 0.695328] [G loss: 0.704850]\n",
      "[Epoch 4/200] [Batch 37/169] [D loss: 0.697735] [G loss: 0.702465]\n",
      "[Epoch 4/200] [Batch 38/169] [D loss: 0.694320] [G loss: 0.703523]\n",
      "[Epoch 4/200] [Batch 39/169] [D loss: 0.695886] [G loss: 0.700437]\n",
      "[Epoch 4/200] [Batch 40/169] [D loss: 0.694361] [G loss: 0.698709]\n",
      "[Epoch 4/200] [Batch 41/169] [D loss: 0.697294] [G loss: 0.697228]\n",
      "[Epoch 4/200] [Batch 42/169] [D loss: 0.696464] [G loss: 0.696935]\n",
      "[Epoch 4/200] [Batch 43/169] [D loss: 0.695082] [G loss: 0.694370]\n",
      "[Epoch 4/200] [Batch 44/169] [D loss: 0.694932] [G loss: 0.695573]\n",
      "[Epoch 4/200] [Batch 45/169] [D loss: 0.694497] [G loss: 0.695359]\n",
      "[Epoch 4/200] [Batch 46/169] [D loss: 0.694687] [G loss: 0.693040]\n",
      "[Epoch 4/200] [Batch 47/169] [D loss: 0.694406] [G loss: 0.693722]\n",
      "[Epoch 4/200] [Batch 48/169] [D loss: 0.693033] [G loss: 0.694852]\n",
      "[Epoch 4/200] [Batch 49/169] [D loss: 0.692644] [G loss: 0.694660]\n",
      "[Epoch 4/200] [Batch 50/169] [D loss: 0.693534] [G loss: 0.694130]\n",
      "[Epoch 4/200] [Batch 51/169] [D loss: 0.692085] [G loss: 0.691717]\n",
      "[Epoch 4/200] [Batch 52/169] [D loss: 0.692319] [G loss: 0.691466]\n",
      "[Epoch 4/200] [Batch 53/169] [D loss: 0.692235] [G loss: 0.691460]\n",
      "[Epoch 4/200] [Batch 54/169] [D loss: 0.691339] [G loss: 0.691773]\n",
      "[Epoch 4/200] [Batch 55/169] [D loss: 0.691152] [G loss: 0.690954]\n",
      "[Epoch 4/200] [Batch 56/169] [D loss: 0.690190] [G loss: 0.693360]\n",
      "[Epoch 4/200] [Batch 57/169] [D loss: 0.691343] [G loss: 0.691432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 58/169] [D loss: 0.690676] [G loss: 0.688592]\n",
      "[Epoch 4/200] [Batch 59/169] [D loss: 0.691543] [G loss: 0.687110]\n",
      "[Epoch 4/200] [Batch 60/169] [D loss: 0.688687] [G loss: 0.689459]\n",
      "[Epoch 4/200] [Batch 61/169] [D loss: 0.690872] [G loss: 0.687362]\n",
      "[Epoch 4/200] [Batch 62/169] [D loss: 0.689936] [G loss: 0.685447]\n",
      "[Epoch 4/200] [Batch 63/169] [D loss: 0.691329] [G loss: 0.685309]\n",
      "[Epoch 4/200] [Batch 64/169] [D loss: 0.692222] [G loss: 0.686989]\n",
      "[Epoch 4/200] [Batch 65/169] [D loss: 0.689248] [G loss: 0.682953]\n",
      "[Epoch 4/200] [Batch 66/169] [D loss: 0.693068] [G loss: 0.682522]\n",
      "[Epoch 4/200] [Batch 67/169] [D loss: 0.690244] [G loss: 0.684102]\n",
      "[Epoch 4/200] [Batch 68/169] [D loss: 0.690465] [G loss: 0.682191]\n",
      "[Epoch 4/200] [Batch 69/169] [D loss: 0.690754] [G loss: 0.681706]\n",
      "[Epoch 4/200] [Batch 70/169] [D loss: 0.693260] [G loss: 0.679922]\n",
      "[Epoch 4/200] [Batch 71/169] [D loss: 0.693301] [G loss: 0.679103]\n",
      "[Epoch 4/200] [Batch 72/169] [D loss: 0.691372] [G loss: 0.680278]\n",
      "[Epoch 4/200] [Batch 73/169] [D loss: 0.693219] [G loss: 0.677889]\n",
      "[Epoch 4/200] [Batch 74/169] [D loss: 0.693540] [G loss: 0.678558]\n",
      "[Epoch 4/200] [Batch 75/169] [D loss: 0.692941] [G loss: 0.680904]\n",
      "[Epoch 4/200] [Batch 76/169] [D loss: 0.694900] [G loss: 0.674980]\n",
      "[Epoch 4/200] [Batch 77/169] [D loss: 0.693509] [G loss: 0.678528]\n",
      "[Epoch 4/200] [Batch 78/169] [D loss: 0.692572] [G loss: 0.679288]\n",
      "[Epoch 4/200] [Batch 79/169] [D loss: 0.693849] [G loss: 0.679464]\n",
      "[Epoch 4/200] [Batch 80/169] [D loss: 0.693310] [G loss: 0.683471]\n",
      "[Epoch 4/200] [Batch 81/169] [D loss: 0.695460] [G loss: 0.682178]\n",
      "[Epoch 4/200] [Batch 82/169] [D loss: 0.694161] [G loss: 0.683086]\n",
      "[Epoch 4/200] [Batch 83/169] [D loss: 0.694358] [G loss: 0.684701]\n",
      "[Epoch 4/200] [Batch 84/169] [D loss: 0.692175] [G loss: 0.687765]\n",
      "[Epoch 4/200] [Batch 85/169] [D loss: 0.693041] [G loss: 0.685617]\n",
      "[Epoch 4/200] [Batch 86/169] [D loss: 0.691330] [G loss: 0.689272]\n",
      "[Epoch 4/200] [Batch 87/169] [D loss: 0.691968] [G loss: 0.690538]\n",
      "[Epoch 4/200] [Batch 88/169] [D loss: 0.693181] [G loss: 0.689500]\n",
      "[Epoch 4/200] [Batch 89/169] [D loss: 0.691165] [G loss: 0.692811]\n",
      "[Epoch 4/200] [Batch 90/169] [D loss: 0.691862] [G loss: 0.693310]\n",
      "[Epoch 4/200] [Batch 91/169] [D loss: 0.692112] [G loss: 0.692826]\n",
      "[Epoch 4/200] [Batch 92/169] [D loss: 0.691036] [G loss: 0.696633]\n",
      "[Epoch 4/200] [Batch 93/169] [D loss: 0.689709] [G loss: 0.695848]\n",
      "[Epoch 4/200] [Batch 94/169] [D loss: 0.689463] [G loss: 0.701141]\n",
      "[Epoch 4/200] [Batch 95/169] [D loss: 0.690597] [G loss: 0.699258]\n",
      "[Epoch 4/200] [Batch 96/169] [D loss: 0.689717] [G loss: 0.698750]\n",
      "[Epoch 4/200] [Batch 97/169] [D loss: 0.690639] [G loss: 0.701281]\n",
      "[Epoch 4/200] [Batch 98/169] [D loss: 0.690604] [G loss: 0.703175]\n",
      "[Epoch 4/200] [Batch 99/169] [D loss: 0.690033] [G loss: 0.702017]\n",
      "[Epoch 4/200] [Batch 100/169] [D loss: 0.690685] [G loss: 0.701927]\n",
      "[Epoch 4/200] [Batch 101/169] [D loss: 0.690499] [G loss: 0.703061]\n",
      "[Epoch 4/200] [Batch 102/169] [D loss: 0.688643] [G loss: 0.702527]\n",
      "[Epoch 4/200] [Batch 103/169] [D loss: 0.692381] [G loss: 0.701355]\n",
      "[Epoch 4/200] [Batch 104/169] [D loss: 0.690733] [G loss: 0.702559]\n",
      "[Epoch 4/200] [Batch 105/169] [D loss: 0.691465] [G loss: 0.703249]\n",
      "[Epoch 4/200] [Batch 106/169] [D loss: 0.691454] [G loss: 0.702685]\n",
      "[Epoch 4/200] [Batch 107/169] [D loss: 0.691669] [G loss: 0.699252]\n",
      "[Epoch 4/200] [Batch 108/169] [D loss: 0.694013] [G loss: 0.703298]\n",
      "[Epoch 4/200] [Batch 109/169] [D loss: 0.693177] [G loss: 0.697923]\n",
      "[Epoch 4/200] [Batch 110/169] [D loss: 0.694578] [G loss: 0.699878]\n",
      "[Epoch 4/200] [Batch 111/169] [D loss: 0.694885] [G loss: 0.697870]\n",
      "[Epoch 4/200] [Batch 112/169] [D loss: 0.694640] [G loss: 0.698622]\n",
      "[Epoch 4/200] [Batch 113/169] [D loss: 0.695198] [G loss: 0.698801]\n",
      "[Epoch 4/200] [Batch 114/169] [D loss: 0.695493] [G loss: 0.696753]\n",
      "[Epoch 4/200] [Batch 115/169] [D loss: 0.694710] [G loss: 0.696914]\n",
      "[Epoch 4/200] [Batch 116/169] [D loss: 0.694606] [G loss: 0.698691]\n",
      "[Epoch 4/200] [Batch 117/169] [D loss: 0.693823] [G loss: 0.698249]\n",
      "[Epoch 4/200] [Batch 118/169] [D loss: 0.693968] [G loss: 0.697982]\n",
      "[Epoch 4/200] [Batch 119/169] [D loss: 0.695728] [G loss: 0.694607]\n",
      "[Epoch 4/200] [Batch 120/169] [D loss: 0.695034] [G loss: 0.697562]\n",
      "[Epoch 4/200] [Batch 121/169] [D loss: 0.694636] [G loss: 0.699333]\n",
      "[Epoch 4/200] [Batch 122/169] [D loss: 0.694685] [G loss: 0.695337]\n",
      "[Epoch 4/200] [Batch 123/169] [D loss: 0.695093] [G loss: 0.697435]\n",
      "[Epoch 4/200] [Batch 124/169] [D loss: 0.692769] [G loss: 0.698035]\n",
      "[Epoch 4/200] [Batch 125/169] [D loss: 0.694029] [G loss: 0.700747]\n",
      "[Epoch 4/200] [Batch 126/169] [D loss: 0.693517] [G loss: 0.699393]\n",
      "[Epoch 4/200] [Batch 127/169] [D loss: 0.692214] [G loss: 0.699083]\n",
      "[Epoch 4/200] [Batch 128/169] [D loss: 0.692214] [G loss: 0.699037]\n",
      "[Epoch 4/200] [Batch 129/169] [D loss: 0.691401] [G loss: 0.700843]\n",
      "[Epoch 4/200] [Batch 130/169] [D loss: 0.691562] [G loss: 0.704074]\n",
      "[Epoch 4/200] [Batch 131/169] [D loss: 0.691575] [G loss: 0.700788]\n",
      "[Epoch 4/200] [Batch 132/169] [D loss: 0.690110] [G loss: 0.701390]\n",
      "[Epoch 4/200] [Batch 133/169] [D loss: 0.690070] [G loss: 0.704458]\n",
      "[Epoch 4/200] [Batch 134/169] [D loss: 0.689244] [G loss: 0.701470]\n",
      "[Epoch 4/200] [Batch 135/169] [D loss: 0.690068] [G loss: 0.702748]\n",
      "[Epoch 4/200] [Batch 136/169] [D loss: 0.687439] [G loss: 0.701503]\n",
      "[Epoch 4/200] [Batch 137/169] [D loss: 0.686755] [G loss: 0.704195]\n",
      "[Epoch 4/200] [Batch 138/169] [D loss: 0.690775] [G loss: 0.703663]\n",
      "[Epoch 4/200] [Batch 139/169] [D loss: 0.687770] [G loss: 0.703689]\n",
      "[Epoch 4/200] [Batch 140/169] [D loss: 0.690929] [G loss: 0.700955]\n",
      "[Epoch 4/200] [Batch 141/169] [D loss: 0.691178] [G loss: 0.698981]\n",
      "[Epoch 4/200] [Batch 142/169] [D loss: 0.690104] [G loss: 0.699961]\n",
      "[Epoch 4/200] [Batch 143/169] [D loss: 0.691464] [G loss: 0.701284]\n",
      "[Epoch 4/200] [Batch 144/169] [D loss: 0.689312] [G loss: 0.698044]\n",
      "[Epoch 4/200] [Batch 145/169] [D loss: 0.689665] [G loss: 0.697189]\n",
      "[Epoch 4/200] [Batch 146/169] [D loss: 0.691859] [G loss: 0.697621]\n",
      "[Epoch 4/200] [Batch 147/169] [D loss: 0.693632] [G loss: 0.695047]\n",
      "[Epoch 4/200] [Batch 148/169] [D loss: 0.691260] [G loss: 0.695107]\n",
      "[Epoch 4/200] [Batch 149/169] [D loss: 0.691219] [G loss: 0.694771]\n",
      "[Epoch 4/200] [Batch 150/169] [D loss: 0.696794] [G loss: 0.686955]\n",
      "[Epoch 4/200] [Batch 151/169] [D loss: 0.694578] [G loss: 0.690296]\n",
      "[Epoch 4/200] [Batch 152/169] [D loss: 0.694192] [G loss: 0.692045]\n",
      "[Epoch 4/200] [Batch 153/169] [D loss: 0.694992] [G loss: 0.691734]\n",
      "[Epoch 4/200] [Batch 154/169] [D loss: 0.695261] [G loss: 0.689947]\n",
      "[Epoch 4/200] [Batch 155/169] [D loss: 0.694404] [G loss: 0.693359]\n",
      "[Epoch 4/200] [Batch 156/169] [D loss: 0.695472] [G loss: 0.692492]\n",
      "[Epoch 4/200] [Batch 157/169] [D loss: 0.692032] [G loss: 0.694204]\n",
      "[Epoch 4/200] [Batch 158/169] [D loss: 0.694977] [G loss: 0.694573]\n",
      "[Epoch 4/200] [Batch 159/169] [D loss: 0.695628] [G loss: 0.694469]\n",
      "[Epoch 4/200] [Batch 160/169] [D loss: 0.691617] [G loss: 0.700569]\n",
      "[Epoch 4/200] [Batch 161/169] [D loss: 0.692947] [G loss: 0.700890]\n",
      "[Epoch 4/200] [Batch 162/169] [D loss: 0.692924] [G loss: 0.705192]\n",
      "[Epoch 4/200] [Batch 163/169] [D loss: 0.690937] [G loss: 0.703690]\n",
      "[Epoch 4/200] [Batch 164/169] [D loss: 0.692849] [G loss: 0.706438]\n",
      "[Epoch 4/200] [Batch 165/169] [D loss: 0.691779] [G loss: 0.709579]\n",
      "[Epoch 4/200] [Batch 166/169] [D loss: 0.687033] [G loss: 0.709435]\n",
      "[Epoch 4/200] [Batch 167/169] [D loss: 0.687299] [G loss: 0.713241]\n",
      "[Epoch 4/200] [Batch 168/169] [D loss: 0.689067] [G loss: 0.717112]\n",
      "[Epoch 5/200] [Batch 0/169] [D loss: 0.687520] [G loss: 0.715432]\n",
      "[Epoch 5/200] [Batch 1/169] [D loss: 0.686326] [G loss: 0.716023]\n",
      "[Epoch 5/200] [Batch 2/169] [D loss: 0.684890] [G loss: 0.719763]\n",
      "[Epoch 5/200] [Batch 3/169] [D loss: 0.688159] [G loss: 0.715745]\n",
      "[Epoch 5/200] [Batch 4/169] [D loss: 0.685680] [G loss: 0.718650]\n",
      "[Epoch 5/200] [Batch 5/169] [D loss: 0.686890] [G loss: 0.715428]\n",
      "[Epoch 5/200] [Batch 6/169] [D loss: 0.687571] [G loss: 0.713238]\n",
      "[Epoch 5/200] [Batch 7/169] [D loss: 0.686772] [G loss: 0.716461]\n",
      "[Epoch 5/200] [Batch 8/169] [D loss: 0.685079] [G loss: 0.712617]\n",
      "[Epoch 5/200] [Batch 9/169] [D loss: 0.686976] [G loss: 0.710212]\n",
      "[Epoch 5/200] [Batch 10/169] [D loss: 0.689992] [G loss: 0.705955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 11/169] [D loss: 0.693011] [G loss: 0.702389]\n",
      "[Epoch 5/200] [Batch 12/169] [D loss: 0.688562] [G loss: 0.698121]\n",
      "[Epoch 5/200] [Batch 13/169] [D loss: 0.694468] [G loss: 0.697797]\n",
      "[Epoch 5/200] [Batch 14/169] [D loss: 0.692033] [G loss: 0.696170]\n",
      "[Epoch 5/200] [Batch 15/169] [D loss: 0.694070] [G loss: 0.692205]\n",
      "[Epoch 5/200] [Batch 16/169] [D loss: 0.696949] [G loss: 0.688767]\n",
      "[Epoch 5/200] [Batch 17/169] [D loss: 0.698785] [G loss: 0.688759]\n",
      "[Epoch 5/200] [Batch 18/169] [D loss: 0.698021] [G loss: 0.686292]\n",
      "[Epoch 5/200] [Batch 19/169] [D loss: 0.701698] [G loss: 0.683190]\n",
      "[Epoch 5/200] [Batch 20/169] [D loss: 0.696890] [G loss: 0.682461]\n",
      "[Epoch 5/200] [Batch 21/169] [D loss: 0.697235] [G loss: 0.684631]\n",
      "[Epoch 5/200] [Batch 22/169] [D loss: 0.695168] [G loss: 0.681849]\n",
      "[Epoch 5/200] [Batch 23/169] [D loss: 0.697718] [G loss: 0.680582]\n",
      "[Epoch 5/200] [Batch 24/169] [D loss: 0.694126] [G loss: 0.680922]\n",
      "[Epoch 5/200] [Batch 25/169] [D loss: 0.695868] [G loss: 0.682891]\n",
      "[Epoch 5/200] [Batch 26/169] [D loss: 0.693802] [G loss: 0.683775]\n",
      "[Epoch 5/200] [Batch 27/169] [D loss: 0.690030] [G loss: 0.684202]\n",
      "[Epoch 5/200] [Batch 28/169] [D loss: 0.690860] [G loss: 0.683585]\n",
      "[Epoch 5/200] [Batch 29/169] [D loss: 0.691011] [G loss: 0.683682]\n",
      "[Epoch 5/200] [Batch 30/169] [D loss: 0.691103] [G loss: 0.685284]\n",
      "[Epoch 5/200] [Batch 31/169] [D loss: 0.688893] [G loss: 0.688237]\n",
      "[Epoch 5/200] [Batch 32/169] [D loss: 0.689441] [G loss: 0.686872]\n",
      "[Epoch 5/200] [Batch 33/169] [D loss: 0.687851] [G loss: 0.686151]\n",
      "[Epoch 5/200] [Batch 34/169] [D loss: 0.686070] [G loss: 0.686507]\n",
      "[Epoch 5/200] [Batch 35/169] [D loss: 0.687311] [G loss: 0.686473]\n",
      "[Epoch 5/200] [Batch 36/169] [D loss: 0.684768] [G loss: 0.684817]\n",
      "[Epoch 5/200] [Batch 37/169] [D loss: 0.689261] [G loss: 0.685626]\n",
      "[Epoch 5/200] [Batch 38/169] [D loss: 0.685947] [G loss: 0.687422]\n",
      "[Epoch 5/200] [Batch 39/169] [D loss: 0.687894] [G loss: 0.680223]\n",
      "[Epoch 5/200] [Batch 40/169] [D loss: 0.686272] [G loss: 0.687568]\n",
      "[Epoch 5/200] [Batch 41/169] [D loss: 0.688194] [G loss: 0.685066]\n",
      "[Epoch 5/200] [Batch 42/169] [D loss: 0.684622] [G loss: 0.681546]\n",
      "[Epoch 5/200] [Batch 43/169] [D loss: 0.687632] [G loss: 0.679582]\n",
      "[Epoch 5/200] [Batch 44/169] [D loss: 0.689857] [G loss: 0.678074]\n",
      "[Epoch 5/200] [Batch 45/169] [D loss: 0.695035] [G loss: 0.677578]\n",
      "[Epoch 5/200] [Batch 46/169] [D loss: 0.693170] [G loss: 0.675841]\n",
      "[Epoch 5/200] [Batch 47/169] [D loss: 0.697373] [G loss: 0.672035]\n",
      "[Epoch 5/200] [Batch 48/169] [D loss: 0.699033] [G loss: 0.667067]\n",
      "[Epoch 5/200] [Batch 49/169] [D loss: 0.699902] [G loss: 0.674007]\n",
      "[Epoch 5/200] [Batch 50/169] [D loss: 0.700209] [G loss: 0.671838]\n",
      "[Epoch 5/200] [Batch 51/169] [D loss: 0.698189] [G loss: 0.675419]\n",
      "[Epoch 5/200] [Batch 52/169] [D loss: 0.698113] [G loss: 0.676772]\n",
      "[Epoch 5/200] [Batch 53/169] [D loss: 0.702856] [G loss: 0.676283]\n",
      "[Epoch 5/200] [Batch 54/169] [D loss: 0.700552] [G loss: 0.680289]\n",
      "[Epoch 5/200] [Batch 55/169] [D loss: 0.698637] [G loss: 0.684245]\n",
      "[Epoch 5/200] [Batch 56/169] [D loss: 0.698037] [G loss: 0.686085]\n",
      "[Epoch 5/200] [Batch 57/169] [D loss: 0.695591] [G loss: 0.693719]\n",
      "[Epoch 5/200] [Batch 58/169] [D loss: 0.695008] [G loss: 0.696865]\n",
      "[Epoch 5/200] [Batch 59/169] [D loss: 0.695887] [G loss: 0.698365]\n",
      "[Epoch 5/200] [Batch 60/169] [D loss: 0.693127] [G loss: 0.701914]\n",
      "[Epoch 5/200] [Batch 61/169] [D loss: 0.693094] [G loss: 0.707044]\n",
      "[Epoch 5/200] [Batch 62/169] [D loss: 0.692817] [G loss: 0.706020]\n",
      "[Epoch 5/200] [Batch 63/169] [D loss: 0.691045] [G loss: 0.713767]\n",
      "[Epoch 5/200] [Batch 64/169] [D loss: 0.690182] [G loss: 0.714505]\n",
      "[Epoch 5/200] [Batch 65/169] [D loss: 0.689308] [G loss: 0.718695]\n",
      "[Epoch 5/200] [Batch 66/169] [D loss: 0.689576] [G loss: 0.718539]\n",
      "[Epoch 5/200] [Batch 67/169] [D loss: 0.689222] [G loss: 0.723588]\n",
      "[Epoch 5/200] [Batch 68/169] [D loss: 0.688892] [G loss: 0.727593]\n",
      "[Epoch 5/200] [Batch 69/169] [D loss: 0.687645] [G loss: 0.728236]\n",
      "[Epoch 5/200] [Batch 70/169] [D loss: 0.689576] [G loss: 0.727525]\n",
      "[Epoch 5/200] [Batch 71/169] [D loss: 0.685648] [G loss: 0.726158]\n",
      "[Epoch 5/200] [Batch 72/169] [D loss: 0.689198] [G loss: 0.725570]\n",
      "[Epoch 5/200] [Batch 73/169] [D loss: 0.688400] [G loss: 0.726228]\n",
      "[Epoch 5/200] [Batch 74/169] [D loss: 0.686948] [G loss: 0.723831]\n",
      "[Epoch 5/200] [Batch 75/169] [D loss: 0.691078] [G loss: 0.726779]\n",
      "[Epoch 5/200] [Batch 76/169] [D loss: 0.690749] [G loss: 0.722697]\n",
      "[Epoch 5/200] [Batch 77/169] [D loss: 0.691378] [G loss: 0.720441]\n",
      "[Epoch 5/200] [Batch 78/169] [D loss: 0.695663] [G loss: 0.715345]\n",
      "[Epoch 5/200] [Batch 79/169] [D loss: 0.695214] [G loss: 0.710700]\n",
      "[Epoch 5/200] [Batch 80/169] [D loss: 0.695421] [G loss: 0.708343]\n",
      "[Epoch 5/200] [Batch 81/169] [D loss: 0.701754] [G loss: 0.705497]\n",
      "[Epoch 5/200] [Batch 82/169] [D loss: 0.699573] [G loss: 0.701829]\n",
      "[Epoch 5/200] [Batch 83/169] [D loss: 0.695376] [G loss: 0.699876]\n",
      "[Epoch 5/200] [Batch 84/169] [D loss: 0.699484] [G loss: 0.693699]\n",
      "[Epoch 5/200] [Batch 85/169] [D loss: 0.698398] [G loss: 0.692693]\n",
      "[Epoch 5/200] [Batch 86/169] [D loss: 0.700580] [G loss: 0.689569]\n",
      "[Epoch 5/200] [Batch 87/169] [D loss: 0.697661] [G loss: 0.688176]\n",
      "[Epoch 5/200] [Batch 88/169] [D loss: 0.696835] [G loss: 0.685646]\n",
      "[Epoch 5/200] [Batch 89/169] [D loss: 0.695831] [G loss: 0.687761]\n",
      "[Epoch 5/200] [Batch 90/169] [D loss: 0.694197] [G loss: 0.685544]\n",
      "[Epoch 5/200] [Batch 91/169] [D loss: 0.694595] [G loss: 0.682978]\n",
      "[Epoch 5/200] [Batch 92/169] [D loss: 0.694281] [G loss: 0.683137]\n",
      "[Epoch 5/200] [Batch 93/169] [D loss: 0.693262] [G loss: 0.683106]\n",
      "[Epoch 5/200] [Batch 94/169] [D loss: 0.692677] [G loss: 0.681571]\n",
      "[Epoch 5/200] [Batch 95/169] [D loss: 0.692337] [G loss: 0.683598]\n",
      "[Epoch 5/200] [Batch 96/169] [D loss: 0.690692] [G loss: 0.682803]\n",
      "[Epoch 5/200] [Batch 97/169] [D loss: 0.690169] [G loss: 0.683467]\n",
      "[Epoch 5/200] [Batch 98/169] [D loss: 0.688637] [G loss: 0.685527]\n",
      "[Epoch 5/200] [Batch 99/169] [D loss: 0.687915] [G loss: 0.681746]\n",
      "[Epoch 5/200] [Batch 100/169] [D loss: 0.688025] [G loss: 0.682715]\n",
      "[Epoch 5/200] [Batch 101/169] [D loss: 0.689830] [G loss: 0.682402]\n",
      "[Epoch 5/200] [Batch 102/169] [D loss: 0.690181] [G loss: 0.681711]\n",
      "[Epoch 5/200] [Batch 103/169] [D loss: 0.687988] [G loss: 0.680951]\n",
      "[Epoch 5/200] [Batch 104/169] [D loss: 0.689641] [G loss: 0.681670]\n",
      "[Epoch 5/200] [Batch 105/169] [D loss: 0.688569] [G loss: 0.679375]\n",
      "[Epoch 5/200] [Batch 106/169] [D loss: 0.687624] [G loss: 0.680001]\n",
      "[Epoch 5/200] [Batch 107/169] [D loss: 0.688249] [G loss: 0.672904]\n",
      "[Epoch 5/200] [Batch 108/169] [D loss: 0.688887] [G loss: 0.673292]\n",
      "[Epoch 5/200] [Batch 109/169] [D loss: 0.687537] [G loss: 0.673241]\n",
      "[Epoch 5/200] [Batch 110/169] [D loss: 0.691723] [G loss: 0.672241]\n",
      "[Epoch 5/200] [Batch 111/169] [D loss: 0.692090] [G loss: 0.670679]\n",
      "[Epoch 5/200] [Batch 112/169] [D loss: 0.694710] [G loss: 0.665376]\n",
      "[Epoch 5/200] [Batch 113/169] [D loss: 0.692953] [G loss: 0.666251]\n",
      "[Epoch 5/200] [Batch 114/169] [D loss: 0.694042] [G loss: 0.668805]\n",
      "[Epoch 5/200] [Batch 115/169] [D loss: 0.696954] [G loss: 0.665922]\n",
      "[Epoch 5/200] [Batch 116/169] [D loss: 0.697189] [G loss: 0.663798]\n",
      "[Epoch 5/200] [Batch 117/169] [D loss: 0.696212] [G loss: 0.665813]\n",
      "[Epoch 5/200] [Batch 118/169] [D loss: 0.697885] [G loss: 0.668968]\n",
      "[Epoch 5/200] [Batch 119/169] [D loss: 0.695713] [G loss: 0.669212]\n",
      "[Epoch 5/200] [Batch 120/169] [D loss: 0.700659] [G loss: 0.669822]\n",
      "[Epoch 5/200] [Batch 121/169] [D loss: 0.697265] [G loss: 0.677079]\n",
      "[Epoch 5/200] [Batch 122/169] [D loss: 0.694316] [G loss: 0.679576]\n",
      "[Epoch 5/200] [Batch 123/169] [D loss: 0.695371] [G loss: 0.681753]\n",
      "[Epoch 5/200] [Batch 124/169] [D loss: 0.694211] [G loss: 0.685850]\n",
      "[Epoch 5/200] [Batch 125/169] [D loss: 0.693997] [G loss: 0.688603]\n",
      "[Epoch 5/200] [Batch 126/169] [D loss: 0.693722] [G loss: 0.690213]\n",
      "[Epoch 5/200] [Batch 127/169] [D loss: 0.692793] [G loss: 0.693717]\n",
      "[Epoch 5/200] [Batch 128/169] [D loss: 0.692778] [G loss: 0.695676]\n",
      "[Epoch 5/200] [Batch 129/169] [D loss: 0.692120] [G loss: 0.695776]\n",
      "[Epoch 5/200] [Batch 130/169] [D loss: 0.692266] [G loss: 0.701289]\n",
      "[Epoch 5/200] [Batch 131/169] [D loss: 0.690351] [G loss: 0.701269]\n",
      "[Epoch 5/200] [Batch 132/169] [D loss: 0.690827] [G loss: 0.703698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 133/169] [D loss: 0.689453] [G loss: 0.706441]\n",
      "[Epoch 5/200] [Batch 134/169] [D loss: 0.689235] [G loss: 0.707933]\n",
      "[Epoch 5/200] [Batch 135/169] [D loss: 0.690324] [G loss: 0.708314]\n",
      "[Epoch 5/200] [Batch 136/169] [D loss: 0.689374] [G loss: 0.709931]\n",
      "[Epoch 5/200] [Batch 137/169] [D loss: 0.690774] [G loss: 0.710965]\n",
      "[Epoch 5/200] [Batch 138/169] [D loss: 0.692539] [G loss: 0.707632]\n",
      "[Epoch 5/200] [Batch 139/169] [D loss: 0.688914] [G loss: 0.710898]\n",
      "[Epoch 5/200] [Batch 140/169] [D loss: 0.689356] [G loss: 0.711555]\n",
      "[Epoch 5/200] [Batch 141/169] [D loss: 0.692281] [G loss: 0.709758]\n",
      "[Epoch 5/200] [Batch 142/169] [D loss: 0.691567] [G loss: 0.708753]\n",
      "[Epoch 5/200] [Batch 143/169] [D loss: 0.692783] [G loss: 0.705883]\n",
      "[Epoch 5/200] [Batch 144/169] [D loss: 0.692501] [G loss: 0.706298]\n",
      "[Epoch 5/200] [Batch 145/169] [D loss: 0.694372] [G loss: 0.706093]\n",
      "[Epoch 5/200] [Batch 146/169] [D loss: 0.693850] [G loss: 0.705540]\n",
      "[Epoch 5/200] [Batch 147/169] [D loss: 0.693645] [G loss: 0.705329]\n",
      "[Epoch 5/200] [Batch 148/169] [D loss: 0.694465] [G loss: 0.702208]\n",
      "[Epoch 5/200] [Batch 149/169] [D loss: 0.696839] [G loss: 0.698462]\n",
      "[Epoch 5/200] [Batch 150/169] [D loss: 0.696820] [G loss: 0.698438]\n",
      "[Epoch 5/200] [Batch 151/169] [D loss: 0.694561] [G loss: 0.697607]\n",
      "[Epoch 5/200] [Batch 152/169] [D loss: 0.696630] [G loss: 0.697453]\n",
      "[Epoch 5/200] [Batch 153/169] [D loss: 0.696680] [G loss: 0.697623]\n",
      "[Epoch 5/200] [Batch 154/169] [D loss: 0.694715] [G loss: 0.696217]\n",
      "[Epoch 5/200] [Batch 155/169] [D loss: 0.694502] [G loss: 0.695631]\n",
      "[Epoch 5/200] [Batch 156/169] [D loss: 0.694291] [G loss: 0.696849]\n",
      "[Epoch 5/200] [Batch 157/169] [D loss: 0.693652] [G loss: 0.698131]\n",
      "[Epoch 5/200] [Batch 158/169] [D loss: 0.692726] [G loss: 0.696331]\n",
      "[Epoch 5/200] [Batch 159/169] [D loss: 0.693132] [G loss: 0.696944]\n",
      "[Epoch 5/200] [Batch 160/169] [D loss: 0.692436] [G loss: 0.693645]\n",
      "[Epoch 5/200] [Batch 161/169] [D loss: 0.692445] [G loss: 0.696165]\n",
      "[Epoch 5/200] [Batch 162/169] [D loss: 0.690869] [G loss: 0.698216]\n",
      "[Epoch 5/200] [Batch 163/169] [D loss: 0.691419] [G loss: 0.697998]\n",
      "[Epoch 5/200] [Batch 164/169] [D loss: 0.690992] [G loss: 0.697140]\n",
      "[Epoch 5/200] [Batch 165/169] [D loss: 0.689369] [G loss: 0.700601]\n",
      "[Epoch 5/200] [Batch 166/169] [D loss: 0.690576] [G loss: 0.698679]\n",
      "[Epoch 5/200] [Batch 167/169] [D loss: 0.689168] [G loss: 0.698652]\n",
      "[Epoch 5/200] [Batch 168/169] [D loss: 0.690009] [G loss: 0.699523]\n",
      "[Epoch 6/200] [Batch 0/169] [D loss: 0.689455] [G loss: 0.699845]\n",
      "[Epoch 6/200] [Batch 1/169] [D loss: 0.686580] [G loss: 0.702104]\n",
      "[Epoch 6/200] [Batch 2/169] [D loss: 0.688225] [G loss: 0.701876]\n",
      "[Epoch 6/200] [Batch 3/169] [D loss: 0.689122] [G loss: 0.703621]\n",
      "[Epoch 6/200] [Batch 4/169] [D loss: 0.687056] [G loss: 0.700358]\n",
      "[Epoch 6/200] [Batch 5/169] [D loss: 0.688619] [G loss: 0.697966]\n",
      "[Epoch 6/200] [Batch 6/169] [D loss: 0.689655] [G loss: 0.694007]\n",
      "[Epoch 6/200] [Batch 7/169] [D loss: 0.688869] [G loss: 0.698240]\n",
      "[Epoch 6/200] [Batch 8/169] [D loss: 0.688703] [G loss: 0.695807]\n",
      "[Epoch 6/200] [Batch 9/169] [D loss: 0.690702] [G loss: 0.694378]\n",
      "[Epoch 6/200] [Batch 10/169] [D loss: 0.689331] [G loss: 0.691825]\n",
      "[Epoch 6/200] [Batch 11/169] [D loss: 0.692749] [G loss: 0.690072]\n",
      "[Epoch 6/200] [Batch 12/169] [D loss: 0.693541] [G loss: 0.686782]\n",
      "[Epoch 6/200] [Batch 13/169] [D loss: 0.695352] [G loss: 0.686259]\n",
      "[Epoch 6/200] [Batch 14/169] [D loss: 0.695735] [G loss: 0.684653]\n",
      "[Epoch 6/200] [Batch 15/169] [D loss: 0.693878] [G loss: 0.688582]\n",
      "[Epoch 6/200] [Batch 16/169] [D loss: 0.695291] [G loss: 0.684350]\n",
      "[Epoch 6/200] [Batch 17/169] [D loss: 0.695109] [G loss: 0.687205]\n",
      "[Epoch 6/200] [Batch 18/169] [D loss: 0.695403] [G loss: 0.688175]\n",
      "[Epoch 6/200] [Batch 19/169] [D loss: 0.693889] [G loss: 0.688978]\n",
      "[Epoch 6/200] [Batch 20/169] [D loss: 0.696035] [G loss: 0.687797]\n",
      "[Epoch 6/200] [Batch 21/169] [D loss: 0.696496] [G loss: 0.690971]\n",
      "[Epoch 6/200] [Batch 22/169] [D loss: 0.694449] [G loss: 0.691695]\n",
      "[Epoch 6/200] [Batch 23/169] [D loss: 0.693785] [G loss: 0.694442]\n",
      "[Epoch 6/200] [Batch 24/169] [D loss: 0.693022] [G loss: 0.695698]\n",
      "[Epoch 6/200] [Batch 25/169] [D loss: 0.694241] [G loss: 0.696912]\n",
      "[Epoch 6/200] [Batch 26/169] [D loss: 0.691365] [G loss: 0.699716]\n",
      "[Epoch 6/200] [Batch 27/169] [D loss: 0.693049] [G loss: 0.701867]\n",
      "[Epoch 6/200] [Batch 28/169] [D loss: 0.692314] [G loss: 0.705198]\n",
      "[Epoch 6/200] [Batch 29/169] [D loss: 0.691735] [G loss: 0.703619]\n",
      "[Epoch 6/200] [Batch 30/169] [D loss: 0.690633] [G loss: 0.703967]\n",
      "[Epoch 6/200] [Batch 31/169] [D loss: 0.691254] [G loss: 0.709490]\n",
      "[Epoch 6/200] [Batch 32/169] [D loss: 0.692211] [G loss: 0.703826]\n",
      "[Epoch 6/200] [Batch 33/169] [D loss: 0.694060] [G loss: 0.704542]\n",
      "[Epoch 6/200] [Batch 34/169] [D loss: 0.693094] [G loss: 0.704197]\n",
      "[Epoch 6/200] [Batch 35/169] [D loss: 0.694097] [G loss: 0.701151]\n",
      "[Epoch 6/200] [Batch 36/169] [D loss: 0.693462] [G loss: 0.702883]\n",
      "[Epoch 6/200] [Batch 37/169] [D loss: 0.692466] [G loss: 0.703291]\n",
      "[Epoch 6/200] [Batch 38/169] [D loss: 0.696221] [G loss: 0.698007]\n",
      "[Epoch 6/200] [Batch 39/169] [D loss: 0.693763] [G loss: 0.699911]\n",
      "[Epoch 6/200] [Batch 40/169] [D loss: 0.695333] [G loss: 0.697389]\n",
      "[Epoch 6/200] [Batch 41/169] [D loss: 0.694952] [G loss: 0.698167]\n",
      "[Epoch 6/200] [Batch 42/169] [D loss: 0.695505] [G loss: 0.694042]\n",
      "[Epoch 6/200] [Batch 43/169] [D loss: 0.694347] [G loss: 0.695215]\n",
      "[Epoch 6/200] [Batch 44/169] [D loss: 0.696057] [G loss: 0.690207]\n",
      "[Epoch 6/200] [Batch 45/169] [D loss: 0.695721] [G loss: 0.691731]\n",
      "[Epoch 6/200] [Batch 46/169] [D loss: 0.695222] [G loss: 0.687077]\n",
      "[Epoch 6/200] [Batch 47/169] [D loss: 0.696063] [G loss: 0.687468]\n",
      "[Epoch 6/200] [Batch 48/169] [D loss: 0.695660] [G loss: 0.687276]\n",
      "[Epoch 6/200] [Batch 49/169] [D loss: 0.693235] [G loss: 0.687642]\n",
      "[Epoch 6/200] [Batch 50/169] [D loss: 0.695797] [G loss: 0.686010]\n",
      "[Epoch 6/200] [Batch 51/169] [D loss: 0.693465] [G loss: 0.685388]\n",
      "[Epoch 6/200] [Batch 52/169] [D loss: 0.693484] [G loss: 0.687537]\n",
      "[Epoch 6/200] [Batch 53/169] [D loss: 0.693369] [G loss: 0.685875]\n",
      "[Epoch 6/200] [Batch 54/169] [D loss: 0.692352] [G loss: 0.686737]\n",
      "[Epoch 6/200] [Batch 55/169] [D loss: 0.692415] [G loss: 0.686945]\n",
      "[Epoch 6/200] [Batch 56/169] [D loss: 0.692255] [G loss: 0.688374]\n",
      "[Epoch 6/200] [Batch 57/169] [D loss: 0.691324] [G loss: 0.685561]\n",
      "[Epoch 6/200] [Batch 58/169] [D loss: 0.689365] [G loss: 0.686794]\n",
      "[Epoch 6/200] [Batch 59/169] [D loss: 0.688653] [G loss: 0.688546]\n",
      "[Epoch 6/200] [Batch 60/169] [D loss: 0.692138] [G loss: 0.688751]\n",
      "[Epoch 6/200] [Batch 61/169] [D loss: 0.688702] [G loss: 0.689608]\n",
      "[Epoch 6/200] [Batch 62/169] [D loss: 0.689916] [G loss: 0.687412]\n",
      "[Epoch 6/200] [Batch 63/169] [D loss: 0.689677] [G loss: 0.684827]\n",
      "[Epoch 6/200] [Batch 64/169] [D loss: 0.688452] [G loss: 0.685100]\n",
      "[Epoch 6/200] [Batch 65/169] [D loss: 0.690238] [G loss: 0.687136]\n",
      "[Epoch 6/200] [Batch 66/169] [D loss: 0.689851] [G loss: 0.687363]\n",
      "[Epoch 6/200] [Batch 67/169] [D loss: 0.689877] [G loss: 0.686918]\n",
      "[Epoch 6/200] [Batch 68/169] [D loss: 0.688057] [G loss: 0.687106]\n",
      "[Epoch 6/200] [Batch 69/169] [D loss: 0.689435] [G loss: 0.684661]\n",
      "[Epoch 6/200] [Batch 70/169] [D loss: 0.691799] [G loss: 0.681014]\n",
      "[Epoch 6/200] [Batch 71/169] [D loss: 0.689053] [G loss: 0.683306]\n",
      "[Epoch 6/200] [Batch 72/169] [D loss: 0.691355] [G loss: 0.686664]\n",
      "[Epoch 6/200] [Batch 73/169] [D loss: 0.690532] [G loss: 0.685268]\n",
      "[Epoch 6/200] [Batch 74/169] [D loss: 0.691421] [G loss: 0.684774]\n",
      "[Epoch 6/200] [Batch 75/169] [D loss: 0.691703] [G loss: 0.682034]\n",
      "[Epoch 6/200] [Batch 76/169] [D loss: 0.690691] [G loss: 0.686945]\n",
      "[Epoch 6/200] [Batch 77/169] [D loss: 0.694210] [G loss: 0.685453]\n",
      "[Epoch 6/200] [Batch 78/169] [D loss: 0.692589] [G loss: 0.681526]\n",
      "[Epoch 6/200] [Batch 79/169] [D loss: 0.693988] [G loss: 0.685250]\n",
      "[Epoch 6/200] [Batch 80/169] [D loss: 0.695041] [G loss: 0.682105]\n",
      "[Epoch 6/200] [Batch 81/169] [D loss: 0.694075] [G loss: 0.687791]\n",
      "[Epoch 6/200] [Batch 82/169] [D loss: 0.697265] [G loss: 0.688013]\n",
      "[Epoch 6/200] [Batch 83/169] [D loss: 0.694619] [G loss: 0.690628]\n",
      "[Epoch 6/200] [Batch 84/169] [D loss: 0.692339] [G loss: 0.690437]\n",
      "[Epoch 6/200] [Batch 85/169] [D loss: 0.695835] [G loss: 0.693887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 86/169] [D loss: 0.693988] [G loss: 0.694204]\n",
      "[Epoch 6/200] [Batch 87/169] [D loss: 0.696177] [G loss: 0.695287]\n",
      "[Epoch 6/200] [Batch 88/169] [D loss: 0.697565] [G loss: 0.695955]\n",
      "[Epoch 6/200] [Batch 89/169] [D loss: 0.694817] [G loss: 0.696488]\n",
      "[Epoch 6/200] [Batch 90/169] [D loss: 0.696190] [G loss: 0.698201]\n",
      "[Epoch 6/200] [Batch 91/169] [D loss: 0.695694] [G loss: 0.698526]\n",
      "[Epoch 6/200] [Batch 92/169] [D loss: 0.695574] [G loss: 0.701692]\n",
      "[Epoch 6/200] [Batch 93/169] [D loss: 0.693419] [G loss: 0.702095]\n",
      "[Epoch 6/200] [Batch 94/169] [D loss: 0.694094] [G loss: 0.702851]\n",
      "[Epoch 6/200] [Batch 95/169] [D loss: 0.692237] [G loss: 0.704388]\n",
      "[Epoch 6/200] [Batch 96/169] [D loss: 0.695020] [G loss: 0.703031]\n",
      "[Epoch 6/200] [Batch 97/169] [D loss: 0.694838] [G loss: 0.703425]\n",
      "[Epoch 6/200] [Batch 98/169] [D loss: 0.692736] [G loss: 0.705219]\n",
      "[Epoch 6/200] [Batch 99/169] [D loss: 0.693913] [G loss: 0.704432]\n",
      "[Epoch 6/200] [Batch 100/169] [D loss: 0.695431] [G loss: 0.704270]\n",
      "[Epoch 6/200] [Batch 101/169] [D loss: 0.697774] [G loss: 0.699498]\n",
      "[Epoch 6/200] [Batch 102/169] [D loss: 0.695137] [G loss: 0.699953]\n",
      "[Epoch 6/200] [Batch 103/169] [D loss: 0.695818] [G loss: 0.700829]\n",
      "[Epoch 6/200] [Batch 104/169] [D loss: 0.695982] [G loss: 0.698989]\n",
      "[Epoch 6/200] [Batch 105/169] [D loss: 0.694407] [G loss: 0.699128]\n",
      "[Epoch 6/200] [Batch 106/169] [D loss: 0.695381] [G loss: 0.698305]\n",
      "[Epoch 6/200] [Batch 107/169] [D loss: 0.693865] [G loss: 0.698649]\n",
      "[Epoch 6/200] [Batch 108/169] [D loss: 0.695437] [G loss: 0.695576]\n",
      "[Epoch 6/200] [Batch 109/169] [D loss: 0.695449] [G loss: 0.694999]\n",
      "[Epoch 6/200] [Batch 110/169] [D loss: 0.695116] [G loss: 0.695487]\n",
      "[Epoch 6/200] [Batch 111/169] [D loss: 0.694075] [G loss: 0.693672]\n",
      "[Epoch 6/200] [Batch 112/169] [D loss: 0.694472] [G loss: 0.694153]\n",
      "[Epoch 6/200] [Batch 113/169] [D loss: 0.693835] [G loss: 0.693980]\n",
      "[Epoch 6/200] [Batch 114/169] [D loss: 0.694659] [G loss: 0.694228]\n",
      "[Epoch 6/200] [Batch 115/169] [D loss: 0.692504] [G loss: 0.693948]\n",
      "[Epoch 6/200] [Batch 116/169] [D loss: 0.691795] [G loss: 0.695505]\n",
      "[Epoch 6/200] [Batch 117/169] [D loss: 0.693722] [G loss: 0.694344]\n",
      "[Epoch 6/200] [Batch 118/169] [D loss: 0.692602] [G loss: 0.695091]\n",
      "[Epoch 6/200] [Batch 119/169] [D loss: 0.691521] [G loss: 0.693231]\n",
      "[Epoch 6/200] [Batch 120/169] [D loss: 0.691940] [G loss: 0.693434]\n",
      "[Epoch 6/200] [Batch 121/169] [D loss: 0.691150] [G loss: 0.692549]\n",
      "[Epoch 6/200] [Batch 122/169] [D loss: 0.690893] [G loss: 0.692780]\n",
      "[Epoch 6/200] [Batch 123/169] [D loss: 0.689364] [G loss: 0.694119]\n",
      "[Epoch 6/200] [Batch 124/169] [D loss: 0.689376] [G loss: 0.693090]\n",
      "[Epoch 6/200] [Batch 125/169] [D loss: 0.691197] [G loss: 0.694066]\n",
      "[Epoch 6/200] [Batch 126/169] [D loss: 0.689575] [G loss: 0.693511]\n",
      "[Epoch 6/200] [Batch 127/169] [D loss: 0.689587] [G loss: 0.692199]\n",
      "[Epoch 6/200] [Batch 128/169] [D loss: 0.690302] [G loss: 0.694947]\n",
      "[Epoch 6/200] [Batch 129/169] [D loss: 0.690413] [G loss: 0.694941]\n",
      "[Epoch 6/200] [Batch 130/169] [D loss: 0.690060] [G loss: 0.692677]\n",
      "[Epoch 6/200] [Batch 131/169] [D loss: 0.688702] [G loss: 0.692647]\n",
      "[Epoch 6/200] [Batch 132/169] [D loss: 0.689462] [G loss: 0.692932]\n",
      "[Epoch 6/200] [Batch 133/169] [D loss: 0.688615] [G loss: 0.691138]\n",
      "[Epoch 6/200] [Batch 134/169] [D loss: 0.688141] [G loss: 0.693073]\n",
      "[Epoch 6/200] [Batch 135/169] [D loss: 0.688113] [G loss: 0.690345]\n",
      "[Epoch 6/200] [Batch 136/169] [D loss: 0.688724] [G loss: 0.692574]\n",
      "[Epoch 6/200] [Batch 137/169] [D loss: 0.689499] [G loss: 0.690906]\n",
      "[Epoch 6/200] [Batch 138/169] [D loss: 0.687667] [G loss: 0.692456]\n",
      "[Epoch 6/200] [Batch 139/169] [D loss: 0.689417] [G loss: 0.688407]\n",
      "[Epoch 6/200] [Batch 140/169] [D loss: 0.691102] [G loss: 0.688470]\n",
      "[Epoch 6/200] [Batch 141/169] [D loss: 0.693741] [G loss: 0.683854]\n",
      "[Epoch 6/200] [Batch 142/169] [D loss: 0.690423] [G loss: 0.687763]\n",
      "[Epoch 6/200] [Batch 143/169] [D loss: 0.693366] [G loss: 0.684875]\n",
      "[Epoch 6/200] [Batch 144/169] [D loss: 0.695390] [G loss: 0.685504]\n",
      "[Epoch 6/200] [Batch 145/169] [D loss: 0.693606] [G loss: 0.686237]\n",
      "[Epoch 6/200] [Batch 146/169] [D loss: 0.696028] [G loss: 0.687132]\n",
      "[Epoch 6/200] [Batch 147/169] [D loss: 0.696326] [G loss: 0.687785]\n",
      "[Epoch 6/200] [Batch 148/169] [D loss: 0.695358] [G loss: 0.694162]\n",
      "[Epoch 6/200] [Batch 149/169] [D loss: 0.693620] [G loss: 0.694223]\n",
      "[Epoch 6/200] [Batch 150/169] [D loss: 0.693973] [G loss: 0.692897]\n",
      "[Epoch 6/200] [Batch 151/169] [D loss: 0.693374] [G loss: 0.697584]\n",
      "[Epoch 6/200] [Batch 152/169] [D loss: 0.694239] [G loss: 0.701032]\n",
      "[Epoch 6/200] [Batch 153/169] [D loss: 0.694189] [G loss: 0.702550]\n",
      "[Epoch 6/200] [Batch 154/169] [D loss: 0.694595] [G loss: 0.701460]\n",
      "[Epoch 6/200] [Batch 155/169] [D loss: 0.692638] [G loss: 0.705605]\n",
      "[Epoch 6/200] [Batch 156/169] [D loss: 0.693117] [G loss: 0.709030]\n",
      "[Epoch 6/200] [Batch 157/169] [D loss: 0.692974] [G loss: 0.709702]\n",
      "[Epoch 6/200] [Batch 158/169] [D loss: 0.694205] [G loss: 0.710926]\n",
      "[Epoch 6/200] [Batch 159/169] [D loss: 0.691479] [G loss: 0.715604]\n",
      "[Epoch 6/200] [Batch 160/169] [D loss: 0.695167] [G loss: 0.714020]\n",
      "[Epoch 6/200] [Batch 161/169] [D loss: 0.690071] [G loss: 0.717613]\n",
      "[Epoch 6/200] [Batch 162/169] [D loss: 0.693485] [G loss: 0.716693]\n",
      "[Epoch 6/200] [Batch 163/169] [D loss: 0.693566] [G loss: 0.717435]\n",
      "[Epoch 6/200] [Batch 164/169] [D loss: 0.692021] [G loss: 0.716945]\n",
      "[Epoch 6/200] [Batch 165/169] [D loss: 0.690630] [G loss: 0.717753]\n",
      "[Epoch 6/200] [Batch 166/169] [D loss: 0.695559] [G loss: 0.711824]\n",
      "[Epoch 6/200] [Batch 167/169] [D loss: 0.695005] [G loss: 0.713682]\n",
      "[Epoch 6/200] [Batch 168/169] [D loss: 0.691967] [G loss: 0.712088]\n",
      "[Epoch 7/200] [Batch 0/169] [D loss: 0.697049] [G loss: 0.706329]\n",
      "[Epoch 7/200] [Batch 1/169] [D loss: 0.692642] [G loss: 0.704069]\n",
      "[Epoch 7/200] [Batch 2/169] [D loss: 0.694850] [G loss: 0.706341]\n",
      "[Epoch 7/200] [Batch 3/169] [D loss: 0.693548] [G loss: 0.702470]\n",
      "[Epoch 7/200] [Batch 4/169] [D loss: 0.693304] [G loss: 0.698234]\n",
      "[Epoch 7/200] [Batch 5/169] [D loss: 0.693858] [G loss: 0.693848]\n",
      "[Epoch 7/200] [Batch 6/169] [D loss: 0.692077] [G loss: 0.698688]\n",
      "[Epoch 7/200] [Batch 7/169] [D loss: 0.692660] [G loss: 0.695557]\n",
      "[Epoch 7/200] [Batch 8/169] [D loss: 0.691926] [G loss: 0.693922]\n",
      "[Epoch 7/200] [Batch 9/169] [D loss: 0.691164] [G loss: 0.690319]\n",
      "[Epoch 7/200] [Batch 10/169] [D loss: 0.688443] [G loss: 0.690194]\n",
      "[Epoch 7/200] [Batch 11/169] [D loss: 0.687784] [G loss: 0.688663]\n",
      "[Epoch 7/200] [Batch 12/169] [D loss: 0.685430] [G loss: 0.687295]\n",
      "[Epoch 7/200] [Batch 13/169] [D loss: 0.685729] [G loss: 0.685282]\n",
      "[Epoch 7/200] [Batch 14/169] [D loss: 0.684131] [G loss: 0.686122]\n",
      "[Epoch 7/200] [Batch 15/169] [D loss: 0.681826] [G loss: 0.683254]\n",
      "[Epoch 7/200] [Batch 16/169] [D loss: 0.684527] [G loss: 0.680650]\n",
      "[Epoch 7/200] [Batch 17/169] [D loss: 0.684097] [G loss: 0.674206]\n",
      "[Epoch 7/200] [Batch 18/169] [D loss: 0.683577] [G loss: 0.672405]\n",
      "[Epoch 7/200] [Batch 19/169] [D loss: 0.686383] [G loss: 0.665148]\n",
      "[Epoch 7/200] [Batch 20/169] [D loss: 0.685595] [G loss: 0.659718]\n",
      "[Epoch 7/200] [Batch 21/169] [D loss: 0.688660] [G loss: 0.659944]\n",
      "[Epoch 7/200] [Batch 22/169] [D loss: 0.687698] [G loss: 0.657172]\n",
      "[Epoch 7/200] [Batch 23/169] [D loss: 0.693068] [G loss: 0.653224]\n",
      "[Epoch 7/200] [Batch 24/169] [D loss: 0.690693] [G loss: 0.655712]\n",
      "[Epoch 7/200] [Batch 25/169] [D loss: 0.692123] [G loss: 0.659071]\n",
      "[Epoch 7/200] [Batch 26/169] [D loss: 0.696591] [G loss: 0.656402]\n",
      "[Epoch 7/200] [Batch 27/169] [D loss: 0.693783] [G loss: 0.659179]\n",
      "[Epoch 7/200] [Batch 28/169] [D loss: 0.698539] [G loss: 0.664359]\n",
      "[Epoch 7/200] [Batch 29/169] [D loss: 0.698565] [G loss: 0.670879]\n",
      "[Epoch 7/200] [Batch 30/169] [D loss: 0.698662] [G loss: 0.673883]\n",
      "[Epoch 7/200] [Batch 31/169] [D loss: 0.696342] [G loss: 0.680649]\n",
      "[Epoch 7/200] [Batch 32/169] [D loss: 0.695559] [G loss: 0.685841]\n",
      "[Epoch 7/200] [Batch 33/169] [D loss: 0.695324] [G loss: 0.688377]\n",
      "[Epoch 7/200] [Batch 34/169] [D loss: 0.696578] [G loss: 0.690378]\n",
      "[Epoch 7/200] [Batch 35/169] [D loss: 0.695729] [G loss: 0.693764]\n",
      "[Epoch 7/200] [Batch 36/169] [D loss: 0.695871] [G loss: 0.697475]\n",
      "[Epoch 7/200] [Batch 37/169] [D loss: 0.694492] [G loss: 0.698168]\n",
      "[Epoch 7/200] [Batch 38/169] [D loss: 0.696352] [G loss: 0.698382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 39/169] [D loss: 0.697054] [G loss: 0.701649]\n",
      "[Epoch 7/200] [Batch 40/169] [D loss: 0.693274] [G loss: 0.705274]\n",
      "[Epoch 7/200] [Batch 41/169] [D loss: 0.695407] [G loss: 0.706350]\n",
      "[Epoch 7/200] [Batch 42/169] [D loss: 0.696797] [G loss: 0.707194]\n",
      "[Epoch 7/200] [Batch 43/169] [D loss: 0.695782] [G loss: 0.707151]\n",
      "[Epoch 7/200] [Batch 44/169] [D loss: 0.696398] [G loss: 0.706832]\n",
      "[Epoch 7/200] [Batch 45/169] [D loss: 0.696338] [G loss: 0.711254]\n",
      "[Epoch 7/200] [Batch 46/169] [D loss: 0.695791] [G loss: 0.709029]\n",
      "[Epoch 7/200] [Batch 47/169] [D loss: 0.695435] [G loss: 0.709138]\n",
      "[Epoch 7/200] [Batch 48/169] [D loss: 0.694320] [G loss: 0.710901]\n",
      "[Epoch 7/200] [Batch 49/169] [D loss: 0.698448] [G loss: 0.707458]\n",
      "[Epoch 7/200] [Batch 50/169] [D loss: 0.693389] [G loss: 0.706697]\n",
      "[Epoch 7/200] [Batch 51/169] [D loss: 0.693117] [G loss: 0.705717]\n",
      "[Epoch 7/200] [Batch 52/169] [D loss: 0.693650] [G loss: 0.705559]\n",
      "[Epoch 7/200] [Batch 53/169] [D loss: 0.694619] [G loss: 0.703938]\n",
      "[Epoch 7/200] [Batch 54/169] [D loss: 0.693689] [G loss: 0.706087]\n",
      "[Epoch 7/200] [Batch 55/169] [D loss: 0.695563] [G loss: 0.704713]\n",
      "[Epoch 7/200] [Batch 56/169] [D loss: 0.695140] [G loss: 0.705546]\n",
      "[Epoch 7/200] [Batch 57/169] [D loss: 0.695527] [G loss: 0.705106]\n",
      "[Epoch 7/200] [Batch 58/169] [D loss: 0.693354] [G loss: 0.701763]\n",
      "[Epoch 7/200] [Batch 59/169] [D loss: 0.693149] [G loss: 0.700911]\n",
      "[Epoch 7/200] [Batch 60/169] [D loss: 0.693461] [G loss: 0.700216]\n",
      "[Epoch 7/200] [Batch 61/169] [D loss: 0.693003] [G loss: 0.698811]\n",
      "[Epoch 7/200] [Batch 62/169] [D loss: 0.691747] [G loss: 0.695384]\n",
      "[Epoch 7/200] [Batch 63/169] [D loss: 0.692842] [G loss: 0.696428]\n",
      "[Epoch 7/200] [Batch 64/169] [D loss: 0.691723] [G loss: 0.693854]\n",
      "[Epoch 7/200] [Batch 65/169] [D loss: 0.691340] [G loss: 0.693484]\n",
      "[Epoch 7/200] [Batch 66/169] [D loss: 0.690859] [G loss: 0.694239]\n",
      "[Epoch 7/200] [Batch 67/169] [D loss: 0.691783] [G loss: 0.695575]\n",
      "[Epoch 7/200] [Batch 68/169] [D loss: 0.688226] [G loss: 0.693219]\n",
      "[Epoch 7/200] [Batch 69/169] [D loss: 0.688891] [G loss: 0.692312]\n",
      "[Epoch 7/200] [Batch 70/169] [D loss: 0.690557] [G loss: 0.688508]\n",
      "[Epoch 7/200] [Batch 71/169] [D loss: 0.692087] [G loss: 0.688710]\n",
      "[Epoch 7/200] [Batch 72/169] [D loss: 0.687625] [G loss: 0.689963]\n",
      "[Epoch 7/200] [Batch 73/169] [D loss: 0.688457] [G loss: 0.687932]\n",
      "[Epoch 7/200] [Batch 74/169] [D loss: 0.691716] [G loss: 0.686579]\n",
      "[Epoch 7/200] [Batch 75/169] [D loss: 0.689090] [G loss: 0.685984]\n",
      "[Epoch 7/200] [Batch 76/169] [D loss: 0.688690] [G loss: 0.684589]\n",
      "[Epoch 7/200] [Batch 77/169] [D loss: 0.687905] [G loss: 0.684677]\n",
      "[Epoch 7/200] [Batch 78/169] [D loss: 0.691106] [G loss: 0.683463]\n",
      "[Epoch 7/200] [Batch 79/169] [D loss: 0.691852] [G loss: 0.681617]\n",
      "[Epoch 7/200] [Batch 80/169] [D loss: 0.693519] [G loss: 0.679349]\n",
      "[Epoch 7/200] [Batch 81/169] [D loss: 0.693035] [G loss: 0.681560]\n",
      "[Epoch 7/200] [Batch 82/169] [D loss: 0.692585] [G loss: 0.681263]\n",
      "[Epoch 7/200] [Batch 83/169] [D loss: 0.693045] [G loss: 0.680114]\n",
      "[Epoch 7/200] [Batch 84/169] [D loss: 0.694483] [G loss: 0.682210]\n",
      "[Epoch 7/200] [Batch 85/169] [D loss: 0.695771] [G loss: 0.685017]\n",
      "[Epoch 7/200] [Batch 86/169] [D loss: 0.694180] [G loss: 0.683997]\n",
      "[Epoch 7/200] [Batch 87/169] [D loss: 0.695000] [G loss: 0.688044]\n",
      "[Epoch 7/200] [Batch 88/169] [D loss: 0.692849] [G loss: 0.688278]\n",
      "[Epoch 7/200] [Batch 89/169] [D loss: 0.692174] [G loss: 0.688440]\n",
      "[Epoch 7/200] [Batch 90/169] [D loss: 0.697571] [G loss: 0.688855]\n",
      "[Epoch 7/200] [Batch 91/169] [D loss: 0.695116] [G loss: 0.687167]\n",
      "[Epoch 7/200] [Batch 92/169] [D loss: 0.697113] [G loss: 0.688868]\n",
      "[Epoch 7/200] [Batch 93/169] [D loss: 0.696137] [G loss: 0.693212]\n",
      "[Epoch 7/200] [Batch 94/169] [D loss: 0.696115] [G loss: 0.694897]\n",
      "[Epoch 7/200] [Batch 95/169] [D loss: 0.698387] [G loss: 0.697262]\n",
      "[Epoch 7/200] [Batch 96/169] [D loss: 0.696197] [G loss: 0.697529]\n",
      "[Epoch 7/200] [Batch 97/169] [D loss: 0.694300] [G loss: 0.698126]\n",
      "[Epoch 7/200] [Batch 98/169] [D loss: 0.695609] [G loss: 0.698276]\n",
      "[Epoch 7/200] [Batch 99/169] [D loss: 0.695244] [G loss: 0.699843]\n",
      "[Epoch 7/200] [Batch 100/169] [D loss: 0.695420] [G loss: 0.701434]\n",
      "[Epoch 7/200] [Batch 101/169] [D loss: 0.696679] [G loss: 0.701265]\n",
      "[Epoch 7/200] [Batch 102/169] [D loss: 0.694922] [G loss: 0.699400]\n",
      "[Epoch 7/200] [Batch 103/169] [D loss: 0.694432] [G loss: 0.702826]\n",
      "[Epoch 7/200] [Batch 104/169] [D loss: 0.692275] [G loss: 0.702845]\n",
      "[Epoch 7/200] [Batch 105/169] [D loss: 0.692435] [G loss: 0.703043]\n",
      "[Epoch 7/200] [Batch 106/169] [D loss: 0.694306] [G loss: 0.704087]\n",
      "[Epoch 7/200] [Batch 107/169] [D loss: 0.692881] [G loss: 0.704336]\n",
      "[Epoch 7/200] [Batch 108/169] [D loss: 0.693532] [G loss: 0.704276]\n",
      "[Epoch 7/200] [Batch 109/169] [D loss: 0.692605] [G loss: 0.707435]\n",
      "[Epoch 7/200] [Batch 110/169] [D loss: 0.692370] [G loss: 0.707774]\n",
      "[Epoch 7/200] [Batch 111/169] [D loss: 0.693375] [G loss: 0.706659]\n",
      "[Epoch 7/200] [Batch 112/169] [D loss: 0.691563] [G loss: 0.706524]\n",
      "[Epoch 7/200] [Batch 113/169] [D loss: 0.689834] [G loss: 0.705179]\n",
      "[Epoch 7/200] [Batch 114/169] [D loss: 0.690739] [G loss: 0.706521]\n",
      "[Epoch 7/200] [Batch 115/169] [D loss: 0.689076] [G loss: 0.707894]\n",
      "[Epoch 7/200] [Batch 116/169] [D loss: 0.688555] [G loss: 0.708069]\n",
      "[Epoch 7/200] [Batch 117/169] [D loss: 0.690184] [G loss: 0.706988]\n",
      "[Epoch 7/200] [Batch 118/169] [D loss: 0.688768] [G loss: 0.707701]\n",
      "[Epoch 7/200] [Batch 119/169] [D loss: 0.688315] [G loss: 0.707100]\n",
      "[Epoch 7/200] [Batch 120/169] [D loss: 0.688982] [G loss: 0.708528]\n",
      "[Epoch 7/200] [Batch 121/169] [D loss: 0.687363] [G loss: 0.708641]\n",
      "[Epoch 7/200] [Batch 122/169] [D loss: 0.689570] [G loss: 0.710179]\n",
      "[Epoch 7/200] [Batch 123/169] [D loss: 0.688582] [G loss: 0.707513]\n",
      "[Epoch 7/200] [Batch 124/169] [D loss: 0.688271] [G loss: 0.709844]\n",
      "[Epoch 7/200] [Batch 125/169] [D loss: 0.688633] [G loss: 0.708167]\n",
      "[Epoch 7/200] [Batch 126/169] [D loss: 0.686019] [G loss: 0.711124]\n",
      "[Epoch 7/200] [Batch 127/169] [D loss: 0.686292] [G loss: 0.708766]\n",
      "[Epoch 7/200] [Batch 128/169] [D loss: 0.688316] [G loss: 0.708832]\n",
      "[Epoch 7/200] [Batch 129/169] [D loss: 0.688544] [G loss: 0.708025]\n",
      "[Epoch 7/200] [Batch 130/169] [D loss: 0.685981] [G loss: 0.700383]\n",
      "[Epoch 7/200] [Batch 131/169] [D loss: 0.688522] [G loss: 0.703787]\n",
      "[Epoch 7/200] [Batch 132/169] [D loss: 0.686185] [G loss: 0.707724]\n",
      "[Epoch 7/200] [Batch 133/169] [D loss: 0.687035] [G loss: 0.704125]\n",
      "[Epoch 7/200] [Batch 134/169] [D loss: 0.688319] [G loss: 0.702859]\n",
      "[Epoch 7/200] [Batch 135/169] [D loss: 0.690036] [G loss: 0.695694]\n",
      "[Epoch 7/200] [Batch 136/169] [D loss: 0.691442] [G loss: 0.699844]\n",
      "[Epoch 7/200] [Batch 137/169] [D loss: 0.691529] [G loss: 0.692324]\n",
      "[Epoch 7/200] [Batch 138/169] [D loss: 0.688562] [G loss: 0.700717]\n",
      "[Epoch 7/200] [Batch 139/169] [D loss: 0.695379] [G loss: 0.691700]\n",
      "[Epoch 7/200] [Batch 140/169] [D loss: 0.696106] [G loss: 0.688719]\n",
      "[Epoch 7/200] [Batch 141/169] [D loss: 0.697622] [G loss: 0.694518]\n",
      "[Epoch 7/200] [Batch 142/169] [D loss: 0.695295] [G loss: 0.694228]\n",
      "[Epoch 7/200] [Batch 143/169] [D loss: 0.697414] [G loss: 0.690183]\n",
      "[Epoch 7/200] [Batch 144/169] [D loss: 0.698024] [G loss: 0.686667]\n",
      "[Epoch 7/200] [Batch 145/169] [D loss: 0.699797] [G loss: 0.688262]\n",
      "[Epoch 7/200] [Batch 146/169] [D loss: 0.697847] [G loss: 0.686319]\n",
      "[Epoch 7/200] [Batch 147/169] [D loss: 0.699878] [G loss: 0.681046]\n",
      "[Epoch 7/200] [Batch 148/169] [D loss: 0.698887] [G loss: 0.679162]\n",
      "[Epoch 7/200] [Batch 149/169] [D loss: 0.700200] [G loss: 0.677835]\n",
      "[Epoch 7/200] [Batch 150/169] [D loss: 0.699211] [G loss: 0.677453]\n",
      "[Epoch 7/200] [Batch 151/169] [D loss: 0.700022] [G loss: 0.679695]\n",
      "[Epoch 7/200] [Batch 152/169] [D loss: 0.700734] [G loss: 0.677762]\n",
      "[Epoch 7/200] [Batch 153/169] [D loss: 0.699021] [G loss: 0.674110]\n",
      "[Epoch 7/200] [Batch 154/169] [D loss: 0.695511] [G loss: 0.675072]\n",
      "[Epoch 7/200] [Batch 155/169] [D loss: 0.697658] [G loss: 0.678420]\n",
      "[Epoch 7/200] [Batch 156/169] [D loss: 0.698293] [G loss: 0.677751]\n",
      "[Epoch 7/200] [Batch 157/169] [D loss: 0.695171] [G loss: 0.678581]\n",
      "[Epoch 7/200] [Batch 158/169] [D loss: 0.695812] [G loss: 0.676364]\n",
      "[Epoch 7/200] [Batch 159/169] [D loss: 0.694527] [G loss: 0.677694]\n",
      "[Epoch 7/200] [Batch 160/169] [D loss: 0.694823] [G loss: 0.677883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 161/169] [D loss: 0.693145] [G loss: 0.677221]\n",
      "[Epoch 7/200] [Batch 162/169] [D loss: 0.692557] [G loss: 0.682535]\n",
      "[Epoch 7/200] [Batch 163/169] [D loss: 0.691624] [G loss: 0.680290]\n",
      "[Epoch 7/200] [Batch 164/169] [D loss: 0.689794] [G loss: 0.682519]\n",
      "[Epoch 7/200] [Batch 165/169] [D loss: 0.692132] [G loss: 0.680875]\n",
      "[Epoch 7/200] [Batch 166/169] [D loss: 0.690043] [G loss: 0.680707]\n",
      "[Epoch 7/200] [Batch 167/169] [D loss: 0.691313] [G loss: 0.684180]\n",
      "[Epoch 7/200] [Batch 168/169] [D loss: 0.685880] [G loss: 0.684617]\n",
      "[Epoch 8/200] [Batch 0/169] [D loss: 0.688759] [G loss: 0.680211]\n",
      "[Epoch 8/200] [Batch 1/169] [D loss: 0.690141] [G loss: 0.684546]\n",
      "[Epoch 8/200] [Batch 2/169] [D loss: 0.686897] [G loss: 0.682817]\n",
      "[Epoch 8/200] [Batch 3/169] [D loss: 0.688826] [G loss: 0.681890]\n",
      "[Epoch 8/200] [Batch 4/169] [D loss: 0.689110] [G loss: 0.683415]\n",
      "[Epoch 8/200] [Batch 5/169] [D loss: 0.687504] [G loss: 0.684202]\n",
      "[Epoch 8/200] [Batch 6/169] [D loss: 0.689565] [G loss: 0.686627]\n",
      "[Epoch 8/200] [Batch 7/169] [D loss: 0.686260] [G loss: 0.688234]\n",
      "[Epoch 8/200] [Batch 8/169] [D loss: 0.688347] [G loss: 0.687486]\n",
      "[Epoch 8/200] [Batch 9/169] [D loss: 0.687771] [G loss: 0.684640]\n",
      "[Epoch 8/200] [Batch 10/169] [D loss: 0.688472] [G loss: 0.688968]\n",
      "[Epoch 8/200] [Batch 11/169] [D loss: 0.688408] [G loss: 0.688351]\n",
      "[Epoch 8/200] [Batch 12/169] [D loss: 0.686135] [G loss: 0.692072]\n",
      "[Epoch 8/200] [Batch 13/169] [D loss: 0.687888] [G loss: 0.693225]\n",
      "[Epoch 8/200] [Batch 14/169] [D loss: 0.691615] [G loss: 0.691498]\n",
      "[Epoch 8/200] [Batch 15/169] [D loss: 0.689157] [G loss: 0.692835]\n",
      "[Epoch 8/200] [Batch 16/169] [D loss: 0.689918] [G loss: 0.689777]\n",
      "[Epoch 8/200] [Batch 17/169] [D loss: 0.685762] [G loss: 0.695126]\n",
      "[Epoch 8/200] [Batch 18/169] [D loss: 0.691141] [G loss: 0.689904]\n",
      "[Epoch 8/200] [Batch 19/169] [D loss: 0.689873] [G loss: 0.693041]\n",
      "[Epoch 8/200] [Batch 20/169] [D loss: 0.693486] [G loss: 0.692400]\n",
      "[Epoch 8/200] [Batch 21/169] [D loss: 0.691455] [G loss: 0.699923]\n",
      "[Epoch 8/200] [Batch 22/169] [D loss: 0.691858] [G loss: 0.698597]\n",
      "[Epoch 8/200] [Batch 23/169] [D loss: 0.690996] [G loss: 0.699764]\n",
      "[Epoch 8/200] [Batch 24/169] [D loss: 0.693748] [G loss: 0.697844]\n",
      "[Epoch 8/200] [Batch 25/169] [D loss: 0.695454] [G loss: 0.700224]\n",
      "[Epoch 8/200] [Batch 26/169] [D loss: 0.695333] [G loss: 0.705324]\n",
      "[Epoch 8/200] [Batch 27/169] [D loss: 0.693912] [G loss: 0.705972]\n",
      "[Epoch 8/200] [Batch 28/169] [D loss: 0.693357] [G loss: 0.705820]\n",
      "[Epoch 8/200] [Batch 29/169] [D loss: 0.693326] [G loss: 0.708213]\n",
      "[Epoch 8/200] [Batch 30/169] [D loss: 0.694961] [G loss: 0.707837]\n",
      "[Epoch 8/200] [Batch 31/169] [D loss: 0.694394] [G loss: 0.707152]\n",
      "[Epoch 8/200] [Batch 32/169] [D loss: 0.698167] [G loss: 0.703350]\n",
      "[Epoch 8/200] [Batch 33/169] [D loss: 0.698381] [G loss: 0.710526]\n",
      "[Epoch 8/200] [Batch 34/169] [D loss: 0.699085] [G loss: 0.709324]\n",
      "[Epoch 8/200] [Batch 35/169] [D loss: 0.702017] [G loss: 0.707518]\n",
      "[Epoch 8/200] [Batch 36/169] [D loss: 0.697043] [G loss: 0.708025]\n",
      "[Epoch 8/200] [Batch 37/169] [D loss: 0.697259] [G loss: 0.704924]\n",
      "[Epoch 8/200] [Batch 38/169] [D loss: 0.698869] [G loss: 0.703785]\n",
      "[Epoch 8/200] [Batch 39/169] [D loss: 0.699805] [G loss: 0.703080]\n",
      "[Epoch 8/200] [Batch 40/169] [D loss: 0.701808] [G loss: 0.698168]\n",
      "[Epoch 8/200] [Batch 41/169] [D loss: 0.700394] [G loss: 0.701559]\n",
      "[Epoch 8/200] [Batch 42/169] [D loss: 0.695753] [G loss: 0.698635]\n",
      "[Epoch 8/200] [Batch 43/169] [D loss: 0.702138] [G loss: 0.695819]\n",
      "[Epoch 8/200] [Batch 44/169] [D loss: 0.701798] [G loss: 0.698486]\n",
      "[Epoch 8/200] [Batch 45/169] [D loss: 0.699053] [G loss: 0.697315]\n",
      "[Epoch 8/200] [Batch 46/169] [D loss: 0.698334] [G loss: 0.696718]\n",
      "[Epoch 8/200] [Batch 47/169] [D loss: 0.698408] [G loss: 0.700276]\n",
      "[Epoch 8/200] [Batch 48/169] [D loss: 0.697088] [G loss: 0.699181]\n",
      "[Epoch 8/200] [Batch 49/169] [D loss: 0.696860] [G loss: 0.699076]\n",
      "[Epoch 8/200] [Batch 50/169] [D loss: 0.696388] [G loss: 0.699548]\n",
      "[Epoch 8/200] [Batch 51/169] [D loss: 0.695384] [G loss: 0.699345]\n",
      "[Epoch 8/200] [Batch 52/169] [D loss: 0.694379] [G loss: 0.700379]\n",
      "[Epoch 8/200] [Batch 53/169] [D loss: 0.691539] [G loss: 0.702165]\n",
      "[Epoch 8/200] [Batch 54/169] [D loss: 0.691605] [G loss: 0.702273]\n",
      "[Epoch 8/200] [Batch 55/169] [D loss: 0.691253] [G loss: 0.697954]\n",
      "[Epoch 8/200] [Batch 56/169] [D loss: 0.688968] [G loss: 0.702554]\n",
      "[Epoch 8/200] [Batch 57/169] [D loss: 0.688326] [G loss: 0.702724]\n",
      "[Epoch 8/200] [Batch 58/169] [D loss: 0.686595] [G loss: 0.702683]\n",
      "[Epoch 8/200] [Batch 59/169] [D loss: 0.686750] [G loss: 0.707920]\n",
      "[Epoch 8/200] [Batch 60/169] [D loss: 0.684937] [G loss: 0.704241]\n",
      "[Epoch 8/200] [Batch 61/169] [D loss: 0.685768] [G loss: 0.702464]\n",
      "[Epoch 8/200] [Batch 62/169] [D loss: 0.683408] [G loss: 0.706740]\n",
      "[Epoch 8/200] [Batch 63/169] [D loss: 0.682999] [G loss: 0.705422]\n",
      "[Epoch 8/200] [Batch 64/169] [D loss: 0.681467] [G loss: 0.709500]\n",
      "[Epoch 8/200] [Batch 65/169] [D loss: 0.683854] [G loss: 0.703068]\n",
      "[Epoch 8/200] [Batch 66/169] [D loss: 0.682827] [G loss: 0.705924]\n",
      "[Epoch 8/200] [Batch 67/169] [D loss: 0.681959] [G loss: 0.703889]\n",
      "[Epoch 8/200] [Batch 68/169] [D loss: 0.682215] [G loss: 0.700968]\n",
      "[Epoch 8/200] [Batch 69/169] [D loss: 0.682773] [G loss: 0.696263]\n",
      "[Epoch 8/200] [Batch 70/169] [D loss: 0.682330] [G loss: 0.698475]\n",
      "[Epoch 8/200] [Batch 71/169] [D loss: 0.682682] [G loss: 0.689200]\n",
      "[Epoch 8/200] [Batch 72/169] [D loss: 0.683354] [G loss: 0.684316]\n",
      "[Epoch 8/200] [Batch 73/169] [D loss: 0.685433] [G loss: 0.687000]\n",
      "[Epoch 8/200] [Batch 74/169] [D loss: 0.687794] [G loss: 0.682087]\n",
      "[Epoch 8/200] [Batch 75/169] [D loss: 0.686958] [G loss: 0.680594]\n",
      "[Epoch 8/200] [Batch 76/169] [D loss: 0.682926] [G loss: 0.677641]\n",
      "[Epoch 8/200] [Batch 77/169] [D loss: 0.687210] [G loss: 0.675632]\n",
      "[Epoch 8/200] [Batch 78/169] [D loss: 0.691802] [G loss: 0.671758]\n",
      "[Epoch 8/200] [Batch 79/169] [D loss: 0.689619] [G loss: 0.670234]\n",
      "[Epoch 8/200] [Batch 80/169] [D loss: 0.689548] [G loss: 0.673255]\n",
      "[Epoch 8/200] [Batch 81/169] [D loss: 0.690246] [G loss: 0.665416]\n",
      "[Epoch 8/200] [Batch 82/169] [D loss: 0.690806] [G loss: 0.661118]\n",
      "[Epoch 8/200] [Batch 83/169] [D loss: 0.694937] [G loss: 0.657703]\n",
      "[Epoch 8/200] [Batch 84/169] [D loss: 0.700873] [G loss: 0.652385]\n",
      "[Epoch 8/200] [Batch 85/169] [D loss: 0.697048] [G loss: 0.657087]\n",
      "[Epoch 8/200] [Batch 86/169] [D loss: 0.698137] [G loss: 0.654627]\n",
      "[Epoch 8/200] [Batch 87/169] [D loss: 0.699861] [G loss: 0.661722]\n",
      "[Epoch 8/200] [Batch 88/169] [D loss: 0.698766] [G loss: 0.661006]\n",
      "[Epoch 8/200] [Batch 89/169] [D loss: 0.702854] [G loss: 0.659039]\n",
      "[Epoch 8/200] [Batch 90/169] [D loss: 0.702888] [G loss: 0.658955]\n",
      "[Epoch 8/200] [Batch 91/169] [D loss: 0.697967] [G loss: 0.667254]\n",
      "[Epoch 8/200] [Batch 92/169] [D loss: 0.700522] [G loss: 0.665518]\n",
      "[Epoch 8/200] [Batch 93/169] [D loss: 0.701314] [G loss: 0.670595]\n",
      "[Epoch 8/200] [Batch 94/169] [D loss: 0.699786] [G loss: 0.669919]\n",
      "[Epoch 8/200] [Batch 95/169] [D loss: 0.700213] [G loss: 0.674169]\n",
      "[Epoch 8/200] [Batch 96/169] [D loss: 0.698052] [G loss: 0.681947]\n",
      "[Epoch 8/200] [Batch 97/169] [D loss: 0.699316] [G loss: 0.679260]\n",
      "[Epoch 8/200] [Batch 98/169] [D loss: 0.698402] [G loss: 0.679521]\n",
      "[Epoch 8/200] [Batch 99/169] [D loss: 0.697398] [G loss: 0.684993]\n",
      "[Epoch 8/200] [Batch 100/169] [D loss: 0.696992] [G loss: 0.687422]\n",
      "[Epoch 8/200] [Batch 101/169] [D loss: 0.698735] [G loss: 0.685439]\n",
      "[Epoch 8/200] [Batch 102/169] [D loss: 0.696998] [G loss: 0.691587]\n",
      "[Epoch 8/200] [Batch 103/169] [D loss: 0.696420] [G loss: 0.691247]\n",
      "[Epoch 8/200] [Batch 104/169] [D loss: 0.696109] [G loss: 0.692393]\n",
      "[Epoch 8/200] [Batch 105/169] [D loss: 0.695594] [G loss: 0.699219]\n",
      "[Epoch 8/200] [Batch 106/169] [D loss: 0.691387] [G loss: 0.699492]\n",
      "[Epoch 8/200] [Batch 107/169] [D loss: 0.692964] [G loss: 0.701756]\n",
      "[Epoch 8/200] [Batch 108/169] [D loss: 0.692467] [G loss: 0.701451]\n",
      "[Epoch 8/200] [Batch 109/169] [D loss: 0.692481] [G loss: 0.705559]\n",
      "[Epoch 8/200] [Batch 110/169] [D loss: 0.689850] [G loss: 0.708212]\n",
      "[Epoch 8/200] [Batch 111/169] [D loss: 0.691106] [G loss: 0.708316]\n",
      "[Epoch 8/200] [Batch 112/169] [D loss: 0.690876] [G loss: 0.705711]\n",
      "[Epoch 8/200] [Batch 113/169] [D loss: 0.690200] [G loss: 0.712151]\n",
      "[Epoch 8/200] [Batch 114/169] [D loss: 0.688698] [G loss: 0.710932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 115/169] [D loss: 0.688273] [G loss: 0.715882]\n",
      "[Epoch 8/200] [Batch 116/169] [D loss: 0.688327] [G loss: 0.714729]\n",
      "[Epoch 8/200] [Batch 117/169] [D loss: 0.688953] [G loss: 0.717299]\n",
      "[Epoch 8/200] [Batch 118/169] [D loss: 0.685924] [G loss: 0.721802]\n",
      "[Epoch 8/200] [Batch 119/169] [D loss: 0.691642] [G loss: 0.720201]\n",
      "[Epoch 8/200] [Batch 120/169] [D loss: 0.689131] [G loss: 0.719425]\n",
      "[Epoch 8/200] [Batch 121/169] [D loss: 0.686397] [G loss: 0.722666]\n",
      "[Epoch 8/200] [Batch 122/169] [D loss: 0.689487] [G loss: 0.715989]\n",
      "[Epoch 8/200] [Batch 123/169] [D loss: 0.693026] [G loss: 0.720840]\n",
      "[Epoch 8/200] [Batch 124/169] [D loss: 0.691551] [G loss: 0.719291]\n",
      "[Epoch 8/200] [Batch 125/169] [D loss: 0.692582] [G loss: 0.712768]\n",
      "[Epoch 8/200] [Batch 126/169] [D loss: 0.691854] [G loss: 0.713602]\n",
      "[Epoch 8/200] [Batch 127/169] [D loss: 0.694213] [G loss: 0.711839]\n",
      "[Epoch 8/200] [Batch 128/169] [D loss: 0.692661] [G loss: 0.710108]\n",
      "[Epoch 8/200] [Batch 129/169] [D loss: 0.696068] [G loss: 0.703694]\n",
      "[Epoch 8/200] [Batch 130/169] [D loss: 0.697036] [G loss: 0.703329]\n",
      "[Epoch 8/200] [Batch 131/169] [D loss: 0.696057] [G loss: 0.702306]\n",
      "[Epoch 8/200] [Batch 132/169] [D loss: 0.698764] [G loss: 0.695267]\n",
      "[Epoch 8/200] [Batch 133/169] [D loss: 0.701273] [G loss: 0.692582]\n",
      "[Epoch 8/200] [Batch 134/169] [D loss: 0.696941] [G loss: 0.690539]\n",
      "[Epoch 8/200] [Batch 135/169] [D loss: 0.698362] [G loss: 0.690217]\n",
      "[Epoch 8/200] [Batch 136/169] [D loss: 0.696457] [G loss: 0.690238]\n",
      "[Epoch 8/200] [Batch 137/169] [D loss: 0.694037] [G loss: 0.690626]\n",
      "[Epoch 8/200] [Batch 138/169] [D loss: 0.693906] [G loss: 0.691710]\n",
      "[Epoch 8/200] [Batch 139/169] [D loss: 0.691491] [G loss: 0.693475]\n",
      "[Epoch 8/200] [Batch 140/169] [D loss: 0.689301] [G loss: 0.695516]\n",
      "[Epoch 8/200] [Batch 141/169] [D loss: 0.689260] [G loss: 0.695675]\n",
      "[Epoch 8/200] [Batch 142/169] [D loss: 0.685162] [G loss: 0.697437]\n",
      "[Epoch 8/200] [Batch 143/169] [D loss: 0.683838] [G loss: 0.694125]\n",
      "[Epoch 8/200] [Batch 144/169] [D loss: 0.682434] [G loss: 0.697001]\n",
      "[Epoch 8/200] [Batch 145/169] [D loss: 0.684376] [G loss: 0.690738]\n",
      "[Epoch 8/200] [Batch 146/169] [D loss: 0.684650] [G loss: 0.690003]\n",
      "[Epoch 8/200] [Batch 147/169] [D loss: 0.687609] [G loss: 0.680649]\n",
      "[Epoch 8/200] [Batch 148/169] [D loss: 0.685484] [G loss: 0.678016]\n",
      "[Epoch 8/200] [Batch 149/169] [D loss: 0.685916] [G loss: 0.672091]\n",
      "[Epoch 8/200] [Batch 150/169] [D loss: 0.694293] [G loss: 0.665862]\n",
      "[Epoch 8/200] [Batch 151/169] [D loss: 0.697434] [G loss: 0.658563]\n",
      "[Epoch 8/200] [Batch 152/169] [D loss: 0.701907] [G loss: 0.659881]\n",
      "[Epoch 8/200] [Batch 153/169] [D loss: 0.696889] [G loss: 0.668002]\n",
      "[Epoch 8/200] [Batch 154/169] [D loss: 0.698440] [G loss: 0.669332]\n",
      "[Epoch 8/200] [Batch 155/169] [D loss: 0.697961] [G loss: 0.667498]\n",
      "[Epoch 8/200] [Batch 156/169] [D loss: 0.697751] [G loss: 0.673964]\n",
      "[Epoch 8/200] [Batch 157/169] [D loss: 0.695342] [G loss: 0.679335]\n",
      "[Epoch 8/200] [Batch 158/169] [D loss: 0.698452] [G loss: 0.676129]\n",
      "[Epoch 8/200] [Batch 159/169] [D loss: 0.694160] [G loss: 0.686981]\n",
      "[Epoch 8/200] [Batch 160/169] [D loss: 0.694712] [G loss: 0.689098]\n",
      "[Epoch 8/200] [Batch 161/169] [D loss: 0.697436] [G loss: 0.693258]\n",
      "[Epoch 8/200] [Batch 162/169] [D loss: 0.694890] [G loss: 0.703552]\n",
      "[Epoch 8/200] [Batch 163/169] [D loss: 0.691466] [G loss: 0.704429]\n",
      "[Epoch 8/200] [Batch 164/169] [D loss: 0.693650] [G loss: 0.710164]\n",
      "[Epoch 8/200] [Batch 165/169] [D loss: 0.692211] [G loss: 0.713571]\n",
      "[Epoch 8/200] [Batch 166/169] [D loss: 0.689767] [G loss: 0.717254]\n",
      "[Epoch 8/200] [Batch 167/169] [D loss: 0.688344] [G loss: 0.722445]\n",
      "[Epoch 8/200] [Batch 168/169] [D loss: 0.688188] [G loss: 0.723614]\n",
      "[Epoch 9/200] [Batch 0/169] [D loss: 0.687743] [G loss: 0.730334]\n",
      "[Epoch 9/200] [Batch 1/169] [D loss: 0.686766] [G loss: 0.728078]\n",
      "[Epoch 9/200] [Batch 2/169] [D loss: 0.689273] [G loss: 0.730751]\n",
      "[Epoch 9/200] [Batch 3/169] [D loss: 0.687290] [G loss: 0.728171]\n",
      "[Epoch 9/200] [Batch 4/169] [D loss: 0.688641] [G loss: 0.724409]\n",
      "[Epoch 9/200] [Batch 5/169] [D loss: 0.691664] [G loss: 0.724473]\n",
      "[Epoch 9/200] [Batch 6/169] [D loss: 0.688879] [G loss: 0.724491]\n",
      "[Epoch 9/200] [Batch 7/169] [D loss: 0.691527] [G loss: 0.723205]\n",
      "[Epoch 9/200] [Batch 8/169] [D loss: 0.693305] [G loss: 0.714992]\n",
      "[Epoch 9/200] [Batch 9/169] [D loss: 0.691832] [G loss: 0.719094]\n",
      "[Epoch 9/200] [Batch 10/169] [D loss: 0.698309] [G loss: 0.712517]\n",
      "[Epoch 9/200] [Batch 11/169] [D loss: 0.702028] [G loss: 0.710312]\n",
      "[Epoch 9/200] [Batch 12/169] [D loss: 0.704292] [G loss: 0.699708]\n",
      "[Epoch 9/200] [Batch 13/169] [D loss: 0.698565] [G loss: 0.701354]\n",
      "[Epoch 9/200] [Batch 14/169] [D loss: 0.701871] [G loss: 0.697917]\n",
      "[Epoch 9/200] [Batch 15/169] [D loss: 0.702756] [G loss: 0.692912]\n",
      "[Epoch 9/200] [Batch 16/169] [D loss: 0.700043] [G loss: 0.691888]\n",
      "[Epoch 9/200] [Batch 17/169] [D loss: 0.702241] [G loss: 0.689749]\n",
      "[Epoch 9/200] [Batch 18/169] [D loss: 0.704543] [G loss: 0.690125]\n",
      "[Epoch 9/200] [Batch 19/169] [D loss: 0.701891] [G loss: 0.690481]\n",
      "[Epoch 9/200] [Batch 20/169] [D loss: 0.698575] [G loss: 0.694237]\n",
      "[Epoch 9/200] [Batch 21/169] [D loss: 0.695485] [G loss: 0.695051]\n",
      "[Epoch 9/200] [Batch 22/169] [D loss: 0.694571] [G loss: 0.697839]\n",
      "[Epoch 9/200] [Batch 23/169] [D loss: 0.692826] [G loss: 0.698290]\n",
      "[Epoch 9/200] [Batch 24/169] [D loss: 0.695669] [G loss: 0.696063]\n",
      "[Epoch 9/200] [Batch 25/169] [D loss: 0.690202] [G loss: 0.700104]\n",
      "[Epoch 9/200] [Batch 26/169] [D loss: 0.690473] [G loss: 0.699544]\n",
      "[Epoch 9/200] [Batch 27/169] [D loss: 0.690463] [G loss: 0.699433]\n",
      "[Epoch 9/200] [Batch 28/169] [D loss: 0.689540] [G loss: 0.700351]\n",
      "[Epoch 9/200] [Batch 29/169] [D loss: 0.687355] [G loss: 0.702613]\n",
      "[Epoch 9/200] [Batch 30/169] [D loss: 0.687398] [G loss: 0.702400]\n",
      "[Epoch 9/200] [Batch 31/169] [D loss: 0.687625] [G loss: 0.703352]\n",
      "[Epoch 9/200] [Batch 32/169] [D loss: 0.685969] [G loss: 0.700927]\n",
      "[Epoch 9/200] [Batch 33/169] [D loss: 0.686132] [G loss: 0.696433]\n",
      "[Epoch 9/200] [Batch 34/169] [D loss: 0.684376] [G loss: 0.697537]\n",
      "[Epoch 9/200] [Batch 35/169] [D loss: 0.687736] [G loss: 0.694373]\n",
      "[Epoch 9/200] [Batch 36/169] [D loss: 0.685444] [G loss: 0.688299]\n",
      "[Epoch 9/200] [Batch 37/169] [D loss: 0.685899] [G loss: 0.691330]\n",
      "[Epoch 9/200] [Batch 38/169] [D loss: 0.691704] [G loss: 0.681606]\n",
      "[Epoch 9/200] [Batch 39/169] [D loss: 0.686152] [G loss: 0.681646]\n",
      "[Epoch 9/200] [Batch 40/169] [D loss: 0.690122] [G loss: 0.680551]\n",
      "[Epoch 9/200] [Batch 41/169] [D loss: 0.694025] [G loss: 0.675334]\n",
      "[Epoch 9/200] [Batch 42/169] [D loss: 0.695238] [G loss: 0.678756]\n",
      "[Epoch 9/200] [Batch 43/169] [D loss: 0.696334] [G loss: 0.674847]\n",
      "[Epoch 9/200] [Batch 44/169] [D loss: 0.701431] [G loss: 0.671455]\n",
      "[Epoch 9/200] [Batch 45/169] [D loss: 0.699256] [G loss: 0.668148]\n",
      "[Epoch 9/200] [Batch 46/169] [D loss: 0.702709] [G loss: 0.667147]\n",
      "[Epoch 9/200] [Batch 47/169] [D loss: 0.701484] [G loss: 0.666966]\n",
      "[Epoch 9/200] [Batch 48/169] [D loss: 0.702173] [G loss: 0.675276]\n",
      "[Epoch 9/200] [Batch 49/169] [D loss: 0.700793] [G loss: 0.672562]\n",
      "[Epoch 9/200] [Batch 50/169] [D loss: 0.706078] [G loss: 0.673065]\n",
      "[Epoch 9/200] [Batch 51/169] [D loss: 0.704364] [G loss: 0.675893]\n",
      "[Epoch 9/200] [Batch 52/169] [D loss: 0.706511] [G loss: 0.673272]\n",
      "[Epoch 9/200] [Batch 53/169] [D loss: 0.701294] [G loss: 0.676643]\n",
      "[Epoch 9/200] [Batch 54/169] [D loss: 0.701251] [G loss: 0.677689]\n",
      "[Epoch 9/200] [Batch 55/169] [D loss: 0.702081] [G loss: 0.682663]\n",
      "[Epoch 9/200] [Batch 56/169] [D loss: 0.700411] [G loss: 0.686021]\n",
      "[Epoch 9/200] [Batch 57/169] [D loss: 0.696585] [G loss: 0.689331]\n",
      "[Epoch 9/200] [Batch 58/169] [D loss: 0.694740] [G loss: 0.695046]\n",
      "[Epoch 9/200] [Batch 59/169] [D loss: 0.692276] [G loss: 0.701393]\n",
      "[Epoch 9/200] [Batch 60/169] [D loss: 0.688795] [G loss: 0.703840]\n",
      "[Epoch 9/200] [Batch 61/169] [D loss: 0.687182] [G loss: 0.705943]\n",
      "[Epoch 9/200] [Batch 62/169] [D loss: 0.685376] [G loss: 0.705519]\n",
      "[Epoch 9/200] [Batch 63/169] [D loss: 0.680034] [G loss: 0.709387]\n",
      "[Epoch 9/200] [Batch 64/169] [D loss: 0.679962] [G loss: 0.714384]\n",
      "[Epoch 9/200] [Batch 65/169] [D loss: 0.677865] [G loss: 0.716775]\n",
      "[Epoch 9/200] [Batch 66/169] [D loss: 0.674691] [G loss: 0.715819]\n",
      "[Epoch 9/200] [Batch 67/169] [D loss: 0.672037] [G loss: 0.720732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 68/169] [D loss: 0.671880] [G loss: 0.717391]\n",
      "[Epoch 9/200] [Batch 69/169] [D loss: 0.672372] [G loss: 0.713630]\n",
      "[Epoch 9/200] [Batch 70/169] [D loss: 0.671684] [G loss: 0.711397]\n",
      "[Epoch 9/200] [Batch 71/169] [D loss: 0.668974] [G loss: 0.699676]\n",
      "[Epoch 9/200] [Batch 72/169] [D loss: 0.673942] [G loss: 0.691649]\n",
      "[Epoch 9/200] [Batch 73/169] [D loss: 0.678171] [G loss: 0.678433]\n",
      "[Epoch 9/200] [Batch 74/169] [D loss: 0.686452] [G loss: 0.665616]\n",
      "[Epoch 9/200] [Batch 75/169] [D loss: 0.692785] [G loss: 0.648623]\n",
      "[Epoch 9/200] [Batch 76/169] [D loss: 0.695658] [G loss: 0.647269]\n",
      "[Epoch 9/200] [Batch 77/169] [D loss: 0.703638] [G loss: 0.634936]\n",
      "[Epoch 9/200] [Batch 78/169] [D loss: 0.702582] [G loss: 0.632757]\n",
      "[Epoch 9/200] [Batch 79/169] [D loss: 0.702874] [G loss: 0.637399]\n",
      "[Epoch 9/200] [Batch 80/169] [D loss: 0.705278] [G loss: 0.636418]\n",
      "[Epoch 9/200] [Batch 81/169] [D loss: 0.704715] [G loss: 0.647073]\n",
      "[Epoch 9/200] [Batch 82/169] [D loss: 0.703165] [G loss: 0.650563]\n",
      "[Epoch 9/200] [Batch 83/169] [D loss: 0.702011] [G loss: 0.664357]\n",
      "[Epoch 9/200] [Batch 84/169] [D loss: 0.703095] [G loss: 0.670416]\n",
      "[Epoch 9/200] [Batch 85/169] [D loss: 0.701710] [G loss: 0.667892]\n",
      "[Epoch 9/200] [Batch 86/169] [D loss: 0.698299] [G loss: 0.676109]\n",
      "[Epoch 9/200] [Batch 87/169] [D loss: 0.698762] [G loss: 0.673621]\n",
      "[Epoch 9/200] [Batch 88/169] [D loss: 0.698671] [G loss: 0.681251]\n",
      "[Epoch 9/200] [Batch 89/169] [D loss: 0.698514] [G loss: 0.684780]\n",
      "[Epoch 9/200] [Batch 90/169] [D loss: 0.697472] [G loss: 0.685899]\n",
      "[Epoch 9/200] [Batch 91/169] [D loss: 0.696081] [G loss: 0.688971]\n",
      "[Epoch 9/200] [Batch 92/169] [D loss: 0.692004] [G loss: 0.695741]\n",
      "[Epoch 9/200] [Batch 93/169] [D loss: 0.694379] [G loss: 0.692265]\n",
      "[Epoch 9/200] [Batch 94/169] [D loss: 0.693989] [G loss: 0.696400]\n",
      "[Epoch 9/200] [Batch 95/169] [D loss: 0.693833] [G loss: 0.692454]\n",
      "[Epoch 9/200] [Batch 96/169] [D loss: 0.691212] [G loss: 0.697277]\n",
      "[Epoch 9/200] [Batch 97/169] [D loss: 0.695223] [G loss: 0.694187]\n",
      "[Epoch 9/200] [Batch 98/169] [D loss: 0.694056] [G loss: 0.697106]\n",
      "[Epoch 9/200] [Batch 99/169] [D loss: 0.692432] [G loss: 0.699349]\n",
      "[Epoch 9/200] [Batch 100/169] [D loss: 0.694522] [G loss: 0.699259]\n",
      "[Epoch 9/200] [Batch 101/169] [D loss: 0.692621] [G loss: 0.700289]\n",
      "[Epoch 9/200] [Batch 102/169] [D loss: 0.693139] [G loss: 0.704660]\n",
      "[Epoch 9/200] [Batch 103/169] [D loss: 0.693440] [G loss: 0.705056]\n",
      "[Epoch 9/200] [Batch 104/169] [D loss: 0.691364] [G loss: 0.705671]\n",
      "[Epoch 9/200] [Batch 105/169] [D loss: 0.693009] [G loss: 0.702371]\n",
      "[Epoch 9/200] [Batch 106/169] [D loss: 0.692494] [G loss: 0.704647]\n",
      "[Epoch 9/200] [Batch 107/169] [D loss: 0.695035] [G loss: 0.709255]\n",
      "[Epoch 9/200] [Batch 108/169] [D loss: 0.696834] [G loss: 0.707799]\n",
      "[Epoch 9/200] [Batch 109/169] [D loss: 0.700388] [G loss: 0.704424]\n",
      "[Epoch 9/200] [Batch 110/169] [D loss: 0.697723] [G loss: 0.707306]\n",
      "[Epoch 9/200] [Batch 111/169] [D loss: 0.698440] [G loss: 0.709269]\n",
      "[Epoch 9/200] [Batch 112/169] [D loss: 0.702005] [G loss: 0.708115]\n",
      "[Epoch 9/200] [Batch 113/169] [D loss: 0.700549] [G loss: 0.702898]\n",
      "[Epoch 9/200] [Batch 114/169] [D loss: 0.703383] [G loss: 0.709807]\n",
      "[Epoch 9/200] [Batch 115/169] [D loss: 0.703048] [G loss: 0.705569]\n",
      "[Epoch 9/200] [Batch 116/169] [D loss: 0.700450] [G loss: 0.706538]\n",
      "[Epoch 9/200] [Batch 117/169] [D loss: 0.704123] [G loss: 0.708387]\n",
      "[Epoch 9/200] [Batch 118/169] [D loss: 0.699247] [G loss: 0.708201]\n",
      "[Epoch 9/200] [Batch 119/169] [D loss: 0.701278] [G loss: 0.706862]\n",
      "[Epoch 9/200] [Batch 120/169] [D loss: 0.700771] [G loss: 0.705899]\n",
      "[Epoch 9/200] [Batch 121/169] [D loss: 0.699864] [G loss: 0.704856]\n",
      "[Epoch 9/200] [Batch 122/169] [D loss: 0.698693] [G loss: 0.706252]\n",
      "[Epoch 9/200] [Batch 123/169] [D loss: 0.699319] [G loss: 0.706334]\n",
      "[Epoch 9/200] [Batch 124/169] [D loss: 0.695789] [G loss: 0.708376]\n",
      "[Epoch 9/200] [Batch 125/169] [D loss: 0.694212] [G loss: 0.710369]\n",
      "[Epoch 9/200] [Batch 126/169] [D loss: 0.692882] [G loss: 0.710236]\n",
      "[Epoch 9/200] [Batch 127/169] [D loss: 0.691855] [G loss: 0.714900]\n",
      "[Epoch 9/200] [Batch 128/169] [D loss: 0.691884] [G loss: 0.711565]\n",
      "[Epoch 9/200] [Batch 129/169] [D loss: 0.689277] [G loss: 0.713969]\n",
      "[Epoch 9/200] [Batch 130/169] [D loss: 0.686101] [G loss: 0.716706]\n",
      "[Epoch 9/200] [Batch 131/169] [D loss: 0.686428] [G loss: 0.720101]\n",
      "[Epoch 9/200] [Batch 132/169] [D loss: 0.683987] [G loss: 0.716968]\n",
      "[Epoch 9/200] [Batch 133/169] [D loss: 0.683474] [G loss: 0.719795]\n",
      "[Epoch 9/200] [Batch 134/169] [D loss: 0.681987] [G loss: 0.725387]\n",
      "[Epoch 9/200] [Batch 135/169] [D loss: 0.678511] [G loss: 0.719121]\n",
      "[Epoch 9/200] [Batch 136/169] [D loss: 0.680389] [G loss: 0.720992]\n",
      "[Epoch 9/200] [Batch 137/169] [D loss: 0.677361] [G loss: 0.718989]\n",
      "[Epoch 9/200] [Batch 138/169] [D loss: 0.676925] [G loss: 0.724120]\n",
      "[Epoch 9/200] [Batch 139/169] [D loss: 0.680722] [G loss: 0.717675]\n",
      "[Epoch 9/200] [Batch 140/169] [D loss: 0.678676] [G loss: 0.715050]\n",
      "[Epoch 9/200] [Batch 141/169] [D loss: 0.678643] [G loss: 0.709643]\n",
      "[Epoch 9/200] [Batch 142/169] [D loss: 0.678543] [G loss: 0.709848]\n",
      "[Epoch 9/200] [Batch 143/169] [D loss: 0.683468] [G loss: 0.701314]\n",
      "[Epoch 9/200] [Batch 144/169] [D loss: 0.680187] [G loss: 0.708563]\n",
      "[Epoch 9/200] [Batch 145/169] [D loss: 0.683396] [G loss: 0.705550]\n",
      "[Epoch 9/200] [Batch 146/169] [D loss: 0.688044] [G loss: 0.696209]\n",
      "[Epoch 9/200] [Batch 147/169] [D loss: 0.685611] [G loss: 0.697773]\n",
      "[Epoch 9/200] [Batch 148/169] [D loss: 0.691036] [G loss: 0.691153]\n",
      "[Epoch 9/200] [Batch 149/169] [D loss: 0.690879] [G loss: 0.691194]\n",
      "[Epoch 9/200] [Batch 150/169] [D loss: 0.691498] [G loss: 0.686183]\n",
      "[Epoch 9/200] [Batch 151/169] [D loss: 0.696927] [G loss: 0.688685]\n",
      "[Epoch 9/200] [Batch 152/169] [D loss: 0.699329] [G loss: 0.684756]\n",
      "[Epoch 9/200] [Batch 153/169] [D loss: 0.689681] [G loss: 0.681434]\n",
      "[Epoch 9/200] [Batch 154/169] [D loss: 0.692687] [G loss: 0.682773]\n",
      "[Epoch 9/200] [Batch 155/169] [D loss: 0.692723] [G loss: 0.676626]\n",
      "[Epoch 9/200] [Batch 156/169] [D loss: 0.699320] [G loss: 0.674140]\n",
      "[Epoch 9/200] [Batch 157/169] [D loss: 0.698572] [G loss: 0.673487]\n",
      "[Epoch 9/200] [Batch 158/169] [D loss: 0.695256] [G loss: 0.674121]\n",
      "[Epoch 9/200] [Batch 159/169] [D loss: 0.696384] [G loss: 0.668935]\n",
      "[Epoch 9/200] [Batch 160/169] [D loss: 0.698489] [G loss: 0.670399]\n",
      "[Epoch 9/200] [Batch 161/169] [D loss: 0.697559] [G loss: 0.664606]\n",
      "[Epoch 9/200] [Batch 162/169] [D loss: 0.695507] [G loss: 0.669095]\n",
      "[Epoch 9/200] [Batch 163/169] [D loss: 0.698700] [G loss: 0.668056]\n",
      "[Epoch 9/200] [Batch 164/169] [D loss: 0.698444] [G loss: 0.663663]\n",
      "[Epoch 9/200] [Batch 165/169] [D loss: 0.693702] [G loss: 0.668212]\n",
      "[Epoch 9/200] [Batch 166/169] [D loss: 0.698649] [G loss: 0.667469]\n",
      "[Epoch 9/200] [Batch 167/169] [D loss: 0.699245] [G loss: 0.670226]\n",
      "[Epoch 9/200] [Batch 168/169] [D loss: 0.702742] [G loss: 0.662822]\n",
      "[Epoch 10/200] [Batch 0/169] [D loss: 0.699716] [G loss: 0.665960]\n",
      "[Epoch 10/200] [Batch 1/169] [D loss: 0.698439] [G loss: 0.672626]\n",
      "[Epoch 10/200] [Batch 2/169] [D loss: 0.697154] [G loss: 0.676083]\n",
      "[Epoch 10/200] [Batch 3/169] [D loss: 0.698188] [G loss: 0.676208]\n",
      "[Epoch 10/200] [Batch 4/169] [D loss: 0.697962] [G loss: 0.675768]\n",
      "[Epoch 10/200] [Batch 5/169] [D loss: 0.693427] [G loss: 0.680972]\n",
      "[Epoch 10/200] [Batch 6/169] [D loss: 0.695462] [G loss: 0.680120]\n",
      "[Epoch 10/200] [Batch 7/169] [D loss: 0.694839] [G loss: 0.681798]\n",
      "[Epoch 10/200] [Batch 8/169] [D loss: 0.697407] [G loss: 0.683919]\n",
      "[Epoch 10/200] [Batch 9/169] [D loss: 0.695150] [G loss: 0.682569]\n",
      "[Epoch 10/200] [Batch 10/169] [D loss: 0.696284] [G loss: 0.682189]\n",
      "[Epoch 10/200] [Batch 11/169] [D loss: 0.693278] [G loss: 0.687940]\n",
      "[Epoch 10/200] [Batch 12/169] [D loss: 0.695223] [G loss: 0.687441]\n",
      "[Epoch 10/200] [Batch 13/169] [D loss: 0.694074] [G loss: 0.689222]\n",
      "[Epoch 10/200] [Batch 14/169] [D loss: 0.693815] [G loss: 0.689659]\n",
      "[Epoch 10/200] [Batch 15/169] [D loss: 0.695075] [G loss: 0.691699]\n",
      "[Epoch 10/200] [Batch 16/169] [D loss: 0.690711] [G loss: 0.697418]\n",
      "[Epoch 10/200] [Batch 17/169] [D loss: 0.692959] [G loss: 0.696006]\n",
      "[Epoch 10/200] [Batch 18/169] [D loss: 0.694777] [G loss: 0.701189]\n",
      "[Epoch 10/200] [Batch 19/169] [D loss: 0.692435] [G loss: 0.702991]\n",
      "[Epoch 10/200] [Batch 20/169] [D loss: 0.691177] [G loss: 0.705647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 21/169] [D loss: 0.691552] [G loss: 0.708413]\n",
      "[Epoch 10/200] [Batch 22/169] [D loss: 0.688506] [G loss: 0.709646]\n",
      "[Epoch 10/200] [Batch 23/169] [D loss: 0.689389] [G loss: 0.713624]\n",
      "[Epoch 10/200] [Batch 24/169] [D loss: 0.687597] [G loss: 0.718483]\n",
      "[Epoch 10/200] [Batch 25/169] [D loss: 0.687260] [G loss: 0.723704]\n",
      "[Epoch 10/200] [Batch 26/169] [D loss: 0.689996] [G loss: 0.723299]\n",
      "[Epoch 10/200] [Batch 27/169] [D loss: 0.691300] [G loss: 0.722025]\n",
      "[Epoch 10/200] [Batch 28/169] [D loss: 0.687824] [G loss: 0.723344]\n",
      "[Epoch 10/200] [Batch 29/169] [D loss: 0.689072] [G loss: 0.728494]\n",
      "[Epoch 10/200] [Batch 30/169] [D loss: 0.688937] [G loss: 0.730610]\n",
      "[Epoch 10/200] [Batch 31/169] [D loss: 0.691895] [G loss: 0.727545]\n",
      "[Epoch 10/200] [Batch 32/169] [D loss: 0.690848] [G loss: 0.728904]\n",
      "[Epoch 10/200] [Batch 33/169] [D loss: 0.695744] [G loss: 0.720307]\n",
      "[Epoch 10/200] [Batch 34/169] [D loss: 0.693370] [G loss: 0.727176]\n",
      "[Epoch 10/200] [Batch 35/169] [D loss: 0.697463] [G loss: 0.714684]\n",
      "[Epoch 10/200] [Batch 36/169] [D loss: 0.692957] [G loss: 0.717784]\n",
      "[Epoch 10/200] [Batch 37/169] [D loss: 0.694781] [G loss: 0.712754]\n",
      "[Epoch 10/200] [Batch 38/169] [D loss: 0.697072] [G loss: 0.711520]\n",
      "[Epoch 10/200] [Batch 39/169] [D loss: 0.695742] [G loss: 0.708046]\n",
      "[Epoch 10/200] [Batch 40/169] [D loss: 0.694485] [G loss: 0.709886]\n",
      "[Epoch 10/200] [Batch 41/169] [D loss: 0.696802] [G loss: 0.703891]\n",
      "[Epoch 10/200] [Batch 42/169] [D loss: 0.697174] [G loss: 0.705753]\n",
      "[Epoch 10/200] [Batch 43/169] [D loss: 0.695315] [G loss: 0.702503]\n",
      "[Epoch 10/200] [Batch 44/169] [D loss: 0.696215] [G loss: 0.702089]\n",
      "[Epoch 10/200] [Batch 45/169] [D loss: 0.695891] [G loss: 0.700603]\n",
      "[Epoch 10/200] [Batch 46/169] [D loss: 0.695567] [G loss: 0.699415]\n",
      "[Epoch 10/200] [Batch 47/169] [D loss: 0.694604] [G loss: 0.702515]\n",
      "[Epoch 10/200] [Batch 48/169] [D loss: 0.695075] [G loss: 0.699600]\n",
      "[Epoch 10/200] [Batch 49/169] [D loss: 0.688369] [G loss: 0.700994]\n",
      "[Epoch 10/200] [Batch 50/169] [D loss: 0.692086] [G loss: 0.701450]\n",
      "[Epoch 10/200] [Batch 51/169] [D loss: 0.688096] [G loss: 0.702697]\n",
      "[Epoch 10/200] [Batch 52/169] [D loss: 0.689043] [G loss: 0.700893]\n",
      "[Epoch 10/200] [Batch 53/169] [D loss: 0.687805] [G loss: 0.701098]\n",
      "[Epoch 10/200] [Batch 54/169] [D loss: 0.685845] [G loss: 0.700933]\n",
      "[Epoch 10/200] [Batch 55/169] [D loss: 0.686081] [G loss: 0.703377]\n",
      "[Epoch 10/200] [Batch 56/169] [D loss: 0.687555] [G loss: 0.696648]\n",
      "[Epoch 10/200] [Batch 57/169] [D loss: 0.687255] [G loss: 0.697765]\n",
      "[Epoch 10/200] [Batch 58/169] [D loss: 0.685910] [G loss: 0.697764]\n",
      "[Epoch 10/200] [Batch 59/169] [D loss: 0.686604] [G loss: 0.688391]\n",
      "[Epoch 10/200] [Batch 60/169] [D loss: 0.688407] [G loss: 0.688874]\n",
      "[Epoch 10/200] [Batch 61/169] [D loss: 0.693491] [G loss: 0.680764]\n",
      "[Epoch 10/200] [Batch 62/169] [D loss: 0.694356] [G loss: 0.682028]\n",
      "[Epoch 10/200] [Batch 63/169] [D loss: 0.694386] [G loss: 0.680234]\n",
      "[Epoch 10/200] [Batch 64/169] [D loss: 0.692362] [G loss: 0.674118]\n",
      "[Epoch 10/200] [Batch 65/169] [D loss: 0.695212] [G loss: 0.675548]\n",
      "[Epoch 10/200] [Batch 66/169] [D loss: 0.697529] [G loss: 0.672684]\n",
      "[Epoch 10/200] [Batch 67/169] [D loss: 0.698965] [G loss: 0.673856]\n",
      "[Epoch 10/200] [Batch 68/169] [D loss: 0.697223] [G loss: 0.672563]\n",
      "[Epoch 10/200] [Batch 69/169] [D loss: 0.700441] [G loss: 0.678459]\n",
      "[Epoch 10/200] [Batch 70/169] [D loss: 0.698694] [G loss: 0.679787]\n",
      "[Epoch 10/200] [Batch 71/169] [D loss: 0.692964] [G loss: 0.683973]\n",
      "[Epoch 10/200] [Batch 72/169] [D loss: 0.693262] [G loss: 0.686424]\n",
      "[Epoch 10/200] [Batch 73/169] [D loss: 0.696425] [G loss: 0.689670]\n",
      "[Epoch 10/200] [Batch 74/169] [D loss: 0.691379] [G loss: 0.693733]\n",
      "[Epoch 10/200] [Batch 75/169] [D loss: 0.691322] [G loss: 0.693932]\n",
      "[Epoch 10/200] [Batch 76/169] [D loss: 0.691608] [G loss: 0.696191]\n",
      "[Epoch 10/200] [Batch 77/169] [D loss: 0.691409] [G loss: 0.699880]\n",
      "[Epoch 10/200] [Batch 78/169] [D loss: 0.689217] [G loss: 0.701807]\n",
      "[Epoch 10/200] [Batch 79/169] [D loss: 0.689027] [G loss: 0.707152]\n",
      "[Epoch 10/200] [Batch 80/169] [D loss: 0.687807] [G loss: 0.708598]\n",
      "[Epoch 10/200] [Batch 81/169] [D loss: 0.684955] [G loss: 0.711679]\n",
      "[Epoch 10/200] [Batch 82/169] [D loss: 0.684114] [G loss: 0.713044]\n",
      "[Epoch 10/200] [Batch 83/169] [D loss: 0.684886] [G loss: 0.712276]\n",
      "[Epoch 10/200] [Batch 84/169] [D loss: 0.681073] [G loss: 0.711999]\n",
      "[Epoch 10/200] [Batch 85/169] [D loss: 0.682768] [G loss: 0.720711]\n",
      "[Epoch 10/200] [Batch 86/169] [D loss: 0.680740] [G loss: 0.716690]\n",
      "[Epoch 10/200] [Batch 87/169] [D loss: 0.677462] [G loss: 0.720621]\n",
      "[Epoch 10/200] [Batch 88/169] [D loss: 0.675072] [G loss: 0.719262]\n",
      "[Epoch 10/200] [Batch 89/169] [D loss: 0.678028] [G loss: 0.723214]\n",
      "[Epoch 10/200] [Batch 90/169] [D loss: 0.685239] [G loss: 0.713668]\n",
      "[Epoch 10/200] [Batch 91/169] [D loss: 0.682612] [G loss: 0.702594]\n",
      "[Epoch 10/200] [Batch 92/169] [D loss: 0.680853] [G loss: 0.706786]\n",
      "[Epoch 10/200] [Batch 93/169] [D loss: 0.685438] [G loss: 0.690957]\n",
      "[Epoch 10/200] [Batch 94/169] [D loss: 0.689276] [G loss: 0.688847]\n",
      "[Epoch 10/200] [Batch 95/169] [D loss: 0.694648] [G loss: 0.679524]\n",
      "[Epoch 10/200] [Batch 96/169] [D loss: 0.698689] [G loss: 0.669328]\n",
      "[Epoch 10/200] [Batch 97/169] [D loss: 0.702404] [G loss: 0.662576]\n",
      "[Epoch 10/200] [Batch 98/169] [D loss: 0.699942] [G loss: 0.656705]\n",
      "[Epoch 10/200] [Batch 99/169] [D loss: 0.709036] [G loss: 0.652319]\n",
      "[Epoch 10/200] [Batch 100/169] [D loss: 0.704510] [G loss: 0.651395]\n",
      "[Epoch 10/200] [Batch 101/169] [D loss: 0.701006] [G loss: 0.651791]\n",
      "[Epoch 10/200] [Batch 102/169] [D loss: 0.705901] [G loss: 0.656506]\n",
      "[Epoch 10/200] [Batch 103/169] [D loss: 0.706882] [G loss: 0.652977]\n",
      "[Epoch 10/200] [Batch 104/169] [D loss: 0.705913] [G loss: 0.658493]\n",
      "[Epoch 10/200] [Batch 105/169] [D loss: 0.703295] [G loss: 0.661364]\n",
      "[Epoch 10/200] [Batch 106/169] [D loss: 0.700433] [G loss: 0.668194]\n",
      "[Epoch 10/200] [Batch 107/169] [D loss: 0.700062] [G loss: 0.671785]\n",
      "[Epoch 10/200] [Batch 108/169] [D loss: 0.699181] [G loss: 0.672768]\n",
      "[Epoch 10/200] [Batch 109/169] [D loss: 0.697445] [G loss: 0.671781]\n",
      "[Epoch 10/200] [Batch 110/169] [D loss: 0.697958] [G loss: 0.674097]\n",
      "[Epoch 10/200] [Batch 111/169] [D loss: 0.692881] [G loss: 0.676440]\n",
      "[Epoch 10/200] [Batch 112/169] [D loss: 0.696027] [G loss: 0.676504]\n",
      "[Epoch 10/200] [Batch 113/169] [D loss: 0.693710] [G loss: 0.679925]\n",
      "[Epoch 10/200] [Batch 114/169] [D loss: 0.691127] [G loss: 0.678977]\n",
      "[Epoch 10/200] [Batch 115/169] [D loss: 0.693298] [G loss: 0.680265]\n",
      "[Epoch 10/200] [Batch 116/169] [D loss: 0.690542] [G loss: 0.682813]\n",
      "[Epoch 10/200] [Batch 117/169] [D loss: 0.692096] [G loss: 0.683394]\n",
      "[Epoch 10/200] [Batch 118/169] [D loss: 0.691002] [G loss: 0.682757]\n",
      "[Epoch 10/200] [Batch 119/169] [D loss: 0.690757] [G loss: 0.683583]\n",
      "[Epoch 10/200] [Batch 120/169] [D loss: 0.691610] [G loss: 0.684551]\n",
      "[Epoch 10/200] [Batch 121/169] [D loss: 0.690132] [G loss: 0.686237]\n",
      "[Epoch 10/200] [Batch 122/169] [D loss: 0.688819] [G loss: 0.688505]\n",
      "[Epoch 10/200] [Batch 123/169] [D loss: 0.686804] [G loss: 0.690239]\n",
      "[Epoch 10/200] [Batch 124/169] [D loss: 0.689085] [G loss: 0.688947]\n",
      "[Epoch 10/200] [Batch 125/169] [D loss: 0.687362] [G loss: 0.688022]\n",
      "[Epoch 10/200] [Batch 126/169] [D loss: 0.687703] [G loss: 0.685080]\n",
      "[Epoch 10/200] [Batch 127/169] [D loss: 0.688642] [G loss: 0.688369]\n",
      "[Epoch 10/200] [Batch 128/169] [D loss: 0.689045] [G loss: 0.688813]\n",
      "[Epoch 10/200] [Batch 129/169] [D loss: 0.693813] [G loss: 0.687569]\n",
      "[Epoch 10/200] [Batch 130/169] [D loss: 0.694489] [G loss: 0.688350]\n",
      "[Epoch 10/200] [Batch 131/169] [D loss: 0.697794] [G loss: 0.687131]\n",
      "[Epoch 10/200] [Batch 132/169] [D loss: 0.694854] [G loss: 0.685727]\n",
      "[Epoch 10/200] [Batch 133/169] [D loss: 0.694267] [G loss: 0.691238]\n",
      "[Epoch 10/200] [Batch 134/169] [D loss: 0.695635] [G loss: 0.693659]\n",
      "[Epoch 10/200] [Batch 135/169] [D loss: 0.695227] [G loss: 0.697262]\n",
      "[Epoch 10/200] [Batch 136/169] [D loss: 0.697782] [G loss: 0.695449]\n",
      "[Epoch 10/200] [Batch 137/169] [D loss: 0.697611] [G loss: 0.698681]\n",
      "[Epoch 10/200] [Batch 138/169] [D loss: 0.695537] [G loss: 0.701026]\n",
      "[Epoch 10/200] [Batch 139/169] [D loss: 0.698512] [G loss: 0.697092]\n",
      "[Epoch 10/200] [Batch 140/169] [D loss: 0.699006] [G loss: 0.702294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 141/169] [D loss: 0.696632] [G loss: 0.706354]\n",
      "[Epoch 10/200] [Batch 142/169] [D loss: 0.695098] [G loss: 0.707564]\n",
      "[Epoch 10/200] [Batch 143/169] [D loss: 0.695863] [G loss: 0.712679]\n",
      "[Epoch 10/200] [Batch 144/169] [D loss: 0.694070] [G loss: 0.711485]\n",
      "[Epoch 10/200] [Batch 145/169] [D loss: 0.692879] [G loss: 0.718514]\n",
      "[Epoch 10/200] [Batch 146/169] [D loss: 0.693644] [G loss: 0.720930]\n",
      "[Epoch 10/200] [Batch 147/169] [D loss: 0.694997] [G loss: 0.723881]\n",
      "[Epoch 10/200] [Batch 148/169] [D loss: 0.690906] [G loss: 0.726140]\n",
      "[Epoch 10/200] [Batch 149/169] [D loss: 0.690235] [G loss: 0.732066]\n",
      "[Epoch 10/200] [Batch 150/169] [D loss: 0.689865] [G loss: 0.732746]\n",
      "[Epoch 10/200] [Batch 151/169] [D loss: 0.689375] [G loss: 0.737091]\n",
      "[Epoch 10/200] [Batch 152/169] [D loss: 0.688219] [G loss: 0.735335]\n",
      "[Epoch 10/200] [Batch 153/169] [D loss: 0.687842] [G loss: 0.737996]\n",
      "[Epoch 10/200] [Batch 154/169] [D loss: 0.689844] [G loss: 0.737403]\n",
      "[Epoch 10/200] [Batch 155/169] [D loss: 0.688362] [G loss: 0.736328]\n",
      "[Epoch 10/200] [Batch 156/169] [D loss: 0.689245] [G loss: 0.738606]\n",
      "[Epoch 10/200] [Batch 157/169] [D loss: 0.685424] [G loss: 0.739353]\n",
      "[Epoch 10/200] [Batch 158/169] [D loss: 0.688839] [G loss: 0.738633]\n",
      "[Epoch 10/200] [Batch 159/169] [D loss: 0.686574] [G loss: 0.735897]\n",
      "[Epoch 10/200] [Batch 160/169] [D loss: 0.692251] [G loss: 0.730853]\n",
      "[Epoch 10/200] [Batch 161/169] [D loss: 0.695968] [G loss: 0.722940]\n",
      "[Epoch 10/200] [Batch 162/169] [D loss: 0.693635] [G loss: 0.721817]\n",
      "[Epoch 10/200] [Batch 163/169] [D loss: 0.693833] [G loss: 0.714191]\n",
      "[Epoch 10/200] [Batch 164/169] [D loss: 0.694284] [G loss: 0.715234]\n",
      "[Epoch 10/200] [Batch 165/169] [D loss: 0.696994] [G loss: 0.710794]\n",
      "[Epoch 10/200] [Batch 166/169] [D loss: 0.694712] [G loss: 0.704890]\n",
      "[Epoch 10/200] [Batch 167/169] [D loss: 0.696291] [G loss: 0.704312]\n",
      "[Epoch 10/200] [Batch 168/169] [D loss: 0.692993] [G loss: 0.701871]\n",
      "[Epoch 11/200] [Batch 0/169] [D loss: 0.696671] [G loss: 0.696505]\n",
      "[Epoch 11/200] [Batch 1/169] [D loss: 0.694625] [G loss: 0.695363]\n",
      "[Epoch 11/200] [Batch 2/169] [D loss: 0.695024] [G loss: 0.689139]\n",
      "[Epoch 11/200] [Batch 3/169] [D loss: 0.694330] [G loss: 0.691017]\n",
      "[Epoch 11/200] [Batch 4/169] [D loss: 0.690894] [G loss: 0.691111]\n",
      "[Epoch 11/200] [Batch 5/169] [D loss: 0.690892] [G loss: 0.686819]\n",
      "[Epoch 11/200] [Batch 6/169] [D loss: 0.689571] [G loss: 0.686984]\n",
      "[Epoch 11/200] [Batch 7/169] [D loss: 0.686982] [G loss: 0.686514]\n",
      "[Epoch 11/200] [Batch 8/169] [D loss: 0.686793] [G loss: 0.687952]\n",
      "[Epoch 11/200] [Batch 9/169] [D loss: 0.687340] [G loss: 0.682949]\n",
      "[Epoch 11/200] [Batch 10/169] [D loss: 0.682729] [G loss: 0.684512]\n",
      "[Epoch 11/200] [Batch 11/169] [D loss: 0.682146] [G loss: 0.685354]\n",
      "[Epoch 11/200] [Batch 12/169] [D loss: 0.681252] [G loss: 0.683205]\n",
      "[Epoch 11/200] [Batch 13/169] [D loss: 0.680028] [G loss: 0.680003]\n",
      "[Epoch 11/200] [Batch 14/169] [D loss: 0.680013] [G loss: 0.675569]\n",
      "[Epoch 11/200] [Batch 15/169] [D loss: 0.683126] [G loss: 0.671752]\n",
      "[Epoch 11/200] [Batch 16/169] [D loss: 0.677751] [G loss: 0.668376]\n",
      "[Epoch 11/200] [Batch 17/169] [D loss: 0.680170] [G loss: 0.664389]\n",
      "[Epoch 11/200] [Batch 18/169] [D loss: 0.684462] [G loss: 0.653936]\n",
      "[Epoch 11/200] [Batch 19/169] [D loss: 0.690361] [G loss: 0.647352]\n",
      "[Epoch 11/200] [Batch 20/169] [D loss: 0.696002] [G loss: 0.640785]\n",
      "[Epoch 11/200] [Batch 21/169] [D loss: 0.699054] [G loss: 0.646203]\n",
      "[Epoch 11/200] [Batch 22/169] [D loss: 0.699787] [G loss: 0.639801]\n",
      "[Epoch 11/200] [Batch 23/169] [D loss: 0.697397] [G loss: 0.649584]\n",
      "[Epoch 11/200] [Batch 24/169] [D loss: 0.702141] [G loss: 0.643759]\n",
      "[Epoch 11/200] [Batch 25/169] [D loss: 0.703398] [G loss: 0.651091]\n",
      "[Epoch 11/200] [Batch 26/169] [D loss: 0.700038] [G loss: 0.657046]\n",
      "[Epoch 11/200] [Batch 27/169] [D loss: 0.701124] [G loss: 0.660631]\n",
      "[Epoch 11/200] [Batch 28/169] [D loss: 0.700031] [G loss: 0.670009]\n",
      "[Epoch 11/200] [Batch 29/169] [D loss: 0.701070] [G loss: 0.672207]\n",
      "[Epoch 11/200] [Batch 30/169] [D loss: 0.698110] [G loss: 0.683489]\n",
      "[Epoch 11/200] [Batch 31/169] [D loss: 0.700023] [G loss: 0.682749]\n",
      "[Epoch 11/200] [Batch 32/169] [D loss: 0.698697] [G loss: 0.694933]\n",
      "[Epoch 11/200] [Batch 33/169] [D loss: 0.698142] [G loss: 0.695542]\n",
      "[Epoch 11/200] [Batch 34/169] [D loss: 0.696404] [G loss: 0.700927]\n",
      "[Epoch 11/200] [Batch 35/169] [D loss: 0.699049] [G loss: 0.707134]\n",
      "[Epoch 11/200] [Batch 36/169] [D loss: 0.696557] [G loss: 0.709410]\n",
      "[Epoch 11/200] [Batch 37/169] [D loss: 0.695412] [G loss: 0.716300]\n",
      "[Epoch 11/200] [Batch 38/169] [D loss: 0.693656] [G loss: 0.713439]\n",
      "[Epoch 11/200] [Batch 39/169] [D loss: 0.693624] [G loss: 0.715763]\n",
      "[Epoch 11/200] [Batch 40/169] [D loss: 0.691765] [G loss: 0.716924]\n",
      "[Epoch 11/200] [Batch 41/169] [D loss: 0.693247] [G loss: 0.723603]\n",
      "[Epoch 11/200] [Batch 42/169] [D loss: 0.693735] [G loss: 0.725139]\n",
      "[Epoch 11/200] [Batch 43/169] [D loss: 0.693133] [G loss: 0.725963]\n",
      "[Epoch 11/200] [Batch 44/169] [D loss: 0.688063] [G loss: 0.729707]\n",
      "[Epoch 11/200] [Batch 45/169] [D loss: 0.693210] [G loss: 0.723940]\n",
      "[Epoch 11/200] [Batch 46/169] [D loss: 0.689454] [G loss: 0.724307]\n",
      "[Epoch 11/200] [Batch 47/169] [D loss: 0.688934] [G loss: 0.724439]\n",
      "[Epoch 11/200] [Batch 48/169] [D loss: 0.691381] [G loss: 0.724910]\n",
      "[Epoch 11/200] [Batch 49/169] [D loss: 0.691202] [G loss: 0.723496]\n",
      "[Epoch 11/200] [Batch 50/169] [D loss: 0.689711] [G loss: 0.722443]\n",
      "[Epoch 11/200] [Batch 51/169] [D loss: 0.693664] [G loss: 0.714204]\n",
      "[Epoch 11/200] [Batch 52/169] [D loss: 0.694857] [G loss: 0.712092]\n",
      "[Epoch 11/200] [Batch 53/169] [D loss: 0.693361] [G loss: 0.710253]\n",
      "[Epoch 11/200] [Batch 54/169] [D loss: 0.689211] [G loss: 0.706616]\n",
      "[Epoch 11/200] [Batch 55/169] [D loss: 0.691882] [G loss: 0.702578]\n",
      "[Epoch 11/200] [Batch 56/169] [D loss: 0.692088] [G loss: 0.701824]\n",
      "[Epoch 11/200] [Batch 57/169] [D loss: 0.693924] [G loss: 0.695490]\n",
      "[Epoch 11/200] [Batch 58/169] [D loss: 0.692027] [G loss: 0.694387]\n",
      "[Epoch 11/200] [Batch 59/169] [D loss: 0.692820] [G loss: 0.689302]\n",
      "[Epoch 11/200] [Batch 60/169] [D loss: 0.688862] [G loss: 0.692552]\n",
      "[Epoch 11/200] [Batch 61/169] [D loss: 0.687870] [G loss: 0.690707]\n",
      "[Epoch 11/200] [Batch 62/169] [D loss: 0.691637] [G loss: 0.685963]\n",
      "[Epoch 11/200] [Batch 63/169] [D loss: 0.690202] [G loss: 0.691651]\n",
      "[Epoch 11/200] [Batch 64/169] [D loss: 0.688955] [G loss: 0.691042]\n",
      "[Epoch 11/200] [Batch 65/169] [D loss: 0.688524] [G loss: 0.685645]\n",
      "[Epoch 11/200] [Batch 66/169] [D loss: 0.687425] [G loss: 0.690521]\n",
      "[Epoch 11/200] [Batch 67/169] [D loss: 0.690186] [G loss: 0.682743]\n",
      "[Epoch 11/200] [Batch 68/169] [D loss: 0.683673] [G loss: 0.682469]\n",
      "[Epoch 11/200] [Batch 69/169] [D loss: 0.687204] [G loss: 0.680204]\n",
      "[Epoch 11/200] [Batch 70/169] [D loss: 0.691639] [G loss: 0.678131]\n",
      "[Epoch 11/200] [Batch 71/169] [D loss: 0.687782] [G loss: 0.676728]\n",
      "[Epoch 11/200] [Batch 72/169] [D loss: 0.687539] [G loss: 0.680513]\n",
      "[Epoch 11/200] [Batch 73/169] [D loss: 0.691884] [G loss: 0.678780]\n",
      "[Epoch 11/200] [Batch 74/169] [D loss: 0.690011] [G loss: 0.682161]\n",
      "[Epoch 11/200] [Batch 75/169] [D loss: 0.685290] [G loss: 0.688064]\n",
      "[Epoch 11/200] [Batch 76/169] [D loss: 0.694175] [G loss: 0.682632]\n",
      "[Epoch 11/200] [Batch 77/169] [D loss: 0.694073] [G loss: 0.684322]\n",
      "[Epoch 11/200] [Batch 78/169] [D loss: 0.693774] [G loss: 0.688908]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-74663eb79cc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0msavepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'image_cov_GG'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-acd13e2ff54d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# 创建ground truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### 加载状态字典\n",
    "load2 = torch.load('net_state_dict.pth')\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "\n",
    "\n",
    "generator.load_state_dict(load2['generator'])\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "optimizer_G.load_state_dict(load2['optimizer_G'])\n",
    "optimizer_D.load_state_dict(load2['optimizer_D'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "savepath = 'image_cov_GG'\n",
    "\n",
    "train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
